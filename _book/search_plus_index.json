{"./":{"url":"./","title":"Introduction","keywords":"","body":"LayaAir engine introduction1. Background and development history of the engine1.1 Layabox’s past life1.2 Layabox’s life2. LayaAir engine services and ecologyLayaAir engine introduction Author: Charley Welcome to LayaAir engine documentation~ 1. Background and development history of the engine 1.1 Layabox’s past life Xie Chenghong, the founder of Layabox, founded the 3D client game R&D company \"China Entertainment Online\" after selling \"Kele8.com\", one of the three major domestic leisure and entertainment platforms, to Tsinghua Tongfang for tens of millions in 2003. When Layabox was founded, the backbone of the engine technology came from the core members of the 3D client game engine who had followed Xie Chenghong for many years, the longest of which was more than 10 years. As early as the end of 2011, Xie Chenghong, the founder of Layabox, established the LAYA laboratory and began to research a universal engine that can release APP and HTML5 at the same time. In 2012, it launched the industry's first large-scale casual battle HTML5 game \"Crazy Snowball\" with real-time interactive multiplayer battles between multiple people on the same screen. In 2013, it launched the industry's first large-scale card strategy HTML5 game \"Shanghai\" that was released simultaneously with HTML5 and APP. \"My Lord\" (formerly known as \"Miao Miao Three Kingdoms\"). and achieved good business results. In 2014, the beta version of the first heavy-action HTML5 game \"Hunting Blade 2\" was completed, proving that HTML5 game technology and quality expression have reached the level of high-quality APPs. Whether it is the accumulation of next-generation engines on the 3D side or the accumulation of large-scale cross-platform game engines in HTML5 and APP over the years. It laid a solid foundation for the establishment and explosion of Layabox. 1.2 Layabox’s life Layabox is an engine service provider and metaverse service provider brand created by Beijing Layabox Technology Co., Ltd. Layabox was founded in 2014. Its open source engine product LayaAir has more than one million global developers as of 2022 and is the leading 3D engine in the fields of HTML5 and mini games. As a technology-leading engine company, many well-known companies and listed companies have adopted LayaAir engine research and development projects, such as: Tencent, Alibaba, Meituan, NetEase, Sanqi Interactive Entertainment, Perfect World, Palm Qu, Dianhun Network, Blue Hong Kong, Coslight Games, Tom Cat, Cheetah Mobile, Seventh Avenue, The9th City, Elite Education, SenseTime Technology, etc. Since the launch of WeChat mini games in 2018, the era of casual mini games has arrived. Well-known traffic platforms at home and abroad have joined hands with Layabox to establish in-depth partnerships to promote the development of the mini game era. These cooperative platforms are: WeChat, Mobile QQ, Baidu , Xiaomi, OPPO, vivo, Alipay, bilibili, Taobao, Youku, Huawei. In 2021, Layabox fully acquired FairyGUI, a well-known game industry tool software, and made every effort to build LayaAir 3.0. On November 8, 2022, the Metaverse platform Layaverse was officially launched. On the same day, LayaAir 3.0 also started testing (for developers with targeted invitations). On June 30, 2023, the official version of LayaAir 3.0 was released. On November 16 of the same year, Laya Air 3.1 with AIGC capability was jointly launched with Zhangqu Technology. 2. LayaAir engine services and ecology The LayaAir engine is open source and free, with a developer ecosystem of over one million. Provided: free community services, LayaAir integrated development environment (IDE), rich learning materials (documents, API, DEMO, videos). Engine official website address: https://layaair.com/ Engine community address: https://discord.gg/Q2yYJUC6gk https://discord.com/channels/1211921905775411220/ Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-03-06 10:41:25 "},"basics/readme.html":{"url":"basics/readme.html","title":"Features","keywords":"","body":"LayaAir3.0 engine function overview1. Engine code1.1 General parts of the engine1.2 2D engine1.3 3D engine2. IDE (Integrated Development Environment)2.1 Common module2.1 2D module2.2 3D module3. Project release3.1 Web version released3.2 Mini game release3.3 Native packaging and releaseLayaAir3.0 engine function overview Author：Charley LayaAir3.0 engine includes three parts: engine code, project development tools, and project release. This article only gives a brief overview of most functions to give developers a preliminary understanding. 1. Engine code Engine code, in addition to the open programmable rendering pipeline, full-platform graphics engine architecture, next-generation PBR rendering flow, ClusterLighting multi-light technology, Forward+ rendering pipeline, high-performance parallel renderer API access (WebGPU) and other core foundations . For developers, we will introduce them from three parts: general, 2D, and 3D. 1.1 General parts of the engine Network (HTTP request, WebSocket request) Loading (can load text, JSON, XML, binary, audio, video, skeleton files, image files and other resources) ECS component system (component system, life cycle method) Scene management Events (dispatching, listening, capturing) Interaction (mouse, keyboard, screen touch, VR controller) Multimedia playback (audio, video) Easing Browser interface (encapsulates commonly used browser window functions and calls browser window functions) Device interface (gyroscope, accelerometer, geolocation) node Screen adaptation Mini-game adaptation (WeChat mini-games, Douyin mini-games, OPPO, vivo, Xiaomi, etc.) 1.2 2D engine 2D sprites (2D basic display objects and containers) 2D view (Scene2D, Dialog) 2D animation (atlas animation, frame-by-frame animation, easing animation, timeline animation, dragon bone, spine bone) 2D text (text, HTML text, BitmapFont) 2D UI components (Image, Button, Label, TextInput, TextArea, Combobox, CheckBox, Radio, RadioGroup, Tab, ViewStack, Clip, FontClip, VScrollBar, HcrollBar, Progressbar, VSlider, HSlider, ColorPicker, Box, List, Tree, Panel) 2D UI effects (mask, filter) 2D scene inheritance class (runtime class) 2D drawing (drawing rectangles and rounded rectangles, circles and sectors, polygons, line segments, polylines, curves, textures and filled textures) 2D physics (Box2D) Tiled Map 1.3 3D engine 3D sprites (3D basic display objects and containers) 3D basic tools (3D coordinate system, 3D transformation, 3D math tools, etc.) 3D scenes (scene management, ambient light, ambient reflection, scene sky, scene fog, etc.) 3D camera 3D lighting (directional light, point light, spot light, area light, shadow, light effect) 3D mesh 3D materials (model materials, particle materials, trailing materials, sky materials) 3D textures 3D particle system 3D trailing 3D physics (bullet, PhysX) 3D animation (rigid body animation, material animation, skeletal animation, camera animation, timeline animation) Custom Shader webXR 2. IDE (Integrated Development Environment) An overview of the IDE is also divided into general modules, 2D modules, and 3D modules for an overview. 2.1 Common module Hierarchy management panel Assets panel Scene window Game window Console panel Timeline Animation panel Animation controller panel Inspector panel Project settings panel IDE plug-in System IDE Assets store 2.1 2D module 2D layout widgets (basic display object nodes, UI components, skeletal animation nodes) 2D animation editing 2D UI editor 2D script management Scene inheritance class management 2D prefabs 2.2 3D module 3D scene editing 3D camera 3D lighting settings 3D animation editing 3D particle system 3D material editing 3D blueprint editing 3D prefabs 3D physics editor 3. Project release 3.1 Web version released Publishing the web version is the basic publishing method, which can be used to run on the browser or native packaged publishing. 3.2 Mini game release It provides adaptation libraries for each mini-game platform, as well as quick release functions for each mini-game platform. 3.3 Native packaging and release Supports publishing as installation packages for iOS and Android platforms. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-03-05 15:44:16 "},"basics/developmentEnvironment/readme.html":{"url":"basics/developmentEnvironment/readme.html","title":"Development Environment","keywords":"","body":"Familiar with the development environmentBuilding a Basic Development EnvironmentOverview of IDE Development Process InterfaceFamiliar with the development environment Prepare the relevant development environment and become familiar with the basic development workflow, which are the prerequisites for learning the engine~ Building a Basic Development Environment Overview of IDE Development Process Interface Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:13:27 "},"basics/developmentEnvironment/download/readme.html":{"url":"basics/developmentEnvironment/download/readme.html","title":"Install","keywords":"","body":"Set up a development environment1. Download and install LayaAir IDE2. Build TS development environment2.1 Download and install Node.js2.2 Install TSC3. Install browser4. Download and install VSCodeSet up a development environment Author: Charley Before getting familiar with the development environment, developers are asked to prepare the relevant tool environment~ 1. Download and install LayaAir IDE The engine is integrated into the IDE, just download the IDE directly. Download address: https://layaair.com/#/engineDownload 2. Build TS development environment LayaAir 3.0 only supports TypeScript language development, so the TypeScript installation environment still needs to be prepared. 2.1 Download and install Node.js 2.1.1 Check whether the node.js environment has been installed Developing using TypeScript requires the Node.js environment. If you have not installed it, please go to the official download (LTS version recommended). Before installation, if you are not sure whether there is a ready-made environment, you can first confirm whether the node environment has been installed, open the command line tool (cmd for windows), and enter the command npm -h npm -h After pressing the Enter key, if you can see the npm command description, version number, installation path and other information, as shown in Figure 1-1 (similar information is enough), it means that it has been installed. If it does not affect use, You can skip the steps of downloading and installing the node environment. (Picture 1-1) 2.1.2 Download and install Node.js official website If there is no installation environment, you can go directly to the node official website to download and install. The LTS version is recommended, as shown in Figure 1-2. The URL address is: https://nodejs.org/en/ (Figure 1-2) Figure 1-2 is for reference only. Just open the link to download the LTS version directly. Note: The default link opens window (x64). For non-64-bit computers, you can click Other Downloads and download the corresponding version. After the download is completed, find the Node.js installation package you just downloaded and install it step by step. When the installation is complete, the interface is as shown in Figure 1-3. (Figure 1-3) After the installation is completed, you can check the installation status by entering npm -h on the command line as described in Section 2.1. 2.2 Install TSC After the Node environment is fine, you can use npm to install the TypeScript compilation environment. 2.2.1 Command line installation typescript Directly enter the command \"npm install -g typescript\" in the command line tool and press the Enter key, as shown in Figure 2-1, to start downloading and installing the TypeScript environment. At this time, be sure to keep the network open. . npm install -g typescript (Figure 2-1) If developers encounter the situation in Figure 2-2 during installation, it is usually caused by cache conflicts. (If you haven’t encountered it, skip this step.) (Figure 2-2) At this time, you can use the cache cleaning command npm cache clean --force, press Enter to execute the command, and re-enter the installation instructions. npm cache clean --force [!Tip|label:Tips] If there is no circumvention, npm installation may not go smoothly. At this time, it is recommended to execute npm cache clean --force to clear the npm cache. Then use cnpm to install. When we see the words \"All packages installed\", we can confirm that the installation of the TypeScript environment is completed, as shown in Figure 2-3, just close the command line tool. (Figure 2-3) The tsc directory in Figure 3-1 is the installation directory of our TypeScript compilation environment. With this, LayaAirIDE can compile TypeScript into JavaScript through this Compiler. 2.2.2 Check TypeScript compilation environment version Enter the \"tsc -v\" command on the command line to view the current TypeScript compiled version, as shown in Figure 2-4. tsc -v (Figure 2-4) If the version number is displayed, TypeScript Compiler (tsc) is installed successfully. 3. Install browser It is recommended to use a browser with a Chromium core as the LayaAir running and debugging environment, such as the Edge browser that comes with Windows or Google's chrome browser. Chrome official website download address: https://www.google.cn/intl/zh-CN/chrome/ 4. Download and install VSCode VSCode is a widely used coding tool and is also the coding tool recommended by LayaAir engine. VSCode official website download address: https://code.visualstudio.com/Download Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:17:26 "},"basics/IDE/GUI/readme.html":{"url":"basics/IDE/GUI/readme.html","title":"GUI","keywords":"","body":"IDE development workflow module overview1. IDE account login2. IDE home page2.1 Project List2.2 Import project2.3 Create project2.4 Developer Mall2.5 Web link2.6 Account settings3. Editor initial interface3.1 Hierarchical management panel3.2 Project Management Panel3.3 UI layout widget panel3.4 Scene window3.5 Preview window3.6 Animation State Machine Panel3.7 Project settings panel3.8 Console Panel3.9 Timeline animation panel3.10 Property setting panel4. Other editing panels4.1 Prefab panel label4.2 Blueprint editing panel5. Project preview and release5.1 Project Preview5.2 Project ReleaseIDE development workflow module overview Author: Charley && Shi Huanhua 1. IDE account login LayaAir3.x uses resource store, community, IDE core configuration cloud storage and other highly network-dependent functions within the IDE, so you must log in to your account before you can use the IDE. There are three ways to log in to your account. The Chinese version of the account supports WeChat scan code login and mobile phone account login. The English version account supports email registration and login. The login interface is shown in Figure 1-1. (Picture 1-1) Before the public beta, only WeChat login was supported. 2. IDE home page The IDE homepage after logging in integrates account module, project list, create project, delete project reference, project description settings, resource store, web links (engine updates, version logs, developer community, engine documentation) and other functions. 2.1 Project List The default module after logging in is the project list. Here is the list of imported or created projects. Click the highlighted area selected by the mouse to open the project and enter the editor mode. The effect is shown in Figure 2-1. (Figure 2-1) The default project sorting order is based on the most recent editing time. If there are a large number of projects, you can also enter the project keyword in the search box to find the corresponding project. The effect is shown in Figure 2-2. (Figure 2-2) In the right menu of the project list unit, there are project-related setting functions, namely: setting the project icon, setting the project description, opening the project directory, and removing the project from the list. The effect is shown in the animation 2-3. (Animation 2-3) 2.2 Import project Click Import Project to import 3.x projects created on other computers or projects that have been removed from the list into the project list. The operation is shown in Figure 2-4. (Figure 2-4) 2.3 Create project If we want to create a new project, we can click Create Project, as shown in Figure 3-1, to create a new project. (Figure 3-1) 2.3.1 Select template In the interface for creating new projects, we have three types of templates for developers to choose from, as shown in Figure 3-2. (Figure 3-2) Core templates refer to 2D and 3D empty project templates, which are suitable for developers who have already started to create a pure template environment. Example templates are examples of functional modules with relatively simple and independent functions, suitable for understanding certain specific functions. Learning templates refer to project functions in the template that are relatively complete and rich, and are suitable for introductory learning and reference for project development. 2.3.2 Project name As shown in Figure 3-3. (Figure 3-3) 2.3.3 Project location As shown in Figure 3-4. (Figure 3-4) 2.3.4 Create project After completing the above options, click Create Project, as shown in Figure 3-5. You can complete the creation of the project and enter the IDE editing interface. As shown in Figure 3-5. (Figure 3-5) 2.4 Developer Mall The developer mall is under construction and will be launched later. 2.5 Web link The link function is under construction and will be launched later. 2.6 Account settings The account setting function currently only supports logging out. Other features are under construction. As shown in Figure 4-6. (Figure 4-6) 3. Editor initial interface The initial interface of the editor includes the hierarchical management panel, project management project, UI layout widget panel, scene window, preview window, animation state machine panel, project settings panel, console, timeline animation panel, and properties panel. 3.1 Hierarchical management panel The hierarchical management panel mainly includes 2D nodes and 3D nodes. If it is a purely 2D project, it can also only include 2D nodes. The panel is shown in Figure 5-1. (Figure 5-1) The hierarchical relationship represents the relationship between parent and child nodes. Child nodes will be affected by the parent node. For example, if the parent node changes its position or rotates its angle, the child nodes will also change synchronously. The root node of 3D nodes is Scene3D, and the root node of 2D nodes is Scene2D. 2D and 3D nodes cannot be mixed to form a parent-child hierarchical relationship. 3.2 Project Management Panel The project management panel includes all the resources and code of the project. The resources are located in the assets directory and the code is located in the src directory. The panel is shown in Figure 5-2. (Figure 5-2) 3.3 UI layout widget panel The UI layout widget panel includes three parts: 2D basic display objects, UI components, and bone nodes, which are used for UI typesetting and layout. The panel is shown in Figure 5-3. (Figure 5-3) 3.4 Scene window The scene window is a place for editing 2D scenes and 3D scenes. It is a window for developers to visually edit the virtual world. The panel is shown in Figure 5-4. (Animation 5-4) 3.5 Preview window The preview window is a visual effect preview window displayed to the user through developer layout editing and code logic. The panel is shown in Figure 5-5. (Figure 5-5) 3.6 Animation State Machine Panel Animation state machine is a tool for controlling timeline animation logic. The animation state machine panel includes functions related to animation layers and state machines. The panel is shown in Figure 5-6. (Figure 5-6) 3.7 Project settings panel The project settings panel includes screen adaptation settings, engine initialization settings, project startup settings, etc. The panel is shown in Figure 5-7. (Figure 5-7) 3.8 Console Panel The console panel is used to print log information, and the printed log information can be copied and cleared. The panel is shown in Figure 5-8. (Figure 5-8) 3.9 Timeline animation panel The timeline animation panel is used for editing 2D and 3D animations. It has two modes, namely keyframe mode and curve mode. As shown in Figure 5-9. (Figure 5-9) 3.10 Property setting panel The properties panel is the place used to set the properties of objects or files. For example, 2D and 3D object properties in the IDE hierarchy panel, property settings or preview viewing of resource files. and the addition of components. Object attribute settings, as shown in Figure 6-1: (Figure 6-1) Resource attribute settings, as shown in Figure 6-2: (Figure 6-2) Code preview, as shown in Figure 6-3: (Figure 6-3) Add components (custom attributes), as shown in Figure 6-4: (Figure 6-4) 4. Other editing panels In addition to the panels displayed on the initial interface, there are also prefab panel tabs opened through prefab files, and blueprint editing panels opened through blueprint files. 4.1 Prefab panel label The tags used to open scene files are all the same. Clicking on the prefab file will form an independent prefab panel label. The effect is shown in Figure 7-1. (Animation 7-1) Prefab panel tags actually do not have their own unique panels. Only the root node of the hierarchical management panel is different from the root node of the scene file. 4.2 Blueprint editing panel The blueprint editing panel allows you to quickly write custom materials without writing code, greatly lowering the threshold for developers. Open the Shader blueprint file or Shader blueprint function file to enter the blueprint editing panel. As shown in Figure 7-2. (Animation 7-2) 5. Project preview and release 5.1 Project Preview Project preview is used to view the running effect of the project in different environments. Project preview is divided into three modes, namely in-IDE preview, browser preview, and mobile preview. As shown in Figure 8. (Figure 8) After opening the preview in the IDE, two buttons will appear, namely restart and open developer tools. 5.1.1 Restart Restart, as the name suggests, restarts the current preview running scene, as shown in Figure 8-1. (Figure 8-1) 5.1.2 Open developer tools Clicking to open the developer tools will bring up the Developer Tools, which is convenient for developers to debug. You can also open the developer tools through the Ctrl + Alt + I shortcut key. (Figure 8-2) 5.2 Project Release Project release is to release the development version into a web version, a mini game version, and a Naitve APP version. Call up the publishing interface through Build in the File menu, as shown in Figure 9. (Figure 9) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:56:58 "},"basics/essentialSkills/readme.html":{"url":"basics/essentialSkills/readme.html","title":"Essential Skills","keywords":"","body":"Essential skills for engine learningTS Language BasicsDevTools Debugging ToolLayaTree Debugging ToolEssential skills for engine learning The LayaAir engine is aimed at developers with a basic computer language background and needs to be familiar with JavaScript language and TypeScript language. For daily development and bug checking, you need to be familiar with debugging tools such as DevTools. TS Language Basics DevTools Debugging Tool LayaTree Debugging Tool Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:19:44 "},"basics/language/readme.html":{"url":"basics/language/readme.html","title":"Language","keywords":"","body":"Language basics1. JavaScript basic Tutorial2. JavaScript ES6 Tutorial3. TypeScript basic Tutorial4. TypeScript Advanced TutorialLanguage basics The LayaAir engine supports developers to use TypeScript language to develop projects. Since TypeScript language is a typed superset of JavaScript language, we must also be familiar with the basic usage of JavaScript language. [!Note|label:Suggestion:] Newbies do not have a lot of energy if they are not students. There is no need to understand the entire language. Once you master the basic syntax, you can learn the engine. Read more engine example source codes. In the process of understanding the engine API, learn while using it. If you encounter something you don’t understand, just query it again. 1. JavaScript basic Tutorial Introduction to JavaScript Language Tutorial: https://wangdoc.com/javascript/ 2. JavaScript ES6 Tutorial Introduction to ES6 Standard: https://wangdoc.com/es6/ 3. TypeScript basic Tutorial TypeScript Chinese Manual: https://www.tslang.cn/docs/ 4. TypeScript Advanced Tutorial In-depth understanding of TypeScript: https://jkchao.github.io/typescript-book-chinese/ Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:25:22 "},"basics/DevTools/readme.html":{"url":"basics/DevTools/readme.html","title":"DevTools","keywords":"","body":"DevTools debugging toolsDevTools development tools overview:Getting started with debugging JavaScript:DevTools debugging tools The most commonly used debugging tool is DevTools. Chrome browser or browsers based on Chromium kernel (such as Edge) can use DevTools. This must be mastered, otherwise problems cannot be located. DevTools development tools overview: https://learn.microsoft.com/zh-cn/microsoft-edge/devtools-guide-chromium/overview Getting started with debugging JavaScript: https://learn.microsoft.com/zh-cn/microsoft-edge/devtools-guide-chromium/javascript/ Only two basic document entries are provided here. In fact, the document is very comprehensive. Please check and learn by yourself according to the menu list of the document. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:18:26 "},"basics/LayaTree/readme.html":{"url":"basics/LayaTree/readme.html","title":"LayaTree","keywords":"","body":"LayaTree Debugging Tools1. LayaTree installation1.1 Add via Chrome App Store1.2 Manual download and installation2. LayaTree usage2.1 Entrance used2.2 Usage tips3. Tool servicesLayaTree Debugging Tools Author: Li Er [!Note] LayaTree is a Chrome browser plug-in tool specially designed by Lear, the developer of LayaAir engine, for the majority of developers of LayaAir engine. This tool can debug and modify during the runtime phase of the project. 1. LayaTree installation 1.1 Add via Chrome App Store [!Tip|label:Tips] Add VPN through the Chrome App Store LayaTree has been put on the chrome browser online store, just search for laya. As shown below: Store address: https://chrome.google.com/webstore/ You can also directly enter the installation address in Chrome: https://chrome.google.com/webstore/detail/laya-tree/jnmdcbmpmfhnlchjdkcngihpjmgofajm?hl=zh-CN&authuser=0 As shown below: 1.2 Manual download and installation You can also download it through the domestic zip package address (v1.0.5) provided by the author: LayaTree zip package: https://womenzhai.cn/LayaTree_V1.0.5.zip zip package installation method Open the Chrome browser and enter the chrome://extensions/ page Turn on developer mode, Just drag the decompressed crx file into this page and restart the browser after the installation is successful. [!Tip|label:Tips] One thing to note is: If the page that needs to be debugged is a file URL, you need to enable access to the file URL. Otherwise, the current laya engine cannot be recognized; 2. LayaTree usage 2.1 Entrance used On the project page that needs to be debugged (the code needs to be unobfuscated), open the developer tools page (F12 or Ctrl+Shift+I) Select the LayaTree tab, as shown below 2.2 Usage tips 2.2.1 How to update the node tree list The original design of LayaTree is to have as little impact on the game as possible and to be a quiet behind-the-scenes operator. Therefore, the node tree of the current page will not be updated in real time. So you need to manually click the Capture Refresh button to update the node tree list. Or check the option to automatically refresh the node tree. As shown below: After turning on the automatic refresh node tree function, you can see the changes in the scene level in real time, without the need to manually capture the refresh. When there are many scene levels, it will slightly affect the accuracy of performance debugging. If you are performing performance tuning, it is recommended not to enable it (it is disabled by default). Daily debugging and development have not been affected. 2.2.2 Adjust parameters at runtime: operate the Camera node Example: To operate the Camera node, you can operate the node's displacement, rotation and scaling by dragging and dropping with the mouse or entering numerical values. Switch the camera's clearFlag via a convenient drop-down box. Turn HDR on or off. In addition, the camera's FOV, far and near cropping area and ratio can be quickly and dynamically modified, which greatly facilitates lens adjustment. Added orthographic camera switch orthographic. 2.2.3 Adjusting parameters at runtime: setting click events and penetration control When operating Sprite nodes, in addition to the displacement, rotation and scaling of conventional nodes, you can also dynamically set the hierarchical relationship zOrder, anchor point, and size. In addition, there are also settings for click events and penetration control that are often used in development. 2.2.4 Adjust parameters during runtime: edit text content directly Operate text nodes and edit text content directly Very easy to use color adjustment based on the color picker​ Use the drop-down boxes to select horizontal and vertical alignment of text Font size, thickness, stroke, and overflow can be adjusted at will beyond the behavior. 2.2.5 AOP-based pause and single-frame debugging operation AOP-based pause and single-frame debugging operation can control the engine cycle without modifying the source code (it should be noted that the properties modified during pause will not be updated until the next frame, so when modifying data, click after the single frame Check) Support TimeScale time scaling, support up to 50 times speed, enjoy the ghost and silky smoothness 2.2.6 cacheAs optimization skills cacheAs is \"none\" and no caching is done. When the value is \"bitmap\", caching the display object into a static image using renderTarget in webgl mode can greatly improve the rendering efficiency. However, the additionally created renderTarget object will increase the memory overhead. Through this Options allow you to easily switch modes and find optimization directions. 2.2.7 Mark selected Added mark selection function. After checking, a red box mark will be displayed when a 2d node is selected. 3. Tool services LayaTreeQQ group: 200482074 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:28:34 "},"basics/IDE/readme.html":{"url":"basics/IDE/readme.html","title":"IDE Basics","keywords":"","body":"IDE basicsIDE basics The foundation of LayaAir IDE includes basic understanding of each component of the IDE, as well as basic interactive operations. Through this part of the documentation, developers will have an overall understanding of the IDE and master the basic operation methods. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:23:45 "},"basics/IDE/layouts/readme.html":{"url":"basics/IDE/layouts/readme.html","title":"layouts","keywords":"","body":"Customize IDE interface layout1. Adjustment to make resource preview more convenient2. Adjust to make hierarchical expansion more convenient3. Adjust to instant preview modeCustomize IDE interface layout Author: Charley && Poems for Flowers LayaAir 3.0 IDE allows developers to layout and layout various functions according to their own habits or preferences. 1. Adjustment to make resource preview more convenient When we create an empty project, such as a 3D empty project, the interface layout is as shown in Figure 1-1. (Picture 1-1) The default mode is relatively simple. Some developers may have higher requirements for resource preview. We might as well adjust it to such an effect. The interface is shown in Figure 1-2. (Figure 1-2) The operation method is shown in the animation 1-3: (Animation 1-3) 2. Adjust to make hierarchical expansion more convenient If the developer has many node levels and needs to expand and view them, it is obviously more convenient to view them vertically in full screen. The effect is shown in Figure 2-1. (Figure 2-1) The operation method is shown in the animation 2-2: (Animation 2-2) 3. Adjust to instant preview mode Sometimes, developers also need to edit scenes (2D and 3D) while viewing real-time preview effects. Then we can separate the Game panel, and the effect is as shown in Figure 3-1. (Figure 3-1) The operation method is shown in the animation 3-2: (Animation 3-2) [!Note] The above three methods are for reference only. If you master the position adjustment method of the IDE panel, you can layout it according to your own needs and preferences~ Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:09:24 "},"basics/IDE/projecFolders/readme.html":{"url":"basics/IDE/projecFolders/readme.html","title":"projecFolders","keywords":"","body":"Project engineering directory description1. Overview of directory structure1.1 Project files1.2 ts compilation configuration file2. Directory of daily development2.1 Project resource directory assets2.2 Project source code directory src3. Other directories3.1 vscode configuration directory.vscode3.2 Local running directory bin3.3 Project library directory engineProject engineering directory description Author：Charley 1. Overview of directory structure The project created by LayaAir IDE consists of five visible directories and several root directory files. The effect is shown in Figure 1. (figure 1) 1.1 Project files The file with the .laya suffix is ​​the LayaAir engine project file and is used to identify whether it is a LayaAir engine project, version information, and projects with different names. 1.2 ts compilation configuration file Since the LayaAir3.0 project only supports TS language development, a tsconfig.json is also created by default. tsconfig.json is used to configure TS compilation options and is located in the root directory of the project. If you want to know the details of this configuration, please go directly to the TS language documentation: https://www.tslang.cn/docs/handbook/tsconfig-json.html https://www.tslang.cn/docs/handbook/compiler-options.html 2. Directory of daily development In the project directory structure of LayaAir 3.0, there are only two directories that developers really need to care about, the project resource directory assets and the project source code directory src. For other directories, everyone knows their functions. 2.1 Project resource directory assets The assets directory is a relatively important project directory. All our scenes and resources are in the assets directory. The IDE's management of project resources comes from this directory. The effect is shown in Figure 2-1: (Figure 2-1) This catalog is closely linked to the final release, For example, resources introduced in assets in the scene will be automatically copied to the publishing directory. The resources referenced in the code must be placed in the resources directory before they will be copied to the release directory. 2.2 Project source code directory src The source code directory in src is as shown in Figure 2-2. (Figure 2-2) [!Tip] The source code directory is easier to understand. For users of LayaAir 1.0 and 2.0, please note that Main.ts is no longer the entrance, it is just a sample script created by default. The entrance is the startup scene set in the IDE. The runtime class or script bound to the startup scene will run following the startup scene and serve as the entrance to the project. 3. Other directories For other directories, developers only need to know their functions. In daily development, developers basically do not need to deal with them. 3.1 vscode configuration directory.vscode Since the recommended coding environment for the LayaAir project is vscode, when creating the project, settings.json is created in .vscode, as shown in Figure 3-1: (Figure 3-1) Settings.json currently only configures some files that need to be hidden and displayed to make the project look more \"neat\". .DS_Store are some system files generated under MacOS system, so there is no need to see them. .meta is a file used by the IDE to identify and manage files, and developers do not need to pay attention to it. The Library, temp, local, and settingst directories are only used by the IDE for system configuration and are not expected to be modified by developers, so they are also hidden. 3.2 Local running directory bin Developers usually don't need to take care of the bin directory. During the development process, the assets directory can be used as the root directory for resource use. The bin directory contains only the entrance to the index.html homepage of the test run and the IDE's built-in code entrance. As shown in Figure 3-2: (Figure 3-2) [!Tip] Developers should try not to modify the entry here and store resources in the bin directory. This is very different from LayaAir 1.0 and 2.0. 3.3 Project library directory engine The engine directory stores the declaration file of the engine library, as shown in Figure 3-3, and usually does not need to be moved. (Figure 3-3) If the developer refers to a third-party class library, the declaration file can also be placed here. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:11:18 "},"basics/IDE/projectSettings/readme.html":{"url":"basics/IDE/projectSettings/readme.html","title":"projectSettings","keywords":"","body":"Detailed explanation of project settings1. Run settings1.1 Resolution setting1.2 Engine initialization settings1.3 Project startup settings1.4 Debug startup settings2. Editor settings2.1 3D prefab editing scene2.2 Enable texture compression when importing resources2.3 Automatically bake IBL2.4 Preview server2.5 3D node level settingsDetailed explanation of project settings Author: Charley, Meng Xingyu The project settings of the IDE include two parts, run settings and editor settings. 1. Run settings 1.1 Resolution setting The resolution setting will affect the preview effect in the IDE, as well as the canvas width and height, adaptation mode, alignment, canvas background color, etc. when the project is running. The settable properties are shown in Figure 1-1: (Picture 1-1) 1.1.1 Screen width and height adaptation The three settings that affect the width and height of the product screen are design width and height (Design Width, Design Height) and scaling mode (Scale Mode). The design width and height are the width and height we set in the IDE and see. This width and height will affect the size of the UI scene background in the IDE, and the viewing effect in the IDE's preview running mode is also based on this width and height. In the actual operating environment, such as different mobile phones. Due to the different screen ratios, it is certainly impossible to completely match the design width and height. Therefore, you need to use the engine's own scaling adaptation mode to scale to meet the developer's screen needs. The scaling adaptation mode involves many knowledge points such as canvas, stage, adaptation algorithm, etc. We introduce it in detail in another document [\"Screen Adaptation\"] (../../common/adaptScreen/readme.md). 1.1.2 Horizontal and vertical screen adaptation Sometimes, we need to force the horizontal and vertical screen settings according to the screen ratio. This can be done by setting the Screen Mode in the IDE. There are three adaptation modes for horizontal and vertical screens, as shown in Figure 1-2. (Figure 1-2) 1, no change: none When set to none, no matter how the screen direction is rotated, the horizontal direction of the game will not change to follow the screen rotation. The effect is shown in the animation 1-3. (Animation 1-3) Through the animation 1-3, we found that when the value is none, when the screen is rotated, the interface based on the vertical screen design will become unsuitable in the horizontal screen. Similarly, the interface based on the horizontal screen design will not be suitable in the vertical screen. It will become unsuitable. Of course, if our layout strategy is used more reasonably, we may also be able to take into account the experience of both horizontal and vertical screens. The effect is shown in the animation 1-4. (Animation 1-4) Although it is not that ugly, in order to achieve the best effect, the best solution is to always keep the vertical screen in the same direction as the device's vertical screen, and the horizontal screen in the same direction as the device's horizontal screen. 2, always horizontal screen: horizontal When the width and height we set are horizontal screen products, horizontal is undoubtedly the best experience, as shown in the animation 1-5. (Animation 1-5) Through the animation 1-5, we found that when the screenMode attribute value is set to horizontal, no matter how the screen direction is rotated, the horizontal direction in the design will always remain perpendicular to the shortest side of the screen. Therefore, when the user's device is in portrait mode, it will be natural to see a horizontal screen image. The device will be turned sideways to match the design of the product. 3, always vertical screen: vertical When the width and height we set are vertical screen products, vertical is undoubtedly the best experience, as shown in the animation 1-6. (Animation 1-6) Through the animation 1-6, we found that when the screenMode attribute value is set to vertical, no matter how the screen direction is rotated, the horizontal direction of the game will always remain vertical to the longer side of the screen. Therefore, even if the user has turned the device horizontally, he still sees the vertical screen image, and will naturally return the device to vertical screen, thus conforming to the design of the product. [!Tip] It should be noted that when running in the browser, the engine's automatic horizontal screen and automatic vertical screen can only rotate the canvas. If the user's phone locks the screen, although the screen will automatically rotate, the browser will not rotate. Over, it will cause the input method to still pop up in the direction of the browser. At this time, it may cause the input method and the browser to be displayed at 90 degrees. When running on a mini-game platform, since the bottom layer of the mini-game has a horizontal or vertical screen configuration, this problem will not occur. 1.1.3 Canvas alignment adaptation The alignV (vertical alignment) and alignH (horizontal alignment) provided in the engine are used to align the canvas. The setting method is shown in Figure 1-7: (Figure 1-7) Parameter description is as follows: The parameters of AlignV vertical alignment are: top (top alignment), middle (vertical center alignment), bottom (bottom alignment). The parameters of AlignH horizontal alignment are: left (aligned to the left), center (aligned to the center horizontally), right (aligned to the right). [!Tip] Canvas alignment cannot be understood as the alignment of the UI interface based on the stage, but the alignment of the canvas relative to the entire physical screen. This setting is basically not used on the mobile side. Most mobile terminals require full-screen adaptation. When the canvas already covers the entire screen, the settings are meaningless. Usually used on the PC side in non-full-screen modes, such as when the canvas is not in full-screen mode (showall and noscale). 1.1.4 Canvas background color setting The canvas background color is actually to set a color for the canvas. The default value is #888888, as shown in Figure 1-8: (Figure 1-8) 1.2 Engine initialization settings There are some engine configuration items that need to be set when the engine is initialized, and the setting entry is as shown in Figure 1-9: (Figure 1-9) 2D attribute parameter description: attribute name Property description Frames per second FPS Device frame rate; used to calculate the maximum rendering interval between two frames. Usually the frame rate on the device is a maximum of 60, that is, only a maximum of 60 frames will appear on the screen in one second, so the frame rate between two frames The duration is 1000ms/60. For high frame rate devices, we can modify the FPS value. For example, for a 120 frame device, the time between two frames is 1000ms/120. Canvas anti-aliasing Whether to turn on anti-aliasing; used to set the antialias anti-aliasing switch attribute of the webGL context, which will cause additional performance consumption. It is mainly used for 2D non-rectangular vector drawing anti-aliasing. When there is no vector drawing graphics or the performance pressure is high, you can choose not to Turn on. It is recommended to use the camera's Fxaa or Msaa for 3D anti-aliasing. Retina Canvas Mode Whether to use HD canvas mode; after turning it on, regardless of any adaptation mode, the canvas will use the physical resolution size. After turning it on, it will consume more performance than not using the physical resolution, but it will keep the text and so on the best clarity. Spend. Canvas transparent Whether the canvas is transparent; the canvas has a background color by default. After turning it on, you can set the canvas to be colorless and transparent. Vertex cache optimization Whether to allocate the largest VB buffer; after turning it on, when rendering 2D, a cache sufficient for 64k vertices will be directly allocated each time a VB is created. This improves efficiency. After turning it off, 64k of video memory can be saved, but performance efficiency will be sacrificed. If 2D is included, it is recommended to keep it turned on by default. Default font The default font of text; after setting, the default font of new text in the IDE will adopt the setting here. Default font size The default font size of text; after setting, the default font size of new text in the IDE will adopt the setting here. 3D attribute parameter description: attribute name Property description Static batching Whether to enable static batching; turning on static batching can reduce the number of rendering state changes between visible mesh draw calls. Dynamic batching Whether to enable dynamic batching; after enabling dynamic batching, if instance merging (same Mesh and same material) is met, the number of RenderBatches rendering batches and Shader submissions can be reduced. Physical function initialization memory When initializing 3D settings, the default physical function initialization memory is in M. Enable UniformBuffer Enable Uniform Buffer; when the Uniform Buffer cache is enabled, the amount of data transferred from the CUP to the GPU can be reduced. Resolution multiple Set the 3D resolution multiple, the default value is 1; reducing the 3D resolution will not affect the resolution of the 2D UI. Appropriate adjustment can reduce performance consumption. Multiple light sources Whether to enable multiple light sources; if multiple light sources are not needed, turning it off can reduce performance consumption. Maximum number of light sources The default value is 32. Number of light clusters The number of lighting clusters in x, y, and z axes; the z value will determine the number of clusters affected by area light (point light, spotlight), Math.floor(2048 / lightClusterCount.z - 1) * 4 is the number of each Cluster The maximum average amount of light received in the area. If the average number of light sources affected by each Cluster is greater than this value, the farther Cluster will ignore the excess light effects. Maximum number of deformations The maximum number of deformations for the mesh renderer. The default value is 32. Whether to use BVH cropping Whether to use BVH clipping; after turning it on, you can set: the maximum number of cells in a BVH node (if it exceeds this number, it will be separated -), the size of the maximum BVH node, and the minimum number of cellbuilds (if it is less than this number, BVH will not be built). 1.3 Project startup settings 1.3.1 Entry startup scenario There are two ways to set the LayaAir 3.0 project running entrance. One is to use the current scene (the scene being edited) as the project running entrance, and the other is to set a fixed project entrance scene. When we set the startup scene in build release and check the startup scene as the entrance, as shown in Figure 1-10. When running the project, after the engine is initialized, the set startup scenario will be run first. (Figure 1-10) 1.3.2 Engine library module The LayaAir engine consists of multiple module components, and only the more basic modules are introduced by default, as shown in Figure 1-11. (Figure 1-11) If applied to other modules, you need to check the corresponding module before you can use its API, otherwise an error will be reported when the project is run. Engine library module description: Engine library module name Engine library module description laya.d3 3D basic module, a must-have library for using 3D laya.ui ui module, including commonly used ui components, a must-have library for using 2D UI components laya.ani 2D animation module, including 2D node animation (sequence frame, atlas animation), built-in skeletal animation, etc. laya.device Gyroscope, accelerometer, geographical location, camera, microphone and other device interface call packaging laya.tiledmap tiledmap map interface encapsulation laya.particle 2D particle encapsulation, not recommended laya. gltf The code directly uses the loading and parsing library of the gltf model laya.physics Package of Box2D physics library laya.physics3D Bullet 3D Physics Library laya.physics3D.wasm Bullet 3D physics library for WebAssembly laya.spine spine animation engine library laya.workerloader WorkerLoader decodes images asynchronously 1.3.3 Start page configuration The startup page refers to the icon displayed before the game starts. If no setting is made, the engine's default icon will be used. Developers can customize icons, as shown in Figure 1-12: (Figure 1-12) Parameter Description: Parameters Description Activate When checked, the startup page will be displayed before the game starts. background color After checking, you can set the background color of the startup page. Pictures The icon displayed on the startup page, the default is the engine icon. When customizing icons, the image path must be placed in the bin directory. Adaptation Screen adaptation of icons. There are four modes: center, fill, contain, and cover. Minimum display time The minimum display time of the startup page, in seconds. Allow activation in preview When checked, the startup page can be seen in preview mode. Otherwise, the splash page will only be visible after publishing. 1.4 Debug startup settings As shown in Figure 1-13, LayaAir IDE can enable the following debugging modules: (Figure 1-13) 1.4.1 Display statistics After checking Show statistics, you can view the current frame rate, memory usage, nodes and other information for project analysis and optimization. As shown in Figure 1-14. (Figure 1-14) If you want to know more details about the parameters on the statistics panel, please consult the document Performance Statistics and Optimization 1.4.2 Display the mobile debugging tool VConsole Debugging on the mobile side usually requires connecting to the browser on the computer side. If the developer does not need breakpoints, but just some common log printing, loading and other viewing, open V Console, and the debugging tool panel as shown in Figure 1-15 will appear on the mobile terminal. (Figure 1-15) 1.4.3 Pop-up window displays global errors If you capture a global error window.onerror, check pop-up window to display global error to throw a detailed error stack in the pop-up window. For example, you can customize a global error with the following code: //Customize a global error let err = new Error(\"Customized Error\"); Laya.Browser.window.onerror(err.message, \"\", \"\", \"\", err); When running, a pop-up window will throw an exception, and the effect is shown in Figure 1-16. (Figure 1-16) 1.4.4 Display 2D physics debugging In LayaAir IDE, if you add physical attributes (rigid body, collision box, etc.) to a 2D node and check Show 2D physical debugging, the node with added physical attributes will display a shadow effect, as shown in the animation 1-17 Shown: (Animation 1-17) 2. Editor settings 2.1 3D prefab editing scene By default, 3D prefabs are edited in the context of a dedicated system empty scene (DefaultPrefabEditEnv). If we specify a target scene through 3D prefab editing scene, it is equivalent to editing directly in a 3D scene. In this way, when switching to a 3D scene, it will be more in line with the needs. The operation is shown in Figure 2-1: (Figure 2-1) The effect is shown in Figure 2-2: (Figure 2-2) 2.2 Enable texture compression when importing resources After checking Enable texture compression when importing resources, when importing texture resources (PNG and JPG) from outside to the IDE, as shown in Figure 2-3, the Texture Compression, enabling this operation will increase operating efficiency, but will affect display quality. (Figure 2-3) This operation has no impact on old resources before this feature is enabled. 2.3 Automatically bake IBL After checking Automatically bake IBL, as shown in Figure 2-4, if the skybox material is changed in Scene3D (Material is changed from skybox to other materials), there is no need to manually click the Bake button for the IBL Tex of Reflection Probe. , after saving the scene, the IDE will automatically re-bake it. (Figure 2-4) Only when the Source of Reflection Probe is Skybox, it will be baked automatically. Custom cannot be baked automatically. 2.4 Preview server The preview server can set the address and port number for previewing in the browser. After setting, refresh the IDE to apply it. The effect is shown in Figure 2-5. (Figure 2-5) 2.5 3D node level settings For 3D nodes, you can select levels and set them. In the editing settings, you can add, delete, and name levels. The effect is shown in Figure 2-6. (Figure 2-6) For more information about hierarchical Layer, you can go to the IDE document Using 3D Sprites to view it. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:14:05 "},"basics/IDE/entry/readme.html":{"url":"basics/IDE/entry/readme.html","title":"entry","keywords":"","body":"Project entry description1. Startup scene1.1 A must-read for LayaAir2.0 users, the entrance has changed1.2 Set startup scene1.3 Engine configuration items before project entry1.4 Entry settings for preview operation2. Entry logic script2.1 Basic usage process of custom component scripts2.2 UI component script3. Custom initializationProject entry description Author: Charley, Meng Xingyu The project entry is the first place where the project is executed after the engine is initialized. For large projects, it is usually the entry point for resource preloading and global initialization. For micro products that do not require preloading, it is usually the main interface and global entry logic. 1. Startup scene 1.1 A must-read for LayaAir2.0 users, the entrance has changed In the LayaAir2.x engine, the Main class is used as the entry class of the project, so the initial configuration of some engines can only be set through code in the entry class (Figure 1-1). (Picture 1-1) However, in LayaAir 3.0, in order to simplify developers' understanding and process, the entrance to the project no longer appears in the form of an entrance class. The entrance to the project becomes the startup scene. The initial configuration of the engine only requires visual configuration in the IDE. More on this below. Old users of LayaAir 2.0, don’t look for the Main entry class anymore, it has been killed~ 1.2 Set startup scene For the LayaAir 3.0 engine, the startup scene can only be set in the IDE as the entry point of the project. If you need to initialize the engine global configuration, configure it directly in the IDE's project settings. If you need code logic, you can directly associate the script with the scene to execute the code logic. In this section, we first introduce how to set up the startup scene. We open the Build Release panel in the File navigation menu. As shown in Figure 1-2, (Figure 1-2) The Startup Scene of the Build Release panel is used to specify the startup scene of the project, as shown in Figure 1-3. (Figure 1-3) Developers can select a scene file in the pop-up panel and designate it as the startup scene. The operation is as shown in the animation 1-4. (Animation 1-4) 1.3 Engine configuration items before project entry Before executing the project entry, developers can also configure some engine initialization settings, as shown in Figure 1-5. We open the `Project Settings' panel and configure it directly in the engine options. (Figure 1-5) For specific parameter setting instructions, please refer to the document [\"Project Settings Detailed Explanation\"] (../projectSettings/readme.md). 1.4 Entry settings for preview operation After the startup scene is released online in the build release, it is undoubtedly the first to be loaded and displayed as the entrance to the project. However, when debugging the project in preview and run, we sometimes do not want to display the startup scene first, which will make the debugging process very long. Therefore, click the drop-down arrow in the red circle in Figure 1-6, and click the check box to use Start Scene or Current Scene as the entry for preview running. (Figure 1-6) The current scene refers to the scene currently open for editing in the IDE. 2. Entry logic script Although this knowledge point is not exclusive to the project entrance, we still briefly talk about the process. First of all, LayaAir 3.0 does not recommend developers to use custom scripts as the entry point for projects. Therefore, from a normal process, the logic of the code must follow the entrance scene, and the corresponding logic is executed through the life cycle methods of the entrance scene activation and adding to the stage and other engines. For the 3D root node Scene3D of the scene, the only scripts that can be bound are custom component scripts. The 2D root node of the scene, Scene2D, can also bind UI component scripts in addition to custom component scripts. Regarding the difference and use of custom component scripts and UI component scripts, please refer to relevant documents. This article only introduces the core process of project entry. For customized component scripts (decorator exposed properties, event methods, life cycle methods, etc.), please refer to Entity Component System (ECS) UI component scripts (associated UI components, differences from custom component scripts, etc.) please refer to UI Inheritance Class 2.1 Basic usage process of custom component scripts Customized component script inherits from the Laya.Script class and defines the component's event methods and its own life cycle methods. Animation 2-1 demonstrates how to add custom component scripts to Scene2D nodes. In the Property Settings panel, click Add Component->New Component Script, then you can rename the script to be created (renamed to aaa in the picture), and finally click Create and Add to create it script. (Animation 2-1) According to the custom component script aaa.ts added in the above animation, a script template class named aaa is generated, as shown in Figure 2-2. Just write the code directly in the script. (Figure 2-2) [!Tip] For specific component script usage documentation, please refer to Entity Component System (ECS) 2.2 UI component script In addition to custom component scripts, UI component scripts can also be used as the logic code for project entry. UI components are mainly used in 2D scenes when there are many nodes that need to be managed, and in application scenarios where parameters need to be passed to the scene when opening the scene (such as dynamic prompts for pop-up windows, etc.). UI components can be used independently or simultaneously with component scripts. UI component script needs to be added at the UI runtime (Runtime) property entrance, as shown in Figure 2-3. And, only in the Scene2D node of the scene or the Property Settings panel of the 2D prefab (Figure 2-3) 2D prefabs have the UI runtime (Runtime) attribute as long as they are root nodes. The following takes the Scene2D node as an example to introduce how to create a UI component script. Double-click the mouse in the UI Runtime attribute input box. The IDE will pop up a window prompting you to create a UI component script file. The default is RuntimeScript.ts. Developers can rename it, such as GIF 2. -BBB shown in 5, click Save to create the script. (Animation 2-5) It is recommended to first learn custom component scripts and their usage, and then learn the related content of UI component scripts. 3. Custom initialization Because of the previous process, the engine was initialized first, and then the entry scene was loaded and started. However, in some special cases, developers may need to execute some logic before engine initialization, for example, they need to determine different operating environments in advance. Then we also provide a customized code flow, using Laya.LayaEnv.beforeInit to define the logic to be executed before the engine is initialized, and using Laya.LayaEnv.afterInit to define the logic to be executed after the engine is initialized. For example, when a developer creates a project, a Main.ts will be automatically generated and the following code will be added: Laya.LayaEnv.beforeInit = function(config: Laya.IStageConfig) { //This method will be called before Laya.init console.log(\"before init\"); //Here you can make customized modifications to config, Laya.Config, and Laya.Config3D. } Laya.LayaEnv.afterInit = function() { //This method will be called after Laya.init console.log(\"after init\"); } const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { onStart() { console.log(\"Game start\"); } } It should be noted that you need to ensure that the script file where these codes are located is referenced in the scene, otherwise the unused code in the project will be eliminated when the version is released, and it will be invalid. Note: If there are no special needs, it is not recommended to use the method in this section to initialize the game. Developers should use the method of mounting component scripts for scenes. You can see the output when running, as shown in Figure 3-1: (Figure 3-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:51:42 "},"basics/IDE/importJsLibrary/readme.html":{"url":"basics/IDE/importJsLibrary/readme.html","title":"import Js Library","keywords":"","body":"Reference third-party JS module1. Use commands to introduce third-party modules1.1 Support method1.2 Usage examples2. Use third-party JS files in LayaAir IDE2.1 Support methods2.2 Usage examplesReference third-party JS module The AStar pathfinding algorithm is used in the examples in this section, so I will write it in front and give a rough introduction. In the 2D entry example of LayaAir3.0 engine, as shown in Figure 1, (figure 1) There is an example of 2D A* pathfinding. Developers can first use this example to understand how to use it in 2D projects, as shown in animation 2. (Animation 2) The working principle of the A* algorithm will not be introduced here. Developers can search the Internet for the specific implementation of the algorithm. Simply put, it is a very commonly used path finding and graph traversal algorithm. It has better performance and accuracy. 1. Use commands to introduce third-party modules 1.1 Support method During the development process, if you need to use some third-party libraries, the recommended solution is to use the module function of JS. Proceed as follows: Execute npm init in the project folder to initialize the project. Use npm install xxx --save to install the xxx package. Then use the import statement in the code to import it. 1.2 Usage examples We use the third-party AStar module to explain: 1.2.1 npm init Using npm init during development will generate a pakeage.json file. This file is mainly used to record the detailed information of the project. It will record the packages we will use in project development, as well as the detailed information of the project. in this project. Executing npm init needs to be executed in a DOS window. We can open the window with the windows+r key, then enter CMD to execute, and then the DOS window can be opened. After opening the window, enter the directory where your project is located in the DOS window. After entering the directory where the project is located, we can directly execute npm init. After executing npm init, we will be asked to fill in some configuration information. If we still don’t know how to fill it in, we can press Enter all the way. package name: project name; version: version number; description: description of the project; entry point: entry file of the project; test command: What command should be used to execute the script file when starting the project; git repository: If you want to upload the project to git, you need to fill in the git warehouse address (the address will not be written here); keywirds: project keywords (not written here); author: the author’s name (not written here); license: the certificate required for the release project (not written here); As shown in Figure 1-1, (Picture 1-1) 1.2.2 npm install xxx --save Take npm installation of AStar as an example, as shown in Figure 1-2. (Figure 1-2) The astar package will be installed into the node_modules directory, and astar will be added under the dependencies attribute of package.json. Take a look at the contents of package.json: { \"name\": \"test\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"bin\": { \"test\": \"bin/bundle.js\" }, \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"astar-typescript\": \"^1.2.5\" } } Next, we can use import AstarFinder in our code. The sample code is as follows: import { AStarFinder } from \"../node_modules/astar-typescript/dist/astar\"; const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { private aStarInstance: AStarFinder; onStart() { console.log(\"Game start\"); // 0 represents a path, 1 represents an obstacle let myMatrix = [ [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 1, 0, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0], [1, 1, 1, 0, 1, 0, 1, 0], [0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0] ]; this.aStarInstance = new AStarFinder({ grid: { // column major matrix matrix: myMatrix } }); let startPos = { x: 0, y: 0 }; let goalPos = { x: 7, y: 7 }; let myPathway = this.aStarInstance.findPath(startPos, goalPos); console.log(myPathway); } } By running this script in the IDE, the shortest route from point 0,0 to point 7,7 can be obtained, as shown in Figure 1-3 (Figure 1-3) So far, the third-party module has been successfully imported into the project, will be automatically loaded in the IDE, and can be previewed and run normally. Through debugging with developer tools, you can see that the introduced AStarFinder class has been successfully integrated into the published code, as shown in Figure 1-4 (Figure 1-4) 2. Use third-party JS files in LayaAir IDE In some special cases, if you need to use some third-party JS files directly, the IDE also provides a separate import function. 2.1 Support methods First place the JS file into the assets folder or src folder of the project: Import as plugin Check \"Import as plug-in\" in the property settings. As shown in animation 2-1, (Animation 2-1) After checking, Allow runtime loading and Automatic loading are checked by default, that is, this script will be automatically loaded at runtime. Allow editor to load If \"Allow editor loading\" is checked, the script will also be loaded in the editor environment. Note that JS scripts should not modify the global environment, otherwise it will affect the stability of the editor. In addition, once the JS script is loaded, there is no unloading and refreshing functions. If the JS file is modified, the editor needs to be refreshed for it to take effect. If unchecked, this script will not be loaded until preview, run or publish. Allow compression on publish Check \"Allow compression when publishing\". When building and publishing, if \"Compress JS files\" is set, this script will be compressed. Depends on others \"Depend on others\" can set up multiple scripts, and these scripts will be scheduled to be loaded first. 2.2 Usage examples In the 2D entry example, if you run \"A* Pathfinding\" under \"Advanced Usage\" without importing astar.js, and click on any area, the character will not move at all, as shown in Figure 2-2 (Figure 2-2) Since the IDE itself does not support the Astar class library and has not imported the Astar class library, an error will be reported during runtime, as shown in Figure 2-3. (Figure 2-3) Therefore, we need to introduce Astar.js to support the A* algorithm. Download astar.js Put astar.js into the assets directory, or the src directory. Here we take assets as an example, as shown in Figure 2-4 (Figure 2-4) Click astar.js, in the properties panel, check \"Import as plug-in\" and click \"Apply\", as shown in Figure 2-5 (Figure 2-5) At this point, astar.js has been imported into the IDE as a plug-in and will be automatically loaded during preview and release. Run the 2D example again to view the A* pathfinding example, as shown in animation 2-6 (Animation 2-6) It is running normally. Next, let's test the release. As shown in Figure 2-7, in the web directory after release, astar.js has been released to the js directory. (Figure 2-7) And is introduced in release\\web\\index.html, as shown in Figure 2-8, (Figure 2-8) After running the released project, A* pathfinding still runs normally. Developers can also use \"Allow editor loading\" and \"Depend on others\". Run the released project reference Web Release. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:05:23 "},"basics/IDE/Hierarchy/readme.html":{"url":"basics/IDE/Hierarchy/readme.html","title":"Hierarchy","keywords":"","body":"Hierarchy panel description1. The function of the hierarchical panel2. Common operations of hierarchical panels2.1 Create node2.2 Search nodes2.3 Hidden nodes2.4 Lock node2.5 Contraction and expansion of nodes2.6 Node sorting2.7 Common functions of right-click menu2.8 Node tree3. 3D scene node operation3.1 Deletion and creation of 3D scene root node3.2 3D basic nodes3.3 Create 3D rendering nodes4. 2D scene node operation4.1 2D basic nodes4.2 UI node4.3 Bone nodesHierarchy panel description 1. The function of the hierarchical panel The hierarchical management panel provides visual operations of nodes and facilitates management between nodes. It mainly includes 2D nodes and 3D nodes. If it is a purely 2D project, it can also only include 2D nodes. The panel is shown in Figure 1-1. (Picture 1-1) The hierarchical relationship represents the relationship between parent and child nodes. Child nodes will be affected by the parent node. For example, if the parent node changes its position or rotates its angle, the child nodes will also change synchronously. The root node of 3D nodes is Scene3D, and the root node of 2D nodes is Scene2D. 2D and 3D nodes cannot be mixed to form a parent-child hierarchical relationship. 2. Common operations of hierarchical panels 2.1 Create node The 3D nodes that can be created are: Sprite3D (this is an empty node); Basic 3D nodes (Cube, Sphere, Cylinder, Capsule, Cone, Plane); Special effects (Particle3D, PixelLine, Trail); Lights (DirectionLight, PointLight, SpotLight, AreaLight); camera. The 2D nodes that can be created are: Basic 2D nodes (Sprite, Animation, Text, SoundNode, VideoNode); UI组件（Box、HBox、VBox、Image、Clip、Button、CheckBox、Radio、RadioGroup、ComboBox、Label、TextInput、TextArea、FontClip、ProgressBar、HSilder、VSlider、List、Panel、Tree、Tab、ViewStack、HScrollBar、VScrollBar、ColorPicker、View、Dialog、OpenDataContextView）； 2D skeletal animation (Spine, Skeleton). The above lists the node types that can be created. The following is an introduction to the ways to create nodes. There are two main ways: one is to create a separate node without a parent relationship, that is, 3D nodes are under Scene3D, and 2D nodes are under Scene2D; The other is to create it under a certain node as its child node. As shown in Figure 1-1, Sprite is a separate node, and Sphere is a child node of Cube. 2.2.1 Single node If a certain node is not selected, as shown in the animation 2-1, assuming it is selected, you can click on the blank space to deselect it. At this time, click + to create the node. The node created at this time is a separate node. (Animation 2-1) As shown in the animation 2-2, when the node is not selected, right-click on the blank space to create it. At this time, a separate node is created. (Animation 2-2) Careful developers may find that there are two places to create Sprites in the created menu bar, as shown in Figure 2-3. One is to directly select Create Sprite, and the other is to select 2D Node->Sprite Create it below. The sprites created in these two ways are the same. Method 1 is for the convenience of operation, and method 2 is because Sprites are basic display sprites and are classified as basic 2D nodes. (Figure 2-3) Note: For the shortcut keys for creating empty nodes, please refer to section 1.3.1 of the document [\"Comprehensive Collection of IDE Shortcut Keys and Mouse Interaction Operations\"] (../shortcutKeyCombinations/readme.md). 2.2.2 Parent-child nodes As shown in the animation 2-4, if you select a node to create, whether you click + to create or right-click to create, the child nodes of the selected node will be created. (Animation 2-4) 2.2 Search nodes In the search bar, you can search for the created nodes based on the node name, as shown in the following animation to search for Sphere nodes: (Animation 2-5) You can also combine it with the project resource panel. For example, there is a picture LayaAir.png in the project resource panel, and set the skin of the Image component in the scene to this picture. At this time, you can right-click the picture and choose to find references in the scene, such as moving As shown in Figure 2-6, you can search for components that reference this resource. (Animation 2-6) 2.3 Hidden nodes As shown in Figure 2-7, the node can be hidden. However, the hiding effect at this time is only in the Scene panel, and the node still exists when Preview is running. (Animation 2-7) If it is a parent-child node and hiding the child node, only the node itself will be hidden. If the parent node is hidden, the child node will also be hidden. The effect is as shown in Figure 2-8. (Animation 2-8) 2.4 Lock node As shown in Figure 2-9, you can lock the node. After locking the node, the node will be in the scene panel and will not be operated. For example, in the animation, the Cube can be selected for movement before locking, but the Cube cannot be selected after locking. (Animation 2-9) If it is a parent-child node, as shown in Figure 2-10, locking the child node will not affect the parent node. If the parent node is locked, the child nodes will also be locked. (Animation 2-10) It should be noted here that locking a node only prevents the mouse from selecting it in the scene panel, but it can still be operated on in the attribute settings panel. This function is often used for background images. After setting the background image, you can lock the background image first to prevent mistaken selection. 2.5 Contraction and expansion of nodes The IDE provides a shrink all button, as shown in animation 2-11. After clicking, all child nodes can be shrunk. (Animation 2-11) Note: For the shortcut keys to expand all sub-nodes, please refer to section 1.3.2 of the document IDE Shortcut Keys and Mouse Interaction Collection. 2.6 Node sorting 3D nodes are in the three-dimensional coordinate system, and their occlusion relationship is related to their coordinates and the position of the camera. But for 2D nodes, if they are added in order, they will increase downward one by one in the hierarchy panel, as shown in the animation 2-12, then the ones added first will be overwritten by those added later. At this time, if you want to modify their occlusion relationship, you can change the ZOrder attribute. (Animation 2-12) Of course, in addition to modifying the ZOrder attribute, you can also change the occlusion relationship by dragging the target node. There are three main types: Drag and drop to be the subordinate node of the target node; After dragging to be the sibling of the target node; Before dragging as a sibling of the target node. Note: For a demonstration of dragging the target node, please refer to section 1.3.3 of the document Complete Collection of IDE Shortcut Keys and Mouse Interaction Operations. 2.7 Common functions of right-click menu In addition to the function of creating nodes in 2.1, the right-click menu also has some common functions: Copy, Paste: As shown in the animation 2-13, select the node to copy (you can also select multiple nodes), and then paste. If there are nodes with the same name after pasting, the IDE will automatically rename them. (Animation 2-13) 2D nodes can only be pasted under Scene2D, and 3D nodes can only be pasted under Scene3D. Rename: As shown in the animation 2-14, the selected node can be renamed. (Animation 2-14) Generate copy: As shown in the animation 2-15, you can generate a copy of the selected node, which retains the attributes of the original node (position, size, unique attributes, etc.). (Animation 2-15) Delete: As shown in the animation 2-16, you can delete the selected node, delete the parent node, and the child nodes will be deleted accordingly. (Animation 2-16) Note: For the shortcut keys for the above operations, please refer to section 1.2 of the document Complete Collection of IDE Shortcut Keys and Mouse Interaction Operations. 2.8 Node tree When running, the hierarchy panel displays the node tree in the running state. As shown in animation 2-17, whichever scene is switched to, the node tree of that scene will be displayed. (Animation 2-17) The example in the animation is \"2D Getting Started Example\". 3. 3D scene node operation 3.1 Deletion and creation of 3D scene root node As mentioned at the beginning of this article, if it is a purely 2D project, it can only include 2D nodes. In other words, 3D nodes can be deleted, including the 3D root node Scene3D. As shown in animation 3-1, the root node Scene3D is deleted. After deletion, it becomes a pure 2D scene. (Animation 3-1) If you create a pure 2D project and want to add a 3D scene, you only need to add the required 3D nodes, as shown in animation 3-2, and the node will be automatically created under Scene3D. (Animation 3-2) 3.2 3D basic nodes The 3D nodes that can be created have been listed in Section 2.1. This section will outline their functions and provide detailed links to the documents corresponding to the nodes. Sprite3D This is an empty node, which is the most basic 3D node and contains many basic functional attributes of 3D sprites. After creation, you can assign attributes such as Mesh to it to display effects. For detailed purposes and usage, please refer to the document Using 3D Sprites. Basic 3D nodes Contains: Cube, Sphere, Cylinder, Capsule, Cone, Plane. They are basic 3D display objects and can be used as auxiliary tools in 3D development. For example, beginners can quickly learn the 3D development process and skilled developers can simulate and test. For detailed usage, please refer to the document 3D Basic Display Object. Special effects Nodes related to special effects include: Particle3D, PixelLine, and Trail; Particle3D is a 3D particle system that can be used to simulate non-fixed natural phenomena such as smoke, fog, water, fire, rain, snow, and streamers. For detailed instructions, please refer to the document 3D Particle Editing Module. PixelLine is a pixel line, which draws 3D sprites by rendering a set of colored lines. For detailed introduction, please refer to the document Pixel Line. Trail is a trail. The trail renderer can create a trail effect behind an object, such as the air column generated by a bullet passing through. For detailed information, please refer to the document Trail. lighting There are four types of light nodes in total, namely DirectionLight (directional light), PointLight (point light source), SpotLight (spotlight), and AreaLight (area light). They determine the color and atmosphere of the environment, and different light sources will present different effects. For detailed setting methods, please refer to the document 3D Light and Shadow. camera The camera node is equivalent to the eye, and all scenes are rendered through it. For detailed description, please refer to the document Using 3D Camera. 3.3 Create 3D rendering nodes Rendering nodes refer to nodes that need to be rendered, such as MeshSprite3D (static mesh sprite), SkinnedMeshSprite3D (skinned animated mesh sprite), etc. As shown in Figure 3-3, just drag it directly from the resource panel to the hierarchy panel. (Figure 3-3) 4. 2D scene node operation The 2D nodes that can be created have been listed in Section 2.1. This section will outline their functions and provide detailed links to the documents corresponding to the nodes. Developers need to note that Scene2D nodes are different from Scene3D nodes and cannot be deleted. 4.1 2D basic nodes Sprite is a 2D sprite, a display object that can be controlled on the screen. Animation is a node animation that can easily create atlas animations and multi-frame animations. Text is the basic component of static text. SoundNode is a component that plays sound. VideoNode is the component that displays video. 4.2 UI node Box is the base class of container components and is used to load components of other display objects. HBox is a container component commonly used for horizontal layout. VBox is a container component commonly used for vertical layout. Image is the most common component that displays images in the UI and is used to display bitmap images. Clip component can be used to display bitmap slice animation. Button is a button component that can display text labels, icons, or both at the same time. CheckBox is a multi-select box component. Radio is a radio button component. RadioGroup is a radio button group. ComboBox is a drop-down list option box component. Label is used to display a piece of text. TextInput is a text input box, which can be used whenever input is required. TextArea is a text area, inherited from TextInput. FontClip cuts the bitmap proportionally from the direction. ProgressBar is used to display progress. HSilder is a horizontal slider that allows you to select values ​​by moving the slider between slider tracks. VSlider is a vertical slider. List displays the project list. Panel is a panel container class with cropping function, which is commonly used to set the display area of ​​elements. Tree component is used to display the tree structure. The Tab component is used to define a tab button group. ViewStack is mainly used for multi-page view switching. HScrollBar is a horizontal scroll bar component VScrollBar is a vertical scroll bar component. ColorPicker displays a list containing multiple color samples. Dialog is mainly used for pop-up panels. OpenDataContextView is a component used in the open data domain. 4.3 Bone nodes Spine implements animation by binding pictures to bones and then controlling the bones. Skeleton can convert some commonly used skeletal animation formats into skeletal animation formats supported by the LayaAir engine. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:02:32 "},"basics/IDE/assets/readme.html":{"url":"basics/IDE/assets/readme.html","title":"assets","keywords":"","body":"Project resource panel description1. Resource directory1.1 Project resource directory assets1.2 Project source code directory src1.3 Right-click menu1.4 Edit 2D pictures into sprite textures2. Quickly create files2.1 Create folder2.2 Create prefab2.2.1 Prefab 2D2.2.2 Prefab 3D2.3 Create scene (scene)2.4 Create shader2.4.1 Shaders2.4.2 Shader Blueprint2.4.3 Shader Blueprint Function2.5 Create materials and configurations2.5.1 Material file2.5.2 Cube texture2.5.3 Rendering texture2.5.4 Animation mask2.6 Create image type2.6.1 Lightmap baking settings2.6.2 Automatic album setting2.7 Create animation state machine2.7.1 2D animation state machine2.7.2 3D animation state machine3. Search panel3.1 Text search3.2 Type search4. Directory Settings Panel4.1 Two-column display4.2 Collapse allProject resource panel description 1. Resource directory After opening the project in LayaAir IDE, it consists of five parts. The effect is shown in Figure 1-1. (Picture 1-1) Project resource directory Project source code directory + quick creation Search panel Catalog setting button First, we can briefly understand the project resource directory and project source code directory, and then give a detailed introduction to the other three functions. 1.1 Project resource directory assets The assets directory is a relatively important project directory. All our scenes and resources are in the assets directory. The IDE's management of project resources comes from this directory. The effect is shown in Figure 1-2: (Figure 1-2) This catalog is closely linked to the final release, For example, resources introduced in assets in the scene will be automatically copied to the publishing directory. The resources referenced in the code must be placed in the resources directory before they will be copied to the release directory. 1.2 Project source code directory src The source code directory in src is shown in Figure 1-3. (Figure 1-3) The source code directory is relatively easy to understand. Usually after installing the code editor, you can double-click the source code to open the code editor. 1.3 Right-click menu By right-clicking any directory or file, you can open the menu, as shown in Figure 1-4 (Figure 1-4) By clicking \"Create\", a \"Lightmap Baking Settings\" file is created in the assets directory in animation 1-5. (Animation 1-5) In the second section, we will explain the types that can be created in the menu. Next, we will introduce other options: Open in File Manager: You can quickly open the file manager to view the file. Find references in the scene: You can search for components that reference this resource. You can view the document [\"Hierarchy Panel Description\"] (../../../basics/IDE/Hierarchy/readme.md) Section 2.2. Rename, delete, copy, paste: basic operations on files, no need to go into details. Generate Copy: You can generate a copy that retains the attributes of the original file. Reimport: Usually used when the import fails, or some external dependencies have changed. For example, there is a material in the model, and the material refers to an external texture, but the texture was not put in at first, but later it was put in. You can use this function . Open project in code editor: You can directly open the code editor to view file information. 1.4 Edit 2D pictures into sprite textures 2D image resources, in the assets directory, will be used as the texture format of the 3D model by default. In 2D interface development, it usually needs to be changed to a 2D image format, which needs to be edited by the developer. As shown in Figure 1-6, this is a png picture with a transparent channel (Figure 1-6) Click on the picture to see the property settings, as shown in Figure 1-7 (Figure 1-7) Default value: By default, the image is used as the Texture map file of the 3D model and can only be used on the material ball. Sprite texture: The picture is a picture texture format of a 2D Sprite object, usually used in 2D development. This attribute is automatically used as the sprite texture when the image resource is named according to the official naming rules. Otherwise, it is the default value, which will cause the resource to display abnormally. Without changing the image type, use and run this image as a 2D image in the Image component. The page background is blue, as shown in Figure 1-8. (Figure 1-8) You can see that there are white burrs in the green area in the picture, so the settings need to be changed, as shown in Figure 1-9 (Figure 1-9) Let’s take a look at the running effect, as shown in Figure 1-10 (Figure 1-10) The image also has some other property settings: Tiling mode: Select the way the texture is tiled. The default option is repeat. Filter Mode: Select how the texture is filtered when stretched by 3D transformations. The default is bilinear filtering. Texture Flip: Flip the image. Texture rotation: Rotate the image. Non-power of 2 scaling: When the texture is not a power of 2, the operation mode is scaled to the power of 2. Readable and writable: When enabled, texture pixels can be dynamically read using scripts. Skin related settings: Nine Gongge: Nine Gongge information. Button skin state: The number of states of the button skin. For the texture format, please refer to the document \"Texture Compression\". 2. Quickly create files There are two quick ways to create files quickly Click + to create quickly Click on the blank space to quickly create Quick creation is a way for developers to quickly create special types of files, as shown in animation 2-1 (Animation 2-1) Click on the blank space in the project resource panel and select Create. You can also create it quickly, as shown in animation 2-2. (Animation 2-2) The files quickly created here will only be in the assets directory. If you want to put them in a certain directory, you can drag the files and put them in, as shown in the animation 2-3. (Animation 2-3) 2.1 Create folder As shown in Figure 2-3, in the quick creation menu, click \"Folder\" to create a folder under assets, and you can modify the folder name. (Figure 2-3) 2.2 Create prefab In the quick creation menu, click \"Prefab 2D\" and \"Prefab 3D\" to create prefab files. 2.2.1 Prefab 2D As shown in Figure 2-4, after creating the 2D prefab, click to open it. The prefab has only one Box root node, which is used for 2D development. (Figure 2-4) At the same time, we can also change the Box component to a Dialog component, as shown in animation 2-5 (Animation 2-5) Dialog is a pop-up window panel that can be set to achieve a pop-up window effect. 2.2.2 Prefab 3D As shown in Figure 2-6, after creating the 3D prefab, click to open it. The prefab only includes Sprite3D objects and is used for 3D object development. (Figure 2-6) Usually 3D prefabs are used to create 3D node objects that can be reused, such as the protagonist, enemies, etc. in the scene. 2.3 Create scene (scene) As shown in Figure 2-7, in the quick creation menu, click \"scene\" to quickly create a scene under assets. (Figure 2-7) 2.4 Create shader 2.4.1 Shaders As shown in Figure 2-8, in the quick creation menu, clicking \"Shader\" will choose to create five types of shader files. (Figure 2-8) By creating a shader, developers can modify the shader to use a custom shader, as shown in Figure 2-9 (Figure 2-9) 2.4.2 Shader Blueprint As shown in Figure 2-10, in the quick creation menu, click \"Shader Blueprint\" to quickly create a shader blueprint file under assets. (Figure 2-10) Double-click the blueprint file to edit it through the visual window (Figure 2-11) 2.4.3 Shader Blueprint Function As shown in Figure 2-12, in the quick creation menu, click \"Shader Blueprint Function\" to quickly create a shader blueprint function file under assets. (Figure 2-12) Double-click the blueprint function file to edit it through the visual window (Figure 2-13) 2.5 Create materials and configurations 2.5.1 Material file As shown in Figure 2-14, in the quick creation menu, clicking \"Material\" will choose to create eight types of material files. (Figure 2-14) By creating Material, developers can modify the material for easy and quick use. 2.5.2 Cube texture As shown in Figure 2-15, in the quick creation menu, click \"TextureCube\" to quickly create a TextureCube file under assets. (Figure 2-15) Click on the Cubemap file to configure (Figure 2-16) Usually Cubemap file is used to configure the texture of the sky box, as shown in Figure 2-17 (Figure 2-17) For specific instructions on how to use TextureCube, developers please refer to the detailed explanation of the skybox in [\"3D Scene Environment Settings\"] (../../../IDE/sceneEditor/environment/readme.md). 2.5.3 Rendering texture As shown in Figure 2-18, in the quick creation menu, click \"RenderTexture\" to quickly create a RenderTexture file under assets. (Figure 2-18) RenderTexture rendering texture is used to render 3D scenes into 2D textures and is used in mixed 2D development, as shown in animation 2-19 (Figure 2-19) For details on how to use RenderTexture, developers please refer to the detailed explanation in \"Mixed Use of 3D\" 2.5.4 Animation mask As shown in Figure 2-20, in the quick creation menu, click \"AvatarMask\" to create an AvatarMask file. (Figure 2-20) By creating an AvatarMask, developers can use it to describe the animation layer mask. For details, please refer to Section 3.5.1 of [\"Animation State Machine Detailed Explanation\"] (../../../IDE/animationEditor/aniController/readme.md) . 2.6 Create image type 2.6.1 Lightmap baking settings As shown in Figure 2-21, in the quick creation menu, click \"Lightmap Baking Settings\" to create a LightingSettings file. (Figure 2-21) By creating LightingSettings, developers can set lighting properties for baking light maps (Figure 2-22) For specific instructions on how to use lighting settings, developers please refer to \"3D Scene Environment Settings\" for detailed explanations on baking light maps 2.6.2 Automatic album setting As shown in Figure 2-23, in the quick creation menu, click \"Automatic Atlas Settings\" to create the AtlasConfig file. (Figure 2-23) By creating an AtlasConfig, developers can use it to automatically package atlases For details on how to use automatic packaging of atlases, developers please refer to \"Web Publishing\" for detailed explanations on atlas packaging. 2.7 Create animation state machine In the quick creation menu, click \"Animation State Machine 2D\" and \"Animation State Machine 3D\" to create an animation state machine. 2.7.1 2D animation state machine As shown in Figure 2-24, after creating the animation state machine 2D, click to open it (Figure 2-24) 2.7.2 3D animation state machine As shown in Figure 2-25, after creating the animation state machine 3D, click to open it (Figure 2-25) The animation state machine defines animation states and switching conditions between animation states to drive objects to play different animations and show different behaviors. For specific instructions on how to use the animation state machine, developers please refer to the detailed explanation in [\"Animation State Machine Detailed Explanation\"] (../../../IDE/animationEditor/aniController/readme.md) 3. Search panel Since there are many resources under assets, the most common way is to search through them. 3.1 Text search By entering \"button\" in the search box, you can quickly retrieve the Button component and quickly drag it into the 2D scene, as shown in animation 3-1 (Animation 3-1) 3.2 Type search By clicking the type search button and selecting the file type, for example, selecting \"LightingSettings\", you can quickly retrieve all lighting settings files, as shown in animation 3-2 (Animation 3-2) 4. Directory Settings Panel 4.1 Two-column display During the development process, there are often too many files in the directory, and repeated browsing of the directory will be cumbersome. This can be solved by clicking the \"Two Column Display\" button, as shown in Figure 4-1. (Animation 4-1) 4.2 Collapse all If there are too many open directories, developers can click \"Collapse All\" to close all directories and restore only the assets and src directories, as shown in animation 4-2. (Animation 4-2) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:45:26 "},"basics/IDE/Inspector/readme.html":{"url":"basics/IDE/Inspector/readme.html","title":"Inspector","keywords":"","body":"Property setting panel description1. General functions1.1 Add components1.2 Previous, next1.3 Lock2. Application scenarios2.1 Node attribute settings2.2 Resource attribute settings2.3 Code previewProperty setting panel description 1. General functions 1.1 Add components In the property settings panel, you can click Add Component to add corresponding components to the node, as shown in Figure 1-1. (Picture 1-1) Components that can be added to 3D nodes include: animation (Timeline Animation, Animation State Machine), 3D Physics, Grid, special effects (particle, tailing, Pixel Line), Light, rendering (UI3D, Reflection Probe, Volume Global Illumination, Static Batch, LOD group), Custom component script, New component script. Components that can be added to 2D nodes include: animation (Timeline Animation, Animation State Machine), 2D Physics, Custom Component Script, New component script. \"Custom component script\" is to add an existing script file; \"New component script\" is to create a new script file. 1.2 Previous, next As shown in Figure 1-2, click to return to the previous node you viewed, and click > to view the node you saw before switching. (Figure 1-2) 1.3 Lock As shown in the animated picture 1-3, click Lock to lock the property panel, and the property setting panel will not switch when switching nodes. (Animation 1-3) 2. Application scenarios 2.1 Node attribute settings 2.1.1 General attribute settings 1,activate Both 2D nodes and 3D nodes have activation functions. When the option shown in Figure 2-1 is unchecked, the node will turn gray in the hierarchy panel, and if the parent node is not activated, the child nodes will be deactivated. (Figure 2-1) After deactivation, the 3D nodes will not be displayed, even when running, as shown in animation 2-2. (Animation 2-2) However, for 2D nodes, deactivation does not affect the node itself, but only deactivates the node's script. For example, as shown in the animation in Figure 2-3, use a script to change the displayed text. The text will not be changed if it is not activated. (Animation 2-3) 2, Double naming Nodes can be renamed as shown in Figure 2-4. (Animation 2-4) 2.1.2 3D nodes static: In the game scene, each Sprite3D has two states: static or dynamic. When an object is marked as static, it ensures that the object is a static and non-moving object in the game scene, and then during the running process of the game Let the game have a smoother running experience. For detailed introduction, please refer to Section 2.3 of [\"Using 3D Sprites\"] (../../../3D/Sprite3D/readme.md). Layer： Mask layer, the rendering camera can control the visible mask layer according to the mask layer, and control whether the sprite is rendered or not. For detailed introduction, please refer to Section 2.4 of [\"Using 3D Sprites\"] (../../../3D/Sprite3D/readme.md). Scene3D has no Layer property. 2.1.3 2D nodes 1, define variables After checking, save the scene and you can manage the nodes in UI runtime. For detailed instructions, please refer to Section 2.3 of \"UI Runtime\". There are no variable properties defined in Scene2D. 2, Scene2D unique properties UI runtime: Runtime entry, for details, please refer to \"UI Runtime\". Use design width and height: If checked, the width and height set in the `Project Settings' panel will be used; if not checked, the width and height can be customized. Preload resource list: You can add some resources that need to be preloaded. 2.1.4 Prefab When the node is a prefab, it will have the following properties: Edit: Enter the editing page of the prefab. Position: Position the prefab resource file in the project resource panel. Overwrite properties: modifications can be overwritten into prefabs. For details about prefabs, please refer to \"Prefab Module\". 2.2 Resource attribute settings In the Resource Panel, click on the files of the following resource types to set the corresponding properties in the Property Settings panel. Picture: You can set the imported picture attributes. For details, please refer to Section 1.4 of Project Resource Panel Instructions. Bitmap font: Bitmap font can be customized. For details, please refer to Section 2.2 of Advanced Text Use. Automatic atlas: An atlas can be automatically generated after publishing. For details, please refer to Section 3.3.1 of Web Publishing. Material: Custom materials can be created. For details, please refer to Material Editing Module. Animation: There are 2D animation files and 3D animation files. For details, please refer to Detailed Explanation of Timeline Animation Editing. Light map baking: You can set lighting attributes. For details, please refer to Section 6 of 3D Scene Environment Settings. Third-party JS files: Provides the function of separate import. For details, please refer to Section 2 of Referencing Third-Party JS Modules. Model: Supported model files with model suffixes of fbx and gltf. For details, please refer to Import and Use of Models and Animations. RenderTexture: You can modify the properties of the rendering texture. For details, please refer to the second section of Mixed Use of 3D. AvatarMask: Developers can use it to set action masks. For details, please refer to Section 3.5.1 of Animation State Machine Detailed Explanation. 2.3 Code preview As shown in Figure 2-5, select the script file in the src folder to preview the code. Developers can use a code editor (VS Code is recommended) to make modifications. If it is referencing third-party JS files, you can set up separate imports. (Figure 2-5) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:08:10 "},"basics/IDE/Game/readme.html":{"url":"basics/IDE/Game/readme.html","title":"Game","keywords":"","body":"Preview run panel description1. Project preview1.1 Preview run1.2 Entrance to preview operation2. The role of IDE preview run panel2.1 Not running2.2 Runtime3. Preview the function of running panel3.1 Resolution3.2 Horizontal and vertical screens3.3 Zoom, restore 1X3.4 MutePreview run panel description 1. Project preview 1.1 Preview run Project preview is used to view the running effect of the project in different environments. Project preview is divided into three modes, namely in-IDE preview, browser preview, and mobile preview. As shown in Figure 1-1. (Picture 1-1) For preview-related shortcut keys, please refer to Section 1.5 of [\"Comprehensive Collection of IDE Shortcut Keys and Mouse Interaction Operations\"] (../../../basics/IDE/shortcutKeyCombinations/readme.md). After opening the preview in the IDE, two buttons will appear, namely Restart and Open Developer Tools: Restart, as the name suggests, restarts the current preview running scene, as shown in Figure 1-2. (Figure 1-2) Clicking to open the developer tools will bring up the Developer Tools, which is convenient for developers to debug. You can also open the developer tools through the Ctrl + Alt + I shortcut key. (Figure 1-3) 1.2 Entrance to preview operation After the startup scene is released online in Build Release, it is undoubtedly the first to be loaded and displayed as the entrance to the project. As shown in Figure 1-4, set the startup scenario in the build release. (Figure 1-4) However, when debugging the project in preview and run, sometimes you do not want to display the startup scene first, which will make the debugging process very long. Therefore, by clicking the drop-down arrow in the red circle in Figure 1-5, you can click the check box to use Start Scene or Current Scene as the entry for preview running. (Figure 1-5) The current scene refers to the scene currently open for editing in the IDE. 2. The role of IDE preview run panel 2.1 Not running First Customize the interface layout and drag the preview running window as shown in Figure 2-1 to facilitate observation of the effect. (Animation 2-1) The advantage of this layout is that it can facilitate developers to perform UI layout and typesetting. This is also a function of the preview running window when it is not running. As shown in the animation 2-2, in the scene panel, the 2D and 3D interfaces cannot be displayed at the same time. If I want to display a label under the model and need to align their positions, then I need to preview the run window Observe the effect. (Animation 2-2) In fact, before clicking the run button, the preview run window only does not execute the script, and other effects will be displayed. For example, the particle effect is shown in the animation 2-3. However, for the sake of efficiency, the particle effect is not displayed in real time in the preview running window. It is refreshed every once in a while. (Animation 2-3) 2.2 Runtime After clicking Run, the script will also be run. As shown in the animation 2-4, clicking the run button will automatically jump to the preview run interface. Here, a script is added to the Main Camera to control the camera through the mouse and keyboard (refer to the document [\"Using 3D Elf\"] (.. /../../3D/Sprite3D/readme.md) Section 6), if you do not click to run, then this script will not be executed. (Animation 2-4) 3. Preview the function of running panel 3.1 Resolution When not running, as shown in animation 3-1, the resolution at which the preview runs is the resolution in the project settings. (Animation 3-1) If it is running, there are many options to choose from for resolution, as shown in the animated picture 3-2. You can also create your own options. Dimensions is the name of the option. After clicking the check mark, you can set the required resolution value. (Animation 3-2) 3.2 Horizontal and vertical screens When running, click the icon as shown in Figure 3-3 to switch between horizontal and vertical screen display. (Animation 3-3) 3.3 Zoom, restore 1X The preview run panel supports scaling and can be quickly restored to 1x the size. The operation is as shown in the animation 3-4. (Animation 3-4) 3.4 Mute If there is audio in the project, click the icon as shown in Figure 3-5 to mute the demo while the preview is running. (Animation 3-5) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:52:49 "},"basics/IDE/shortcutKeyCombinations/readme.html":{"url":"basics/IDE/shortcutKeyCombinations/readme.html","title":"shortcutKey Combinations","keywords":"","body":"IDE shortcut keys and mouse interactive operations encyclopedia1. Common basic interaction1.1 Switch panel display level1.2 Common operations on files and nodes1.3 Common operations of the hierarchical panel1.4 Common operations of levels and scenes1.5 Run preview function1.6 Property panel operation2. 2D scene window interaction3. 3D scene window interaction3.1 Operating the window camera3.2 Operation model4. Timeline animation editing shortcut keys4.1 Shortcut keys for the timeline frame panel4.2 Shortcut keys for the timeline curve panel5. Blueprint Editor Shortcut Keys5.1 Generate node shortcut keys5.2 Blueprint mouse interactionIDE shortcut keys and mouse interactive operations encyclopedia Author: charley The basic interaction of IDE is divided into keyboard input, shortcut keys, mouse interaction, and the function combination of mouse and keyboard. This article will introduce the basic interaction of IDE, understand all function key combinations, give full play to the advantages of both hands, and improve development efficiency. The keys in the document are all based on the Windows system keyboard. The Command key on the Mac system keyboard corresponds to the Ctrl key and will not be explained separately. 1. Common basic interaction The hierarchy panel, property panel, project panel, etc. are all places where almost every function can be used, so we first introduce these common basic interactions. 1.1 Switch panel display level In the IDE's function panel, developers can drag and drop the layout at will. When they are in the same window, the display level will be determined based on the click switching of the panel label. As shown in Figure 1-1. (Animation 1-1) In addition to clicking on the panel label to switch, we can also use the following shortcut keys to switch to some commonly used panels: Function name Operation Scene panel Scene Ctrl + 1 Run panel Game Ctrl + 2 Property panel Inspector Ctrl + 3 Hierarchy panel Ctrl + 4 Project resource panel Project Ctrl + 5 Console panelConsole Ctrl + 6 Timeline panel Timeline Ctrl + 7 1.2 Common operations on files and nodes 1.2.1 Rename: F2 Whether it is the name of the node or the file or folder, use the shortcut key F2 to enter the rename mode. If it is a mouse operation, click to select, wait half a second and then click again, which is also equivalent to F2. 1.2.2 Copy, paste, delete, select Whether in the hierarchy panel, project panel, or scene panel, you can use the following shortcut keys to select a node object or file: Function name Operation copy Ctrl + C Paste Ctrl + V Delete Delete Select all Ctrl + A Select a single Left click of the mouse Multiple selection Ctrl + left mouse click Continuous multiple selection Shift + left mouse click 1.3 Common operations of the hierarchical panel 1.3.1 Create empty node In addition to creating nodes through the right-click menu of the mouse, you can also use the following shortcut keys to quickly create empty nodes. Function description Operation Under the root node, create an empty child node Ctrl + shift + N Create an empty child node for the current selected node Everything + shift + N Create an empty parent node for the current selected node (multiple selections possible) Ctrl + shift + G The empty node of 2D is Sprite, and the empty node of 3D is Sprite3D. 1.3.2 Expand all sub-nodes: Alt + left mouse click In the case of forward expansion, click the triangular arrow in front of the node to expand a layer of child nodes. When you use the Alt + left mouse button click combination function key, you can directly expand all hierarchical nodes below it, as shown in the animation 1-2. (Animation 1-2) 1.3.3 Sequence adjustment of hierarchical panels 1. Drag and drop as a subordinate node of the target node When selecting a node and holding down the left mouse button, drag the node to the target node. When the target node displays a green rectangular frame, release the left mouse button to become a child node of the target node. The effect is as shown in the animation 1. -3 shown. (Animation 1-3) 2. After dragging it to the same level of the target node When a node is selected and the left mouse button is pressed, drag the node to the target node. When the green line is below the target node, release the left mouse button to change the position of the node to the same level behind the target node. The effect is shown in the animation 1-4. (Animation 1-4) 3. Drag and drop to the target node before sibling When a node is selected and the left mouse button is pressed, drag the node to the target node. When the green line is above the target node, release the left mouse button to change the position of the node to the front of the target node at the same level. The effect is shown in the animation 1-5. (Animation 1-5) It should be noted that 2D nodes can only be dragged arbitrarily under Scene2D, 3D nodes can only be dragged arbitrarily under Scene3D, and 2D and 3D nodes cannot be dragged under each other's nodes. 1.4 Common operations of levels and scenes 1.4.1 Window focus of 3D nodes: F Whether it is the hierarchy panel or the scene, after selecting a node, use the shortcut key F to focus the window camera on the node. The effect is shown in the animation 1-6. (Animation 1-6) Double-click a 3D node with the left mouse button to focus the window camera on the node. 1.4.2 Copy and paste nodes: Ctrl + D Whether it is a 2D node or a 3D node, after selecting the node in the hierarchy panel or scene panel, you can copy and paste the node through the shortcut key Ctrl + D. 1.5 Run preview function After the developer completes editing in the LayaAir IDE, three running preview methods are provided, namely running preview in the IDE, running preview in the browser, and running preview by scanning the QR code on the mobile phone. The buttons are shown in Figure 1-7. (Figure 1-7) In addition to mouse click operations, the above functions also provide the following shortcut keys: Function description Operation Run preview in IDE Ctrl + P Run preview in browser Ctrl + Shift + P Scan code with mobile phone to run preview Ctrl + Shift + O 1.6 Property panel operation 1.6.1 Sliding input of attribute values When the attribute value is a numeric type, and the mouse moves over the input box, the mouse style will be converted to a two-way arrow style. At this time, you can slide in the direction of the arrow to change the value, or you can click on the direct input box to enter it through the keyboard. 1.6.2 Attribute saving: Ctrl + S Whether you change attributes in the attribute panel or operate in the scene, the attribute values ​​will change. If you confirm the changes, you can save them with the shortcut key Ctrl + S. Saving is universal, and the subsequent functions will not be repeatedly introduced for saving. 2. 2D scene window interaction When in a Scene2D node or 2D Prefab node, the 2D scene view window is launched. The following shortcut keys are currently supported: Function description Operation Pan view stage Middle click and long press and drag, right click and long press and drag Scroll window content up and down Mouse wheel Zoom window content Ctrl + mouse wheel The effect is shown in the animation 2-1: (Animation 2-1) 3. 3D scene window interaction In 3D scenes, there are mainly two types of basic operations. First, changing the camera position and angle of the scene window allows developers to observe the 3D scene world just like their own eyes. The second is to change the position and angle of the model and place the model in an appropriate position in the scene. For details on 3D scene window interaction, please view the document Basic Interaction of 3D Scene Editing. 3.1 Operating the window camera 3.1.1 Rotate window camera: right mouse button In a 3D scene, just keep pressing the 'right mouse button' to enter the window camera rotation mode, and release the 'right mouse button' to exit the window camera rotation mode. In this mode, by moving the mouse in the direction of the screen, you can change the angle of the window camera and observe the entire scene from any angle. The effect is as shown in animation 3-1. (Animation 3-1) 3.1.2 Spatial displacement window camera: When you hold down the right mouse button + keyboard function keys, you can press the camera up, down, left, and back. The specific function keys are as follows: Function description Operation Camera up displacement Right mouse button + E Camera Down displacement Right mouse button + Q Camera left displacement Right mouse button + A Camera right displacement Right mouse button + D Camera forward displacement Right mouse button + W Camera backwards displacement Right mouse button + S The effect of shifting the window camera is shown in Figure 3-2. (Animation 3-2) Up, down, front, left, right, is a relative direction. No matter it is rotated to any angle, it will be displaced in this relative direction. Displacement window camera acceleration: On the basis of the displacement window camera, hold down Shift to superimpose, and you can accelerate the movement based on the original function. The operation keys are: right mouse button + shift + (E, Q, A, D, W, S) 3.1.3 Displace the window camera in the screen: Q \\ middle mouse button In addition to using the right mouse button + keyboard function keys (E, Q, A, D) to move the window camera up, down, left, and right, you can also use the shortcut key Q or the middle mouse button to start the screen displacement in any direction. When using the shortcut key Q, press the left mouse button and drag it to move the window camera in any direction on the screen. The effect is as shown in the animation 3-3. (Animation 3-3) To exit this mode, you need to use the shortcut keys of other modes, unless you need to continuously use this mode to move the window camera. Otherwise, it is recommended to use the middle mouse button to initiate screen displacement in any direction. The middle mouse button mode will only enter this mode when pressed and dragged. Release the middle mouse button and it will automatically return to other modes. 3.1.4 Window camera zoom: mouse wheel Window camera zoom is essentially the front-to-back displacement of the window camera. Because during the displacement process, the object is observed based on the perspective principle of near and far, and there is an illusion of zooming, so it is called a zoom window camera. The effect is shown in the animation 3-4. (Animation 3-4) 3.1.5 Rotate the window camera around the focus center: Alt + left-click drag When observing or operating a specific model, we may need to find a suitable angle that is not frontal. At this point, none of the methods introduced before are inconvenient. So any rotation around the target is the most suitable operation. Before we can rotate the window camera, the first thing we need to do is focus and center the model on the window camera. The shortcut key for focus is F, which was introduced in 1.4.1 above. After focusing, you can rotate around the focus center by dragging the left button to any angle through the combination of Alt + left button. The effect is as shown in the animation 3-5. (Animation 3-5) 3.2 Operation model There are four tools for operating models, namely displacement, rotation, scaling, and mixed use. Different tool modes can be started through the shortcut keys W, E, R, T. Shortcut key name Button Model Displacement Tool W Model Rotation Tool E Model scaling tools R Hybrid Edit Model T 3.2.1 Model displacement tool: W After entering the model displacement tool mode through the shortcut key W, red, green and blue axes and pieces will appear on the model. The three axes of red, green, and blue represent the three directions of X, Y, and Z respectively. The color of the axis corresponds to the coordinate axis in the upper right corner. The direction pointed by the arrow is the positive direction. Dragging one of the axes will cause the model to move in the positive and negative directions of the axis. The effect is as shown in the animation in Figure 3-6. (Animation 3-6) Pay attention to the attribute panel. If the model does not have any rotation (rotation is all 0), drag one of the axes, and only the attribute value of that axis will change. If there is rotation, it will affect other axis attribute values. Three adjacent faces, blue is the XY face, green is the XZ face, and red is the YZ face. By dragging one of the faces, the model can be displaced arbitrarily within the range of the face, as shown in the animation in Figure 3-7. (Animation 3-7) 3.2.2 Model rotation tool: E After entering the model rotation tool mode through the shortcut key E, red, green and blue intersecting arcs and an outer white circle will appear on the model. When the mouse is drawn over the model, a translucent circle will also appear. The red, green, and blue arcs represent the directions of the X, Y, and Z axes respectively, and the colors correspond to the coordinate axes in the upper right corner. After selecting one of the arcs, it will turn into a complete circle, which means rotation along that axis. The effect is as shown in the animated picture 3-8. (Animation 3-8) The outer white circle is based on the vertical rotation of the screen, and the effect is shown in the animation 3-9. (Animation 3-9) If the mouse is dragged on the translucent circle, it can be rotated at any angle, as shown in the animation in Figure 3-10. (Animation 3-10) 3.2.3 Model scaling tool: R After entering the model zoom tool mode through the shortcut key R, there are not only red, green and blue axes on the model, but also a central white block and an outer white circle. The red, green, and blue axes represent the directions of the X, Y, and Z axes respectively. Pulling one of the axes will scale the mode on that axis. The effect is as shown in the animation 3-11. (Animation 3-11) The white block in the center and the white circle in the outer layer are both scaled on three axes at the same time. The only difference between the two is the difference in scaling rate. The effect is shown in the animation 3-12. (Animation 3-12) 3.2.4 Model tool collection: T After entering the model tool collection through the shortcut key T, the model operation tools introduced above will be gathered together. The only thing to note is that in blending mode, the scaling of the center block is no longer retained. It can only be scaled overall through the outer white circle, and scaled from a single axis by pulling the squares on each axis. The effect is shown in animation 3-13. (Animation 3-13) 3.2.5 Multiple selection of models The multi-selection methods are box selection, Shift, and Ctrl. The frame selection of the model is to use the mouse to pull up the rectangular area of ​​the screen. As long as it is within the rectangular area, it will be selected regardless of the distance. In addition to box selection, you can also use Shift or Ctrl combined with mouse clicks to perform continuous multiple selections. Whether it is single selection or multiple selection, the selected model will have a red border. 4. Timeline animation editing shortcut keys 4.1 Shortcut keys for the timeline frame panel Function description Button Insert blank frame F5 Delete blank frames Shift + F5 Delete keyframes Delete Copy keyframes Ctrl + C Paste keyframes Ctrl + V When the mouse is in the timeline frame panel operation, vertical scrolling display properties Ctrl+wheel 4.2 Shortcut keys for the timeline curve panel Function description Button Lock the frame scale panel (no scaling), centered on the mouse pointer, without limiting the precision of the scaling attribute scale panel. Ctrl+Scroll Wheel Lock the attribute scale panel (no scaling), center the mouse pointer, and scale the precision of the frame scale panel without limit. (Unlimited zoom will cause the zoom to no longer be centered on the mouse pointer before zooming when the zoom is stretched to 0 frames visible). Alt+scroll wheel Locks the attribute scale panel (without zooming), centered on the mouse pointer, and limits the accuracy of the scaled frame scale panel. (Always keep the mouse pointer as the center for zooming. When the zoom is stretched to 0 frames and visible, the scale precision is prohibited from being reduced and only the scale precision is allowed to be enlarged.) Alt+Shift+Scroll Wheel Keep holding down the Shift key to move keyframes and always maintain horizontal displacement. Both single and batch movements are valid. Shift Keep holding down the Ctrl key to move keyframes and always maintain vertical displacement. Both single and batch movements are valid. Ctrl Since there are detailed documentation related to timeline animation, I will not introduce it here. If you want to know more, please go to Detailed Explanation of Timeline Animation Editing document. 5. Blueprint Editor Shortcut Keys 5.1 Generate node shortcut keys When you press and hold the shortcut key on the keyboard and click with the left mouse button, you can quickly generate different types of blueprint nodes. Function description Shortcut key combinations Quickly generate Float nodes 1 + left mouse button Quickly generate Vector2 nodes 2 + left mouse button Quickly generate Vector3 nodes 3 + left mouse button Quickly generate Vector4 nodes 4+ left mouse button Quickly generate If nodes i + left mouse button Quickly generate Boolean nodes b + left mouse button Quickly generate sampler2D nodes t + left mouse button 5.2 Blueprint mouse interaction Function description Button Move the blueprint node as a whole Middle mouse button\\right button, press and drag Overall zoom blueprint node Mouse wheel Since there are detailed documentation related to the blueprint editor, I will not introduce it here. If you want to know more, please go to Blueprint Editing Module document. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 17:20:30 "},"basics/common/readme.html":{"url":"basics/common/readme.html","title":"Engine General Basics","keywords":"","body":"Engine general basisEngine general basis The general foundation of the engine refers to the basic functions of the engine that will be used in both 2D and 3D projects. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:11:27 "},"basics/common/terms/readme.html":{"url":"basics/common/terms/readme.html","title":"basics","keywords":"","body":"Basic concepts of engine use1. Canvas2. Stage3. Object4. Node, display list, display object, container objectBasic concepts of engine use Author : Charley 1. Canvas The canvas is the browser's canvas, as shown in Figure 1: (figure 1) All visible images of the LayaAir engine game are drawn frame by frame, and the results are displayed during continuous playback. The number of frames played per second represents the performance indicator of whether the game is smooth. The canvas is the container for each frame of drawing displayed by the engine. Without the canvas, it is like a painter without drawing paper, and it is impossible to paint in thin air. The higher the frame number, the smoother the picture. Usually 60 frames is a full frame, but it will vary depending on the device. Some models can reach 90 frames or 120 frames. The size of the LayaAir canvas depends on the design width and height set by our game and the screen adaptation in the LayaAir engine, as shown in Figure 2. (figure 2) Under different model resolutions, the canvas size may vary. This knowledge will be introduced in the screen adaptation documentation. 2. Stage The stage is the Stage of the engine, and is the actual area used by the LayaAir engine to draw game images on the canvas and provide feedback on interactive events. You can imagine that a painter only paints in the center area of ​​a piece of paper (canvas), leaves only a little edge, or paints the entire paper. This planning can be understood in the engine as the size of the stage. The picture in the game is actually limited by the stage of the engine. If the stage is not full screen, the light canvas will be full screen, and the part beyond the stage will not be displayed. If the equipment is compared to a table and the canvas is drawing paper, even if the drawing paper covers the entire table, if it is stipulated that the painter can only paint in a certain area, then the artist will not go beyond that area when painting. Therefore, for games that require full-screen adaptation, not only must the size of the canvas reach the full screen size, but the size of the stage must also fill the size of the canvas. The size of the stage is also related to the design width and height and screen adaptation. The above adaptation document is also suitable for students who want to understand the concept of stage in depth. 3. Object Students with programming knowledge can all understand that in object-oriented programming, objects are instances of classes. In a broad sense, data with attribute structures or data structures that can set attributes can also be called objects, such as json objects and empty objects {}. 4. Node, display list, display object, container object In the LayaAir engine, the Node (node) class is the base class for all objects that can be placed in the display list. The 2D basic sprite Sprite and the 3D basic sprite Sprite3D both inherit from Node. Not only this, but all subclasses that inherit from Node. Or grandchild class, also called node, for example: Sprite node, Image node. Only node objects that inherit from a subclass or grandchild of Node can add child node objects. In nodes, visible objects such as pictures, text, animations, models, etc. are display objects. Some nodes themselves are not responsible for rendering and display, but are only used to mount child nodes. Such objects are called container objects. For example Sprite, Sprite3D, Box, etc. Sprite is special. When a texture resource is added, it becomes a display object. When no texture is added and is only used to mount child nodes, it is a container object. The display list is an abstract concept. The display list can be understood as a node tree based on the stage. Whether it is a display object or a container object, it is within the display list. The display list is used to manage all objects displayed when LayaAir is running. It should be noted that the two subclasses Sprite and Sprite3D inherited from Node are the 2D basic display object and the 3D basic display object respectively. The two cannot be mixed and added, which means that Sprite and its sub-nodes cannot be used as sub-nodes of Sprite3D, and Sprite3D and its sub-nodes cannot be used as sub-nodes of Sprite. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:01:16 "},"basics/common/Component/readme.html":{"url":"basics/common/Component/readme.html","title":"Component","keywords":"","body":"Entity Component System (ECS)1. What is ECS2. Built-in methods of component scripts2.1 Component life cycle methods2.2 Component event methods3. How components are exposed in the IDE3.1 Identification of component scripts @regClass()3.2 Identification of component properties @property()3.3 Executing life cycle method @runInEditor in IDE3.4 @classInfo()4. Using attributes in code4.1 Node type method4.2 Use of component types4.3 Prefab type attributesEntity Component System (ECS) Author: Charley, Gu Zhu, Meng Xingyu 1. What is ECS ECS is the abbreviation of Entity-Component-System, which is a data-driven game design pattern. LayaAir's ECS treats each display object node with a unique ID in the scene as an entity. Each entity can have one or more different component system scripts added to it. Here, the component system is composed of components and systems. Components only contain data, not logic. The logical behavior of game objects is controlled by the system, so the system is the logical control part of the entity, and the component is the data interface part between the system and the outside world. . LayaAir exposes the interface to the IDE through decorators, allowing developers to intuitively pass in data. The life cycle methods and event methods provided by the engine for the component system can serve as the entrance to system logic control. Developers can realize the complete functions of component system scripts by inheriting the engine's component script class Laya.Script. We usually refer to component system scripts as component scripts for short. Then add it to the entity through IDE or code to achieve complete ECS functions. Component scripts are in principle decoupled and have a single responsibility, so that multiple entities can share the same component system. 2. Built-in methods of component scripts After inheriting the engine's component script class Laya.Script, you can directly use the engine to provide built-in life cycle methods and event methods for component scripts. These methods can be used as the execution entry point for component script logic. As shown below: (Figure 2-1) Life cycle method of component script 2.1 Component life cycle methods Life cycle methods refer to methods that are automatically called during the creation, destruction, activation, and disabling of objects. When using custom component scripts, the following life cycle methods can be implemented to facilitate rapid development of business logic. A log can be printed in each method to facilitate testing by developers. Name Conditions onAdded is called after being added to the node. Unlike Awake, onAdded will be called even if the node is not activated onReset Reset component parameters to default values. If this function is implemented, the component will be reset and automatically recycled to the object pool to facilitate reuse next time. If there is no reset, no recycling will be performed onAwake Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once onEnable Executed after the component is enabled, such as after the node is added to the stage onStart Executed before onUpdate is executed for the first time, it will only be executed once onUpdate Executed when each frame is updated, try not to write large loop logic here or use the getComponent method onLateUpdate Executed when each frame is updated and executed after onUpdate. Try not to write large loop logic here or use the getComponent method onPreRender Executed before rendering onPostRender Executed after rendering onDisable Executed when the component is disabled, such as after the slave node is removed from the stage onDestroy Executed when manually calling node destruction The usage in the code is as follows: //Called after being added to the node. Unlike Awake, onAdded will be called even if the node is not activated. onAdded(): void { console.log(\"Game onAdded\"); } //Reset component parameters to default values. If this function is implemented, the component will be reset and automatically recycled to the object pool to facilitate reuse next time. If there is no reset, no recycling will be performed onReset(): void { console.log(\"Game onReset\"); } //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { console.log(\"Game onAwake\"); } //Executed after the component is enabled, such as after the node is added to the stage onEnable(): void { console.log(\"Game onEnable\"); } //Executed before executing update for the first time, it will only be executed once onStart(): void { console.log(\"Game onStart\"); } //Executed when each frame is updated, try not to write large loop logic here or use the getComponent method onUpdate(): void { console.log(\"Game onUpdate\"); } //Executed when each frame is updated, and executed after update. Try not to write large loop logic here or use the getComponent method. onLateUpdate(): void { console.log(\"Game onLateUpdate\"); } //Execute before rendering onPreRender(): void { console.log(\"Game onPreRender\"); } //Execute after rendering onPostRender(): void { console.log(\"Game onPostRender\"); } //Executed when the component is disabled, such as after the slave node is removed from the stage onDisable(): void { console.log(\"Game onDisable\"); } //Executed when manually calling node destruction onDestroy(): void { console.log(\"Game onDestroy\"); } The following takes a bullet script Bullet.ts in the \"2D Getting Started Example\" as an example to explain the life cycle method. The following is the code of this script file: const { regClass, property } = Laya; /** * Bullet script to implement bullet flight logic and object pool recycling mechanism */ @regClass() export default class Bullet extends Laya.Script { constructor() { super(); } onEnable(): void { //Set initial speed let rig: Laya.RigidBody = this.owner.getComponent(Laya.RigidBody); rig.setVelocity({ x: 0, y: -10 }); } onTriggerEnter(other: any, self: any, contact: any): void { //If touched, remove the bullet this.owner.removeSelf(); } onUpdate(): void { //If the bullet goes beyond the screen, remove the bullet if ((this.owner as Laya.Sprite).y In the game, when adding bullets to the stage, they must have an initial velocity each time they are added to the stage. However, if onEnable() is replaced with onAwake(), then the initial velocity will be invalid. onUpdate() is executed once every frame. If the bullet exceeds the screen, the bullet is removed. The if condition here is judged once every frame. onDisable() is triggered after the node is removed from the stage. When the bullet is removed beyond the screen, this method is triggered. Here, the bullet is recycled to the object pool. 2.2 Component event methods Event methods refer to methods that are automatically triggered based on conditions under certain specific circumstances. For example, a collision event is only triggered when an object collides. When using custom component scripts, the following event methods can be implemented to facilitate rapid development of business logic. 2.2.1 Physical events Name Conditions onTriggerEnter Execute when triggering starts onTriggerStay Execute when triggered continuously onTriggerExit Executed when the end trigger onCollisionEnter Executed when collision starts onCollisionStay Executed when collision continues onCollisionExit Executed when collision ends The usage in the code is as follows: //Execute when the trigger starts onTriggerEnter(other: Laya.PhysicsComponent | Laya.ColliderBase, self?: Laya.ColliderBase, contact?: any): void { } //Execute when triggered continuously onTriggerStay(other: Laya.PhysicsComponent | Laya.ColliderBase, self?: Laya.ColliderBase, contact?: any): void { } //Execute when the trigger ends onTriggerExit(other: Laya.PhysicsComponent | Laya.ColliderBase, self?: Laya.ColliderBase, contact?: any): void { } //Execute when collision starts onCollisionEnter(collision: Laya.Collision): void { } //Execute when collision continues onCollisionStay(collision: Laya.Collision): void { } //Executed when the collision ends onCollisionExit(collision: Laya.Collision): void { } The following uses an example of a small ball collision to demonstrate physical events. Here is a code snippet from the collision part of the program: //After the collision enters, the object changes color public onTriggerEnter(other:Laya.PhysicsComponent):void { (this.owner.getComponent(Laya.MeshRenderer).material as Laya.BlinnPhongMaterial).albedoColor = new Laya.Color(0.0, 1.0, 0.0, 1.0);//绿色 } //When collision continues, print log public onTriggerStay(other:Laya.PhysicsComponent):void { console.log(\"peng\"); } //After the collision leaves, the object changes back to its original color public onTriggerExit(other:Laya.PhysicsComponent):void { (this.owner.getComponent(Laya.MeshRenderer).material as Laya.BlinnPhongMaterial).albedoColor = new Laya.Color(1.0, 1.0, 1.0, 1.0);//白色 } As shown in the animation 2-2, onTriggerEnter is executed when the collision starts, the ball and the cube enter the collision, and the ball turns green; onTriggerStay is executed when the collision continues, and the log \"peng\" is printed; after the collision leaves, onTriggerExit is executed, and the ball becomes The original color of the cube changes to white. (Animation 2-2) 2.2.2 Mouse events Name Conditions onMouseDown Execute when mouse is pressed onMouseUp Executed when mouse is raised onRightMouseDown Executed when the right or middle mouse button is pressed onRightMouseUp Executed when the right or middle mouse button is raised onMouseMove Executed when the mouse moves on the node onMouseOver Executed when the mouse enters the node onMouseOut Executed when the mouse leaves the node onMouseDrag After the mouse is pressed on an object, it is executed when dragging onMouseDragEnd Press and hold an object with the mouse, drag it a certain distance, and then release the mouse button to execute onMouseClick Execute when mouse clicks onMouseDoubleClick Executed when the mouse double-clicks onMouseRightClick Executed when the mouse right button is clicked The usage in the code is as follows: //Executed when the mouse is pressed onMouseDown(evt: Laya.Event): void { } //Executed when the mouse is raised onMouseUp(evt: Laya.Event): void { } //Executed when the right or middle mouse button is pressed onRightMouseDown(evt: Laya.Event): void { } //Executed when the right mouse button or middle button is lifted onRightMouseUp(evt: Laya.Event): void { } //Executed when the mouse moves on the node onMouseMove(evt: Laya.Event): void { } //Executed when the mouse enters the node onMouseOver(evt: Laya.Event): void { } //Executed when the mouse leaves the node onMouseOut(evt: Laya.Event): void { } //After the mouse is pressed on an object, it is executed when dragging onMouseDrag(evt: Laya.Event): void { } //Hold down an object with the mouse, drag it a certain distance, and execute after releasing the mouse button. onMouseDragEnd(evt: Laya.Event): void { } //Execute when mouse clicks onMouseClick(evt: Laya.Event): void { } //Executed when the mouse double-clicks onMouseDoubleClick(evt: Laya.Event): void { } //Executed when the mouse right clicks onMouseRightClick(evt: Laya.Event): void { } Taking onMouseDown and onMouseUp as examples, add the following code to the custom component script \"Script.ts\": const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { /** * Executed when mouse is pressed */ onMouseDown(evt: Laya.Event): void { console.log(\"onMouseDown\"); } /** * Executed when the mouse is raised */ onMouseUp(evt: Laya.Event): void { console.log(\"onMouseUp\"); } } As shown in Figure 2-3, after adding the component script to the property panel of Scene2D, uncheck Mouse Through first, because if it is checked, mouse events under Scene2D will not respond. If it is a 3D scene, it will be passed to Scene3D. (Figure 2-3) Run the project, as shown in the animation 2-4. When the mouse is pressed, onMouseDown is executed and \"onMouseDown\" is printed; when the mouse is released, onMouseUp is executed and \"onMouseUp\" is printed. (Animation 2-4) 2.2.3 Keyboard events Name Conditions onKeyDown Executed when the keyboard is pressed onKeyPress Executed when the keyboard generates a character onKeyUp Executed when the keyboard is raised The usage in the code is as follows: //Execute when keyboard is pressed onKeyDown(evt: Laya.Event): void { } //Executed when the keyboard generates a character onKeyPress(evt: Laya.Event): void { } //Executed when the keyboard is raised onKeyUp(evt: Laya.Event): void { } Note: onKeyPress is executed when a character is generated, such as the letters \"a\", \"b\", \"c\", etc. This method will not be executed if keys such as up, down, left, and right keys, F1, F2, etc. are not character input keys. 3. How components are exposed in the IDE In LayaAir 3.0 IDE, if you want to display the properties of component scripts in the IDE, you need to use decorator rules to achieve this. 3.1 Identification of component scripts @regClass() Component scripts written by developers need to use the decorator identifier @regClass() before the class definition. The sample code is as follows: const { regClass } = Laya; @regClass() export class Script extends Laya.Script { } As shown in the animated picture 3-1, only when the above decorator identifier is used, the developer's customized component script will be recognized as a component by the IDE, and can be used in the Property Settings Panel of the node (entity) -> Add Component - > Custom component script added. (Animation 3-1) A TS file can only have one class using @regClass(). Classes marked with @regClass() will be compiled in the IDE environment, but when they are finally released, if the class is not referenced by other classes, has not been added to the node, or the prefab/scene it is in has not been released, Then this class will be clipped. 3.2 Identification of component properties @property() 3.2.1 General use of component properties When the developer wants to expose the properties of the component to external editors through the IDE, they can pass in data. The decorator identifier @property() needs to be used before the class attribute is defined. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript1 extends Laya.Script { //The standard way of writing decorator attributes, suitable for IDEs that need to display tips or Chinese aliases of attributes and other complete functional requirements @property({ type: String, caption: \"An alias for IDE display\", tips: \"This is a text object, you can only enter text\" }) public text1: string = \"\"; //Abbreviation of decorator attribute type, suitable for requirements that only define types @property(String) public text2: string = \"\"; constructor() { super(); } } @property() is the decorator identifier that the IDE identifies component attributes and displays on the IDE property panel. The type is the parameter that the decorator attribute identifier must carry. If we don't need to write a tips description for the attribute, we don't need to redefine an alias for the attribute to be displayed in the IDE, etc. Just follow the abbreviation of the above example. If there are syntax warnings in the abbreviation, please use a new version of IDE and solve it through the IDE's Developer -> Update engine d.ts file function, or use standard writing to solve it. 3.2.2 Use of decorators for property accessors Sometimes, developers control the reading and writing behavior of properties through property accessors (getters) and property setters (setters). When a property accessor and a property setter exist at the same time, the decorator's property identifier @property() can be used directly before the property accessor. At this time, the component properties are used in the same way as the conventional usage introduced in the previous section. All are readable and writable. If the script only has a property accessor, then this property is read-only and can only be displayed in the IDE, but cannot be edited. The sample code for using a decorator with both getter and setter is as follows: const { regClass, property } = Laya; @regClass() class Animal { private _weight: number = 0; @property( { type : Number } ) get weight() : number { return this._weight; } set weight(value: number) { this._weight = value; } } 3.2.3 Whether to serialize and save After being defined as a component attribute through a decorator, by default, the attribute name and value will be serialized and saved to the scene file or prefab file where the component is added. For example, after adding custom components to scene.ls, open this scene.ls through vscode, and you can find the serialized and saved component attribute names and values. The effect is as shown in animation 3-2. (Animation 3-2) After serialization and saving, it is not only convenient to visually view and edit component property values ​​in the IDE. During the running phase, you can also directly use serialized stored values. For data with complex structures, directly using serialized values ​​can also save the overhead caused by data structure generation. Therefore, sometimes, even if it does not need to be displayed and edited on the property panel, it can be set as a component property through a decorator, and the value can be serialized and stored in the scene or prefab file. However, sometimes, our component properties are just for the convenience of understanding and adjustment in the IDE. When used, these values ​​​​are not actually useful, so we also provide control over whether to serialize and save. When the decorator attribute is defined, if serializable is passed in the object parameter as false, then the attribute will not be serialized. For example, the developer's requirement is to serialize and save the radian value, but the radian value is not intuitive when manually adjusting the value. At this time, the angle value can be directly entered in the IDE without saving it, and only the converted radian value is stored. . The sample code is as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { @property({ type: Number }) _radian: number = 0; //Underlined attributes will not appear on the IDE's attribute panel by default and are only used to store the input radian. @property({ type: Number, caption: \"angle\", serializable: false }) //Serializable is set to false here, so degree will not be saved to the scene file get degree() { return this._radian * (180 / Math.PI);//Since it is not serialized and saved, it is necessary to back-calculate the radian saved by _radian back to the angle for display in the IDE property panel } set degree(value: number) { this._radian = value * (Math.PI / 180);//Convert the input angle value into radians and store it in _radian. } onStart() { console.log(this._radian); } } 3.2.4 Whether component properties are displayed in the IDE By default, decorator attribute rules will only mark non-underlined class attributes as component attributes of the IDE. For attributes with underlines, they will not be displayed in the IDE. At this time, the only value of the component attribute is to save the value to the scene file. This is mentioned above, and the example is also applied. If there is no need to serialize and save the underlined properties to the scene file, there is no need to use a decorator. If the developer wants to display the underlined attributes in the IDE, this can be done. Pass the decorator attribute identifier into the object and set the parameter private to false. The sample code is as follows: @property({ type: \"number\", private: false }) _velocity: number = 0; The private parameter can not only cause underlined attributes to be displayed, but also set private to true so that attributes without underlines do not appear in the IDE's property panel. Here, we slightly modify the previous radian conversion example, the code is as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { @property({ type: Number , private: true }) radian: number = 0; //After private is set to true, radian will not appear on the IDE's property panel, but is only used to store the input radian. @property({ type: Number, caption: \"angle\", serializable: false }) //Serializable is set to false here, so degree will not be saved to the scene file get degree() { return this.radian * (180 / Math.PI);//Since it is not serialized and saved, it is necessary to back-calculate the radian saved by radian back to the angle for display in the IDE property panel. } set degree(value: number) { this.radian = value * (Math.PI / 180);//Convert the input angle value into radians and store it in radian. } onStart() { console.log(this.radian); } } 3.2.5 The type identified by the decorator attribute The type identified by the decorator attribute supports engine object types (for example: Laya.Vector3, Laya.Sprite3D, Laya.Camera, etc.), custom object types (requires marking ＠regClass()), and basic types of the TS language. 3.2.5.1 Engine object type The understanding of engine object types is relatively simple. After exposing component attributes, you can directly pass in the value of the corresponding type. For example, Laya.Sprite3D can only pass in 3D nodes. Trying to drag in 2D nodes or resources is prohibited. Examples of commonly used engine object types are as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { @property( { type:Laya.Camera } ) //Camera type private camera: Laya.Camera; @property( { type:Laya.Scene3D } ) //3D scene root node type private scene3D: Laya.Scene3D; @property( { type:Laya.DirectionLightCom } ) //DirectionLight component type private directionLight: Laya.DirectionLightCom; @property( { type:Laya.Sprite3D } ) //Sprite3D node type private cube: Laya.Sprite3D; @property( { type:Laya.Prefab } ) //Load the object obtained by Prefab private prefabFromResource: Laya.Prefab; @property( { type:Laya.ShurikenParticleRenderer } ) //ShurikenParticleRenderer component type private particle3D: Laya.ShurikenParticleRenderer; @property( { type:Laya.Node } ) //Node type private scnen2D: Laya.Node; @property( { type:Laya.Box } ) //Get the Box component private box: Laya.Box; @property( { type:Laya.List } ) //Get the List component private list: Laya.List; @property( { type:Laya.Image } ) //Get the Image component private image: Laya.Image; @property( { type:Laya.Label } ) //Get the Label component private label: Laya.Label; @property( { type:Laya.Button } ) //Get the Button component private button: Laya.Button; @property( { type:Laya.Sprite } ) //Get the Sprite component private sprite: Laya.Sprite; @property( { type:Laya.Animation } ) //Get the Animation component private anmation: Laya.Animation; @property( { type:Laya.Vector3 } ) //Laya.Vector3 type private vector3 : Laya.Vector3; } As shown in animation 3-3, drag the Image that has been added in the scene into the Image property entrance exposed by @property, so that this node is obtained, and then you can use code to control the properties of the Image in the script (reference Section 4.1). (Animation 3-3) 3.2.5.2 Custom object type A custom object type is to set a custom imported object. Exposes component properties as identified by the object's decorator property. For example, the following two TS codes: //MyScript.ts const { regClass, property } = Laya; import Animal from \"./Animal\"; @regClass() export class MyScript extends Laya.Script { @property({ type : Animal }) animal : Animal; } //Animal.ts const { regClass, property } = Laya; @regClass() export default class Animal { @property({ type : Number }) weight : number; } The Animal object is referenced in the component script MyScript, and the type identified by the decorator attribute is set to Animal. Although Animal is not a component script inherited from Laya.Script, it is referenced by the component script MyScript and exposed to the IDE, so the Animal class definition It was also necessary to mark @regClass() before. The properties identified by @property() under this class can also appear in the IDE property panel. 3.2.5.3 TS language basic types Finally, there are the commonly used basic types of TS language. However, it should be noted that the basic types need to be described using strings. Only numbers, strings, and Boolean types can be marked by their object types. Type Type writing demonstration Type Description Number type \"number\" You can also use Number to mark this type Single-line string text type \"string\" You can also use String to mark this type Boolean value type \"boolean\" You can also use Boolean to mark this type Integer type \"int\" Equivalent to { type: Number, fractionDigits: 0 } Positive integer type \"uint\" Equivalent to { type: Number, fractionDigits: 0 , min: 0 } Multiline string text type \"text\" Equivalent to { type: string, multiline: true } any type \"any\" Types will only be serialized and cannot be displayed or edited. Typed array type Int8Array, Uint8Array, Int16Array, Uint16Array, Int32Array, Uint32Array, Float32Array Supports 7 typed array types array type [\"number\"]、[\"string\"] Use square brackets to enclose the array element type, The sample code is as follows: const { regClass, property } = Laya; //enumerate enum TestEnum { A, B, C }; //Enumeration in string form enum Direction { Up = 'UP', Down = 'DOWN', Left = 'LEFT', Right = 'RIGHT' }; @regClass() export class Script extends Laya.Script { @property(Number)//Number type, equivalent to { type : \"number\" } num : number; @property(String)//Single-line string text type, equivalent to { type: \"string\"} str : string; @property(Boolean)//Boolean value type, equivalent to { type: \"boolean\"} bool : boolean; @property(\"int\")//Integer type, equivalent to { type: Number, fractionDigits: 0 } int : number; @property(\"uint\") //Positive integer type, equivalent to { type: Number, fractionDigits: 0, min: 0 } uint : number; @property(\"text\")//Multiline string text type, equivalent to { type: String, multiline: true } text : string; @property(\"any\")//Any type will only be serialized and cannot be displayed or edited. a : any; @property(Int8Array)//Typed array type, in addition to Int8Array, it also supports Uint8Array, Int16Array, Uint16Array, Int32Array, Uint32Array, and Float32Array. The usage methods are similar. i8a: Int8Array; @property({ type: [\"number\"] })//Array type, use square brackets to include the array element type arr1: number[]; @property({ type: [\"string\"] })//Array type, use square brackets to include the array element type arr2: string[]; //Ordinary enumeration types (can be abbreviated) will be displayed as a drop-down box for users to choose. @property(TestEnum) enum: TestEnum; //Enumerations in string form cannot use type abbreviations, such as: @property(Direction). The standard writing method must be specified with the type parameter below. @property({ type: Direction }) direc: Direction; //Dictionary type, you need to use array parameters to set the type. The Record type in the following example needs to be placed in the string as the first element of the array parameter. The second element of the array parameter is the type of the dictionary input value, used for Determine the input control type of the property panel @property({ type: [\"Record\", Number] }) dict: Record; } The sample effect is shown in the animation 3-4: (Animation 3-4) 3.2.6 Input controls for component property values The IDE has built-in number (number input), string (string input), boolean (multiple selection box), color (color box + color palette + color picker), vec2 (XY input combination), vec3 (XYZ input combination) , vec4 (XYZW input combination), asset (select resources), these input controls. Normally, the IDE will automatically select the corresponding attribute value input control based on the component attribute type. But in some cases, it is also necessary to force the input control to be specified. For example, the data type is string, but it actually expresses color. The default string editing control is not suitable. You need to set the parameter inspector of the component attribute identification here to \"color\". The sample code is as follows: //Displayed as color input (if the type is Laya.Color, you do not need to define it this way, if it is a string type, you need it) @property({ type: String, inspector: \"color\"}) color: string; Note: The color obtained according to the above method is the color value of the 2D component, for example: rgba(217, 232, 0, 1) The effect is shown in the animation 3-5: (Animation 3-5) If the inspector parameter is null, the property input control will not be constructed for the property, unlike if the hidden parameter is set to true. If hidden is true, it is created but not visible, and if inspector is null, it is not created at all. 3.2.7 Classification and sorting of component attributes By default, the properties of the component will be uniformly displayed under the property classification column with the component script name. The effect is shown in Figure 3-6: (Figure 3-6) If the developer wants to categorize certain attributes within the component, this can be achieved through the object parameter catalog identified by the decorator attribute. The sample code is as follows: @property({ type : \"number\" }) a : number; @property({ type: \"string\"}) b : string; @property({ type: \"boolean\",catalog:\"adv\"}) c : boolean; @property({ type: String, inspector: \"color\" ,catalog:\"adv\"}) d: string; As can be seen from the above code, when the same catalog name (\"adv\") is set for multiple attributes (c and d), they will be classified according to the catalog name. The effect is shown in Figure 3-7: (Figure 3-7) If we want to give this category a Chinese alias, we can do it through the parameter catalogCaption. The sample code is as follows (change the d attribute of the above example): @property({ type: String, inspector: \"color\" ,catalog:\"adv\", catalogCaption:\"Advanced Component\"}) d: string; The effect is shown in Figure 3-8: (Figure 3-8) When faced with multiple component attribute classifications, we can also customize the display order of columns through the parameter catalogOrder. The smaller the value is displayed in front, if not provided, it will be displayed in the order in which the attributes appear. The sample code is as follows: @property({ type : \"number\", catalog:\"bb\", catalogOrder:1 }) a : number; @property({ type: \"string\"}) b : string; @property({ type: \"boolean\", catalog:\"adv\"}) c : boolean; @property({ type: String, inspector: \"color\", catalog:\"adv\", catalogCaption:\"Advanced Component\", catalogOrder:0}) d: string; The effect is shown in Figure 3-9: (Figure 3-9) The attribute classification name catalogCaption and attribute classification sorting catalogOrder can be configured in the attribute with the same name in any catalog. There is no need to configure all attributes once. 3.2.8 Summary of decorator attribute identification parameters The above introduces the parameter functions of commonly used decorator attribute identifiers (those in bold are those that appeared above). Here we give an overview and summary of all parameters. Parameter name Parameter usage example Description name name: \"abc\" Generally no setting is required type type: \"string\" The type of value that can be entered in the component attribute, refer to the introduction above caption caption: \"angle\" The alias of the component attribute, commonly used in Chinese, does not need to be set, the component attribute name will be used by default tips tips: \"This is a text object, you can only enter text.\" Tips description of component attributes, used to further describe the function of the attribute and other purposes catalog catalog:\"adv\" Set the same value for multiple attributes and display them in the same column catalogCaption catalogCaption:\"Advanced Components\" The alias of the attribute classification column. If not provided, the column name will be used directly. catalogOrder catalogOrder:0 The display order of the columns, the smaller the value is displayed in front. If not provided, the order in which the attributes appear inspector inspector: \"color\" Attribute value input control, built-in: number, string, boolean, color, vec2, vec3, vec4, asset hidden hidden: \"!data.a\" true to hide, false to display. You can use Boolean values ​​directly, or you can use expressions to obtain Boolean operation results by putting conditional expressions into strings. In the string expression, data is a variable with a fixed name, which is a data collection of all registered attributes of the current type. All js syntax can be used in expressions, but engine-related types cannot be referenced, nor global objects such as Laya can be used. readonly readonly: \"data.b\" true means read-only. You can use Boolean values ​​directly, or you can use expressions to obtain Boolean operation results by putting conditional expressions into strings. (The format of the expression is the same as above) validator validator: \"if (value == data.text1) return 'cannot be the same as text1 value' \" You can use expressions and put them in strings. For example, in the example, if the value entered in the IDE is equal to the value of text1, \"Cannot be the same as the value of text1\" will be displayed serializable serializable： false Control whether component properties are serialized and saved, true: serialized and saved, false: not serialized and saved multiline multiline: true When the string type is used, whether it is multi-line input, true: yes, false: no password password: true Whether to enter a password, true: yes, false: no. Password entry will hide the entered content submitOnTyping submitOnTyping: false If set to true, each time a character is entered, it will be submitted. If set to false, it will only be submitted once after the input is completed and the text input box loses focus by clicking elsewhere. prompt prompt: \"Text prompt information\" Before entering text, there will be a prompt message in the text box enumSource enumSource: [{name:\"Yes\", value:1}, {name:\"No\",value:0}] Component properties display and enter values ​​in the form of drop-down boxes reverseBool reverseBool: true Invert the Boolean value. When the attribute value is true, the multi-select box is displayed as unchecked. nullable nullable: true Whether to allow null values, the default is true min min: 0 For numeric types, the minimum value of the number max max: 10 For numeric types, the maximum value of the number range range: [0, 5] When the numeric type is used, the component properties are displayed and the input value is displayed in the form of a sliding bar within a range step step: 0.5 When the numeric type is used, the minimum change precision value when the mouse slides or the wheel scrolls in the input box fractionDigits fractionDigits: 3 For numeric types, how many decimal places should be kept after the attribute value? percentage percentage: true When the range parameter is set to [0,1], the percentage can be set to true and displayed as a percentage fixedLength fixedLength: true When the array type is used, the array length is fixed and no modification is allowed. arrayActions arrayActions: [\"delete\", \"move\"] array type, you can limit the operations that can be performed on the array. If not provided, the array allows all operations, if provided, only the listed operations are allowed. The types provided are: \"append\", \"insert\", \"delete\", \"move\" elementProps elementProps: { range: [0, 10] } Applies to array type properties. Here you can define attributes of array elements showAlpha showAlpha: false When the color type is used, it indicates whether to provide modification of the transparency a value. true means provided, false means not provided defaultColor defaultColor: \"rgba(217, 232, 0, 1)\" For color types, define a non-null default color value colorNullable colorNullable: true For color type, set to true to display a checkbox to determine whether the color is null isAsset isAsset: true Indicates that this attribute refers to a resource assetTypeFilter assetTypeFilter: \"Image\" resource type, set the loaded resource type useAssetPath useAssetPath: true The attribute type is string, and when selecting a resource, this option determines whether the attribute value is the original path of the resource or in the format of res://uuid. The default is false. If it is true, it is the original path of the resource. It is generally not used because if the resource is renamed, the path will be lost. position position: \"before x\" The order in which attributes are displayed defaults to the order in which they appear in the type definition. Position can artificially change this order. The sentence patterns that can be used are: \"before x\", \"after x\", \"first\", \"last\" private private：false Control whether component properties are displayed in the IDE, false: displayed, true: not displayed addIndent addIntent:1 Increase indentation, the unit is level, note not pixels onChange onChange: \"onChangeTest\" When the property changes, call the function named onChangeTest. The function needs to be defined on the current component class The code examples are as follows (only those not introduced above are listed): //hide control @property({ type: Boolean }) a: boolean; @property({ type: String, hidden: \"!data.a\" })//Put the conditional expression !data.a in the string. If a is true (checked in the IDE), then !data.a returns false. At this time, the hidden attribute represents the display hide: string = \"\"; // read-only control @property({ type: Boolean }) b: boolean; @property({ type: String, readonly: \"data.b\" })//Place the conditional expression data.b in the string. If b is true (checked in the IDE), then data. b will return true. At this time, the readonly attribute indicates read-only. read: string = \"\"; //data checking mechanism @property(String) text1: string; @property({ type: String, validator: \"if (value == data.text1) return 'cannot be the same as a value' \" }) text2: string = \"\"; //Password input @property({ type: String, password: true }) password: string; //If true or default, the text input is submitted every time it is entered; otherwise it is only submitted when it is out of focus. @property({ type: String, submitOnTyping: false }) submit: string; //Input text prompt information @property({ type: \"text\", prompt: \"Text prompt information\" }) prompt: string; //Display as drop-down box @property({ type: Number, enumSource: [{name:\"Yes\", value:1}, {name:\"No\",value:0}] }) enumsource: number; //reverse boolean value @property({ type: \"boolean\", reverseBool: true }) reverseboolean : boolean; //Allow null value @property({ type: String, nullable: true }) nullable: string; //Control the precision and range of digital input @property({ type: Number, range:[0,5], step: 0.5, fractionDigits: 3 }) range : number; //displayed as percentage @property({ type: Number, range:[0,1], percentage: true }) percent : number; //Fixed array length @property({ type: [\"number\"], fixedLength: true }) arr1: number[]; //Operations allowed by the array @property({ type: [\"number\"], arrayActions: [\"delete\", \"move\"] }) arr2: number[]; //Enable the maximum and minimum values ​​to be limited when editing array elements @property({ type: [Number], elementProps: { range: [0, 100] } }) array1: Array; //If it is a multi-dimensional array, elementProps also needs to use multiple layers @property({ type: [[Number]], elementProps: { elementProps: { range: [0, 10] } } }) array2: Array>; //Does not provide modification of transparency a value @property({ type: Laya.Color, showAlpha: false }) color1: Laya.Color; //For color types, defaultColor defines a non-null default value. @property({ type: String, inspector: \"color\", defaultColor: \"rgba(217, 232, 0, 1)\" }) color2: string; //Display a checkbox to determine whether the color is null @property({ type: Laya.Color, colorNullable: true }) color3: Laya.Color; //Load the Image resource type and set the resource path format @property({ type: String, isAsset: true, assetTypeFilter: \"Image\" }) resource: string; //The x attribute appears before the testposition attribute @property({ type: String }) x: string; //You can use position to artificially arrange the testposition attribute to be displayed before the x attribute. @property({ type: String, position: \"before x\" }) testposition: string; //Increase indentation, the unit is level @property({ type: String, addIndent:1 }) indent1: string; @property({ type: String, addIndent:2 }) indent2: string; //When the property changes, call the function named onChangeTest @property({ type: Boolean, onChange: \"onChangeTest\"}) change: boolean; onChangeTest() { console.log(\"onChangeTest\"); } 3.2.9 Special usage of decorator attribute identification In addition to the basic parameter properties listed above, @property also has some special combinations. Type attribute nested array or dictionary Examples are as follows: @property([[\"string\"]]) test1: string[][] = [[\"a\", \"b\", \"c\"], [\"e\", \"f\", \"g\"]]; @property([[\"Record\", \"string\"]]) test2: Array> = [{ name: \"A\", value: \"a\" }, { name: \"B\", value: \"b\" }]; @property({ type: [\"Record\", [Number]], elementProps: { elementProps: { range: [0, 10] } } }) test3: Record = { \"a\": [1, 2, 3], \"b\": [4, 5, 6] }; @property([\"Record\", [Laya.Prefab]]) test4: Record; One of its important applications is to implement dynamic drop-down boxes. As mentioned in Section 3.2.8 above, there are two ways to implement a drop-down box: one is to set the attribute type to Enum, and the other is to set the enumSource to an array. Both methods can achieve a fixed drop-down option list, but if you want the option list to be dynamic, you can use the following method: //This attribute provides a get method to return the drop-down option. This data is generally only used in the editor, so the settings are not saved. @property({ type: [[\"Record\", String]], serializable: false }) get itemsProvider(): Array> { return [{ name: \"Item0\", value: \"0\" }, { name: \"Item1\", value: \"1\" }]; } //Set enumSource to a string, indicating to use the attribute with this name as the drop-down data source @property({ type: String, enumSource: \"itemsProvider\" }) enumItems: string; 3.3 Executing life cycle method @runInEditor in IDE In addition to exposing component properties on the IDE property panel, developers can also use the decorator identifier @runInEditor to trigger life cycle methods (onEnable, onStart and other component script life cycle methods) when the component is loaded in the IDE. The sample code is as follows: const { regClass, property, runInEditor } = Laya; @regClass() @runInEditor //The key point here is to put it before the class. Either @regClass() or @runInEditor comes first. export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) sp3: Laya.Sprite3D; constructor() { super(); } onEnable() { console.log(\"Game onStart\", this.sp3.name); } } Unless there are special needs, we do not recommend this. On the one hand, static objects are more conducive to editing in the IDE. On the other hand, because in order to optimize the performance of the scene editor, the frame rate refresh is much slower than normal operation, so the effect will be significantly different from normal operation. 3.4 @classInfo() The decorator identifier @classInfo() has two main functions: 3.4.1 Add the component list of IDE Developers' custom component scripts are by default located under 'Add Component->Custom Component Script' in the 'Property Settings' panel, as shown in Figure 3-10. (Animation 3-10) If we want to add this component to our own defined component list category in this component list, we can use the decorator identifier @classInfo(). The sample code is as follows: const { regClass, property, classInfo } = Laya; @regClass() @classInfo( { menu : \"MyScript\", caption : \"Main\", }) export class Main extends Laya.Script { onStart() { console.log(\"Game start\"); } } Then we save the code and return to the IDE, we will find that the customized classification has appeared in the component list. As shown in animation 3-11. (Animation 3-11) 3.4.2 Attribute grouping Assume that the decorator is used to expose 5 attributes A, B, C, D, and E. The display effect is as follows: (Figure 3-12) When there are many attributes, the attributes can be displayed in groups, and @classInfo() is used. @classInfo() can add non-data type attributes to the type. For example, to display two attributes BC in a group, the implementation is as follows: const { regClass, property, classInfo } = Laya; @regClass() @classInfo({ properties: [ { name: \"Group1\", inspector: \"Group\", options: { members: [\"b\", \"c\"] }, position: \"after a\" } ] }) export class NewScript extends Laya.Script { @property(String) public a: string = \"\"; @property(String) public b: string = \"\"; @property(String) public c: string = \"\"; @property(String) public d: string = \"\"; @property(String) public e: string = \"\"; } Among them, members specifies the list of attribute names belonging to this group. If there are many attributes, you can also use this format [ \"b~c\" ] to represent all attributes from attribute b to attribute c. position is optional and indicates where this group is displayed. The display effect is as follows: (Figure 3-13) 4. Using attributes in code The addition and identification of component components have been introduced previously. I believe that developers with a certain foundation can already use LayaAir's physical component system directly. But for some novice developers, this section uses examples of several common types of properties to further help you understand the basis of component development. 4.1 Node type method LayaAir is divided into 2D node and 3D node types. When set to 2D node Laya.Sprite, 3D node cannot be used as its attribute value. When set to a 3D node Laya.Sprite3D, a 2D node cannot be used as its attribute value. 4.1.1 Use of 2D nodes First, as shown in animation 4-1, drag the 2D node Sprite that has been added in the scene into the property entrance exposed by @property, so that the node is obtained. (Animation 4-1) Then you can use code in the script to change the properties of the node, for example, add texture to Sprite, etc. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type : Laya.Sprite}) public spr: Laya.Sprite; onAwake(): void { this.spr.size(512, 313); //Set Sprite size this.spr.loadImage(\"atlas/comp/image.png\"); //Add texture } } The effect is shown in Figure 4-2: (Figure 4-2) 4.1.2 Basic use of 3D nodes First, as shown in the animation 4-3, drag the 3D node Cube that has been added in the scene into the property entrance exposed by @property, so that this node is obtained. (Animation 4-3) Then you can use code in the script to change the properties of the node. For example, you can make the Cube rotate around itself. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type : Laya.Sprite3D}) public cube: Laya.Sprite3D; private rotation: Laya.Vector3 = new Laya.Vector3(0, 0.01, 0); onStart() { Laya.timer.frameLoop(1, this, ()=> { this.cube.transform.rotate(this.rotation, false); }); } } The effect is shown in the animation 4-4: (Animation 4-4) 4.1.3 Advanced use of 3D nodes @property( { type :Laya.Sprite3D } ) //Node type public p3d: Laya.Sprite3D; onAwake(): void { this.p3d.transform.localPosition = new Laya.Vector3(0,5,5); let p3dRenderer = this.p3d.getComponent(Laya.ShurikenParticleRenderer); p3dRenderer.particleSystem.simulationSpeed = 10; } By exposing the @property( { type :Laya.Sprite3D } ) node type attribute and dragging in the particle node, the particle node object can be obtained. The transform can be modified directly, and the simulationSpeed ​​property is obtained through getComponent(Laya.ShurikenParticleRenderer).particleSystem. 4.2 Use of component types @property( { type : Laya.ShurikenParticleRenderer } ) //Component type public p3dRenderer: Laya.ShurikenParticleRenderer; onAwake(): void { (this.p3dRenderer.owner as Laya.Sprite3D).transform.localPosition = new Laya.Vector3(0,5,5); this.p3dRenderer.particleSystem.simulationSpeed = 10; } By exposing the @property( { type : Laya.ShurikenParticleRenderer } ) component type property and dragging in the particle node, you can get the particle's ShurikenParticleRenderer component. The transform can be modified through (this.p3dRenderer.owner as Laya.Sprite3D), and the simulationSpeed ​​property is obtained through this.p3dRenderer.particleSystem. You cannot use Laya.ShuriKenParticle3D directly as the attribute type because the IDE cannot recognize it, only node and component types can. Even if the type is set to Laya.Sprite3D, although the IDE identifies the attribute as a Sprite3D node, it cannot be converted into a Laya.ShuriKenParticle3D object. 4.3 Prefab type attributes When using Laya.Prefab as a property, for example: @property( { type : Laya.Prefab } ) //Load the object of Prefab private prefabFromResource: Laya.Prefab; At this time, you need to drag in the prefab resource from the assets directory as shown in Figure 4-5. The instantiated prefab will be directly obtained during runtime. (Animation 4-5) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:31:07 "},"basics/common/Loader/readme.html":{"url":"basics/common/Loader/readme.html","title":"Loader","keywords":"","body":"Detailed explanation of resource loading method of LayaAir engine1. Load a single resource1.1 How to load common resources1.2 Typed loading method2. Load multiple resources2.1 Multi-resource loading method that omits types2.2 Typed multi-resource loading method2.3 Unified multi-resource loading method3. Do not parse or cache loaded resources4. Option parametersDetailed explanation of resource loading method of LayaAir engine Author: Charley Resource loading is the core module of the game engine and a must-use function. The LayaAir engine provides the Loader class for loading text, JSON, binary, images and other resources. Next, we will thoroughly master the use of various resource loading in this document. 1. Load a single resource 1.1 How to load common resources Usually, the Laya.loader.load(\"resource path\") method is used to load a single resource, and .then(\"callback method\") is used to handle the post-loading logic. Laya.loader.load(url).then((res)=> {/** Without type, used for regular resources */}); The complete script example is as follows: const { regClass, property } = Laya; @regClass() export class LoaderDemo extends Laya.Script { onAwake(): void { this.loadTexture(\"resources/image/monkey2.png\", 500);//You need to put the corresponding resources in resources/image this.loadTexture(\"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\"); } /**Load and display images */ loadTexture(url: string, x: number = 0, y: number = 0): void { Laya.loader.load(url).then((res: Laya.Texture) => { let img = new Laya.Image(); img.texture = res; // img.skin = url; //UI components can also set skin directly img.pos(x, y); this.owner.addChild(img); }); } } 1.2 Typed loading method Sometimes, network resources do not have a suffix, or the picture xxx.png is not used as a Texture and needs to be defined as a TextureCube. Therefore, these times need to be distinguished by type. The usage is basically the same as without type, except that the second parameter of load is added: the type identification string. Laya.loader.load(url, type).then((res)=> { //With type, used to distinguish resources without suffix, or resources with different functions of the same suffix. //For example, the picture xxx.png is defined as TextureCube, use load(\"xxx.png\", Laya.Loader.TEXTURECUBE). What you get is a TextureCube. }); The complete script example is as follows: const { regClass, property } = Laya; @regClass() export class LoaderDemo extends Laya.Script { onAwake(): void { //The following URL may become invalid in the future and is only used for example reference. this.loadHTMLImage(\"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\"); } /** Load URL without suffix resources */ loadHTMLImage(url: string): void { Laya.loader.load(url, Laya.Loader.IMAGE).then((res: Laya.Texture) => { let sp = new Laya.Sprite(); sp.texture = res; this.owner.addChild(sp); }); } } Commonly used types are as follows: Engine global variables Type identification string Type description Laya.Loader.TEXT text Text type Laya.Loader.JSON json JSON type Laya.Loader.XML xml XML type Laya.Loader.BUFFER arraybuffer Binary type Laya.Loader.IMAGE image Texture type Laya.Loader.SOUND sound sound type Laya.Loader.VIDEO video Video type Laya.Loader.ATLAS atlas Atlas type, return the json information of the album after loading is completed (and create a small image Texture in the album) Laya.Loader.HIERARCHY HIERARCHY Hierarchical resources, such as scene ls files and prefab lh files Laya.Loader.FONT font Bitmap font type Laya.Loader.TTF ttf TTF font type Laya.Loader.MESH MESH Mesh resources Laya.Loader.MATERIAL MATERIAL Material resources Laya.Loader.TEXTURE2D TEXTURE2D Texture2D resources Laya.Loader.TEXTURECUBE TEXTURE2D TextureCube Resources Laya.Loader.SPINE SPINE Spine Resources 2. Load multiple resources Many times, we need to preload a large amount of resources on the Loading interface. In this way, after entering the game after passing the loading progress bar, the resources will be displayed directly, and there will be no waiting for the resources to be loaded. At this time, we need to use multiple resource loading methods. 2.1 Multi-resource loading method that omits types If we only load the more commonly used resources, which can be identified by the file suffix, then it is definitely more concise to omit the type. Loading multiple APIs is basically the same as loading a single one, except that when loading multiple ones, the first parameter is an array of resource addresses. Laya.loader.load([url1, url2]).then((res:Array)=> { /** Load multiple, without type, used for regular resources */ }); The complete script example is as follows: const { regClass, property } = Laya; @regClass() export class LoaderDemo extends Laya.Script { onAwake(): void { let resArr: Array = [ \"image/bird.jpg\", \"image/cloud.png\", \"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\" ]; this.loadTextures(resArr); } /** Load multiple resources * @param url resource array */ loadTextures(url: Array): void { Laya.loader.load(url).then((res: Array) => { let sp: Laya.Sprite = new Laya.Sprite(); this.owner.addChild(sp); let i: number = 0; //Redraw every second Laya.timer.loop(1000, this, () => { i == res.length && (i = 0); //Clear all drawings of sp nodes (excluding child nodes) sp.graphics.clear(); //Redraw the texture on the sp node sp.graphics.drawTexture(res[i]); i++; }); }); } } 2.2 Typed multi-resource loading method If most resources do not need to be typed, and some resources need to be distinguished by type, how to use the loading method? In the resource array, the type needs to be passed in, and the type that is not required can still be omitted. Laya.loader.load([url1, { url:url2, type: type }]).then((res:Array)=> { /** Load multiple, set the type as needed to meet various needs */ }); The complete script example is as follows: const { regClass, property } = Laya; @regClass() export class LoaderDemo extends Laya.Script { onAwake(): void { let resArr: Array = [ \"image/bird.jpg\", \"image/cloud.png\", { url: \"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\", type: \"image\" }, { url: \"https://layaair.com/3.x/demo/resources/res/apes/monkey1.png\", type: Laya.Loader.IMAGE } ]; this.loadTextures(resArr); } /** Load multiple resources * @param url resource array */ loadTextures(url: Array): void { //The type returned by the loading callback, if it is diverse, it is best to be any Laya.loader.load(url).then((res: Array) => { let sp: Laya.Sprite = new Laya.Sprite(); this.owner.addChild(sp); let i: number = 0; //Redraw every second Laya.timer.loop(1000, this, () => { i == res.length && (i = 0); //Clear all drawings of sp nodes (excluding child nodes) sp.graphics.clear(); //Redraw the texture on the sp node sp.graphics.drawTexture(res[i]); i++; }); }); } } The type in the example deliberately uses two methods: string identification and engine global variable identification. Developers can use either one. For details, refer to the type identification table in 1.2. 2.3 Unified multi-resource loading method Sometimes, multiple resources loaded need to use type identifiers, and these types are all of the same type. For example, all resources loaded are URL resources without suffixes. At this time, we can set the type identifier uniformly. Laya.loader.load([url1, url2], type).then((res:Array)=> { /** Load multiple, unified type, simple and practical */ }); The complete script example is as follows: const { regClass, property } = Laya; @regClass() export class LoaderDemo extends Laya.Script { onAwake(): void { let resArr: Array = [ \"image/bird.jpg\", \"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\", \"image/cloud.png\", \"https://layaair.com/3.x/demo/resources/res/apes/monkey2.png\", ]; this.loadTextures(resArr); } /** Load multiple resources * @param url resource array */ loadTextures(url: Array): void { //Load the type returned by the callback, if not sure, just any Laya.loader.load(url, Laya.Loader.IMAGE).then((res: Array) => { let sp: Laya.Sprite = new Laya.Sprite(); this.owner.addChild(sp); let i: number = 0; //Redraw every second Laya.timer.loop(1000, this, () => { i == res.length && (i = 0); //Clear all drawings of sp nodes (excluding child nodes) sp.graphics.clear(); //Redraw the texture on the sp node sp.graphics.drawTexture(res[i]); i++; }); }); } } 3. Do not parse or cache loaded resources The load() method provided by the engine loads resources and may do some encapsulation after parsing. For example, if we use the load() method to load a json data, we need to be in data to get the data in the json file. Use the load() method, the example is as follows: onEnable(): void { const jsonPath: string = \"json/bagList.json\"; Laya.loader.load(jsonPath).then((json) => { let _json = json.data; if (_json.bagList && _json.bagList.length > 0) { //Pass json data to the data source attribute array of the list component this.bagList.array = _json.bagList; } }); } And when we use the fetch() method, we can directly get the data in the json file. However, it should be noted that resources loaded using fetch will not be cached and can only be used in the callback after the loading is completed. The loading cache cannot be read through getRes. Use the fetch() method, the example is as follows: onEnable(): void { const jsonPath: string = \"json/bagList.json\"; //fetch gets the original data, but there is no cache and cannot be obtained with getRes. Laya.loader.fetch(jsonPath, \"json\").then((_json) => { if (_json.bagList && _json.bagList.length > 0) { //Pass json data to the data source attribute array of the list component this.bagList.array = _json.bagList; } }); } fetch loading is limited to the following types: type identification string resource type text string json any xml XMLDocument arraybuffer ArrayBuffer image HTMLImageElement \\ImageBitmap sound HTMLAudioElement When using it, just fill in the corresponding type identification string in the second parameter. For more fetch loading code examples, please refer to the Using Binary Images document Tips​ Unless the purpose of fetch is clearly understood, it is not recommended for developers to use it. 4. Option parameters When using the load() method or the fetch() method to load resources, the Option parameter can be used, such as code: //Create Option let option:any = {}; option.blob = this.imgBlob; //Get HTMLImageElement by passing blob object Laya.loader.fetch(\"\" ,\"image\", null, option).then((res)=>{ }); Specify the fetch() method through the Option parameter and pass the blob object to obtain HTMLImageElement Currently supported Option parameters: export interface ILoadOptions { type?: string; //Resource type. For example: Loader.IMAGE. priority?: number; //(default = 0) The priority of loading. The larger the number, the higher the priority. Those with higher priority are loaded first. group?: string; //Group to facilitate resource management. cache?: boolean; // Whether to cache noRetry?: boolean; //Whether to retry loading silent?: boolean; //Whether to prompt loading failure useWorkerLoader?: boolean; //(default = false) Whether to use worker loading (only for IMAGE type and ATLAS type, and effective when the browser supports it) constructParams?: TextureConstructParams; //Picture properties, reference is as follows propertyParams?: TexturePropertyParams; //Texture properties, reference is as follows blob?: ArrayBuffer; //Pass the blob object to get HTMLImageElement noMetaFile?: boolean; //Do not download Meta(json) files [key: string]: any; } TextureConstructParams { width?: number, height?: number, format?: TextureFormat, mipmap?: boolean, canRead?: boolean, sRGB?: boolean, } TexturePropertyParams { wrapModeU?: number, wrapModeV?: number, filterMode?: FilterMode, anisoLevel?: number, premultiplyAlpha?: boolean, hdrEncodeFormat?: HDREncodeFormat, } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:43:48 "},"basics/common/Scene/readme.html":{"url":"basics/common/Scene/readme.html","title":"Scene","keywords":"","body":"Scene management1. Scenarios in IDE1.1 Create a new scene1.2 Scene division1.3 autoDestroyAtClosed attribute1.4 mouseThrough attribute2. Used in code2.1 Scene class2.2 Open the scene2.3 Close scene2.4 Scene loading page2.5 Destruction and garbage collectionScene management LayaAir 3.0 continues to use the 2.0 development ideas for componentization, scripting, and scene management development. The project uses Scene management to manage scenes. LayaAir has made a series of solutions for Scene, so that developers do not need to consider scenes, levels, and pages. For resource and memory management, you only need to simply call the interface and manage the scene, and leave the rest to the engine. You only need to focus on game logic development. In the 2.0 project development, whether you are creating a scene Scene, page View, dialog box Dialog, or 3D scene scene3d, the file type and suffix are all scene. However, the division of scenes in 3.0 is different, and it is no longer a unified suffix scene method. 1. Scenarios in IDE 1.1 Create a new scene Use the IDE to create a new 3D project, create a scene in the IDE, and save it. By default, it will be saved as Scene1.ls in the assets directory. As shown in the animation 1-1 (Animation 1-1) Open the assets directory through the resource manager, and you can see that the suffix of Scene1 is the ls file. The difference between this scene ls file and 2.0 is that it includes the Scene3D scene and the Scene2D scene. As shown in Figure 1-2 (Figure 1-2) Scene3D: To edit the root node of a 3D scene, you can refer to the [\"Basic Interaction of 3D Scene Editing\"] (../../../IDE/sceneEditor/basic/readme.md) document and \"3D Scene Environment Settings》 document to learn more about the operation and use of 3D scenes, as shown in Figure 1-3 (Figure 1-3) Scene2D: To edit the root node of a 2D scene, you can refer to the [\"UI Editor Basic Interaction\"] (../../../IDE/uiEditor/basic/readme.md) document and \"UI Runtime\" document to learn more about the operation and code usage of 2D scenes, as shown in Figure 1-4 (Figure 1-4) But the important point is that in the scene created by the same IDE, editing of 3D scenes and 2D scenes can be supported 1.2 Scene division What if the developer only needs a 3D scene or a 2D scene for a certain scene? When you only need a 2D scene, you can click Scene3D, right-click and select Delete, then the remaining scene will be a simple Scene2D scene, as shown in Figure 1-5 (Figure 1-5) When you only need 3D scenes, you can find that Scene2D cannot be deleted, as shown in Figure 1-6 (Figure 1-6) The reason why it cannot be deleted is because Scene2D has a very important property Auto Destroy At Closed As long as Scene2D is not edited, Scene2D is just a Sprite node with attributes and will not have any impact on the 3D scene. 1.3 autoDestroyAtClosed attribute /**After the scene is closed, whether to automatically destroy (destroy nodes and used resources), the default is false*/ autoDestroyAtClosed: boolean = false; When Auto Destroy At Closed is checked, the scene's Destroy() method will be automatically called when it is closed. 1.4 mouseThrough attribute Another attribute is Mouse Through, which is checked by default. Since both 2D scenes and 3D scenes can receive mouse events, there may be conflicts at this time. If Mouse Through is checked, script events such as onMouseClick under Scene2D will not respond and will be passed to Scene3D. If Mouse Through is not checked, script events such as onMouseClick under Scene2D will respond 2. Used in code 2.1 Scene class /** * Scene class, responsible for scene creation, loading, destruction and other functions * After the scene is removed from the node, it will not be recycled by the automatic garbage mechanism. If you want to recycle, please call the destroy interface. You can view the list of scenes that have not been destroyed through the unDestroyedScenes attribute. */ export class Scene extends Sprite { /**After creation, the list of scenes that have not been destroyed is convenient for viewing the list of scenes that have not been destroyed and memory management. This attribute is read-only, please do not modify it directly*/ static readonly unDestroyedScenes: Set = new Set(); /**After the scene is closed, whether to automatically destroy (destroy nodes and used resources), the default is false*/ autoDestroyAtClosed: boolean = false; _scene3D: any; The scene class first inherits from Sprite, which is itself a Scene2D node. Editing the 2D interface actually means adding 2D sub-node components under it. The attribute _scene3D is used to manage Scene3D, which is associated with the corresponding Scene2D and Scene3D in the IDE. 2.2 Open the scene 1. Basic use First, let’s take a look at the most basic usage of the scene class, opening a scene /** * Load and open the scene * @param url scene address * @param closeOther Whether to close other scenes, the default is true (optional), [Note] If autoDestroyAtClosed=true is not set for the closed scene, the resources may not be recycled and need to be recycled manually. * @param param The parameters for opening the page will be passed to the onOpened method (optional) * @param complete Open the completion callback and return the scene instance (optional) * @param progress Loading progress callback (optional) */ static open(url: string, closeOther: boolean = true, param: any = null, complete: Handler = null, progress: Handler = null): Promise { Scene.showLoadingPage(); return Scene.load(url, Handler.create(null, this._onSceneLoaded, [closeOther, complete, param]), progress); } (Figure 2-1) For example, create a scene named OpenScene and save it in the assets path uiDemo/page/OpenScene.ls. You can open the scene like this in the code without closing other scenes. Laya.Scene.open(\"uiDemo/page/OpenScene.ls\", false); You can also open a UI implemented by a prefab, such as code Laya.Scene.open(\"dailog.lh\"); The running effect is shown in the animation 2-2 (Animation 2-2) 2. Pass and receive parameters There are two scenes, Scene.ls and Msg.ls, in the project. You can pass parameters to the Msg scene through Laya.Scene.open in the Scene scene. The code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Button }) public uiBtn: Laya.Button; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.uiBtn.on(Laya.Event.CLICK, this, () => { //After clicking, open the Msg scene Laya.Scene.open(\"Msg.ls\", false, { \"text\": \"Click successful!\" }); }); } } Among them, the Scene scene has a Button component, which needs to be dragged into the property entrance exposed by @property in the IDE. The parameter data passed by the Scene scene is { \"text\": \"Click successfully!\" }. In the Runtime of the Msg scene, the onOpened method will accept the passed parameters, and the value of param.text is the text \"click\" Success!\", the code is as follows: const { regClass } = Laya; import { MsgRTBase } from \"./MsgRT.generated\"; @regClass() export class MsgRT extends MsgRTBase { onOpened(param: any): void { console.log(param.text); } } In this way, when you click the Button in the Scene scene, the log \"Click successful!\" will be printed, and the effect is as shown in the animation 2-3: (Animation 2-3) 2.3 Close scene 1. Close the specified scene /** * Close the scene (including dialog box) according to the address * @param url scene address * @param name If name is not empty, name must be the same to close * @return Returns whether the shutdown is successful. If the url cannot be found, it will be unsuccessful. */ static close(url: string, name?: string): boolean { For example, you can close a scene by passing in the specified address parameter. Laya.Scene.close(\"uiDemo/page/OpenScene.ls\"); 2. Close the current scene this.close() (Figure 2-4) Using Runtime, you can easily use this.close() to close the scene 3. Close all scenes (excluding dialog) /** * Close all scenes, excluding dialog boxes. If you close the dialog box, please use Dialog.closeAll() * [Note] In a closed scene, if autoDestroyAtRemoved=true is not set, the resources may not be recycled and need to be recycled manually. */ static closeAll(): void { 4. Life cycle method called after closing /** * After the shutdown is completed, call this method (if there is a shutdown animation, it will be executed after the animation is completed) * @param type If it is triggered by clicking the default close button, pass in the name of the close button, otherwise it is null. */ onClosed(type: string = null): void { } The Runtime class of the scene will be called the onClosed() method when the scene is closed, and various resources can be released within the method. 2.4 Scene loading page Load.Scene.setLoadingPage(loadPage: Sprite) Set the loading interface. The engine will delay opening the loading interface after calling the open method, and close the loading interface after the page is added to the stage. Laya.Scene.showLoadingPage(param: any = null, delay: number = 500) Display the loading interface and open the parameters. If it is a scene, it will be passed to the onOpened method. Delay opening time, default 500 milliseconds Laya.Scene.hideLoadingPage(delay: number = 500) Hide the loading interface and delay the closing time, the default is 500 milliseconds. For example, if you want to open a new scene and use the loading page, first define a script code and add the Laya.Prefab attribute that may be dragged into the loading scene. The code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Prefab }) private loadingScenePrefab: Laya.Prefab; private loadingScene: Laya.Node; constructor() { super(); } /** * Executed before executing update for the first time, it will only be executed once */ onStart(): void { //Create Loading scene this.loadingScene = this.loadingScenePrefab.create(); //Set the Loading scene Laya.Scene.setLoadingPage(this.loadingScene as Laya.Sprite); //Manual call to display Loading scene Laya.Scene.showLoadingPage(this.loadingScene); Laya.timer.once(3000,this,()=>{ //Jump to Game scene after 3 seconds Laya.Scene.open(\"Game.ls\"); }) } } Under the open scene Scene.ls, hang up the script and drag in Loading.lh as the scene. (Figure 2-5) In this way, the Loading scene can be used as the loading scene. 2.5 Destruction and garbage collection /** * Destroy the scene (including dialog box) according to the address * @param url scene address * @param name If name is not empty, name must be the same to close * @return Returns whether the destruction is successful. If the url cannot be found, it will not be successful. */ static destroy(url: string, name?: string): boolean { /** * Destroy resources that are not currently being used. This function will ignore resources with lock=true. */ static gc(): void { Resource.destroyUnusedResources(); } The code is used as follows: Laya.Scene.destroy(\"scene.ls\"); Laya.Scene.gc(); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:57:33 "},"basics/common/Node/readme.html":{"url":"basics/common/Node/readme.html","title":"Node","keywords":"","body":"Node managementAdd toFindChangeRemoveNode management Similar to HTML, the entire HTML is composed of various nodes. The root node is the HTML tag, and then there are the child nodes, and then the child nodes nest the child nodes to form a node tree. Then the browser renders based on this node tree, and then The page we need is rendered, and Laya is actually the same. Different components and scenes form a node tree, which is rendered by the Laya engine. Nodes are the basis of project development. Only by fully understanding how to operate nodes can complex requirements be realized faster. Each node component class inherits from the Node class, which is the base class for all objects that can be placed in the display list. This display list manages all objects displayed in the Laya runtime. Use the Node class to arrange display objects in a display list. Node objects can have child display objects. Let’s get familiar with all the basic functions of the Node class Add to Add child node addChild(node:Node) Without considering the hierarchy, we can add child nodes to a node, so that the child nodes can follow the parent node to display or move, and facilitate management. The added child nodes will be added to the end of all child nodes. Add a child node to the specified index position addChildAt(index:number) It is often necessary to consider the hierarchical relationship or occlusion relationship of nodes, and if you already know that you need to add it to the specified hierarchical position, you can use this method. Add child nodes in batches addChildren(...args:any[]) Directly adding a group of child nodes to the parent node in order is equivalent to calling the addChild child node once in a loop. Find Get the child node object according to the name getChildByName(name: string) When we know the name of a node, we can use this method to find a child node one level below the parent node. Get the child node object according to the index position of the child node getChildAt(index:number) When we know the index position of a node, we can use this method to find a child node one level below the parent node. Get the index position of the child node according to the child node object getChildIndex(node:Node) When we want to know the index position of a node, we can use this method to get the child nodes Get the number of child node objects numChildren By calling the numChildren attribute of the parent node, you can get the number of all child nodes at the next level of the parent node, which can be used to traverse all child nodes. Note that the child nodes under the child node are not included. Get the parent node object parent You can directly obtain the parent node by calling the parent attribute of the child node. Whether the current container contains the specified node object contains(node: Node) To determine whether a node contains a child node, you can use this method. Note that this search process will traverse all nested child nodes. Check whether this node is the upper node of a certain node isAncestorOf(node: Node) Change Set the index position of the child node setChildIndex(node:Node,index:number) If you want to change the display level of child nodes, you can call this method. Note that if the index exceeds the number of nodes of the parent node, an exception will be thrown. Pass in the new node and replace it at the index position of the existing child node replaceChild(newNode: Node, oldNode: Node) If you want to replace an existing node with a new node, you can call this method. Note that the original child node will be removed but will not be destroyed. Remove Delete child node removeChild(node: Node) This method is called when deleting a child node. Note that the child node will be removed but will not be destroyed. Remove yourself from the parent container removeSelf() When you do not need to know the parent node, you can directly delete yourself from the parent node by calling this method. This method is used more frequently. Delete the corresponding child node according to name removeChildByName(name: string) When we know the name of a node, we can use this method to delete the child node from the parent node. Delete the corresponding child node according to the index position removeChildAt(index: number) When we know the index position of a node, we can use this method to delete the child node from the parent node Delete all child nodes in the specified index range removeChildren(beginIndex: number = 0, endIndex: number = 0x7fffffff) This method can quickly delete all child nodes in the specified index range Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:53:17 "},"basics/common/Timer/readme.html":{"url":"basics/common/Timer/readme.html","title":"Timer","keywords":"","body":"Timer1. Frame interval1.1 Execute once regularly (based on frame rate)1.2 Timed repeated execution (based on frame rate)2. Time interval2.1 Execute once regularly (unit: milliseconds)2.2 Scheduled repeated execution (unit: milliseconds)3. Pause timer execution4. Delayed execution of current frame5. Clean up timer6. Execute and delete the timer immediatelyTimer Timer Laya.Timer is a clock management class. It is a singleton, do not instantiate this class manually, it should be accessed through Laya.timer. At the same time, Laya.Timer represents the main clock of the game, and is also the clock for managing scenes, animations, easing and other effects. By controlling the scaling of this clock, the effect of fast forward and slow playback can be achieved. 1. Frame interval 1.1 Execute once regularly (based on frame rate) Laya.timer.frameOnce is defined as follows: /** * Executed once at a scheduled time (based on frame rate). * @param delay How many frames to delay (unit is frame). * @param caller execution domain (this). * @param method timer callback function. * @param args callback parameters. * @param coverBefore Whether to cover the previous delayed execution, the default is true. */ frameOnce(delay: number, caller: any, method: Function, args: any[] = null, coverBefore: boolean = true): void { this._create(true, false, delay, caller, method, args, coverBefore); } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //After 60 frames, the transparency of the image becomes 0.5 Laya.timer.frameOnce(60, this, () => { this.Image.alpha = 0.5; }) } } 1.2 Timed repeated execution (based on frame rate) Laya.timer.frameLoop, defined as follows: /** * Scheduled repeat execution (based on frame rate). * @param delay The number of frames (unit: frame). * @param caller execution domain (this). * @param method timer callback function. * @param args callback parameters. * @param coverBefore Whether to cover the previous delayed execution, the default is true. */ frameLoop(delay: number, caller: any, method: Function, args: any[] = null, coverBefore: boolean = true): void { this._create(true, true, delay, caller, method, args, coverBefore); } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //After every 60 frames, the transparency of the image is reduced by 0.1 Laya.timer.frameLoop(60, this, () => { this.Image.alpha -= 0.1; }) } } 2. Time interval 2.1 Execute once regularly (unit: milliseconds) Laya.timer.once, defined as follows: /** * Execute once regularly. * @param delay delay time (unit: milliseconds). * @param caller execution domain (this). * @param method timer callback function. * @param args callback parameters. * @param coverBefore Whether to cover the previous delayed execution, the default is true. */ once(delay: number, caller: any, method: Function, args: any[] = null, coverBefore: boolean = true): void { this._create(false, false, delay, caller, method, args, coverBefore); } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //After 1 second, the transparency of the image becomes 0.5 Laya.timer.once(1000, this, () => { this.Image.alpha = 0.5; }) } } 2.2 Scheduled repeated execution (unit: milliseconds) Laya.timer.loop is defined as follows: /** *Repeated execution at regular intervals. * @param delay interval time (unit milliseconds). * @param caller execution domain (this). * @param method timer callback function. * @param args callback parameters. * @param coverBefore Whether to cover the previous delayed execution, the default is true. * @param jumpFrame Whether the clock jumps frame. Time-based cyclic callback. If multiple callbacks can be executed within a unit time interval, for performance reasons, the engine will only execute it once by default. After setting jumpFrame=true, the callback will be executed multiple times continuously. */ loop(delay: number, caller: any, method: Function, args: any[] = null, coverBefore: boolean = true, jumpFrame: boolean = false): void { var handler: TimerHandler = this._create(false, true, delay, caller, method, args, coverBefore); if (handler) handler.jumpFrame = jumpFrame; } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //After every 1 second, the transparency of the image is reduced by 0.1 Laya.timer.loop(1000, this, () => { this.Image.alpha -= 0.1; }) } } 3. Pause timer execution Once the timer is paused, the game will be at rest: /** * Pause the clock */ pause(): void { this.scale = 0; } /** *Restore clock */ resume(): void { this.scale = 1; } 4. Delayed execution of current frame Executed immediately after the current frame is executed. Executed before rendering, the execution priority is higher than the timer delayed by one frame: /** * Delayed execution. * @param caller execution domain (this). * @param method timer callback function. * @param args callback parameters. */ callLater(caller: any, method: Function, args: any[] = null): void { CallLater.I.callLater(caller, method, args); } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //The loop is called 10 times, but the timer callback function is only executed once, that is, the \"hideImage\" log is only printed once for (let i = 0; i 5. Clean up timer Laya.timer.clear: Clear the specified timer. The definition is as follows: /** * Cleanup timer. * @param caller execution domain (this). * @param method timer callback function. */ clear(caller: any, method: Function): void { var handler: TimerHandler = this._getHandler(caller, method); if (handler) { handler.clear(); } } Laya.timer.clearAll: Clear all timers in the specified scope of the object. The definition is as follows: /** * Clear all timers on the object. * @param caller execution domain (this). */ clearAll(caller: any): void { if (!caller) return; for (var i: number = 0, n: number = this._handlers.length; i It is recommended to clear the timer or clear all timers before a module function is destroyed. 6. Execute and delete the timer immediately Laya.timer.runCallLater: Execute callLater immediately and delete it after execution. The definition is as follows: /** * Execute callLater immediately. * @param caller execution domain (this). * @param method timer callback function. */ runCallLater(caller: any, method: Function): void { CallLater.I.runCallLater(caller, method); } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //Delay one frame to execute hideImage Laya.timer.callLater(this, this.hideImage); //The current frame executes hideImage immediately and deletes the timer after execution. Laya.timer.runCallLater(this, this.hideImage); } hideImage(): void { console.log(\"hideImage\"); this.Image.visible = false; } } Note: The above example will print a \"hideImage\" because runCallLater in LayaAir will delete the timer after executing the callback. If the timer is not deleted, after the current frame executes the callback hideImage of runCallLater, the callback hideImage of callLater will also be executed, and two \"hideImages\" will be printed. Laya.timer.runTimer: Execute the timer immediately in advance and delete it from the queue after execution. The definition is as follows: /** * Immediately execute the timer in advance and delete it from the queue after execution * @param caller execution domain (this). * @param method timer callback function. */ runTimer(caller: any, method: Function): void { var handler: TimerHandler = this._getHandler(caller, method); if (handler && handler.method != null) { this._map[handler.key] = null; handler.run(true); } } Usage examples are as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //If there is no Laya.timer.runTimer, hideImage will be executed after 5 seconds. Laya.timer.loop(5000, this, this.hideImage); //Execute hideImage immediately Laya.timer.runTimer(this, this.hideImage); } hideImage(): void { console.log(\"hideImage\"); this.Image.visible = false; } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:07:57 "},"basics/common/Event/readme.html":{"url":"basics/common/Event/readme.html","title":"Event","keywords":"","body":"Event management1. Understanding the event1.1 What is an event?1.2 Classification of events2. Engine built-in events2.1 Event type Laya.Event2.2 Event dispatch Laya.EventDispatcher2.3 Event handling Laya.Handler3. Customized eventsEvent management 1. Understanding the event 1.1 What is an event? Events refer to actions that are preset by the system and can be recognized and responded to by the object. Events refer to the object's response to external actions. When an event occurs on the other party, the code corresponding to the event will be executed. For example, if you press the mouse on an object, the object is preset to recognize the mouse press event, and the corresponding code will be executed. 1.2 Classification of events Engine built-in events Customized events The events we use can be built-in events in the engine or custom events. Using custom types of events is called custom events. 2. Engine built-in events Events in the LayaAir3.0 engine mainly include three parts: Laya.Event event type, event interface, different event types must implement this interface. Laya.EventDispatcher event dispatch, each passed event will be distributed to a specific handler. Laya.Handler event handling, different processors need to implement this interface. 2.1 Event type Laya.Event Laya.Event is a collection of event types. When an event occurs, the Laya.Event object will be passed as a parameter to the event listener. As shown in Figure 2-1, for event types, please refer to API document. (Figure 2-1) For example Laya.Event.CLICK:string = \"click\". The CLICK static attribute is used to define the type type attribute value of the event object as a click event. This event is an event dispatched by the system after being triggered by a mouse click. Developers can also call the event() method to dispatch these events. How to dispatch events will be covered in the following content. (Figure 2-2) Click any one of the three buttons in Figure 2-2 to enter the corresponding function. Let's take a look at how the code uses CLICK (the following code is from the \"2D Getting Started Example\"): onEnable(): void { console.log(\"IndexRT onEnable\") //Listen to ui button click event this.uiBtn.on(Laya.Event.CLICK, this, () => { //After clicking, open the UI scene example console.log(\"uiBtn\"); Laya.Scene.open(\"scenes/UiMain.ls\"); }); //Listen to physical button click events this.phyBtn.on(Laya.Event.CLICK, this, () => { //After clicking, open the physics game example console.log(\"phyBtn\"); Laya.Scene.open(\"scenes/PhysicsGameMain.ls\"); }); //Listen to the 3D blend button click event this.d3Btn.on(Laya.Event.CLICK, this, () => { //After clicking, open the 3D mixed scene example console.log(\"d3Btn\"); Laya.Scene.open(\"scenes/D3Main.ls\"); }); } 2.2 Event dispatch Laya.EventDispatcher The event dispatching Laya.EventDispatcher mode is an extension of the listening mode and is driven by events. Whenever an event occurs, the event dispatcher Laya.EventDispatcher distributes it to a specific event handler Laya.Handler Handle the event. Laya.EventDispatcher represents event sender, event capture delivery and distribution. Laya.EventDispatcher event dispatcher is the base class of schedulable event classes. For example, the Node class as a basic node inherits from the Laya.EventDispatcher class. As long as you inherit this class, you can act as an event sender to send events to its detectors. listener. For example, the Button in the above example code inherits from Laya.EventDispatcher, and you can use the .on method to listen to the CLICK` event. Laya.EventDispatcher has the following functions: 2.2.1 Event dispatch event /** * Dispatch events. * @param type event type. * @param data (optional) callback data. Note: If you need to pass multiple parameters p1, p2, p3,... you can use an array structure such as: [p1, p2, p3,...]; if you need to call back a single parameter p, And p is an array, you need to use a structure such as: [p]. For other single parameters p, you can directly pass in the parameter p. * @return Whether this event type has a listener, if there is a listener, the value is true, otherwise the value is false. */ event(type: string, data: any = null) Used to dispatch events. For example, we can dispatch a CLICK event in code: //Listen to ui button click event this.uiBtn.on(Laya.Event.CLICK, this, () => { //After clicking, open the UI scene example console.log(\"uiBtn\"); Laya.Scene.open(\"scenes/UiMain.ls\"); }); //uiBtn dispatches a click event by itself. Since there is a listener on it, the uiMain scene will be opened immediately. this.uiBtn.event(Laya.Event.CLICK); 2.2.2 Continuous event listening on /** * Use the EventDispatcher object to register an event listener object of a specified type so that the listener can receive event notifications. * @param type Type of event. * @param caller The execution domain of the event listening function. * @param listener event listening function. * @param args (Optional) Callback parameters for the event listening function. * @return this EventDispatcher object. */ on(type: string, caller: any, listener: Function, args: any[] = null) Used to register event listeners of specified types with the event dispatcher so that the event listeners can receive event notifications. When an event is listened to, the callback method listener of the scope caller will be called. In the above example of 2.2.1, this.uiBtn.on uses continuous listening. 2.2.3 Single event listening once /** * Use the EventDispatcher object to register an event listener object of a specified type so that the listener can receive event notifications. This listening event will be automatically removed after responding once. * @param type Type of event. * @param caller The execution domain of the event listening function. * @param listener event listening function. * @param args (Optional) Callback parameters for the event listening function. * @return this EventDispatcher object. */ once(type: string, caller: any, listener: Function, args: any[] = null) Used to register event listeners of specified types with the event dispatcher so that the event listeners can receive event notifications. The event listeners will be automatically removed after responding once. For example, the listening method of the button in the above 2.2.1 example can also be changed to single event listening: //Listen to a UI button click event this.uiBtn.once(Laya.Event.CLICK, this, () => { //After clicking, open the UI scene example console.log(\"uiBtn\"); Laya.Scene.open(\"scenes/UiMain.ls\"); }); 2.2.4 Delete the specified listener off /** * Remove the listener from the EventDispatcher object. * @param type Type of event. * @param caller The execution domain of the event listening function. * @param listener Event listening function. * @return this EventDispatcher object. */ off(type: string, caller: any, listener: Function, onceOnly: boolean = false) Used to remove a listener from an event dispatcher object: onDestroy(): void { //Delete the listener for the ui button this.uiBtn.off(Laya.Event.CLICK, this); } When this scene is deleted and destroyed, it is best to delete the button's event listener to ensure that all references are released. 2.2.5 Delete all listeners of the specified event type offAll /** * Removes all listeners for the specified event type from the EventDispatcher object. * @param type (optional) event type, if the value is null, remove all types of listeners from this object. * @return this EventDispatcher object. */ offAll(type: string = null) Used to remove all listeners for the specified event type from the event dispatcher object. For example, the uiBtn button has registered multiple event listeners. You can use the offAll method to delete all click event listeners at once: onDestroy(): void { //Delete the listener for the ui button this.uiBtn.offAll(Laya.Event.CLICK); } 2.2.6 Delete all listeners in the specified scope offAllCaller /** * Remove all event listeners with caller as target * @param caller caller object */ offAllCaller(caller: any) Used to remove all listeners of the specified scope from the event dispatcher object. For example, the uiBtn button has registered listeners for multiple events. You can use the offAllCaller method to delete all listeners on this scope at once: onDestroy(): void { //Delete the listening of this scope this.uiBtn.offAllCaller(this); } 2.2.7 Check whether the listener hasListener has been registered Used to determine whether the event dispatcher object has a listener registered for a specific type of event. /** * Check if the EventDispatcher object has any listeners registered for a specific event type. * @param type The type of event. * @return true if a listener of the specified type is registered; false otherwise. */ hasListener(type: string) For example: if( this.uiBtn.hasListener( Laya.Event.CLICK ) ) console.log(\"uiBtn has click event listening\"); 2.3 Event handling Laya.Handler When an event is listened to, the handler used to process the event Processor properties include: caller: Object | null; execution domain method: Function | null execution method args: any[] | null parameter once = false indicates whether to execute only once. If true, recover() is executed after the callback to recycle, and it will be reused after recycling. The default is false. Processor methods include: create() creates a Handler from the object pool Laya.Handler event handler, it is recommended to use the Laya.Handler.create() method to create it from the object pool to reduce object creation consumption. When the created Handler object is no longer used, you can use Laya.Handler.recover() to recycle it to the object pool. Do not use this object again after recycling, otherwise it will cause unpredictable errors. It should be noted that since mouse events also use the object pool, incorrect recycling and calling may affect the execution of the event. onAwake(): void { console.log(\"Game Start\"); this.Tab.selectHandler = Laya.Handler.create(this,(index:number)=>{ console.log(index); }) } Tab will listen for the user to click on a certain tab and create a handler from the object pool. clear(): Handler clears object references this.Tab.selectHandler.clear(); recover(): void is cleaned and recycled into the Handler object pool this.Tab.selectHandler.recover(); run(): any execution processor this.Tab.selectHandler.run(); //You can call run() yourself runWith(data: any): any executes the processor and carries additional data this.Tab.selectHandler.runWith(1); //You can call runWith() yourself and pass in parameter 1 setTo(caller: any, method: Function | null, args: any[] | null, once = false): Handler Set the specified attribute value of this object. onAwake(): void { console.log(\"Game Start\"); this.Tab.selectHandler = Laya.Handler.create(this,(index:number)=>{ // console.log(index); }) this.Tab.selectHandler.setTo(this,(index:number)=>{ console.log(index); },[],false); } You can change the specified attributes yourself 3. Customized events In most cases, developers use the engine's built-in events, and sometimes they need to use custom events. Here's an example to illustrate dispatching a custom event. In LayaAir IDE, create a new 2D empty project, create a custom component script under Scene2D, and add the following code: onAwake(): void { //Listen to the custom event \"Click\" this.owner.on(\"Click\",this,()=>{ console.log(\"Listened to the custom \"Click\" event\"); }) } //Execute after mouse click and send Click event. onMouseClick(evt: Laya.Event): void { //custom event this.owner.event(\"Click\"); } This.owner in the example is Scene2D. When the mouse clicks on the scene, the custom event \"Click\" will be dispatched. This \"Click\" is the custom event. When \"Click\" is listened to, the log of \"Customized \"Click\" event listened to\" will be printed. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:42:02 "},"basics/common/Tween/readme.html":{"url":"basics/common/Tween/readme.html","title":"Tween","keywords":"","body":"Easing1. Overview2. Ease2.1 Uniform motion (linearIn)2.2 Acceleration (expoIn)2.3 Rapid acceleration (strongIn)2.4 BackIn3. Tween3.1 Introduction to commonly used APIs3.2 Parameter description3.3 Easing example3.4 Understanding Props parameters3.5 Understand the easing duration (duration) and delayed execution (delay) parameters3.6 Understanding ease parameters3.7 Understanding the completion callback (complete) parameters3.8 Implement process callback through Props parametersEasing 1. Overview The greatest use of easing is to apply it to the movement performance of the design. It can combine physics, mathematics and other principles to truly simulate and display the movement phenomena in life, which is more in line with the laws of nature and human cognition, and allows objects to interact according to the user's expected behavior. Provide a continuity of experience. Easing animation is common in game development. It is one of the important factors to improve the game UI experience, such as dialog boxes popping up and closing, button animations appearing and disappearing, props flying into backpacks, etc. We can directly use the animation provided by the LayaAir engine Tween easing class and Ease class for quick implementation. Next we introduce the Tween and Ease classes respectively 2. Ease The Ease class defines a large number of easing functions to achieve the specific easing effect of the Tween animation. The Tween class of the LayaAir engine is used in combination with the Ease class to basically meet the easing effect requirements of game development. We mainly look at the following easing effects to understand: 2.1 Uniform motion (linearIn) In rare cases, uniform motion will be used, which will appear stiff. It does not conform to the laws of the physical world. In a real state of motion, the speed of an object will change with the state of motion. 2.2 Acceleration (expoIn) Start the movement at zero velocity and then increase the speed as you execute. 2.3 Rapid acceleration (strongIn) Start the movement at zero velocity and then speed it up as you execute 2.4 BackIn Start by moving backwards, then move in the opposite direction toward the target More effects can be viewed through examples 3. Tween The Tween easing class is used to implement easing of the target object's attributes, such as target value settings such as the easing distance of the x or y axis of the target object, as well as settings such as easing start, stop, and cleanup. 3.1 Introduction to commonly used APIs The easing class Tween provides more methods, and we commonly use two methods, namely from() and to(). The parameter settings of these two methods are exactly the same, but the effects are different. Different, from is to generate movement from the easing target point to the initial position (from the easing target position), and to is to generate movement from the initial position to the easing target position (to the easing target position), which will be detailed later with examples. Note, developers can first understand the basic instructions of these two methods: /** * From the props attribute, ease to the current state. * @param target target object (the object whose attribute value is about to be changed). * @param props Changed property list, such as {x:100,y:20,ease:Ease.backOut,complete:Handler.create(this,onComplete),update:new Handler(this,onComplete)}. * @param duration The time spent, in milliseconds. * @param ease easing type, the default is uniform motion. * @param complete End callback function. * @param delay delay execution time. * @param coverBefore Whether to cover the previous easing. * @param autoRecover Whether to automatically recycle, the default is true, and it will automatically recycle to the object pool after easing. * @return Returns the Tween object. */ static from(target: any, props: any, duration: number, ease: Function = null, complete: Handler = null, delay: number = 0, coverBefore: boolean = false, autoRecover: boolean = true): Tween { return Pool.getItemByClass(\"tween\", Tween)._create(target, props, duration, ease, complete, delay, coverBefore, false, autoRecover, true); } /** * Easing the props property of the object to the target value. * @param target target object (the object whose attribute value is about to be changed). * @param props Changed property list, such as {x:100,y:20,ease:Ease.backOut,complete:Handler.create(this,onComplete),update:new Handler(this,onComplete)}. * @param duration The time spent, in milliseconds. * @param ease easing type, the default is uniform motion. * @param complete End callback function. * @param delay delay execution time. * @param coverBefore Whether to cover the previous easing. * @param autoRecover Whether to automatically recycle, the default is true, and it will automatically recycle to the object pool after easing. * @return Returns the Tween object. */ static to(target: any, props: any, duration: number, ease: Function|null = null, complete: Handler|null = null, delay: number = 0, coverBefore: boolean = false, autoRecover: boolean = true): Tween { return Pool.getItemByClass(\"tween\", Tween)._create(target, props, duration, ease, complete, delay, coverBefore, true, autoRecover, true); } 3.2 Parameter description Both methods to() and from() support static methods, so we don't need to instantiate the Tween class to use it. The parameters of to() and from() are relatively simple to understand. Here we focus on the props, duration, ease, complete, and delay parameters. props props are the properties of the target object that need to be changed to produce the easing effect. The public properties of the object can be set, such as the most commonly used x, y position properties, and alpha transparency properties, as well as other properties such as rotation, axis, size, etc. The setting of attributes is in the form of object data, such as {x:100,y:20,ease:Ease.backOut,complete:Handler.create(this,onComplete),update:new Handler(this,onComplete)} duration duration is the time it takes to execute the easing effect, in milliseconds. The longer the time, the slower the easing effect. ease Ease is an easing type, which can use various functions defined under the Ease class to change the animation process. complete complete is the callback method after easing is completed. For example, when a button appears to be easing, we cannot allow the user to click it during the easing process. In this case, we can use the easing to complete the callback, and add button monitoring to the callback function. delay delay is the time of delayed execution. Later, the text easing fluctuation effect will be produced through delayed execution in the instance. 3.3 Easing example In the following code, we first implement the text easing animation of the \"LayaBox\" character through the Tween.from() method. from() ： //Create easing text private createTween():void{ //\"LayaBox string total width\" var w:number = 800; //The starting position of text creation (>>Use the right shift operator here, which is equivalent to /2. Using >> is more efficient) var offsetX:number = Laya.stage.width - w >> 1; //Displayed string var demoString:string = \"LayaBox\"; var letterText:Laya.Text; //Create individual characters based on the \"LayaBox\" string length and use an easing animation for each individual character for(var i:number = 0,len:number = demoString.length;i (Animation 3-1) Combined with the example code, and then through the motion effect of animation 3-1, we can see that after the text \"Layabox\" appears at the initial position (y-axis 300), it disappears instantly, and then is set from the easing method Tween.from The target { y : 100 } (y axis 100) moves towards the initial position (easing effect from top to bottom). Because this method is first displayed at the initial position, and then disappears instantly from the easing target position to the initial position. It will create a visual difference and feel more like a bounce effect. So let's continue to understand the effects of Tween.to, and developers can choose which easing method to use according to their needs. to(): We can continue to use the above example, just change Tween.from to Tween.to //The object letterText attribute y moves from the initial y attribute to the 100 attribute of the easing target. The easing effect takes 3000 milliseconds. The easing type uses the elasticOut function method, and the delay interval is 1000 milliseconds. Laya.Tween.to( letterText , {y:100}, 3000, Laya.Ease.elasticOut, null, 1000 ); The operation effect is shown in the animation 3-2. (Animation 3-2) 3.4 Understanding Props parameters Regardless of Tween.from or Tween.to, the second parameter Props (property) can affect the motion trajectory of the easing effect, etc. Since the easing effects of Tween.from and Tween.to are originally opposite, Tween.from has a falling feeling, while Tween.to in GIF 3-2 has a bouncing upward feeling. If we swap the initial y attribute value with the easing target's y attribute value, let's take a look at the difference between the falling effect achieved using Tween.to and Tween.from. Continuing with the previous example, modify the code as follows. //Initial y attribute of text letterText.y = 100; //Laya.Tween.from(letterText,{y:100},3000,Laya.Ease.elasticOut,null,i*1000);//Comment this line and change Laya.Tween.from to Laya.Tween. to Laya.Tween.to(letterText, { y : 300 }, 3000, Laya.Ease.elasticOut, null, i * 1000); The running effect is shown in the animation 3-3 (Animation 3-3) Since in the animated picture 3-3, the initial y attribute is at 100, the effect of Tween.to is to move from the initial attribute to the attribute of the easing target. Therefore, when the y attribute of the easing target is 300, it will produce a movement from the initial y-axis of 100 to the y-axis of 300, which is the effect of falling. There will be a significant difference between implementing the falling effect with Tween.from. Therefore, developers should pay attention to the difference in effects between the two when using them. 3.5 Understand the easing duration (duration) and delayed execution (delay) parameters Continuing to use the previous example, we change the third parameter duration to 1000 milliseconds and the sixth parameter delay to 100 milliseconds. The effect is as shown in the animation 3-4. Both the easing speed and the speed of the falling interval will produce obvious changes. Therefore, it can be seen that different animation effect goals can also be achieved by adjusting the duration or delay time. I won’t go into details here, developers can adjust the experience themselves. (Animation 3-4) The modified code for the effect of animation 3-4 is as follows: //Initial y attribute of text letterText.y = 100; //Laya.Tween.from(letterText,{y:100},3000,Laya.Ease.elasticOut,null,i*1000);//Comment this line and change Laya.Tween.from to Laya.Tween. to Laya.Tween.to(letterText, { y : 300 }, 1000, Laya.Ease.elasticOut, null, i * 100); 3.6 Understanding ease parameters The fourth parameter ease corresponds to each method of the laya.utils.Ease class. In this section, we change it to the Ease.bounceIn effect, as shown in the animation 3-5. (Animation 3-5) The modified code for the effect of animation 3-5 is as follows: //Initial y attribute of text letterText.y = 100; //Laya.Tween.from(letterText,{y:100},3000,Laya.Ease.elasticOut,null,i*1000);//Comment this line and change Laya.Tween.from to Laya.Tween. to Laya.Tween.to(letterText, { y : 300 }, 1000, Laya.Ease.bounceIn, null, i * 100); 3.7 Understanding the completion callback (complete) parameters The fifth parameter complete is used to call back after executing the easing effect. We continue to use the previous example and add a callback method to make the font color turn red after the easing is completed. Usage example: Laya.Tween.to(letterText, { y : 300 }, 1000, Laya.Ease.bounceIn, Laya.Handler.create(this,this.changeColor,[letterText]), i * 100); The added changeColor method is as follows /** * Callback method after easing is completed * txt easing object */ private changeColor(txt:Laya.Text):void{ //Change text font to red txt.color = \"#ff0000\"; } The code running effect is shown in Figure 3-6. (Animation 3-6) 3.8 Implement process callback through Props parameters The complete (complete callback) parameter can be implemented not only in the fifth parameter, but also in the second parameter Props. However, in order to make the code clearer and easier to read, we do not recommend implementing the completion callback in Props. Here we only introduce how to implement update callback in Props. That is to say, if we want to execute the callback method during the easing process, it is impossible to implement the fifth parameter, because the fifth parameter must be executed after the easing is completed. Therefore, we continue to use the previous example and add a font color update callback in the Props parameter. Usage example: /** * The object letterText property y eases from 100 to 300, and the color is updated through the callback method every frame * Use 1000 milliseconds to complete the easing effect * The easing type uses bounceIn * After the easing effect of a single character ends, use the changeColor callback function to change the character to red * Execution with delay interval i*100 milliseconds */ Laya.Tween.to(letterText, { y : 300, update: new Laya.Handler(this, this.updateColor,[letterText])}, 1000, Laya.Ease.bounceIn, Laya.Handler.create(this,this.changeColor,[letterText]), i * 100); The added changeColor method is as follows /** * Callback update method when easing is in progress * txt easing object */ private updateColor(txt:Laya.Text):void{ var c:number = Math.floor(Math.random()*3); switch (c) { case 0: txt.color = \"#eee000\"; break; case 1: txt.color = \"#ffffff\"; break; case 2: txt.color = \"#ff0000\"; break; default: txt.color = \"#eee000\"; break; } } When the code is running, since the update callback is executed every frame, there is a flashing effect during the easing process. As shown in animation 3-7 (Animation 3-7) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:10:52 "},"basics/common/Pool/readme.html":{"url":"basics/common/Pool/readme.html","title":"Pool","keywords":"","body":"Object pool usage1. Overview2. Object Pool Pool2.1 Obtain an object pool2.2 Clean up an object pool2.3 Obtain objects from the pool2.4 Recycle objects into the pool2.5 Obtain and recycle objects through class namesObject pool usage 1. Overview During the project development process, many objects are constantly created and removed, such as the creation and removal of character attack bullets, special effects, the destruction and refresh of NPCs (non-player characters), etc., which consumes a lot of performance during the creation process. , especially when the number is large, this will cause lag. Therefore, using an object pool can avoid the creation of a large number of objects. If we put objects into the pool every time they are used, such as monsters, bullets, etc., and the monsters are killed and no longer needed, they can be placed in the pool. The next time they are used, they can be taken directly from the pool. It needs to be created only if the object pool does not exist. The advantage of the object pool is that it reduces the overhead of instantiating objects, allows objects to be used repeatedly, and reduces the chance of new memory allocation and garbage collector running. In addition, when the object is removed, it is not immediately erased from the memory. Only when the memory is considered to be insufficient, the garbage collection mechanism will be used to clear it. Clearing is very memory intensive and may cause lags. Using the object pool will reduce the garbage objects of the program and effectively improve the running speed and stability of the program. Next, let's take a look at how to use the object pool (Pool) in LayaAir. 2. Object Pool Pool Pool is an object pool class, used for storage and reuse of objects. Reasonable use of object pools can effectively reduce the cost of object creation, avoid frequent garbage collection, and thus optimize game smoothness. 2.1 Obtain an object pool /** * Get the object pool based on the object type identification character. * @param sign Object type identification character. * @return object pool. */ static getPoolBySign(sign: string): any[] { return Pool._poolDic[sign] || (Pool._poolDic[sign] = []); } Laya.Pool identifies and manages object pools through object type identifiers, which are string names. If this identifier does not exist in the object pool system, an object pool with the identifier will be created. Therefore, we can also define multiple object pools through identification to handle different types of objects respectively. For example, the attacking bullet is an object pool, and the NPC player is an object pool. So, when we want to use an object pool, we need to call it in the code like this: let bulletPool = Laya.Pool.getPoolBySign(\"Bullet\"); With the object pool, we can check the current situation of the object pool, such as checking the number of objects in the object pool, continuing to add objects, and so on. For example code: let bulletPool = Laya.Pool.getPoolBySign(\"Bullet\"); // Check the number of objects in the current object pool console.log( bulletPool.length ); if( bulletPool.length == 0 ) { //Put the bullet into the object pool pool.push( new Bullet() ); } 2.2 Clean up an object pool /** * Clear the objects in the object pool. * @param sign Object type identification character. */ static clearBySign(sign: string): void { if (Pool._poolDic[sign]) Pool._poolDic[sign].length = 0; } For example, in a game, when a battle ends and there is no need for the object pool for bullets, we can clean up the object pool through code: Laya.Pool.clearBySign(\"Bullet\"); 2.3 Obtain objects from the pool 2.3.1 Obtained by identification /** * Get an object of this type stored in the object pool based on the object type identification character passed in. If there is no object of this type in the object pool, null is returned. * @param sign Object type identification character. * @return An object of this type in the object pool. If there is no object of this type in the object pool, null is returned. */ static getItem(sign: string): any { var pool: any[] = Pool.getPoolBySign(sign); var rst: any = pool.length ? pool.pop() : null; if (rst) { rst[Pool.POOLSIGN] = false; } return rst; } This is the most basic operation. An example of getting an object from the object pool. If there is no available object in the object pool, null is returned. The usage code is as follows: let bullet = Pool.getItem(\"Bullet\"); If the object obtained at this time is null, then we should consider there are two situations: For an object that needs to be created very frequently, or the process of creating this object consumes performance, we can pre-create a group of objects during the loading process of this scene and put this group of objects into the object pool. //Create the object pool of bullets for the first time let bulletPool = Laya.Pool.getPoolBySign(\"Bullet\"); //Create 10 bullet objects and put them into the object pool for( var i = 0 ; i The performance requirements for creating objects are not high. We can create objects through the following methods and put the objects into the object pool at any time. 2.3.2 Obtain through identification, create if not /** * According to the incoming object type identification character, obtain an object instance of this type identification in the object pool. * When there is no object identified by this type in the object pool, use the function passed in to create an object of this type to create a new object and return it. * @param sign Object type identification character. * @param createFun Method used to create objects of this type. * @param caller this object * @return an object identified by this type. */ static getItemByCreateFun(sign: string, createFun: Function, caller: any = null): any { var pool: any[] = Pool.getPoolBySign(sign); var rst: any = pool.length ? pool.pop() : createFun.call(caller); rst[Pool.POOLSIGN] = false; return rst; } Based on the above situation, if there are no objects in the object pool, you can use this method to create objects at any time: let bullet = Laya.Pool.getItemByCreateFun(\"Bullet\", function() { //Create a bullet let bullet = new Bullet(); // Get the object pool of bullets var pool = Laya.Pool.getPoolBySign(\"Bullet\"); //Put the bullet into the object pool, or not into the object pool, according to the developer's needs pool.push( bullet ); // Return bullet object return bullet; }); 2.4 Recycle objects into the pool 2.4.1 Recycling through objects /** * Put the object into the object pool corresponding to the type identifier. * @param sign Object type identification character. * @param item object. */ static recover(sign: string, item: any): void { if (item[Pool.POOLSIGN]) return; item[Pool.POOLSIGN] = true; Pool.getPoolBySign(sign).push(item); } For example, during a battle in the game, when the bullet taken out of the object pool has ended its life cycle, we can recycle the bullet object into the object pool through code: Laya.Pool.recover(\"Bullet\", bullet); 2.5 Obtain and recycle objects through class names Often when we are doing complex system architecture, it is a good way to obtain and recycle objects by using class names. Laya's Pool object has already considered this situation for us, let's take a look first 2.5.1 Obtaining objects through class names /** * According to the incoming object type identification character, obtain an object instance of this type identification in the object pool. * When there is no object identified by this type in the object pool, a new object is created and returned based on the type passed in. * @param sign Object type identification character. * @param cls The class used to create objects of this type. * @return an object identified by this type. */ static getItemByClass(sign: string, cls: new () => T): T { if (!Pool._poolDic[sign]) return new cls(); var pool = Pool.getPoolBySign(sign); if (pool.length) { var rst = pool.pop(); rst[Pool.POOLSIGN] = false; } else { rst = new cls(); } return rst; } 2.5.2 Recycling based on class name /** * Recycle according to the class name. If the class has a class name, it will be recycled. If not, it will not be recycled. * @param instance specific instance of the class */ static recoverByClass(instance: any): void { if (instance) { var className: string = instance[\"__className\"] || instance.constructor._$gid; if (className) Pool.recover(className, instance); } } With these two corresponding methods, we don't need to care about the creation and recycling of each object in the code, we can only care about the internal logic of the object. For example, there are many skill special effects during combat. We can manage the object pool for each special effect in a unified way: export class EffectA { constructor() { super(); } static create(): Effect { Pool.getItemByClass(EffectA); } recover(): void { Pool.recoverByClass(this); } } export class EffectB { constructor() { super(); } static create(): EffectB { Pool.getItemByClass(EffectB); } recover(): void { Pool.recoverByClass(this); } } In summary, the Pool provided by Laya is a relatively basic object pool. Developers can expand the use of the object pool according to their own needs, making it easier to implement more complex object management. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:54:57 "},"basics/common/network/readme.html":{"url":"basics/common/network/readme.html","title":"network","keywords":"","body":"Telecommunication1. Overview2. Http connection2.1 Laya.HttpRequest2.2 GET2.3 POST2.4 Extend HttpRequest3. WebSocket connection3.1 Laya.Soccet3.2 Laya.Byte binary reading and writing4. Use of ProtocolBuffer4.1 Message Definition4.2 Add protobuf class library to the project4.3 Load protocol file4.4 Message method4.5 Code ExampleTelecommunication 1. Overview During our project development process, apart from the fact that a single machine does not need to use network communication, when developing a network project, it is inevitable to deal with network communication. This chapter will explain the network communication part of LayaAir. Usually we use Http and WebSocket, two network communication methods. First, let’s compare the differences between the two: HTTP： Advantages: The protocol is mature, widely used, based on TCP/IP, has the reliability of TCP, low R&D cost, rapid development, and is widely supported, such as nginx/apache/tomcat, etc. Disadvantages: stateless and connectionless, only PULL mode, PUSH is not supported, data packets are large, and all header information must be included in each request. Features: stateless, connectionless (short connection), supports C/S mode, suitable for text transmission, but can also transmit other types of data, such as pictures, videos, etc. WebSocket： Advantages: The protocol is relatively new, but has become mature. It is based on TCP/IP and has the reliability of TCP. The data message is smaller. Only the handshake phase when establishing a connection requires larger header information, and the header information in the subsequent data exchange phase is The information is small, connection-oriented, stateful protocol, and supports the server to actively push data (PUSH mode). Disadvantages: WebSocket is an application layer protocol. Although the data packets are relatively concise, compared with the TCP/IP protocol, its data packet header information is relatively large. For very small data packets, this may cause some additional traffic consumption. In addition, more server resources may be consumed due to the need to maintain the connection. Features: Stateful, connection-oriented, small data header, supports full-duplex communication, suitable for applications requiring real-time communication. Through the above analysis of protocol characteristics, it is recommended that: For weak network games, such as elimination games and card games, you can use HTTP protocol directly. If security is considered, use HTTPS directly, or use symmetric encryption on the content body; For real-time and interactive requirements, and the team has relevant experience, you can give priority to the websocket protocol, such as large online games such as SLG and RPG. 2. Http connection The HTTP protocol, the Hypertext Transfer Protocol, is the basis of Web networking and one of the protocols commonly used in mobile phone networking. The HTTP protocol is an application built on the TCP protocol. 2.1 Laya.HttpRequest In the LayaAir engine, HttpRequest is the basic class for us to send requests. The HttpRequest class actually wraps the native XMLHttpRequest. Let’s first understand HttpRequest. 2.1.1 Native XMLHttpRequest object /** * The native XMLHttpRequest reference encapsulated by this object. */ get http(): any { return this._http; } XMLHttpRequest is available through the ._http attribute. XMLHttpRequest in Chinese can be interpreted as extensible hypertext transfer request. It provides the client with the functionality to transfer data between the client and the server. It provides a simple way to get data via a URL without causing the entire page to refresh. This allows the web page to update only part of the page without disturbing the user. Properties Properties Type Description onreadystatechange function A JavaScript function object that will be called when the readyState property changes. readyState unsigned short Five statuses of requests response varies The type of response entity is specified by responseType, which can be ArrayBuffer, Blob, Document, JavaScript Object (i.e. \"json\"), or a string. If the request is incomplete or failed, the value is null responseText DOMString The response to this request is text, or null when the request was unsuccessful or has not yet been sent. Read-only. responseType XMLHttpRequestResponseType Setting this value changes the response type. Just tell the server the response format you expect. status unsigned short The response status code for the request (for example, status code 200 indicates a successful request). Read-only statusText DOMString Response status information for this request, consisting of a status code and reason phrase (such as \"200 OK\"). Read only upload XMLHttpRequestUpload You can add an event listener on upload to track the upload process. withCredentials boolean Indicates whether to use authentication information (such as cookies or authorization headers) when making cross-site Access-Control requests. Defaults to false timeout number Request timeout Method abort() If the request has already been sent, the request is aborted immediately. getAllResponseHeaders() Returns all response header information (response header name and value), or null if the response header has not been accepted. getResponseHeader() Returns the value of the specified response header. If the response header has not been accepted or the response header does not exist, null is returned. open() Initialize a request. send() Send the request. If the request is in asynchronous mode (default), this method will return immediately. In contrast, if the request is in synchronous mode, the method will not return until the response to the request has been fully accepted. setRequestHeader() Assign a value to the specified HTTP request header. Before doing this, you must confirm that you have opened a URL by calling the open() method. Therefore, in the process of using HttpRequest, we can also obtain the XMLHttpRequest object and perform related operations on the XMLHttpRequest object. We will not explain too much about XMLHttpRequest here. Developers can check the relevant documents by themselves. For detailed information on XMLHttpRequest, please see W3C's xhr standard; XMLHttpRequest sends various types of data, you can refer to Sending Data and this article on html5rocks To understand the basic use of XMLHttpRequest, you can refer to MDN's Introduction to XMLHttpRequest; If you want to know about cross-domain requests, you can refer to W3C's cors standard; 2.1.2 send() method Send a request. Usually the request is sent asynchronously, and the parameter types of send are as follows: /** * Send HTTP request. * @param url The requested address. Most browsers implement a Same Origin Security Policy and require that the URL have the same hostname and port as the text containing the script. * @param data (default = null)The data sent. * @param method (default = \"get\")The HTTP method used for the request. Values ​​include \"get\", \"post\", \"head\". * @param responseType (default = \"text\") The response type of the web server, which can be set to \"text\", \"json\", \"xml\", \"arraybuffer\". * @param headers (default = null) HTTP request header information. The parameters are in the form of a key-value array: key is the name of the header and should not include blanks, colons or newlines; value is the value of the header and should not include newlines. For example [\"Content-Type\", \"application/json\"]. */ send(url: string, data: any = null, method: \"get\" | \"post\" | \"head\" = \"get\", responseType: \"text\" | \"json\" | \"xml\" | \"arraybuffer\" = \"text\", headers: any[] | null = null) 2.1.3 Supported event types The basic ones we commonly use are progress events, completion events, error events, etc. /** * Dispatched when the request progress changes. * @eventType Event.PROGRESS * */ /*[Event(name = \"progress\", type = \"laya.events.Event\")]*/ /** * Dispatched after the request is completed. * @eventType Event.COMPLETE * */ /*[Event(name = \"complete\", type = \"laya.events.Event\")]*/ /** * Dispatched when request error occurs. * @eventType Event.ERROR * */ /*[Event(name = \"error\", type = \"laya.events.Event\")]*/ 2.1.4 How to use it in code The HttpRequest used in the LayaAir engine inherits the EventDispatcher, which has the function of event dispatching. In addition, it has the function of sending requests. Let's write a simple example to see how to use it: class LayaSample { constructor() { //Create HttpRequest object let http: Laya.HttpRequest = new Laya.HttpRequest(); //Set the timeout http.http.timeout = 10000; //Sent a simple request http.send(\"resources/data.txt\", \"\", \"get\", \"text\");//You need to create a new data.txt file in the resources folder //Set the completion event and add a callback method http.once(Laya.Event.COMPLETE, this, this.completeHandler); //Set error event and add callback method http.once(Laya.Event.ERROR, this, this.errorHandler); //Set progress events and add callback methods http.on(Laya.Event.PROGRESS, this, this.processHandler); } private processHandler(data:any): void { console.log(\"processHandler\"); } private errorHandler(error:any): void { console.log(\"errorHandler\"); } private completeHandler(data:any): void { console.log(\"completeHandler\"); } } new LayaSample(); 2.2 GET In the above example, we sent a simple request using the get method. Used to obtain a remote file in text format. If we dynamically request remote data, it can be changed to the following format: this.hr = new HttpRequest(); this.hr.once(Event.PROGRESS, this, this.onHttpRequestProgress); this.hr.once(Event.COMPLETE, this, this.onHttpRequestComplete); this.hr.once(Event.ERROR, this, this.onHttpRequestError); //Sent a get request with the parameters name=myname and psword=xxx this.hr.send('http://xkxz.zhonghao.huo.inner.layabox.com/', null, 'get', 'text'); The focus here is the send method, which should be distinguished from the send of XMLHttpRequest. 2.3 POST The following method of requesting a data using the post method is as follows: this.hr = new HttpRequest(); this.hr.once(Event.PROGRESS, this, this.onHttpRequestProgress); this.hr.once(Event.COMPLETE, this, this.onHttpRequestComplete); this.hr.once(Event.ERROR, this, this.onHttpRequestError); //Sent a post request with the parameters name=myname and psword=xxx this.hr.send('http://xkxz.zhonghao.huo.inner.layabox.com/', 'name=myname&psword=xxx', 'post', 'text'); Note: There is a difference between GET and POST requests: GET request parameters are passed through the URL, and POST request parameters are included in the request body. GET requests are less secure than POST requests because the parameters are exposed directly in the URL, so GET requests cannot be used to pass sensitive information. The parameters passed in the url of the GET request are limited in length (there is no limit on the length of the URL in the HTTP protocol. The limit is the limit imposed by the specific browser and server. Different browsers have different length limits). POST has no limit on length. GET request parameters will be completely retained in the browser's history, and POST request parameters will not be retained. GET requests are URL encoded (percent encoding), and POST requests support multiple encoding methods. 2.4 Extend HttpRequest During the development process, HttpRequest may not meet our needs, such as uploading files, setting timeouts, operating form data, etc. Extending HttpRequest is very simple. You can inherit HttpRequest or simply rewrite the HttpRequest class yourself. This depends on the needs of the developer. It is recommended to directly inherit EventDispatcher when rewriting HttpRequest. Rewriting is to repackage the XMLHttpRequest class. Here is a simple demonstration of inheritance: class HttpRequestExtension extends Laya.HttpRequest { constructor() { super(); } public send(url:string,data:any=null,method:string=\"get\", responseType:string=\"text\", headers:any=null):void{ super.send(url,data,method,responseType,headers); this._http.upload.onprogress= function(e:any):void { //upload progress } this._http.upload.onload= function(e:any):void { } this._http.upload.onerror= function(e:any):void { } this._http.upload.onabort = function(e:any):void { } } } The above is a demonstration of uploading files, adding some upload events of XMLHttpRequest. The super.send here simply uses the method of the parent class. Developers can not use it and write another one to meet their own needs. 3. WebSocket connection WebSocket is a technology based on the ws protocol, which makes it possible to establish a full-duplex connection. Websocket is commonly used in browsers, but this protocol is not restricted by the platform it is used on. The format of data sent by websocket is generally binary and string. The LayaAir engine has encapsulated the Socket and Byte classes for us, and sending and receiving data can be completed by combining the Byte class. 3.1 Laya.Soccet In the LayaAir engine, Socket is the basic class we use WebSocket. Socket encapsulates HTML5 WebSocket, allowing full-duplex real-time communication between the server and the client, and allowing cross-domain communication. After establishing a connection, both the server and the Browser/Client Agent can actively send or receive text and binary data to each other. Let’s first understand the usage of Socket 3.1.1 Connect server There are three ways to connect to the server through Socket: way Description Constructor parameter passing Connect immediately, such as new Socket(\"192.168.1.2\",8899); note that the host parameter here does not have the ws prefix. connect method Pass the url and port number to connect to the server; socket.connect(\"192.168.0.1.2\", 8989); note that the host parameter here does not have the ws prefix. connectByUrl method Pass the entire url, such as socket.connectByUrl(\"ws://localhost:8989\"); there is the ws prefix here. 3.1.2 Send data Sending data is very simple. You only need to call the send function of Socket. The parameter can be string or ArrayBuffer. Sending string format: this.socket.send(\"hello world\");//This is the form of sending a string. Send data in binary format: //Write a byte this.byte.writeByte(1); //Write an int16 data this.byte.writeInt16(20); //Write a 32-bit floating point data this.byte.writeFloat32(20.5); //Write a string; this.byte.writeUTFString(\"hello\"); //Declare a temporary Byte type here var by:Laya.Byte = new Laya.Byte(); //Set endian; by.endian = Laya.Byte.LITTLE_ENDIAN; //Write an int32 data by.writeInt32(5000); //Write a uint16 data by.writeUint16(16); //Write the temporary byte data into byte. Note here that by.buffer is written; this.byte.writeArrayBuffer(by.buffer); //Here, the byte array data is sent to the server through the socket. this.socket.send(this.byte.buffer); //Clear the data; make it easier to read and write next time; this.byte.clear(); We saw above that the data we need is read into a Byte array through a byte array, and what is finally sent to the server is byte.buffer, which is an ArrayBuffer data type. It must be noted here that the parameter of send is ArrayBuffer. Many developers may not pay attention and directly pass it into Byte, resulting in incorrect data being sent. If it is written as this.socket.send(this.byte); this is wrong, so you must pay attention to this. 3.1.3 Receive data The data received by the client from the server will be dispatched to the Event.MESSAGE listening function. The parameter of receiveHandler is the data sent back by the server. It may be a string or a binary ArrayBuffer. We don't need to read the received string, we can just use it directly. But if what is received is binary, we need to read it and convert it into the type we need. private receiveHandler(msg: any = null): void { ///Receive data trigger function //.............Here we assume that what is received is a binary ArrayBuffer this.byte.clear(); this.byte.writeArrayBuffer(msg);//Read the received binary data into a byte array for easy analysis. this.byte.pos = 0;//Set offset pointer; ////Start reading the data below. Read the data in order according to the data passed by the server. var a:number = this.byte.getByte(); var b:number = this.byte.getInt16(); var c:number = this.byte.getFloat32(); var d:string = this.byte.getString(); var e:string = this.byte.getUTFString(); } 3.1.4 Supported event types What we commonly use is basically that the connection is successfully established, data is received, the connection is closed, scheduling after an exception occurs, etc. /** * Scheduled after the connection is successfully established. * @eventType Event.OPEN * */ /*[Event(name = \"open\", type = \"laya.events.Event\")]*/ /** * Scheduled after receiving data. * @eventType Event.MESSAGE * */ /*[Event(name = \"message\", type = \"laya.events.Event\")]*/ /** * Dispatched after the connection is closed. * @eventType Event.CLOSE * */ /*[Event(name = \"close\", type = \"laya.events.Event\")]*/ /** * Scheduling after an exception occurs. * @eventType Event.ERROR * */ /*[Event(name = \"error\", type = \"laya.events.Event\")]*/ 3.1.5 How to use it in code Let’s give a simple WebSocket code example for sending and receiving data: private connect(): void { //Create Socket object this.socket = new Socket(); //Establish a connection to the server this.socket.connectByUrl(\"ws://echo.websocket.org:80\"); //Indicates the data in the buffer that needs to be sent to the server this.output = this.socket.output; //Add listening event this.socket.on(Event.OPEN, this, this.onSocketOpen); this.socket.on(Event.CLOSE, this, this.onSocketClose); this.socket.on(Event.MESSAGE, this, this.onMessageReveived); this.socket.on(Event.ERROR, this, this.onConnectError); } //Connection established successfully callback private onSocketOpen(e: any = null): void { console.log(\"Connected\"); // send string this.socket.send(\"demonstrate \"); //Send using output.writeByte var message: string = \"demonstrate \"; for (var i: number = 0; i 3.2 Laya.Byte binary reading and writing In development projects, binary operations are indispensable. In the HTML5 era, binary support has made great breakthroughs. However, the API is cumbersome and inconvenient for developers to develop projects. In the era of web games, the binary array ByteArray of ActionScript 3.0 has complete functions and the API operation is simple and easy to understand. Therefore, LayaAir's Byte takes over the characteristics of HTML5's TypedArray while referring to ByteArray. Let’s take a look at the main uses 3.2.1 Common methods Construction method parameter: length: length When the length parameter is passed in, an internal array buffer is created, the size of the buffer is the length size passed in. typedArray: typed array When an arbitrary typed array object (typedArray) containing elements of any type (such as Int32Array) is passed as a parameter, typeArray is copied to a new typed array. Each value in typeArray is converted according to the constructor before being copied to the new array. The newly generated typed array object will have the same length as the passed array (for example, if the original typeArray.length==2, then the length of the newly generated array is also 2, but each item in the array has been converted. ). ArrayBuffer: Binary data buffer. The above three methods can instantiate a Byte and create binary data according to different parameters. //Instantiate a binary array Byte var byte:Laya.Byte = new Laya.Byte(); //Or pass in a typed array var uint8Byte:Uint8Array = new Uint8Array(10); var byte:Laya.Byte = new Laya.Byte(uint8Byte); //Or pass in an ArrayBuffer type var buffer:ArrayBuffer = new ArrayBuffer(20); var byte:Laya.Byte = new Laya.Byte(buffer); writeArrayBuffer(arraybuffer:*, offset:number = 0, length:number = 0):void Writes the specified binary buffer data. Specify the offset and length of the data, as follows: var byte:Laya.Byte = new Laya.Byte(); var byte1:Laya.Byte = new Laya.Byte(); byte1.writeFloat32(20.0);//Write a four-byte floating point number byte1.writeInt16(16);//Write a two-byte integer byte1.writeUTFString(\"hell world\");//Write a string; byte.writeArrayBuffer(byte1.buffer,6);//Read the data of byte1 into byte starting from the sixth byte. Omit the floating point number 20.0 and the integer 16 byte.pos = 0;// console.log(byte.readUTFString())//Read the string from byte. Read data getByte():number Read signed bytes from a byte stream. getInt16():number Reads an Int16 value from the byte stream at the current byte offset. getInt32():number Reads an Int32 value from the byte stream at the current byte offset. getFloat32():number Reads an IEEE 754 single-precision (32-bit) floating-point number from the byte stream at the current byte offset. getFloat32Array(start:number, len:number)any Reads the specified length of data from the specified location to create a Float32Array object and returns this object. getFloat64():number Reads an IEEE 754 double-precision (64-bit) floating-point number from the byte stream at the current byte offset. getInt16():number Reads an Int16 value from the byte stream at the current byte offset. getInt32():number Reads an Int32 value from the byte stream at the current byte offset. getUint8():number Reads a Uint8 value from the byte stream at the current byte offset. getUint16():number Reads a Uint16 value from the byte stream at the current byte offset. getUint32():number Reads a Uint32 value from the byte stream at the current byte offset. getInt16Array(start:number, len:number):any Reads data of the specified length from the specified location to create an Int16Array object and returns this object. getString():string Read character value. getUTFBytes(len:number = -1):string The read string must be the string written by the writeUTFBytes method. getUTFString():string Read UTF-8 string. data input writeByte(value:number):void writes a byte in the byte stream. var byte:Laya.Byte = new Laya.Byte(); byte.writeByte(10);//between 0-255 writeFloat32(value:number):void writes a Float32 value at the current byte offset. The range is $\\left[-2^{128}, 2^{127}\\right]$, which is approximately -3.4E38—3.4E+38. var byte:Laya.Byte = new Laya.Byte(); byte.writeFloat32(10.021); writeFloat64(value:number):void writes a float64-bit value. The value range is -1.7E308~1.7E+308. writeInt16(value:number):void writes an Int16 value at the current byte offset. The range is -32768 to +32767. var byte:Laya.Byte = new Laya.Byte(); byte.writeInt16(120); writeInt32(value:number):void writes an Int32 value at the current byte offset. A signed integer between -2,147,483,648 and +2,147,483,647. **writeUint16**(value:number):void writes a Uint16 value at the current byte offset. writeUint32(value:number):void writes a Uint32 value at the current byte offset. writeUint8(value:number):void writes a Uint8 value at the current byte offset. writeUTFBytes(value:string):void writes a string. The string written by this method must be read using the readUTFBytes method. writeUTFString(value:string):void writes a UTF-8 string to the byte stream. clear():void clears data. var byte:Laya.Byte = new Laya.Byte(); byte.writeInt16(120); byte.pos =0;//Return the reading position to zero. getSystemEndian():string[static] Gets the byte storage order of the system. console.log(Laya.Byte.getSystemEndian());//Print the byte order of the system 3.2.2 Properties BIG_ENDIAN : string= bigEndian[static] means that the most significant byte of a multibyte number is at the beginning of the byte sequence. LITTLE_ENDIAN : string= littleEndian[static] means that the least significant byte of a multi-byte number is at the beginning of the byte sequence. posnumber currently reads the position. var byte:Laya.Byte = new Laya.Byte(); byte.writeInt16(120); byte.pos =0;//Return the reading position to zero. length: number Length in bytes. endian : string byte order. var byte:Laya.Byte = new Laya.Byte(); byte.endian = Laya.Byte.BIG_ENDIAN; //Set to big endian; bytesAvailable : number[read-only]The number of bytes of data that can be read from the current position of the byte stream to the end. var byte:Laya.Byte = new Laya.Byte(); byte.writeFloat32(20.0); byte.writeInt16(16); byte.writeUTFString(\"hell world\"); byte.pos = 6; console.log(byte.bytesAvailable) 3.2.3 Code Demonstration Below we use a complete code to demonstrate the application of this class. For example, in network connection, we receive and send network messages. var msg:any ={name:\"xxx\",age:18,weight:65.5,height:175}; var byte:Laya.Byte = new Laya.Byte(); //instantiate byte array byte.endian = Laya.Byte.LITTLE_ENDIAN; //Set the big and small ends byte.writeUTFString(msg.name); //data input byte.writeByte(msg.age); byte.writeFloat32(msg.weight); byte.writeInt16(msg.height); Take a look at the output: //Set pos to 0 and start reading from the beginning in the order of writing. byte.pos = 0; console.log(byte.getUTFString()); console.log(byte.getByte()); console.log(byte.getFloat32()); console.log(byte.getInt16()); 3.2.4 Typed array Laya's byte package is a typed array. Developers can refer to mdn's official API description. to expand the application of your own project. DataView view provides a view that matches the platform's order of bytes in memory (endian ) Independent low-level interface for reading and writing multi-numeric types from ArrayBuffer. Uint8Array The array type represents an 8-bit unsigned integer array, and the content is initialized to 0 when created. After creation, the elements in the array can be referenced as objects or using array subscript indexing. Int8Array: Type array represents an array of two's complement 8-bit signed integers. Contents are initialized to 0. Once created, you can use the object's methods to reference elements in the array, or use standard array indexing syntax. Int16Array(); type array represents a two's complement 16-bit signed array. Uint16Array(); type array represents a two's complement 16-bit unsigned array Int32Array(); type array represents a two's complement 32-bit signed array Uint32Array(); type array represents a two's complement 32-bit unsigned array Float32Array(); type array represents a 32-bit floating point array. Float64Array(); type array represents a 64-bit floating point array. 4. Use of ProtocolBuffer protocolbuffer (hereinafter referred to as PB) is a data exchange format of Google. It is independent of language and platform. Similar to data representation languages ​​such as XML and JSON, ProtocolBuffer is a flexible, efficient, and automatic method for serializing structured data. The format is somewhat similar to XML. You can define the data format yourself. It is a binary format that allows you to use A canonical language defines a pattern. As a protocol format for network communication, ProtocolBuffer is a very popular method now. Let's take a look at it. 4.1 Message Definition Here is a simple example, which is a very simple request message format. // awesome.proto package awesomepackage; //Specify proto version syntax = \"proto3\"; //message contains multiple types of fields message AwesomeMessage { string awesome_field = 1; // becomes awesomeField } In the above example, the type of fields is string. Of course, you can also specify more complex fields, such as enumeration type enum, or nested message type. After the above Message is defined, we save the protocol file to the project directory \"assets/res/protobuf/awesome.proto\"; 4.2 Add protobuf class library to the project We can download the latest protobuf class library from https://github.com/protobufjs/protobuf.js and put it in the bin directory of the project, and reference protobuf.js in index.html 4.3 Load protocol file protobuf class library, loads protocol files through the load method /** * Loads one or multiple .proto or preprocessed .json files into a common root namespace and calls the callback. * @param {string|string[]} filename One or multiple files to load * @param {Root} root Root namespace, defaults to create a new one if omitted. * @param {LoadCallback} callback Callback function * @returns {undefined} * @see {@link Root#load} */ function load(filename, root, callback) { if (typeof root === \"function\") { callback = root; root = new protobuf.Root(); } else if (!root) root = new protobuf.Root(); return root.load(filename, callback); } 4.4 Message method Message.verify(message: Object): null|string Verify whether a Message object meets the requirements for a valid message. Message.create(properties: Object): Message Creates a new message instance from a set of Javascript data that meets the requirements for a valid message. Message.encode(message: Message|Object , writer: Writer): Writer Encode the Message object for network communication transmission. Message.decode(reader: Reader|Uint8Array): Message In network communication transmission data, the Mesaage object is obtained by decoding. Message.toObject(message: Message , options: ConversionOptions): Object Convert Message object data to a set of Javascript data. 4.5 Code Example onAwake(): void { var resPath: string = \"assets/res/protobuf/awesome.proto\"; //Load protobuf file this.ProtoBuf.load(resPath, this.onAssetsLoaded); } private onAssetsLoaded(err: any, root: any): void { if (err) throw err; // Get a Message message type var AwesomeMessage: any = root.lookupType(\"awesomepackage.AwesomeMessage\"); console.log(AwesomeMessage); // Initialization data var payload: any = { awesomeField: \"AwesomeString\" }; console.log(payload); //Verify whether the data is valid var errMsg: any = AwesomeMessage.verify(payload); // If there is an exception, throw an exception and terminate if (errMsg) throw Error(errMsg); //Create the entity of Message var message: any = AwesomeMessage.create(payload); console.log(message); //Compile Message entity into Buffer data format and wait for sending data var buffer: any = AwesomeMessage.encode(message).finish(); console.log(buffer); } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:51:22 "},"basics/common/adaptScreen/readme.html":{"url":"basics/common/adaptScreen/readme.html","title":"adaptScreen","keywords":"","body":"LayaAir screen adaptation and effective anti-aliasing1. Basic concepts1.1 Physical resolution1.2 Scaling factor and logical resolution1.3 Device pixel ratio1.4 Logical width and height1.5 Physical width and height (screen width and height)1.6 Design width and height1.7 Canvas width and height1.8 Adapted width and height1.9 Stage width and height2. Introduction to anti-aliasing2.1 Causes of sawtooth generation2.2 Engine built-in anti-aliasing2.3 Turn on anti-aliasing, why does it still feel jagged?2.4 Let the canvas use physical resolution3. Detailed explanation of LayaAir screen adaptation mode3.1 The easiest to understand adaptation mode3.2 Recommended adaptation mode for mobile terminals3.3 Other adaptation modes3.4 Notch adaptation ideas3.5 Other adaptation-related learningLayaAir screen adaptation and effective anti-aliasing Author: Charley Sometimes I see some 3D games that have very obvious aliasing. After communicating with some developers, I found that many people don’t know how to remove the obvious aliasing. This is not a problem only encountered by new developers. Developers with experience in game development, even developers who have developed many games using the LayaAir engine, may not be clear about it. In addition, I have recently encountered developers who want to know how to adapt Liu Haiping, so I will give a comprehensive introduction through this article. In order to allow novice developers to understand this matter, this article starts from the basic concepts and introduces in detail the various screen adaptation scaling modes of the LayaAir engine, the notch adaptation ideas, and how to effectively anti-alias. 1. Basic concepts The following basic concepts are very important and will affect the understanding of the engine adaptation principles later. Please read them carefully. 1.1 Physical resolution The simple understanding of physical resolution is the resolution supported by the hardware, in pixels (px), so we call each pixel on this hardware a physical pixel, also called a device pixel. The actual pixels on the screen are expressed in a mathematical expression such as the number of rows × the number of columns, which is the physical resolution. The LayaAir engine runs on a browser or other running environment. When performing screen adaptation, the physical resolution actually refers to the screen resolution on the browser or running environment. It is expressed as the number of pixels in the screen width × the number of pixels in the screen height. Therefore, the physical resolution width and height obtained by horizontal screen and vertical screen will be different. For example: In the default portrait screen state of iPhone8, the physical resolution width and height are expressed as 750 × 1334. In landscape mode, the physical resolution width and height are expressed as 1334 × 750. 1.2 Scaling factor and logical resolution 1.2.1 Scaling factor Origin iOS draws graphics in point (pt) as the unit. In the early days, 1 point=1 pixel. The iPhone 4 launched in 2010 began to adopt Retina screen display technology, and the physical resolution was increased by 4 times. At this time, if the iPhone 4 still uses the 1pt=1px solution, it will result in a display effect as shown below. (Picture 1) In Figure 1, the full-screen design is based on the 320 × 480 of the iPhone 3GS. The display effect under the iPhone 4 is as shown on the left side of Figure 1. The original full-screen content only occupies a quarter, and the rest is left blank. If the full-screen design is based on the iPhone 4 resolution of 640 × 960, the display effect on the iPhone 3GS screen will be as shown on the right side of Figure 1, with a large amount of content beyond the displayable area. Obviously, Apple will not let what happens in Figure 1 happen. In fact, the scaling factor of iPhone4 is @2X, that is, on this model, a point is represented by a 2×2 pixel matrix, as shown in Figure 2 The effect is shown, perfectly solving the problems that may occur in Figure 1. (figure 2) With the development of the times, the physical resolution of subsequent models is getting higher and higher, and one point occupies more and more physical pixels, as shown in the figure below. (image 3) The concept of scaling factors also applies to Android models 1.2.2 Logical resolution The simple understanding of logical resolution is the resolution used by the software. Our design adaptation depends entirely on it, and it is also reflected in the mathematical expression of multiplication. In order to better understand this concept, let's first look at a set of data tables. (Figure 4) From the data in Figure 4, we can see that with the update of mobile phone devices, the physical resolution has become higher and higher. If we perform screen adaptation according to the physical resolution, not counting Android, iPhone models alone will It's very fragmented. Fortunately, under the influence of the scaling factor, we see that the logical resolution basically does not change much, so the engine adaptation we will talk about later is mainly adapted to the logical resolution. 1.3 Device pixel ratio When we develop based on browsers, the scaling factor concept introduced previously corresponds to DPR (Device Pixel Ratio), which is called device pixel ratio in Chinese. The DPR value of the browser can be obtained through Laya.Browser.pixelRatio in the LayaAir engine. Let me expand on a few words here. In the browser, the zoom is controlled by the user by default. For example, when we expand the mobile browser with two fingers, we find that the web page will be enlarged, but the clarity will not be reduced. This is caused by the user's own scaling, and the scaling is not determined by the DPR value. If we want to adapt through logical resolution like APP development, let the browser determine how many physical pixels a CSS pixel occupies based on the DPR of the device. That requires relevant configuration using viewport in the meta tag of the entry HTML page. code show as below: The above code is added by default in the LayaAir engine, and it is mandatory to add it and cannot be deleted. Through the above viewport configuration, the page will not only prohibit the user from manual scaling, but will also automatically scale according to the DPR of the device. 1.4 Logical width and height The logical width and height refers to the width and height of the logical resolution. In the browser, the logical resolution pixels that can be scaled are CSS pixels. When the viewport is set, the browser will determine how many pixels a CSS occupies based on the DPR value. For example, when the DPR is 3, one CSS pixel will occupy 3×3 physical pixels. In the LayaAir engine, you can obtain the width of the logical resolution through Laya.Browser.clientWidth and the height of the logical resolution through Laya.Browser.clientHeight. In the portrait mode of mobile devices such as mobile phones, the narrow side is width and the long side is height. If the screen is flipped to landscape mode, the long side is the width and the narrow side is the height. In PC browsers, it is the visible width and height of the browser window obtained. 1.5 Physical width and height (screen width and height) Physical width and height correspond to the concept of physical resolution introduced previously, also known as screen width and height. Developers can obtain the width and height values ​​through the interface encapsulated by the engine. Through Laya.Browser.width, they can get the number of pixels on the screen width, and through Laya.Browser.height, they can get the number of pixels on the screen height. The screen width and height are the hardware screen width and height only in full screen mode. Developers need to understand that the screen width and height actually refers to the width and height of the running environment window. For example, when running on a browser, it is the width and height of the browser display window. The physical width and height in the LayaAir engine are calculated by logical width and height*DPR. The weird iPhone 6/7/8 Plus models have a logical resolution of 736×414 and a DPR value of 3. The multiplied result is obviously the same as the real physical resolution of each Plus model 1920×1080. incompatible. At this point, developers only need to understand that this is the case, and do not need to worry about adaptation errors. Since the LayaAir engine has made relevant configurations using viewport in the meta tag of the portal page, it will automatically scale according to DPR, and will eventually automatically Scaled to correspond to actual physical resolution. As for why the Plus model has such strange settings, I won’t go into details here. Interested students can search for answers on Baidu. 1.6 Design width and height Design width and height are the width and height used by developers when designing products. Faced with many models, some novice developers are a little confused about which one to choose as the design width and height. Here are a few words. (Figure 5) When designing width and height, the first thing to consider is to prioritize compatibility with most commonly used screen ratios. From the table in Figure 5 above, we can see that excluding outdated models, mobile phone screens are basically divided into two categories, one is a non-full-screen mobile phone with an aspect ratio of about 1:1.78, and the other is a mobile phone with an aspect ratio of about 1:1.78. The ratio is about 1:2.17 for a full-screen mobile phone. Most of the screen ratios of Android models of various brands are also these two or close to these two. Based on the principle of giving priority to performance, developers usually choose a smaller resolution as the main effect design, and then adapt it to other screen ratios. For example: the common width 750 height 1334 or width 720 height 1280. The above description of width and height refers to the design of portrait mode, and the reverse is required for horizontal screen. Open the Project Settings panel of the LayaAir 3.0 IDE and you can set it directly. The effect is shown in Figure 6. (Figure 6) 1.7 Canvas width and height As we all know, is the canvas in HTML5, and its width and height attributes are the width and height of the canvas. The canvas width and height will directly adopt the design width and height value in the noscale, exactfit, and noborder LayaAir engine adaptation modes. In other adaptation modes, it will change according to the adaptation rules. The value of the canvas width and height will have an impact on the final clarity and performance of the image. Even jagged edges or blurry images are related to the canvas width and height value here. We run any page in the IDE. After using F12 to enter debugging mode in chrome, we find the canvas tag with the ID of layaCanvas in the entry page. Remember this position. The red circle marked in Figure 7 is the initial width and height of the canvas. You can pay more attention to this when understanding the screen adaptation mode later. (Figure 7) 1.8 Adapted width and height Since Canvas draws based on bitmap pixels, the width and height of the canvas have an impact on the picture quality and performance, or there may be issues such as the special resolution of plus. Therefore, it cannot be adapted by directly changing the width and height of the canvas, otherwise there will be some adaptation problems. In the LayaAir engine, the scaling ratio required to adapt to width and height is calculated based on different adaptation mode rules, and then the canvas is scaled to the logical resolution range through the transform matrix (matrix), and then scaled through the viewport and DPR mechanisms. reduction. Based on the above, we need to understand that the adapted width and height are the final effect width and height processed by the LayaAir engine adaptation rules, which will directly affect the final effect after restoration through DPR. When you understand each adaptation mode, you can observe the canvas width and height and the matrix scaling effect of transform in the HTML entry page to compare the differences between different modes. For example, as shown in the red circle in Figure 8, the adapted width and height are 249.99975 and 444.666222 respectively. After restoring to the physical resolution size, although there is a slight loss in accuracy, it is difficult to see. (Figure 8) 1.9 Stage width and height The stage width and height refers to the stage width and height of the LayaAir engine. The node objects of the engine are added and controlled on the stage. Within the scope of the stage, you can control the display, event monitoring, collision detection, etc., so the stage width and height Adaptation is still very important. In the DevTools console, we can view the stage width and height through the engine API (Laya.stage.width and Laya.stage.height). By default, the stage width and height are directly equal to the design width and height. In the adaptation modes of full, fixedwidth, fixedheight, and fixedauto, the stage width and height will change according to the adaptation rules. The third section of this article will introduce it in detail. 2. Introduction to anti-aliasing 2.1 Causes of sawtooth generation The pixels of our screen are composed of a matrix sequence of rows and columns. In other words, there are no slashes on the screen. If you draw horizontal and vertical straight lines on a canvas based on pixel drawing, it will definitely be quite smooth. But what about drawing curves and diagonal lines? It can only be composed of two adjacent pixels that are continuously extended. If this sentence is difficult to understand, let's imagine a staircase and look at it from the side. It probably looks like this. The schematic effect is shown in Figure 9-1. (Figure 9-1) In addition, the basic composition of a 3D model is a polygonal grid composed of triangular faces. Drawing a model composed of 3D polygons is the same as our vector drawing of diagonal lines, curves, and circles. Therefore, it is normal for non-rectangular vector graphics and 3D models to produce aliasing. 2.2 Engine built-in anti-aliasing The LayaAir engine has built-in anti-aliasing methods, 3D anti-aliasing can be set in Camera. LayaAir provides a high-precision MSAA anti-aliasing solution and a high-performance FXAA anti-aliasing solution, as shown in Figure 9-2. (Figure 9-2) To learn more about the differences in 3D anti-aliasing parameters, you can read the \"Using 3D Camera\" document. 2D anti-aliasing, if you want to turn it on, you can set it in Project Settings, as shown in Figure 9-3. (Figure 9-3) After turning on anti-aliasing, the jagged edges will become smooth and blurred. The schematic effect is shown in Figure 9-4. (Figure 9-4) The blurred aliasing will be relatively smooth and difficult to see with the naked eye on a screen with a relatively high pixel density. In order to achieve the goal of eliminating the jagged feeling. 2.3 Turn on anti-aliasing, why does it still feel jagged? Some developers have discovered that when the anti-aliasing function is turned on, why do they still feel jagged? There are two reasons, The first is the problem of anti-aliasing solutions. For example, there are some small differences in accuracy between 3D anti-aliasing MSAA and FXAA. Second, no matter how high-precision anti-aliasing is, it is impossible to really remove aliasing. It can only make the edge transition smoother through some algorithms. Thereby reducing the aliasing phenomenon. On some screens with a relatively large pixel density, making it difficult for the naked eye to recognize does not really make the aliasing disappear. Therefore, if developers want to further reduce the aliasing, they should keep the canvas in sync with the physical resolution. Otherwise, the solution of stretching and scaling the canvas for full-screen adaptation may cause the anti-aliasing effect to be weakened. 2.4 Let the canvas use physical resolution In the adaptation mode of the LayaAir engine, there is only the full mode, which allows the canvas to use the physical resolution by default. In addition to keeping the physical resolution of the canvas, full mode is equivalent to no adaptation plan. For UI layout, the adaptation threshold is high, and it is only suitable for pure 3D games or 3D games with very simple UI layout. Therefore, we recommend another solution, by turning on the retina canvas mode useRetinalCanvas configuration, so that all adaptation modes use the physical resolution as the size of the canvas. We can set these two solutions through the IDE's project settings panel, and the effect is shown in Figure 10. (Figure 10) 2.5.1 Dynamically enable retina canvas mode If you want to dynamically control the opening and closing of retina canvas mode, you can also add configuration code in the project code. code show as below: if(condition){ Laya.stage.useRetinalCanvas = false; }else{ Laya.stage.useRetinalCanvas = true; } Laya.stage.alignH = \"left\"; What needs to be reminded here is that any one of the scaleMode, width, height, alignH, and alignV of the Stage needs to be set synchronously so that the modification will take effect. Because setting the above properties will adjust the engine adaptation method, thereby modifying the canvas and other related adaptation data. 2.5.2 Pros and cons of turning on retina canvas mode Theoretically speaking, turning on retina canvas mode will cause more performance consumption on models that exceed the designed width and height. Because the more pixels on the canvas, the greater the performance consumption. Therefore, many 2D games will use a relatively smaller resolution as the game design width and height. But from a practical perspective, the performance pressure brought by physical width and height is not that risky. You know, some small game platforms require physical resolution. Therefore, LayaAirIDE will forcibly turn on the retina canvas mode (useRetinalCanvas) when exporting some small game platform versions. In addition, turning on retina canvas mode can not only solve problems in some small game platforms and reduce aliasing, but also make adaptation easier. Because the retina canvas mode is not used and the aliasing phenomenon is avoided, the mobile terminal can only use the full mode. In addition to allowing the canvas and stage to adopt the physical resolution, the full mode does not make any adaptations, so for the 2D UI, all It requires manual adaptation by developers. Therefore, it is recommended to turn on retina canvas mode, especially for 3D games. If the performance pressure of certain models is taken into consideration, developers can dynamically turn on or off the retina canvas mode through logical control on the models with pressure or functions with performance pressure. 3. Detailed explanation of LayaAir screen adaptation mode There are 8 adaptation modes of the LayaAir engine. In order to let everyone truly understand the adaptation strategies of each adaptation mode, so as to better adapt the screen. This section takes the 2D sample project created by LayaAirIDE as an example. The design width and height are adjusted to 750×1334 for a vertical screen interface, and each adaptation mode is compared with different models. In terms of model selection for adaptation and comparison, the 640 × 960 of iPhone 4 represents the old model with an aspect ratio of 1.5, just for comparison of the adaptation effect. The 750 × 1334 of iPhone8 is the model we selected for the width and height design. The aspect ratio is about 1.78. No matter which mode it is, it is a perfect 1:1 adaptation. iPhone8 Plus represents the same ratio model with the same aspect ratio of approximately 1.78, but the physical resolution and DPR are different from iPhone8. iPhoneX represents various full-screen models with an aspect ratio greater than 2. 3.1 The easiest to understand adaptation mode 3.1.1 The default non-scaling mode noscale Noscale mode is the default mode of the engine. In this mode, the original physical resolution of the design will always be maintained on any screen, which is equivalent to attaching the unscaled design width and height canvas directly to the screen. A screen whose physical width and height are equal to the design width and height will be displayed in full screen. If the physical width and height are lower than the design width and height, the display will be incomplete. If the physical width and height exceed the design width and height, the screen background will leak out (white screen). This mode is usually not used, and is only used by a few developers who do not use engine adaptation solutions and have custom adaptation rules. In noscale mode, the comparison effects of different models are shown in Figure 11-1. (Figure 11-1) 3.1.2 Physical resolution canvas mode full The full mode means that the canvas width and height and the stage width and height must be in a complete full-screen state, but like the noscale mode, the design width and height are not scaled. In full mode, the canvas size directly takes the physical resolution. The canvas will be as large as the physical width and height. In this mode, the setting of the design width and height parameters is meaningless. Just set 0,0 directly. This mode still requires you to define your own adaptation rules, and is mostly used in 3D games. If you have a UI interface and don't want to define your own adaptation rules, a better 3D adaptation solution will be introduced later. In full mode, the comparison effects of different models are shown in Figure 11-2. (Figure 11-2) In particular, if the background screen color is black, it is the canvas background color, not the stage background color. The default canvas background color can be changed through Project Settings. (Figure 11) The white screen background in noscale mode is the browser's default, which means that the canvas is only that big, and the area not covered by the canvas is the white screen background. If the retina canvas mode is turned on in noscale mode, the display effect will be the same as the full mode effect in Figure 11-2, but the difference is that the full mode stage (stage) width and height are also physical width and height, so the game screen coverage You can still respond to clicks and other events wherever you go. When noscale turns on the retina canvas mode, it only forcibly changes the canvas to the physical width and height, and does not change the stage width and height, so parts outside the game screen (design width and height) will not respond to clicks and other events. 3.1.3 Forced stretching of full screen mode exactfit Exactfit is a full-screen stretching adaptation mode with unequal ratios. The width and height of the canvas and the width and height of the stage will be equal to the game design width and height. Then it is forced to scale to the logical width and height without considering the proportion. So unless the design width and height are equal to the physical width and height, there will be some deformation caused by stretching. The greater the difference between the screen resolution aspect ratio and the design aspect ratio, the more obvious the distortion will be. Stretch to the physical width and height of the full screen, so unless the design width and height are equal to the physical width and height, there will be some deformation due to the stretching industry. The greater the difference between the width and height ratios of different models, the more obvious the deformation will be. This mode is the only adaptation mode among all adaptation modes that does not require developers to make additional adaptation adjustments. It can ensure full-screen display, no blank space, and no cropping on any model. It also has many disadvantages. Obviously, when the physical width-to-height ratio is different from the designed width-to-height ratio, stretching and deformation will occur, which is suitable for developers who do not have strict requirements for interface deformation. In exactfit mode, the comparison effects of different models are shown in Figure 11-3. (Figure 11-3) 3.2 Recommended adaptation mode for mobile terminals On the mobile side, we usually need a full-screen adaptation solution that maintains the design's aspect-to-height ratio scaling. The following modes are the adaptation modes that we recommend developers to adopt first. If it is a 3D game, it is recommended to turn on the retina canvas (useRetinalCanvas) mode. 3.2.1 Width-preserving adaptation mode fixedwidth The fixedwidth mode is a proportional scaling mode that ensures that content with a designed width must be displayed in full screen. This mode is recommended for vertical screen games. In this mode, the canvas width and stage width will be equal to the design width. However, the canvas height and stage height will be scaled and changed based on the ratio of the physical width to the design width, and will not use the design height we configured. Therefore, when the changed canvas and stage height are higher than the original design height, the canvas background color will be exposed at the bottom. If the changed canvas and stage height are lower than the original design height, the excess portion will be cropped. Fixedwidth mode, comparison of different models, as shown in Figure 12-1. (Figure 12-1) When you see the black background color in Figure 12-1, some developers may think when they see this, what I need is full-screen adaptation, and this is not suitable. In fact, don't worry, this is to let everyone understand the adaptation rules of fixedwidth, and it is not dealt with on purpose. Since in this mode, the width and height of the stage have been scaled to fill the full screen, so. Developers can use the relative layout attributes (top and bottom) to drag the background to full screen and the buttons to a relative position on the screen. Achieve perfect full-screen adaptation on all screens. 3.2.2 Fixedheight adaptation mode The fixedheight mode is a proportional scaling mode that ensures that high-design content must be displayed in full screen. This mode is recommended for horizontal screen games. In this mode, the canvas height and stage height will be equal to the design height. However, the canvas width and stage width will be scaled and changed according to the ratio of physical height to design height, and will not use the design width we configured. Therefore, when the changed canvas and stage width are smaller than the original design width, the excess part will be cropped, as shown in Figure 12-2. If the changed canvas and stage width are larger than the original design width, the canvas background color will be exposed at the bottom, as shown in Figure 12-3. (Figure 12-2) (Figure 12-3) Figures 12-2 and 12-3 are still deliberately left unprocessed. Through the relative layout attributes (left and right), the background is pulled to full screen and the buttons are pulled to a relative position on the screen. Achieve perfect full-screen adaptation on all screens. 3.2.3 Automatically maintain width and height mode fixedauto The fixedauto automatic width and height mode ensures that the content of the designed width and height must be displayed in full screen at the resolution of any model. This is a proportional scaling full-screen adaptation mode in which the design width and height will never be cropped, but the background color of the canvas may be left, as shown in Figure 12-4. Therefore, you still need to use relative layout attributes for full-screen adaptation. This mode is suitable for both horizontal screen and vertical screen games. (Figure 12-4) This mode actually uses fixedwidth or fixedheight, which is judged by comparing the physical aspect ratio and the design aspect ratio. If the physical aspect ratio is smaller than the design aspect ratio, fixedwidth mode is used, otherwise fixedheight is used. 3.3 Other adaptation modes 3.3.1 Show all HD mode showall The adaptation result of showall mode is very similar to fixedauto. It also ensures that the design width and height will be displayed on the screen. However, the difference and problem is that the canvas and stage of showall mode do not achieve full-screen adaptation at all resolutions. It takes the minimum ratio of (physical width/design width) and (physical height/design height), performs proportional scaling, and changes the stage and canvas sizes. Therefore, the blank part left is the part of the stage that cannot be controlled, which makes it truly impossible to adapt to the full screen on mobile phones with different aspect ratios from the design. But it is not without its advantages. The advantage is that there is no need to use the relative layout for secondary adaptation. The design effect will be what it is, and it will definitely be displayed in full without deformation or cropping. And because the size of the canvas is changed, on screens with relatively large physical resolution differences, there will be no blur caused by the smaller design resolution, and it will still be high-definition. The disadvantage is that it cannot be adapted to the full screen of mobile phones, so this mode is usually not used for mobile phone adaptation. This mode is recommended for horizontal screen web games running in PC browsers. showall mode, comparison of different models, as shown in Figure 13-1. (Figure 13-1) Showall mode is a high-definition adaptation mode because the width and height of the canvas have been scaled and changed. Therefore, this mode does not require the use of retina canvas mode (useRetinalCanvas). After using it, the canvas adopts the physical resolution, which is not good. 3.3.2 The mode noboder that definitely does not leave a bottom edge The adaptation rule of noboder is exactly the opposite of showall. It takes the maximum ratio of (physical width/design width) and (physical height/design height) for scaling. This will result in that when the resolution aspect ratio is different from the design aspect ratio on a screen, the design effect will definitely exceed the screen and be cropped. So there is no way to leave the bottom edge of the canvas or stage. In addition, the width and height of the canvas and stage in this mode will remain the same as the designed width and height, so full-screen adaptation depends entirely on scaling the canvas. Without using retina mode, when the physical resolution far exceeds the design resolution, the screen will be stretched due to Stretch creates blur. Noboder mode, comparison effects of different models, as shown in Figure 13-2. (Figure 13-2) Although this mode can also allow cropped buttons to return to the screen content through secondary adaptation of relative layout, the secondary adaptation method is more complicated. Therefore, this mode is not recommended. 3.4 Notch adaptation ideas Since the launch of the iPhone Our adaptation creates trouble. But once you find the pattern, it’s actually not too complicated. Let’s share a common processing idea. You can adjust the adaptation specifically based on this adaptation idea. 3.4.1 How to identify notch Although the resolution of the current models on the market is seriously fragmented, if you carefully summarize it, you can find a rule, that is, the resolution has only a few aspect ratios. At least, for full-screen models, the aspect ratio must be greater than 2. So, we can get the width and height of the screen resolution and then calculate the aspect ratio. If the value is greater than 2, it will be treated as a notch screen for adaptation. As for the more detailed ones, you can continue to study them carefully. This section just introduces an idea. 3.4.2 Relative layout The UI component of LayaAirIDE provides relative layout attributes based on the parent container, such as top, bottom, left, and right. We can put all the buttons that need special processing into a container component, such as box. Then, we control the relative layout attributes of this container in the onAwake life cycle of the scene Runtime class, so that we can perform special position processing under the notch screen. The sample code is as follows: onAwake():void{ //Aspect ratio greater than 2 means notch screen if((Browser.clientHeight/Browser.clientWidth)>2) { this.scaleGroup.top = 25; //Avoid top bangs sample code this.scaleGroup.bottom = 50;//Avoid the bottom line sample code } } 3.4.3 How to debug Since Chrome's debugging does not provide a virtual machine with bangs blocked, in addition to real machine debugging, simulation debugging can be performed in the WeChat mini game development tool. 3.5 Other adaptation-related learning In addition to the adaptation mode, there are also other adaptation-related contents, such as horizontal and vertical screen adaptation, canvas alignment, etc. You can go to the basic documentation of the IDE to view Detailed Explanation of Project Settings. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:23:59 "},"basics/common/Browser/readme.html":{"url":"basics/common/Browser/readme.html","title":"Browser","keywords":"","body":"Browser interface1. Overview2. Obtain screen related data2.1 Logical width and height2.2 Physical width and height (screen width and height)2.3 Device pixel ratio3. Call native objects3.1 document Dom3.2 window window3.3 container canvas4. Determine the operating environmentBrowser interface 1. Overview In project development, we often need to deal with the external operating environment, such as running in a browser or running in some small game platforms, we need to obtain device information, etc. The interfaces for these functions are all through Laya.Browser called. Laya.Browser is a browser proxy class that encapsulates some functions provided by the browser and native JavaScript, as well as information about the running environment such as mini games. This chapter will introduce what functions Laya.Browser has: Get screen related data Call native object Judge the operating environment Below we will explain each in detail 2. Obtain screen related data Usually we use browsers such as Chrome or MS Edge to develop projects. These browsers provide very convenient DevTools tools for debugging. You can refer to the link below https://learn.microsoft.com/zh-cn/microsoft-edge/devtools-guide-chromium/overview As shown in Figure 2-1, the browser provides device emulation mode to facilitate viewing and debugging. (Figure 2-1) The iPhone 6/7/8 Plus device is selected in the above picture, but taking iPhone as an example, as the model increases, the resolution of the screen device is also constantly changing, as shown in Figure 2-2 (Figure 2-2) As you can see from the picture, the physical width and height, DPR, and logical width and height are different. Therefore, to obtain these screen-related information, the Laya.Browser class provides us with the following methods. Let's take a look at the Laya.Browser related API: /** * The visible width of the browser window. *Obtained by analyzing browser information. The priority of multiple browser attribute values ​​is: window.innerWidth (including scroll bar width) > document.body.clientWidth (excluding scroll bar width). If the former is 0 or empty, the latter is selected. */ static get clientWidth(): number { Browser.__init__(); return Browser._clientWidth || Browser._window.innerWidth || Browser._document.body.clientWidth; } static set clientWidth(value: number) { Browser._clientWidth = value; } /** * The visible height of the browser window. *Obtained by analyzing browser information. The priority of multiple property values ​​of the browser is: window.innerHeight (including scroll bar height) > document.body.clientHeight (excluding scroll bar height) > document.documentElement.clientHeight (excluding scroll bar height), if the former is 0 or empty, the latter is selected. */ static get clientHeight(): number { Browser.__init__(); return Browser._clientHeight || Browser._window.innerHeight || Browser._document.body.clientHeight || Browser._document.documentElement.clientHeight; } static set clientHeight(value: number) { Browser._clientHeight = value; } /** The physical width of the browser window. Device pixel ratio is taken into account. */ static get width(): number { Browser.__init__(); return ((ILaya.stage && ILaya.stage.canvasRotation) ? Browser.clientHeight : Browser.clientWidth) * Browser.pixelRatio; } /** The physical height of the browser window. Device pixel ratio is taken into account. */ static get height(): number { Browser.__init__(); return ((ILaya.stage && ILaya.stage.canvasRotation) ? Browser.clientWidth : Browser.clientHeight) * Browser.pixelRatio; } /** Get the device pixel ratio. */ static get pixelRatio(): number { if (Browser._pixelRatio -1) Browser._pixelRatio = 2; else { Browser._pixelRatio = (Browser._window.devicePixelRatio || 1); if (Browser._pixelRatio 2.1 Logical width and height In the LayaAir engine, you can obtain the width of the logical resolution through Laya.Browser.clientWidth and the height of the logical resolution through Laya.Browser.clientHeight. In the portrait mode of mobile devices such as mobile phones, the narrow side is width and the long side is height. If the screen is flipped to landscape mode, the long side is the width and the narrow side is the height. In PC browsers, it is the visible width and height of the browser window obtained. Most browsers usually call window.innerWidth through JavaScript to obtain the visible width of the browser window. However, some special browsers have differences, so Laya.Browser does a good job of encapsulating these problems and only Just call Browser.clientWidth and Browser.clientHeight. 2.2 Physical width and height (screen width and height) Physical width and height are also called screen width and height. Developers can use Laya.Browser.width to get the number of pixels on the screen width, and use Laya.Browser.height to get the number of pixels on the screen height. The screen width and height are the hardware screen width and height only in full screen mode. Developers need to understand that the screen width and height actually refers to the width and height of the running environment window. For example, when running on a browser, it is the width and height of the browser display window. The physical width and height in the LayaAir engine is calculated by logical width and height * DPR. DPR is the device pixel ratio to be introduced below. 2.3 Device pixel ratio The DPR in Figure 2-2 is the device pixel ratio, which developers can obtain through Laya.Browser.pixelRatio Through logical width and height. Only by physical width and height and device pixel ratio can we better achieve screen adaptation. If you want to know more detailed screen adaptation, please refer to \"Screen Adaptation\" document 3. Call native objects Usually native objects include the following: document Dom window container canvas Laya.Browser also encapsulates calls to these objects for us. Take a look at the API: /**Reference to the browser’s native document object. */ static get document(): any { Browser.__init__(); return Browser._document; } /**Reference to the browser’s native window object. */ static get window(): any { return Browser._window || Browser.__init__(); } /**Canvas container, a container used to hold canvas. Convenient to control the canvas*/ static get container(): any { if (!Browser._container) { Browser.__init__(); Browser._container = Browser.createElement(\"div\"); Browser._container.id = \"layaContainer\"; Browser._document.body.appendChild(Browser._container); } return Browser._container; } static set container(value: any) { Browser._container = value; } 3.1 document Dom In the LayaAir engine, you can obtain the native document object through Laya.Browser.document. At the same time, Laya.Browser also provides methods for using Dom node elements: /** * Create browser native nodes. * @param type node type. * @return A reference to the created node object. */ static createElement(type: string): any { Browser.__init__(); return Browser._document.createElement(type); } /** * Returns a reference to the first object in the Document object with the specified id. * @param type node id. * @return node object. */ static getElementById(type: string): any { Browser.__init__(); return Browser._document.getElementById(type); } /** * Remove the specified browser native node object. * @param type node object. */ static removeElement(ele: any): void { if (ele && ele.parentNode) ele.parentNode.removeChild(ele); } Some problems can be solved by interacting with the native Dom. For example, LayaAir uses the HTML DOM element iframe. When inserting some third-party websites, we generally use iframes, and even third-party channels basically use iframes to embed an application. We will also encounter the use of iframes in our projects. The following example demonstrates the application of iframe in the project. The code looks like this: var iframe:any = Laya.Browser.document.createElement(\"iframe\"); iframe.style.position=\"absolute\";//Set layout positioning. This cannot be missing. iframe.style.zIndex = 100;//Set level iframe.style.left =\"100px\"; iframe.style.top =\"100px\"; iframe.src = \"http://ask.layaair.com/\"; Laya.Browser.document.body.appendChild(iframe); What developers need to remind here is to remember to set the positioning and level. Many developers are not careful and cause the iframe to go under the game layer and become invisible. 3.2 window window In the LayaAir engine, you can obtain the native window object through Laya.Browser.window. For example, we want to use window.open(url) in the project to open another web page to transfer data. The sample code is as follows: //Get to send data Laya.Browser.window.open(\"https://layaair.com/\"); //Post sends data //url must be a real address, content represents the data to be sent let win2 = Laya.Browser.window.open(url); win2.postMessage(content, url);//It is best to add a delay here //Listener registration Laya.Browser.window.addEventListener(\"click\", (event: any) => { console.log(event.type); }) Window.open() 方法、window.postMessage()方法、Window.addEventListener()方法 3.3 container canvas The canvas container can be obtained through Laya.Browser.container in the LayaAir engine. For example, we can hide the canvas and only display the Dom page: Laya.Browser.container.style.display = \"none\"; Style display attribute 4. Determine the operating environment When developing cross-platform projects, it is often necessary to deal with compatibility issues on different platforms, and different operating environments will have different handling methods. The Laya.Browser class determines these operating environments. For us developers, to determine the operating environment, we only need to directly call the interface of the Laya.Browser class. So far, these interfaces can be used /** Indicates whether it is on a mobile device, including IOS and Android devices. */ static onMobile: boolean; /** Indicates whether it is in an IOS device. */ static onIOS: boolean; /** Indicates whether it is on a Mac device. */ static onMac: boolean; /** Indicates whether it is within the iPhone device. */ static onIPhone: boolean; /** Indicates whether it is within the IPad device. */ static onIPad: boolean; /** Indicates whether it is in an Android device. */ static onAndroid: boolean; /** Indicates whether it is in QQ browser. */ static onQQBrowser: boolean; /** Indicates whether it is in mobile QQ or QQ browser. */ static onMQQBrowser: boolean; /** Indicates whether it is in Safari. */ static onSafari: boolean; /** Indicates whether it is in Chrome */ static onChrome: boolean; /** Indicates whether it is in IE browser*/ static onIE: boolean; /** Indicates whether it is in WeChat*/ static onWeiXin: boolean; /** Indicates whether it is on PC. */ static onPC: boolean; /** WeChat mini game **/ static onMiniGame: boolean; /** Xiaomi Mini Games **/ static onKGMiniGame: boolean; /** OPPO mini games **/ static onQGMiniGame: boolean; /** VIVO mini-game **/ static onVVMiniGame: boolean; /** Douyin mini game*/ static onTTMiniGame: boolean; /** @private */ static onFirefox: boolean;//TODO: Please add more /** @private */ static onEdge: boolean;//TODO: Please add more /** @private */ static onLayaRuntime: boolean; For example, we can judge in code like this: //If it is Chrome browser if (Laya.Browser.onChrome) { console.log(\"Chrome\"); } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:26:17 "},"basics/common/device/readme.html":{"url":"basics/common/device/readme.html","title":"device","keywords":"","body":"Device interfaceUse audioGyroscope and AccelerometerGet location informationUse Baidu MapDevice interface Device interfaces refer to interface calls that interact with hardware devices. These parts are usually encapsulated for calling the native API of the browser (or operating environment). Use audio Gyroscope and Accelerometer Get location information Use Baidu Map Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:39:04 "},"basics/common/device/media/readme.html":{"url":"basics/common/device/media/readme.html","title":"media","keywords":"","body":"Use audio1. The difference between the application of music and sound effects2. Audio compatibility preparation3. Audio volume control4. Device mute control5. Dealing with loss of focusUse audio ​ There are currently two mainstream methods for HTML5 audio playback, one is Audio tag playback, and the other is WebAudio binary playback. ​ Audio is a dom element with a UI interface. On the mobile side, Audio is downloaded and played at the same time. It is suitable for files with relatively large sound files. However, Audio will have gesture restrictions on the mobile side. The gesture-requirement-for-media-playback attribute indicates that It can only be played if there is a user's gesture operation. ​ WebAudio is a new form of sound playback that can load multiple sounds for synthesis. It decodes binary files into a format supported by the browser for playback. And using this interface, you can even realize the animation effect of the audio spectrum, giving the sound a synthesis function. ​ Music and sound effects are commonly used basic elements in games. The LayaAir engine encapsulates WebAudio and Audio. On browsers that support WebAudio, WebAudio is used first, and on browsers that do not support WebAudio, Audio is used to maximize compatibility with audio in all browsers. The format support makes it more convenient for developers to directly play audio by calling the laya.media.SoundManager API interface. 1. The difference between the application of music and sound effects ​ Music: refers to the background music used in the game. Use the playMusic method in the laya.media.SoundManager audio management class to play. Since it is background music, the playMusic method can only play one audio file at the same time. ​ Sound effect: The playSound method in the laya.media.SoundManager audio management class is used, allowing multiple audio files to be played at the same time. 2. Audio compatibility preparation ​ Since the compatibility of various browsers for audio playback issues is different, we must make preliminary compatibility preparations before starting the application. (1) Use the \"Format Factory\" audio file conversion tool. Select 44100Hz, 96kbps for conversion. (2) Keep audio files as small as possible, not only due to bandwidth limitations, but also the efficiency of browser audio decoding. 3. Audio volume control ​ Sound volume control can be set through the setSoundVolume method in the laya.media.SoundManager audio management class: /** * Set sound volume. Depending on the parameters, you can set the volume of the specified sound (background music or sound effects) or the volume of all sound effects (excluding background music). * @param volume volume. The initial value is 1. Volume ranges from 0 (silent) to 1 (maximum volume). * @param url (default = null)Sound playback address. Default is null. If it is empty, it means setting the volume of all sound effects (excluding background music). If it is not empty, it means setting the volume of the specified sound (background music or sound effects). */ static setSoundVolume(volume: number, url: string = null): void { if (url) { SoundManager._setVolume(url, volume); } else { SoundManager.soundVolume = volume; for (let i = SoundManager._channels.length - 1; i >= 0; i--) { let channel = SoundManager._channels[i]; if (channel.url != SoundManager._bgMusic) { channel.volume = volume; } } } } By setting the volume parameter, you can effectively control the volume of the sound file corresponding to the URL. The initial value is 1. Volume ranges from 0 (silent) to 1 (maximum volume). 4. Device mute control If you use the device mute key to mute the audio automatically, the device will be muted. UseAudioMusic needs to be set to false. Laya.SoundManager.useAudioMusic = false; 5. Dealing with loss of focus If it is not a full-screen game on a mobile phone, or interactive in a browser. It may cause the game to lose focus after switching out of the game, and after losing focus, the audio will stop playing. This is caused by the browser mechanism. Developers have two ways to avoid it. One is to set autoStopMusic to false in the entry file. …… //Whether to automatically stop background music after losing focus. false will not automatically stop and will continue to play. true means automatic stop Laya.SoundManager.autoStopMusic = false; …… If this is not set, it will stop when focus is lost. Developers need to control the loss and recovery of focus by listening for the loss of stage focus and the gain of stage focus (on the mini-game platform, it also depends on the platform cut-out rules of each mini-game), and the restoration in the browser The reference code is as follows: …… //Loop play_sound _sound.play(0); //Handling of losing stage focus (cutting out of the game) Laya.stage.on(Laya.Event.BLUR, this, () => { _sound.stop(); }); //Processing of obtaining stage focus (switching back to the game) Laya.stage.on(Laya.Event.FOCUS, this, () => { _sound.play(0); }); …… Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:32:25 "},"basics/common/device/motion/readme.html":{"url":"basics/common/device/motion/readme.html","title":"motion","keywords":"","body":"laya.device.motion detailed explanation: gyroscope and accelerometer1. Gyroscope2. Accelerometer2.1 Obtain the physical direction movement information of the device2.2 Obtain device display direction movement informationlaya.device.motion detailed explanation: gyroscope and accelerometer There are four classes in laya.device.motion for developers to use, namely acceleration information AccelerationInfo, accelerator Accelerator, gyroscope, and saved rotation information RotationInfo. This section will describe the related content of laya.device.motion API in detail. 1. Gyroscope Gyroscope monitors device orientation changes through the change event. This event has two callback parameters: absolute - true if the orientation provided by the device is based on the difference between the device coordinate system and the earth coordinate system; absolute is false if the device cannot detect the earth coordinate system. rotationInfo - RotationInfo type, including alpha, beta, gamma three values, which will be discussed in detail below. The alpha, beta, and gamma properties must indicate the orientation of the device, expressed as a transformation from a coordinate system fixed on the earth to a coordinate system fixed on the device. The coordinate system must be adjusted as described below. The earth's coordinate system is an \"east, north, and up\" system located at the user's location. It has 3 axes, ground tangent to the user's location in the 1984 World Geodetic System spheriod. East (X) is on the ground, perpendicular to the north axis, and east is positive. North (Y) is on the ground, pointing towards the North Pole (pointing towards the North Pole). Up (Z) is perpendicular to the ground, upward is positive. For a mobile device, such as a phone or tablet, the device coordinate system is defined relative to the standard orientation of the screen. If the screen orientation changes when the device is rotated or the sliding keyboard is expanded, this does not affect the orientation of the coordinate system with respect to the device. x is positive on the screen or keyboard plane, the right side of the screen or keyboard. y is on the screen or keyboard screen, and above the screen or keyboard is positive. -z is perpendicular to the screen or keyboard screen, and positive away from the screen or keyboard. Rotations must use the right-hand rule, that is, forward rotation along an axis is clockwise rotation when viewed from the direction of that axis. Starting from the coincidence of the two systems, the following rules apply for rotation: Take the z-axis of the device coordinate system as the axis and rotate it by alpha degrees. The scope of alpha is [0, 360]. (figure 1) Take the x-axis of the device coordinate system as the axis and rotate it by beta degrees. The scope of beta is [-180, 180]. (figure 2) The y-axis of the device coordinate system is set as the axis and rotated by gamma degrees. The scope of gamma is [-90, 90]. (image 3) The following demonstrates obtaining rotation orientation information: class Gyroscope_Sample { private info: Laya.Text; constructor() { Release.heat(550, 400); this.info = new Laya.Text(); this.info.fontSize = 50; this.info.color = \"#FFFFFF\"; this.info.size(Laya.stage.width, Laya.stage.height); Laya.stage.addChild(this.info); Laya.Gyroscope.instance.on(Laya.Event.CHANGE, this, this.onDeviceorientation); } private onDeviceorientation(absolute: Boolean, rotationInfo: Laya.RotationInfo): void { this.info.text = \"alpha:\" + Math.floor(rotationInfo.alpha) + '\\n' + \"beta :\" + Math.floor(rotationInfo.beta) + '\\n' + \"gamma:\" + Math.floor(rotationInfo.gamma); } } new Gyroscope_Sample(); 2. Accelerometer The Accelerator class periodically sends activity detected by the device's motion sensor. This data represents the motion of the device in three dimensions. When the device moves, the sensor detects this movement and returns the device's accelerated coordinates. Even when stationary, acceleration coordinates including gravity can be obtained. The callback function of the change event has one of the following parameters: acceleration - AccelerationInfo type. Provides the acceleration information of the host device relative to the earth coordinate system, which is expressed in the main coordinate system defined in the gyroscope chapter, and the unit is m/s^2. accelerationIncludingGravity - AccelerationInfo type. For implementations that cannot provide acceleration data that excludes the effects of gravity (e.g., lack a gyroscope), acceleration data that is affected by gravity can be provided as an alternative. This is not easy to use for many applications, but providing this information means providing maximum support. In this case, the accelerationIncludingGravity property provides the host device's acceleration information, plus an anti-gravity acceleration with equal and opposite acceleration. Its expression is the principal coordinate system defined in the gyroscope chapter. The unit of acceleration information is m/s^2. rotationRate - RotationInfo type. The property provides the rate at which the host device rotates in space. It is expressed in the angle change rate defined in the gyroscope chapter. The unit must be deg/s. interval - The interval for obtaining data from the hardware, in milliseconds. 2.1 Obtain the physical direction movement information of the device The accelerometer axis is the physical orientation of the device, which means that when you rotate the device, the accelerometer axis also rotates. The following demonstrates obtaining device motion information: class Gyroscope_Sample { private info: Laya.Text; constructor() { Release.heat(550, 400); this.info = new Laya.Text(); this.info.fontSize = 50; this.info.color = \"#FFFFFF\"; this.info.size(Laya.stage.width, Laya.stage.height); Laya.stage.addChild(this.info); Laya.Accelerator.instance.on(Laya.Event.CHANGE, this, this.onMotoin); } private onMotoin(acceleration: Laya.AccelerationInfo, accelerationIncludingGravity: Laya.AccelerationInfo, rotationRate: Laya.RotationInfo, interval: number): void { this.info.text = 'acceleration:(' + acceleration.x.toFixed(3) + ', ' + acceleration.y.toFixed(3) + ', ' + acceleration.z.toFixed(3) + ')\\n' + 'accelerationIncludingGravity:(' + accelerationIncludingGravity.x.toFixed(3) + ', ' + accelerationIncludingGravity.y.toFixed(3) + ', ' + accelerationIncludingGravity.z.toFixed(3) + ')\\n' + 'rotationRate: alpha ' + Math.floor(rotationRate.alpha) + ', beta ' + Math.floor(rotationRate.beta) + ', gamma ' + Math.floor(rotationRate.gamma) + '\\n' + 'interval: ' + interval; } } new Gyroscope_Sample(); 2.2 Obtain device display direction movement information Since we may need to display running information in the direction, this means that even if the device is rotated, the accelerometer axis does not change. For example, the y-axis always remains vertical. Use Accelerator.getTransformedAcceleration() to get the running information in the display direction. In the onMotion function of the above example code, use Accelerator.getTransformedAcceleration() to convert the information before using AccelerationInfo: private onMotoin(acceleration: Laya.AccelerationInfo, accelerationIncludingGravity: Laya.AccelerationInfo, rotationRate: Laya.RotationInfo, interval: number): void { acceleration = Laya.Accelerator.getTransformedAcceleration(acceleration); accelerationIncludingGravity = Laya.Accelerator.getTransformedAcceleration(accelerationIncludingGravity); ...... } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:37:56 "},"basics/common/Stat/readme.html":{"url":"basics/common/Stat/readme.html","title":"Stat","keywords":"","body":"Performance statistics and optimization1. Calling the performance statistics panel2. Introduction to FPS2.1 FPS Overview2.2 FPS in WebGL mode2.3 Numerical description of FPS3. Introduction to DrawCall3.1 Introduction3.2 Optimization method3.3 Other categories4. Numerical description of NodeNums5. Sprite3D numerical description6. TriangleFace value description7. RenderNode value description8. SkinRenderNode value description9. ParticleRenderNode value description10. FrustumCulling value description11. GPUMemory value description12. TextureMemory value description13. RenderTextureMemory value description14. BufferMemory value description15. UploadUniformNum value descriptionPerformance statistics and optimization From the beginning of the design of the LayaAir engine, performance was the first goal and a lot of performance optimization was done in the engine. Proper use of engines can allow games and other engine products to achieve the experience of native APPs. If developers cannot take advantage of the engine, the final performance experience of the game may not be possible. Therefore, in the process of making games, it is still very necessary to master game and engine optimization skills. To understand the performance of the engine, you must first understand the performance statistics panel. The performance statistics panel will be introduced in detail below. 1. Calling the performance statistics panel The performance statistics panel built into the LayaAir engine can detect current performance in real time. The call statistics panel will be different depending on the development language. Directly enter the TS language code Laya.Stat.show(0,0); to bring up the performance statistics panel. The sample Demo.ts code is as follows: //Initialize the stage Release.heat(1136, 640); //Call the performance statistics panel method, (0,0) is the panel position coordinates Laya.Stat.show(0,0); Tips: Pay attention to capitalization. 2. Introduction to FPS 2.1 FPS Overview FPS is the abbreviation of Frames Per Second. Assume that the frame rate of the game is 60FPS, which means that the execution time of each frame when the game is running is 1/60 second. The higher the frame rate value, the smoother it feels visually. (Figure 2-1) The current full frame rate of PCs and mobile phones is 60 frames, as shown in Figure 2-1. However, some games do not have high requirements for smoothness of the screen. You can also use the engine's frame rate limiting method Stage.FRAME_SLOW. Limit FPS frame rate to a maximum of 30 frames. Since the actual running environment is in the browser, performance also depends on the efficiency of the JavaScript interpreter. Therefore, the FPS value of the same game may be different in different browsers. This part is not something that developers can decide. What developers can do is to use the best engines and optimization projects as much as possible to improve the FPS frame rate on low-end devices or low-performance browsers. 2.2 FPS in WebGL mode LayaAir engine supports WebG rendering mode. As shown in Figure 2-2; FPS(WebGL) is the frame rate in WebGL mode. (Figure 2-2) 2.3 Numerical description of FPS In Figure 2-1 and Figure 2-2, the first yellow value of FPS 60 is the current FPS frame rate, the higher the better. The second yellow value 16 is the time spent rendering each frame in milliseconds. The smaller the value, the better. If these two values ​​cannot be maintained at full frame, they will change during product operation, as shown in the animation 2-3. (Animation 2-3) 3. Introduction to DrawCall The number of DrawCalls is an important indicator that determines performance, located in the third row of the statistics panel, as shown in Figure 4. The fewer DrawCalls, the better. It is recommended that developers try to limit it to less than 100. (Figure 3-1) 3.1 Introduction DrawCall can be understood as \"drawing instruction\", which means that the CPU calls the graphics API and sends graphics drawing commands to the GPU. Generally, the CPU's memory reading and writing or data processing speed is very slow compared to the GPU's rendering speed. That is to say, after the GPU has finished processing the data, there are still many DrawCalls that have not been processed by the CPU, and the GPU is in a low power state at this time. In other words, the root cause is that the CPU does not process DrawCall in time, resulting in performance degradation. So the less DrawCall, the better. In WebGL mode, DrawCall represents a rendering submission batch. Each time the CPU prepares data and notifies the GPU for rendering, the process is called a DrawCall. In each DrawCall, in addition to notifying the GPU of rendering, which is more time-consuming, switching materials and Shaders are also very time-consuming operations. 3.2 Optimization method To optimize the number of DrawCalls, you can take the following methods: Merge meshes: Merge multiple meshes of the same material into one large mesh to reduce the number of rendering calls. Use an atlas: Merge multiple small textures into a large texture atlas to reduce the number of texture switches. Use batch processing: Put multiple objects of the same material in a batch and render them together to reduce the number of rendering calls. Use GPU instantiation: Use GPU instantiation technology to instantiate and render multiple objects of the same model, reducing the number of rendering calls. Reduce transparent objects: The rendering of transparent objects requires mixing operations, which will increase the number of DrawCalls. You can minimize the number of transparent objects. Use static batch processing: static batch processing of objects that will not change to reduce the number of rendering calls. Through the above optimization methods, the number of DrawCalls can be effectively reduced and the performance of the game can be improved. For detailed optimization methods, please refer to \"2D Performance Optimization\" and \"3D Performance Optimization\". 3.3 Other categories There are also a few different categories in the performance statistics panel: OpaqueDrawCall: Indicates the number of opaque objects rendered in the built-in rendering pipeline. TransDrawCall: Indicates the number of transparent objects rendered in the built-in rendering pipeline. DepthCastDrawCall: Indicates the number of shadow maps rendered in the built-in rendering pipeline. InstanceDrawCall: Indicates the number of instances of DrawCall. CMDDrawCall: Indicates the number of rendering instructions in the command stream. BlitDrawCall: Indicates the number of times blit is used to render the final image to the screen. 4. Numerical description of NodeNums NodeNums is an indicator in the performance statistics panel, indicating the number of nodes in the current scene. The larger the value of NodeNums, the more nodes there are in the scene and the greater the impact on performance. Therefore, unnecessary nodes in the scene should be minimized during development to improve game performance. As shown in Figure 4-1. (Pic 4-1) 5. Sprite3D numerical description Sprite3D is an indicator in the performance statistics panel, indicating the number of Sprite3D nodes in the current scene. Sprite3D is the basic class of 3D nodes, which can include 3D models, materials, lighting and other attributes, and can perform operations such as 3D transformation and animation. The number of Sprite3D is one of the important factors affecting game performance. Too many Sprite3Ds will increase the number of renderings, thus affecting the game's frame rate and performance. Therefore, the number of Sprite3D nodes in the scene should be minimized during development to improve game performance. As shown in Figure 5-1. (Figure 5-1) 6. TriangleFace value description TriangleFace is an indicator in the performance statistics panel, indicating the number of triangle faces rendered in the current scene. The larger the value of TriangleFace, the more triangle faces need to be rendered in the scene, and the greater the impact on performance. In 3D rendering, each MeshRenderer (MeshSprite3D, SkinnedMeshSprite3D) is composed of multiple triangular faces. Therefore, the number of triangles that need to be rendered should be minimized during development to improve game performance. As shown in Figure 6-1. (Figure 6-1) To reduce the number of triangle faces that need to be rendered TriangleFace, you can take the following methods: Optimize the model: use a simpler model and reduce the number of faces. Merge meshes: Merge multiple meshes of the same material into one mesh to reduce the number of renderings. Use LOD technology: use models with different levels of detail based on distance to reduce the number of faces of distant models. Use occlusion culling: According to the camera's frustum, invisible models are eliminated to reduce the number of rendered faces. Through the above method, the number of triangle faces that need to be rendered can be effectively reduced and the performance of the game can be improved. 7. RenderNode value description RenderNode is an indicator in the performance statistics panel, indicating the number of rendering nodes in the current scene. Rendering nodes refer to nodes that need to be rendered, including Sprite, MeshSprite3D, SkinnedMeshSprite3D, etc. The number of RenderNodes is one of the important factors affecting game performance. Too many RenderNodes will increase the number of renderings, affecting the game's frame rate and performance. As shown in Figure 7-1. (Figure 7-1) 8. SkinRenderNode value description SkinRenderNode is an indicator in the performance statistics panel, indicating the number of skeletal animation rendering nodes in the current scene. Skeletal animation rendering nodes refer to nodes that require skeletal animation rendering, including SkinnedMeshSprite3D, etc. As shown in Figure 8-1. The number of SkinRenderNode is one of the important factors affecting game performance. Too many SkinRenderNodes will increase the number of renderings, thus affecting the game's frame rate and performance. (Figure 8-1) 9. ParticleRenderNode value description ParticleRenderNode is an indicator in the performance statistics panel of LayaAir engine version 3.0, indicating the number of particle rendering nodes in the current scene. Particle rendering nodes refer to nodes that require particle rendering, including ParticleSystem. As shown in Figure 9-1. You can optimize by reducing the number of particles and using reasonable particle emitter settings to avoid excessive particle numbers. (Figure 9-1) 10. FrustumCulling value description Frustum Culling is an indicator in the performance statistics panel, indicating the number of rendering nodes with frustum clipping enabled in the current scene. View frustum clipping means that only objects within the view frustum are rendered, and objects beyond the view frustum are not rendered, thereby reducing unnecessary rendering and improving game performance. As shown in Figure 10-1. The greater the number of Frustum Culling, the greater the number of rendering nodes that enable frustum clipping in the scene, and the greater the impact on performance. (Figure 10-1) During development, you can avoid unnecessary rendering by setting the appropriate size and position of the view frustum to prevent the view frustum from being too large or too small. You can also improve the efficiency of Frustum Culling through reasonable node management and frustum clipping settings, thereby improving the performance of the game. 11. GPUMemory value description GPUMemory is an indicator in the performance statistics panel, indicating the amount of GPU memory occupied in the current scene. GPU memory refers to the memory used to store data required by the GPU, including textures, buffers, etc. As shown in Figure 11-1. Too much GPUMemory usage can cause game lags, frame drops and other problems. (Figure 11-1) 12. TextureMemory value description TextureMemory is an indicator in the performance statistics panel of the LayaAir engine version 3.0, indicating the size of the texture memory occupied in the current scene. Texture memory refers to the memory used to store texture data, including maps, fonts, etc. As shown in Figure 12-1 If TextureMemory takes up too much, it will cause game freezes, frame drops and other problems. (Figure 12-1) 13. RenderTextureMemory value description RenderTextureMemory is an indicator in the performance statistics panel, indicating the size of the rendering texture memory occupied in the current scene. Rendering texture memory refers to the memory used to store rendering texture data, including RenderTarget used to dynamically generate textures, etc. As shown in Figure 13-1. (Figure 13-1) In games, RenderTextureMemory is used to store rendering texture data, which can be used to implement some special effects, post-processing, screen capture and other functions. Rendering textures can render the scene onto a texture, and then apply this texture as a material to other objects to achieve some special effects. However, the use of rendering textures will occupy a certain amount of memory resources. If the rendering texture memory occupies too much, it will cause game lags, frame drops and other problems. Therefore, in game development, it is necessary to use rendering textures rationally and avoid excessive rendering texture memory usage to improve game performance. 14. BufferMemory value description BufferMemory is an indicator in the performance statistics panel, indicating the size of the buffer memory occupied in the current scene. Buffer memory refers to the memory used to store buffer data, including vertex buffers, index buffers, etc. As shown in Figure 14-1. (Figure 14-1) 15. UploadUniformNum value description Uniforms are a way to send data from an application in the CPU to a shader in the GPU, but uniforms and vertex attributes are a little different. First of all, uniform is global. Global means that the uniform variable must be unique within each shader program object, and it can be accessed by any shader at any stage of the shader program. Second, no matter what you set the uniform values ​​to, uniforms will keep their data until they are reset or updated. For a detailed introduction to Uniform, please refer to Custom Shader. uploadUniformNum represents the number of Uniform updates in the Shader. Every time a Uniform is added, a count is increased. As shown in Figure 15-1, the parameters are located in the last row of the statistics panel. (Figure 15-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 16:00:05 "},"basics/3D/readme.html":{"url":"basics/3D/readme.html","title":"Basic of 3D Engine","keywords":"","body":"3D engine basicsIntroduction to 3D Concepts3D Transform3D engine basics This chapter introduces the basic concepts and API usage related to the engine. Introduction to 3D Concepts 3D Transform Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:19:47 "},"basics/3D/beginner/readme.html":{"url":"basics/3D/beginner/readme.html","title":"beginner","keywords":"","body":"Introduction to 3D Concepts1. Scene and camera1.1 Camera1.2 Perspective projection and orthogonal projection2. Coordinate system and coordinates2.1 Coordinate system2.2 Vertex coordinates and UV coordinates3. Triangle, Grid, model3.1 Triangular surface3.2 Grid3.3 Model4. Material4.1 Model material4.2 Sky material4.3 Particles4.4 Trailing5. Texture, map, patch6. Lights, shadows, reflected light6.1 Lighting6.2 Shadow6.3 Reflected light7. Additive color light effects, ambient light, floodlight, light map8. Shader9. 3D physics system, 3D animation system10. Common mathematical concepts of 3D basics10.1 Vectors10.2 Matrix10.3 Euler angles and quaternions10.4 Ray10.5 Bounding volumeWrite at the endIntroduction to 3D Concepts Author ：charley The biggest obstacle to learning is the unknown. For example, if you can't recognize the eighteen weapons in front of you, how can you fight on the battlefield? What's more, 3D game development is a job with high threshold. This article puts aside the structure of the engine and is based on the logic of understanding the 3D game world for the first time, so that developers without 3D foundation can have an overview of the basic functions of the LayaAir 3D engine and the basic concepts of 3D through this article. At least, we need to understand the basics of the 3D world, and then learn and master them one by one based on the official documents. 1. Scene and camera 1.1 Camera The scene is the 3D world in the game. Only with the scene can you add all objects to the scene, including cameras. The camera is equivalent to the eyes of the 3D game world. Through the camera, players can see the three-dimensional world in the game and see various objects in the scene. Therefore, there must be at least one camera in the scene. (Picture 1-1) When we write the code for a 3D game, we must first add a 3D scene to the stage and a 3D camera. Then write other code. The camera can be the only one in the 3D scene, or multiple cameras can be placed. For example, it is used in the pop-up window dressing panel that appears in the 3D scene in Figure 1-2, or in the same-screen requirements of some battle games. Multiple cameras. (Figure 1-2) 1.2 Perspective projection and orthogonal projection The camera's imaging effects are divided into two types: perspective and orthogonal. The 3D camera of the LayaAir engine is in perspective mode by default, which is a visual effect that simulates the human eye, as shown in Figure 1-3, near is large and far is small. (Figure 1-3) Orthogonal has no sense of perspective and is often used in some 2D and 3D mixed games or model viewers. (Figure 1-4) 2. Coordinate system and coordinates Coordinates are one of the foundations of the 3D space world. You cannot do anything without coordinates, move the camera, position, draw graphics, etc. When learning LayaAir 3D, we need to understand two coordinates, one is the position coordinate and the other is the UV coordinate. Before understanding these two coordinates, we first introduce the spatial Cartesian rectangular coordinate system. 2.1 Coordinate system The spatial Cartesian rectangular coordinate system is formed by the intersection of three mutually perpendicular coordinate axes xyz passing through the same origin. (Figure 2-1) When the positive directions of the two axes of the coordinate system are the same, the positive direction of the third axis is opposite, so the coordinate system is divided into a left-handed coordinate system and a right-handed coordinate system. These two coordinate systems are not good or bad, and they are both widely used. For example, engines such as Unity use a left-handed coordinate system, and engines such as LayaAir use a right-handed coordinate system. So it is necessary for us to understand what the left-handed coordinate system and the right-handed coordinate system are, and the difference between the two. The reason why the two 3D coordinate systems are named after the left and right hands is to facilitate memory. The directions of the three fingers of the left and right hands are used to represent the positive directions of the three coordinate axes. These three fingers are the thumb, index finger, and middle finger respectively. Whether it is the left hand or the right hand, we must remember that the direction of the thumb is the positive direction of the x-axis, the direction of the index finger is the positive direction of the y-axis, and the direction of the middle finger is the positive direction of the z-axis. Now we face the screen and have our hands ready to pose. First point the index fingers (y-axis) of the left and right hands toward the sky (pointing to the ceiling in the room), and then point the middle fingers (z-axis) forward (the direction where the eyes are looking straight when standing upright). At this time, the middle fingers of the two hands They should all be 90 degrees perpendicular to the index finger. Then, extend your thumb (x-axis) and keep it 90 degrees perpendicular to both your index and middle fingers. You can refer to the gestures in Figure 2-2. (Figure 2-2) There are different explanations and introductions of left- and right-hand coordinate systems on the Internet. If the picture and axis orientation are different from those introduced in this article, it is generally due to the difference in camera angle. Don’t worry about anything else. When learning LayaAir, this article shall prevail to understand and remember. That’s it. After arranging it, we will find that while keeping the positive directions of the z-axis and y-axis in the same direction, the positive direction of the x-axis is opposite. This is the difference between the left-handed coordinate system and the right-handed coordinate system. The LayaAir engine unity export plug-in automatically adapts to the LayaAir engine by inverting the x-axis. Therefore, if you edit and export directly in Unity and then use it in the LayaAir engine, you do not need to manually convert the coordinates. If developers must manually adjust coordinates in the LayaAir engine project, they need to pay attention to the difference between the left-hand coordinate system and the right-hand coordinate system in the positive x-axis direction. 2.2 Vertex coordinates and UV coordinates After understanding the coordinate system, let’s learn about the vertices. A vertex can be understood as any position point with xyz coordinates in 3D space, but a vertex not only contains coordinate position information, but also UV, normal, color and other information. Let’s not talk about anything else first, let’s continue to understand UV. UV is actually a coordinate. To be complete, it should be UVW (because xyz has been occupied by the vertex coordinate axis, so choose three letters to represent it). These three axes U are the horizontal direction of the screen, V is the vertical direction of the screen, and the direction of W is Perpendicular to the surface of the monitor, so far, it is not used in general game development, so we usually call it UV for short. If W is removed, as shown in Figure 2-3, the UV coordinate is a 2D plane coordinate. The UV coordinate can be used for model texture mapping, etc. (I will mention it later when I introduce textures). (Figure 2-3) The UV coordinate map texture's right and downward directions are the positive directions of U and V coordinates respectively. The value range is 0-1, regardless of the pixels of the texture image. As shown in Figure 2-4, the model vertex data exported by the 3D art production software will correspond to the UV coordinates of the texture to ensure correct sampling during rendering. (Figure 2-4) Relative to UV coordinates, which will eventually correspond to pixels on the texture, vertex coordinates do not have a constant unit of measurement. The smallest unit is a point. Whether it is the real world or the 3D world, a point is a basic abstract concept, and it represents a A single individual can be infinitely large or infinitely small. Therefore, a point can be a pixel, or a basic unit of any unit such as 1 millimeter, 1 nanometer, 1 kilometer, etc. The measurement unit used between the final vertices is usually set by 3D art combined with game design. The unit used more often by 3D game art is meters. Therefore, the program settings must be consistent with the units set by the art. Otherwise, the visual effect will be too large or too small, resulting in effects that are inconsistent with the design. 3. Triangle, Grid, model Models are the basis of visible objects in 3D games, such as characters, houses, trees, mountains, rivers, etc. Almost most visible objects are based on models. 3.1 Triangular surface To further understand the model, we first start with the triangular plane (referred to as the triangular plane). The triangular plane is composed of three vertices and is the only basic polygon that the graphics card can handle. One of the important reasons why triangles are regarded as the most basic polygons is that triangles composed of three points must be on the same plane, while polygons composed of four or more points are not in three-dimensional space. It must be on the same plane. 3.2 Grid Mesh is formed by splicing one triangular surface or multiple triangular surfaces and is the basis for constructing the shape of the model. In the LayaAir engine, the triangular surface vertex data and the triangular surface index data collection that constitute various graphic shapes are grids, so the grid is invisible when the game is running. Figure 3-1 uses pixel line sprites to represent the model. grid composition. (Figure 3-1) 3.3 Model The model is composed of mesh (Mesh) and material (Material). There is too much material content, and I will explain it in the next section. From the perspective of forming a three-dimensional graphic shape, we can clarify the following relationships. The basis of the model is the grid, and the basis of the grid is the triangular surface. The more triangles there are, the richer the details that the model can express. Figure 3-2 shows the difference in model detail performance between 40,000 faces, 4,000 faces, and 400 faces. Those with richer details are usually called fine models, while those with relatively weak details are called simple models. (Figure 3-2) Whether to use a precise model or a simple model requires R&D technology to put forward demands on the art based on the overall effect and the pressure that the game hardware performance can withstand. At this point, mobile H5 and mini-games can maintain the same standards as mobile game APP standards. 4. Material As mentioned before, the grid is only three-dimensional shape data, and the grid shape itself is invisible. How can it be seen, then a material is needed. As the name suggests, material is the texture of the material. For example, wood and metal, glass and hair, different material textures will be significantly different in terms of roughness, gloss, reflection, transparency, color, texture, etc. Based on the differences between these objects, we can divide materials into many types. The materials supported by the LayaAir engine are classified into model materials, sky materials, particle materials, and trailing materials. 4.1 Model material The model materials of the LayaAir engine can be further divided into lighting materials (BlinnPhongMaterial), unlit materials (UnlitMaterial), and PBR materials (PBRMaterial). The BlinnPhong material is the standard photosensitive material used by default, while the UnlitMaterial material is just the opposite. It is not affected by light and only displays the appearance image effect of the original texture. In Figure 4-1, the left side of the picture shows the effect of the lighting material (BlinnPhongMaterial) after being illuminated by light, and the right side of the picture shows the effect of the unlit material (UnlitMaterial) after it is also illuminated by light. (Pic 4-1) PBR material is a material based on Physical Rendering (Physically Based Rendering). By simulating the physical laws of nature, it can make the texture of 3D models more realistic and approach or restore the texture of the real world. For example, the barrel in Figure 4-2 is made of PBR material. (Figure 4-2) Based on the concept of a model composed of meshes and materials, theoretically all visible objects of shape are models. However, based on the ease of development, the engine will further encapsulate some common functions, such as the sky, particle system, and tailing system introduced below. 4.2 Sky material The 3D sky simulated by LayaAir provides two ready-made meshes, one is a cube mesh (SkyBox). This kind of sky is called a sky box and uses the cube mapping method. The other is the spherical mesh (SkyDome), which can be called a sky sphere or a spherical sky and uses the sphere mapping method. Of course, developers can also customize other sky grids to create skies. The sky created by the spherical mesh (SkyDome) can show more realistic sky effects, such as curved clouds and a more realistic horizon. Compared with the cubic mesh (SkyBox), this technical solution has more vertices and naturally consumes more performance. Developers need to create the sky based on their needs. After creating the sky, LayaAir also provides three ready-made sky materials: skybox material (SkyBoxMaterial), panoramic sky material (SkyPanoramicMaterial), and procedural sky material (SkyProceduralMaterial). SkyBoxMaterial is formed from 6 seamlessly connected material texture maps, which is similar to a box being opened and tiled. For example, the texture shown in Figure 4-3, (Figure 4-3) Panorama Sky Material (SkyPanoramicMaterial) is a technical solution with only one map texture, such as the texture shown in Figure 4-4. (Figure 4-4) Procedural Sky Material (SkyProceduralMaterial) does not require a texture, as shown in Figure 4-5, just set the sun type and other parameters. However, only the sky created by the spherical mesh (SkyDome) can use the procedural sky material, because the vertex shading used by this material requires more detailed vertex information. (Figure 4-5) 4.3 Particles Particles are a collection of dispersed tiny objects. By making these tiny objects move according to a certain algorithm, more flexible effects such as flames, smoke, explosions, and flowing water can be achieved. The particle system is not a form of drawing, but an animation method. The role of the particle system is to control particles during their life cycle of generation, movement, change, and disappearance. The particle system of the LayaAir engine includes multiple parts such as particle emitters, particle animators, and particle renderers. (Figure 4-6) 4.4 Trailing Trailing, as the name suggests, is the effect of trailing behind a tail. It is often used for strip-shaped 3D special effects, such as knife-light trailing, action trajectory trailing in parkour ball games, etc. The LayaAir engine has a built-in trailing system and trailing material to facilitate developers to quickly use 3D trailing. (Figure 4-7) 5. Texture, map, patch Texture refers to the appearance effect of the surface of an object, which is expressed in the form of a 2D bitmap. Figure 5-1 shows the texture of the 3D globe surface. (Figure 5-1) Mapping A simple and popular understanding is the process of pasting 2D textures to 3D model meshes. This process of mapping the 3D vertex coordinates to the UV coordinates of the 2D texture is completed by the engine. The developer can directly call the API and set the corresponding texture for the material. The left side of Figure 5-2 shows the effect of only adding materials without setting textures. The right side of Figure 5-2 is the mapped effect of adding texture to the material. (Figure 5-2) It can be seen from the rendering 5-2 that although the mesh and material can already make the model visible in the 3D game scene, without material mapping and texture, all you see is a solid color model with different textures. Texture gives you a real, rich look. Therefore, texture is also a relatively important knowledge point. If we expand the discussion, texture can introduce a lot. This article will not go into details. At this point in the introduction, we have a preliminary understanding of the difference between textures and maps. However, many times, when documenting or oral communication, many people will refer to the textures used for mapping, also referred to as textures. So we should be able to understand that textures refer to textures in some application scenarios. The reason why patch is introduced together with texture is because many people have a misunderstanding when they have little knowledge of 3D, thinking that a patch is just a 2D texture bitmap placed in 3D space. In fact, in three-dimensional space, even if there is only one triangular plane, a grid can be formed and materials can be set. Then this is a model. So patches are essentially the same as other polyhedral models. As shown in Figure 5-3, the grass image seen in the 3D space is actually the texture of the grass patch material. (Figure 5-3) 6. Lights, shadows, reflected light Light sources are an indispensable and important part of 3D scenes. Grids and textures determine the shape and appearance of objects. Light sources can illuminate, produce shadows, and can also affect the scene environment and the color, brightness, atmosphere, etc. of the 3D model. 6.1 Lighting The light source in 3D is light. Others such as floodlight and ambient light are light effects rather than light sources. There are four types of 3D lights: DirectionLight, PointLight, SpotLight, and AreaLight. The LayaAir engine not only supports any type of these light sources, but also supports the addition of multiple different types of light sources in the same scene. Direction Light is a light that simulates natural sunlight. The light from the light source is always parallel and has no attenuation. The direction of the light source can be set in LayaAir to illuminate the entire scene. (Figure 6-1) PointLight is a light source that is centered on the light source point and emits in all directions. The light source point is located at a certain position in the 3D space. Similar to the way candle light, bonfires, household lights, etc. emit light in reality, this light has an irradiation range and an attenuation radius. Places outside the light range are in lightless darkness. (Figure 6-2) SpotLight is similar to point light. It is a positional light. It is also located at a certain position in the 3D space. It also has an irradiation range and attenuation radius. However, unlike the directionless point light that radiates around, spot light It has a light source direction and is a light source with a tapered angle, similar to the light source effects such as flashlight holes and stage spotlights in reality. (Figure 6-3) AreaLight An area light can be defined by one of two shapes in space: a rectangle or a disk. An area light emits light from one side of the shape. The emitted light spreads evenly in all directions over the surface area of ​​the shape. Because this lighting calculation is very processor intensive, area lights are baked into lightmaps. 6.2 Shadow Shadows are generated when light illuminates the model. Real-time shadows change with changes in light angle, light intensity, model position, etc. It can produce a stronger sense of three-dimensionality and reality. (Figure 6-4) 6.3 Reflected light Reflected light refers to the light effect produced by the reflection of the light source when it shines on the 3D model. In order to simulate the natural reflection phenomenon, the engine uses different lighting models for reflected light according to different materials. For example, the BlinnPhong material uses diffuse reflection and specular reflection models. Let’s briefly understand the difference between the two. (Figure 6-5) The diffuse reflection in the engine mainly simulates the optical reflection effect of rough and uneven material surfaces. The ideal diffuse reflection material surface is completely smooth and lackluster. When the light source shines on this material, it will show divergent reflections. Effect. The specular reflection in the engine is used to simulate the optical reflection effect of a smooth horizontal surface. It is a directional reflection. The reflection direction is centered on the normal of the reflection plane and is equal to the angle between the incident direction. The ideal specular material has a completely smooth surface, like a mirror. Specular reflection is often used for sparkling visual effects and produces bright spot-like spots, so specular reflection is sometimes called specular highlight. Some material-related documents mention highlight color or highlight map. We must understand that this refers to the highlight color and highlight map for specular reflection effects. Based on the optical phenomena of diffuse reflection and specular reflection, multiple lighting models are used in the engine to simulate reflection phenomena in natural light. This article will reveal a little bit first. Let’s have a preliminary understanding first. Let's move on to learn about some other light-related concepts. 7. Additive color light effects, ambient light, floodlight, light map The previous section introduced 3D lighting and the light effects closely related to lighting. This section still introduces light, but these lights are not illumination lights, they just look more like some effects of light. We'll take a look at some of the other light effects in the LayaAir engine one by one. Additive color light effect can make the material itself have a glowing effect. This is a light feeling simulated by the additive color method and is not produced by light, such as the engine's special effects material (EffectMaterial). This self-illumination effect will not affect the surrounding environment and other models, but will be affected by the background color. (Figure 7-1) Ambient Light is similar to the Global Color Filter. Set a bright color such as white to make the scene brighter even if there is no light source. If you want to express the feeling of a cloudy day, you can also add some dark ambient light colors. Or to express the effect of night vision goggles, etc., you can set it through ambient light. (Figure 7-2) Bloom is a post-effect in the LayaAir engine. Even if there is no light source, an effect similar to a halo superposition can be produced. (Figure 7-3) Lightmap is a method of simulating light and shadow effects in game scenes through mapping. It is also a commonly used method of producing pseudo-lighting visual effects in games to save performance. The light effects in Figure 7-4 are not achieved through lights, but are the effects of light maps. (Figure 7-4) 8. Shader Shader is called shader in Chinese. Shader is essentially a program written in GLSL shading language (there are several shading languages, only GLSL language can be used based on webGL) and runs on the GPU. It is used to tell the graphics software how to calculate and output images. Shaders are mainly divided into two categories: vertex shaders and fragment shaders (also called fragment shaders). A vertex shader is a program used to process vertex data, such as vertex coordinates, normals, colors, and texture coordinates. It is called on each vertex and can transform a geometry (for example: a triangle) from one position to another, for example, for vertex transformation, texture coordinate generation, texture coordinate transformation, etc. Fragment shaders are used to calculate and fill the color of each pixel, so they are also called pixel shaders. It can be used for interpolation operations, texture access, texture application, fog, color calculation, etc. LayaAir provides a custom Shader function, which allows developers to implement some functions or effects that are not provided by the engine. There is a certain threshold for the implementation of Shader. Novices should not rush to study this first, just have a basic understanding first. 9. 3D physics system, 3D animation system The 3D physics system calculates gravity, motion, rotation, collision feedback, etc. by simulating real physical properties. The LayaAir engine has built-in 3D physics engines such as bullet. Animation is an integral part of interactive games. The LayaAir engine supports the use of material animation, rigid body animation, camera animation, and skeletal animation. Among them, material animation is an animation that changes the color and texture of the material. Rigid body animation, also known as transformation animation, refers to animation that only rotates, scales, and displaces the model without changing the vertices and materials of the model, such as sole halo, knife light, etc. Rigid body animation is also often used in conjunction with material animation. Skeletal animation is also called skin animation. This kind of animation mainly produces animation by changing the vertices of the model. Camera animation refers to the animation effect produced by changing the position of the camera. 10. Common mathematical concepts of 3D basics In the previous sections, we have already had a basic conceptual understanding of 3D games and graphics development. Finally, we briefly introduce some basic common concepts of 3D mathematics. For example: vectors, matrices, Euler angles, quaternions, rays, bounding volumes. 10.1 Vectors A quantity that has both magnitude and direction is called a vector (called a vector in physics). Vectors also have dimensions, for example, 2 dimensions, 3 dimensions, and 4 dimensions. Corresponding to vector is quantity (called scalar in physics), which is a quantity with only magnitude and no direction. Some articles understand quantity as a 1-dimensional vector, but the vector we usually refer to is 2 or more dimensions, excluding 1 dimension. In the LayaAir engine, examples of encapsulation methods for 2-dimensional, 3-dimensional, and 4-dimensional vectors are: Vector2(1, 2), Vector3(1, 1, 3), and Vector4(1, 2, 3, 0.5). However, the Vector method encapsulated by the LayaAir engine can not only be used as a vector, but can also be used for vertex coordinate positions or when expressing colors. For example, the origin coordinates Vector3(0, 0, 0), the color values ​​Vector3 (0.6, 0.6, 0.6) and Vector4(0.9, 0.5, 0.1, 1). When it comes to vectors, let’s understand the components by the way. We decompose a vector into the sum of vectors in several directions. Then these decomposed vectors are called components of the vector (also called vector projection). For example, if a certain vector coordinate u is (5, 10), then the decomposed vector coordinates w1 (5, 0) and w2 (0, 10) are both components of the vector coordinate u. In the engine, we can also regard vector elements as components, such as Vector3(0.6, 0.6, 0.5), which has 3 components, of which 0.5 is called the third component of this vector. 10.2 Matrix In linear algebra, a matrix is ​​a rectangular block of numbers organized in rows and columns. If a vector is defined as a 1-dimensional array, then the matrix is ​​a 2-dimensional array. Don't understand 2 dimensions here as 2D, it means that the rows and columns from the array form 2 dimensions. To understand it from the perspective of arrays, vectors are arrays of quantities, and matrices are arrays of vectors. The matrix is ​​a form directly used to describe the orientation in the graphics API of the graphics card, and the vector rotation can be performed immediately. The LayaAir engine provides a 3×3 rotation matrix Matrix3x3() and a 4×4 transformation matrix Matrix4x4(). The transformation matrix can be used for translation, rotation, and scaling calculations. 10.3 Euler angles and quaternions Euler angles and quaternions are both mathematical methods used for rotation calculations. The matrix just introduced can obviously also be used for rotation calculations. Why are these two methods introduced? Relatively speaking, the 3×3 rotation matrix requires 9 numbers, the Euler angle only requires 3 numbers (3-dimensional vector), and the quaternion only requires 4 numbers (4-dimensional vector), which is obviously much lighter. Whether that is the optimal Euler angle is not necessarily the case. Although Euler angles take up less memory and are easier to use, Euler angles also have their own unique problems, which may cause universal joint deadlock. Quaternions, on the other hand, occupy less memory than matrices and are not troubled by gimbal deadlocks. Moreover, smooth interpolation can only be accomplished with quaternions. 10.4 Ray A ray is a straight line formed by infinite extension with only one endpoint. The ray in the LayaAir engine is a data object with two attributes: starting point and emission direction. It is often used for basic collision detection and can also be used for mouse picking. 10.5 Bounding volume The bounding volume is used for visible detection calculations. The basic idea is to replace the surrounded body with a complex structure with a slightly larger and simple structure. When performing detection, it can improve the detection efficiency. For example, once it is detected that the surrounding body is blocked and invisible, no matter what kind of model is inside the surrounding body, it will be invisible. The LayaAir engine provides box-shaped bounding bodies (bounding boxes) and spherical bounding bodies (bounding spheres). Write at the end LayaAir has provided a large number of engine documents on the official engine website, especially 3D documents, sample DEMOs, and API documentation. However, there are still some developers who are unable to start when learning 3D, so this is a more basic introductory document, which should have covered most basic concepts. I hope that everyone can further learn the use of the engine based on the enlightenment knowledge of this article, and conduct targeted in-depth research and study from the concepts involved in this article that are not fully understood. This article is only a basic introductory document, covering as many basic concepts as possible. However, in order to maintain the continuation of the writing logic during the document writing process, some basic concepts are not fully introduced, such as normals, octrees, Concepts such as homogeneous coordinates are not discussed. Developers can, if they encounter some unfamiliar words during the learning process of the official website documents, try to buy basic graphics books or find suitable articles in search engines to make up for the lessons. You can also give feedback in the community on the official website, and we will supplement and improve the documentation used by the engine. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:14:06 "},"basics/3D/Transform/readme.html":{"url":"basics/3D/Transform/readme.html","title":"Transform","keywords":"","body":"3D transform1. Translation transformation2. Rotation transformation2.1 rotate()2.2 localRotationEuler()3. Scale transformation4. Other transformations5. Local space and world space6. Parent-child relationship in the 3D world3D transform Previously Introduction to 3D Concepts I talked about the coordinate system and several basic mathematical tools in LayaAir. An important application of these basic concepts is three-dimensional transformation, which is also three-dimensional. The foundation of the graphic world. The Transform3D class is used to implement three-dimensional transformation in LayaAir, which includes translation transformation, rotation transformation, scaling transformation, etc. This section demonstrates these transformations using a cube model. Create a \"3D empty project\" in LayaAir IDE. After opening the project, the IDE has created a cube by default. In the property panel of Scene2D, create a new component script and add a decorator to expose the properties of the cube. The code is as follows: @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; Then in the IDE, drag the Cube node into the property entrance exposed by the decorator, and you can control the Cube node with code. 1. Translation transformation The translation transformation is defined as follows: /** * Translation transformation. * @param translation moving distance. * @param isLocal Whether it is local space. */ translate(translation: Vector3, isLocal: boolean = true): void { if ( isLocal ) { Matrix4x4.createFromQuaternion(this.localRotation, Transform3D._tempMatrix0); Vector3.transformCoordinate(translation, Transform3D._tempMatrix0, Transform3D._tempVector30); Vector3.add(this.localPosition, Transform3D._tempVector30, this._localPosition); this.localPosition = this._localPosition; } else { Vector3.add(this.position, translation, this._position); this.position = this._position; } } The translation transformation method translate() has two parameters. The first translation represents the moving distance. It is a Vector3 type variable that contains both the moving distance and the moving direction. The second isLocal determines whether it is local space. The default value is true, which is local space. If false is passed in, it is world space. If the starting position of the object in local space and world space is the same, and it has not undergone transformations such as rotation, then the result of its movement in the two spaces is the same. The difference between the two will be explained in Section 5. Use translation transformation to move the cube by a distance of 1 in the x, y and z directions respectively. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; // translation distance private translate: Laya.Vector3 = new Laya.Vector3(1, 1, 1); constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { // Translate cube this.cube.transform.translate(this.translate, false); } } The effect is shown in Figure 1-1, where 1 is the original position and 2 is the position after translation. (Picture 1-1) 2. Rotation transformation Regarding rotation, two rotation interfaces are provided in Transform3D: 2.1 rotate() The first is angle/radical rotation rotate(), defined as follows: /** * Rotation transformation. * @param rotation rotation amplitude. * @param isLocal Whether it is local space. * @param isRadian Whether the radian system. */ rotate(rotation: Vector3, isLocal: boolean = true, isRadian: boolean = true): void { var rot: Vector3; if (isRadian) { rot = rotation; } else { Vector3.scale(rotation, Math.PI / 180.0, Transform3D._tempVector30); rot = Transform3D._tempVector30; } Quaternion.createFromYawPitchRoll(rot.y, rot.x, rot.z, Transform3D._tempQuaternion0); if ( isLocal ) { Quaternion.multiply(this._localRotation, Transform3D._tempQuaternion0, this._localRotation); this.localRotation = this._localRotation; } else { Quaternion.multiply(Transform3D._tempQuaternion0, this.rotation, this._rotation); this.rotation = this._rotation; } } The rotation method rotate() has three parameters. The first rotation represents the rotation amplitude, which is the angle of rotation around the x, y, and z directions. The second isLocal determines whether it is local space. The default value is true, which is local space. If false is passed in, it is world space. The third isRadian determines whether it is in radian system. The default value is true, which is radian system. If false is passed in, it represents the angle value. Use the rotation transformation rotate() to rotate the cube around the y-axis and use the angle value. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; // Rotation angle private rot: Laya.Vector3 = new Laya.Vector3(0, 1, 0); constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Set timer execution, scheduled repeated execution (based on frame rate) Laya.timer.frameLoop(1, this, this.animate); } private animate(): void { // Rotate cube (quaternion) this.cube.transform.rotate(this.rot, false, false); } } The effect of rotation is shown in the animation 2-1: (Animation 2-1) 2.2 localRotationEuler() The second is Euler angle rotation localRotationEuler():Vector3. Its use is very simple. You only need to assign a value to the rotation angle. Rotate the cube 45 degrees around the x, y, and z directions respectively, using the angle value. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; // Rotation angle private rot: Laya.Vector3 = new Laya.Vector3(45, 45, 45); constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { // Rotate cube (Euler angles) this.cube.transform.localRotationEuler = this.rot; } } The effect after rotation is shown in Figure 2-2: (Figure 2-2) If you want to achieve the effect shown in Figure 2-1, that is, rotate the animation around the Y axis, you need to increase the value of localRotationEulerY every frame. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; // Rotation angle private rot: Laya.Vector3 = new Laya.Vector3(0, 1, 0); constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Set timer execution, scheduled repeated execution (based on frame rate) Laya.timer.frameLoop(1, this, this.animate); } private animate(): void { // Rotate cube (Euler angles) this.cube.transform.localRotationEulerY += this.rot.y; } } 3. Scale transformation The scaling transformation can be done using the method localScale(): Vector3. If the incoming Vector3 has the same values ​​in the x, y, and z directions like (2, 2, 2), (3, 3, 3), then the scaling transformation will be a proportional scaling, that is, a proportional enlargement of 2 times. ,3 times. If it is non-proportional scaling, for example, the cube is enlarged to 2 times its original size in the x-axis direction, while the y and z directions remain unchanged. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Sprite3D }) public cube: Laya.Sprite3D; //zoom factor private scale: Laya.Vector3 = new Laya.Vector3(2, 1, 1); constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { // Scale the cube this.cube.transform.localScale = this.scale; } } The effect is shown in Figure 3-1: (Figure 3-1) 4. Other transformations In addition to the three common transformations introduced above, there are some other commonly used methods and properties in Transform3D: lookAt(target: Vector3, up: Vector3, isLocal: boolean = false, isCamera: boolean = true): void: Observe the target position. localPosition:Vector3: local position. localMatrix:Matrix4x4: local matrix. position:Vector3: world position. worldMatrix:Matrix4x4: World matrix. getRight(right: Vector3): void: Get the right direction. getUp(up: Vector3): void: Get the upward direction. getForward(forward: Vector3): Get the forward direction. 5. Local space and world space Local space, also called object space, is the coordinate system relative to the object itself. In local space, the object's own position is regarded as the origin (0, 0, 0), and each object has its own independent local space. World space refers to a common, global coordinate system used to describe the positions of all objects. Local space allows the behavior of objects (such as movement and rotation) to become independent and not directly affected by other objects or global space. To give an example, when the cube is rotated 45 degrees around the x-axis, moving the cube in the local space means moving in the direction of its own coordinate system, as shown in the animation in Figure 5-1: (Animation 5-1) Correspondingly, moving the cube in the world space means moving in the direction of the global, fixed coordinate system, as shown in animated picture 5-2: (Animation 5-2) This article only uses a simple cube to illustrate usage. The transformation of complex models is similar to that of a cube. For detailed examples, please refer to the TransformDemo scene in \"Engine API Usage Example\". 6. Parent-child relationship in the 3D world When the parent node transforms in the 3D world, its child nodes will transform accordingly. However, transformations of child nodes will not affect the parent node. For example, the Sprite3DParent scene in \"Engine API Usage Example\" is shown in the animation in Figure 6-1. When the parent node is rotated, the child nodes will rotate accordingly. (Animation 6-1) Rotate the child nodes, and the parent node is not affected by the child nodes, as shown in animated figure 6-2. (Animation 6-2) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:18:48 "},"IDE/uiEditor/readme.html":{"url":"IDE/uiEditor/readme.html","title":"UI Editor","keywords":"","body":"UI editing moduleUI editor basic interaction2D basic display objectUI ComponentUI inheritance classMixed Use 3DUI editing module UI is the abbreviation of User interface, and the Chinese meaning is user interface. For example, progress bars, character avatars, rankings, shopping malls, game tasks, function buttons, etc. in the game interface. In fact, UI editing refers to a wider scope. All visible 2D display object layouts and interface layout behaviors belong to UI editing. The UI editing module is an important module for visual operation of 2D games and 2D UI interfaces, which can greatly improve the development efficiency of 2D games and 2D UI production. The UI editing of LayaAirIDE can realize the separation of UI editing and code, and visual typesetting, so that art and planning without programming foundation can also be learned and mastered. It also allows programmers to use code to manage and control the UI, as well as implement interaction logic. UI editing mainly includes hierarchical panels, scene panels, UI editing and layout tools, 2D prefabs, UI widgets (basic display objects, UI components, skeletal animation), etc. We can view the functional documents of each sub-module separately: UI editor basic interaction 2D basic display object UI Component UI inheritance class Mixed Use 3D Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:31:52 "},"IDE/uiEditor/basic/readme.html":{"url":"IDE/uiEditor/basic/readme.html","title":"Basic Interaction","keywords":"","body":"Basic interaction of UI editor1. Basic interactive icon description of UI editor2. Window camera mode3. Panning mode4. Alignment settings5. Width and height settings6. Row, column spacing, and column number settings7. Display settings8. Zoom settingsBasic interaction of UI editor 1. Basic interactive icon description of UI editor First, let’s take a look at the basic interaction icons of the UI editor, as shown in Figure 1-1. (Picture 1-1) ​ From left to right, they are window camera mode, panning mode, left alignment, left and right center alignment, right alignment, top alignment, top and bottom center alignment, bottom alignment, same width, same height, uniform line spacing, uniform column spacing, table arrangement, and display. settings, zoom settings. 2. Window camera mode ​ Click the little hand icon in the 2D scene to enter the window camera mode. You can also press and hold the right mouse button to enter this mode directly. In this mode, keep pressing the left or right mouse button to drag the entire scene in any direction. The effect is as follows As shown in animation 2-1. (Animation 2-1) 3. Panning mode Click the arrow icon in the 2D scene to enter the panning mode. In this mode, keep pressing the left mouse button to drag the selected control in any direction. If the scene has many levels, it will be difficult to drag the component you want to move. At this time, you can click to select the component from the hierarchy panel and drag it. The effect is as shown in animation 3-1. (Animation 3-1) If you want to move multiple controls at one time, just press and hold the left mouse button outside the canvas and slide across the canvas, as shown in animation 3-2. (Animation 3-2) 4. Alignment settings Move the control on the parent node of the control. You can move only one, or you can move multiple at one time. The method is to long-press the left mouse button outside the canvas and then slide across the canvas, and click on the alignment setting you need. Name Function Shortcut keys left aligned Translate the selected control horizontally to the leftmost side of the control's parent node. Ctrl+Alt+1 Left and right center alignment Translate the selected control horizontally to the horizontal center of the control's parent node. Ctrl+Alt+2 Align right Translate the selected control horizontally to the rightmost side of the control's parent node. Ctrl+Alt+3 align top Move the selected control vertically to the top of the control's parent node. Ctrl+Alt+4 Center alignment up and down Translate the selected control vertically to the vertical center of the control's parent node. Ctrl+Alt+5 align bottom Move the selected control vertically to the bottom of the control's parent node. Ctrl+Alt+6 5. Width and height settings Same width (shortcut Ctrl+Alt+7): Use the canvas as an analog object to modify the width of the selected control, as shown in animation 5-1. (Animation 5-1) Same height (shortcut Ctrl+Alt+8): Use the canvas as an analog object to modify the height of the selected control, as shown in animation 5-2. (Animation 5-2) 6. Row, column spacing, and column number settings Uniform line spacing: Arrange the selected controls with even line spacing in pixels. The effect is as shown in animation 6-1. (Animation 6-1) Uniform column spacing: Arrange the selected controls with uniform column spacing in pixels, as shown in the animation in Figure 6-2. (Animation 6-2) Table arrangement: Arrange the selected controls in a neat table format. You can complete it by directly inputting the values. It is very convenient. The effect is shown in the animation 6-3. (Animation 6-3) 7. Display settings The display setting function can be used to modify the background color of the editor scene window. Developers can choose it themselves. The effect is shown in Figure 7-1. (Figure 7-1) You can also set the reference image when editing the UI in Design Image (when designing the UI according to art requirements, the bitmap placed in the scene will not be displayed at runtime). The parameter settings are as follows: Source: Select the bitmap as the reference image. Offset: The position of the reference image. Alpha: the transparency of the reference image. In Front: Whether it is located on the upper level. When checked, the reference image will be on top. 8. Zoom settings Developers can choose to zoom in on the current scene. As shown in Figure 8-1. (Figure 8-1) Shortcut keys for zoom settings. Button Function ctrl + + Zoom in ctrl + - Zoom out ctrl + 1 Restore to 100% ctrl + mouse wheel Free zoom Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 10:48:23 "},"IDE/uiEditor/widgets/readme.html":{"url":"IDE/uiEditor/widgets/readme.html","title":"widgets","keywords":"","body":"UI widgetsUI widgets The UI widgets of the LayaAir engine are divided into three categories. They are: Basic display objects: 2D sprites, 2D node animations, basic text, audio nodes, and video nodes. UI components: images, buttons, display text, text input, text fields, drop-down boxes, multi-select boxes, radio buttons, radio button groups, navigation label groups, navigation containers, bitmap slices, bitmap font slices, Vertical scroll bar, horizontal scroll bar, progress bar, vertical swipe bar, horizontal swipe bar, color picker, basic container, list, tree list, open data field. Skeleton: Spine skeleton, built-in skeleton. As shown in Figure 1: (figure 1) When using it, just drag the widget directly into the scene window. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:31:12 "},"2D/displayObject/readme.html":{"url":"2D/displayObject/readme.html","title":"Display Object","keywords":"","body":"2D Basic Display Object2D Basic Display Object Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:03:21 "},"2D/displayObject/Sprite/readme.html":{"url":"2D/displayObject/Sprite/readme.html","title":"Sprite","keywords":"","body":"Sprite1. Overview2. Use in IDE2.1 Create Sprite2.2 Basic attributes2.3 Sprite’s unique properties2.4 Other attributes2.5 Script control properties3. Used in code3.1 Create Sprite3.2 Display pictures3.3 Basic attributes3.4 Other attributesSprite 1. Overview The Sprite in the game is a display object that can be controlled on the screen. If the display object on the screen cannot be controlled, it is just a node. To be precise, a Sprite is a 2D image that can be transformed into a controllable animation by changing its own properties, such as angle, position, scaling, color, etc. Sprite is a basic display list node that displays graphics. Pictures or vector graphics can be drawn through graphics, which supports rotation, scaling, displacement and other operations. Sprite is also a container class and can be used to add multiple child nodes. Sprite has been optimized for rendering in different situations, thus ensuring that a class can achieve rich functions while achieving high performance. In addition, in LayaAir 2D UI, Sprite is the base class of all node objects, as shown in Figure 1-1. The basic functions of the Sprite class will be inherited to all inherited node objects (due to limited space, only the The subclass of the Sprite class part. For all inheritance relationships, please refer to API document), so this article will introduce the basic functions of the Sprite class in detail, and subsequent node objects will not be introduced again. (Picture 1-1) 2. Use in IDE 2.1 Create Sprite 2.1.1 Created in Scene2D In a Scene2D hierarchy window, you can create sprites under any node or in a blank position by right-clicking the mouse, as shown in animation 2-1: (Animation 2-1) No effect can be seen on the sprite created at this time. In fact, an empty 2D sprite node is created. 2.1.2 Create in control Under the 2D tag of Widget, sprites can be created under any node, as shown in animation 2-2: (Animation 2-2) 2.2 Basic attributes As shown in Figure 2-3, elves have the following basic attributes: (Figure 2-3) Basic attributes Function description Position The position coordinates of the sprite Size The width and height of the sprite Anchor Sprite's anchor point Scale Scaling of sprites Skew The tilt angle of the sprite Rotation The rotation of the sprite Visible Whether the sprite is visible Alpha Sprite transparency Let’s go through a set of operations to see how these attributes are operated, as shown in Figure 2-4: (Animation 2-4) Since the sprite at this time is just an empty node and has no display object, the adjustment of Visible and Alpha will not cause any display changes. Let's first take a look at some commonly used basic attributes: 2.2.1 Position The position of the sprite refers to the position of the canvas where the sprite's anchor point/pivot point is located. Position has two parameters, x and y. The upper left corner of the canvas is the origin. Pointing from left to right is the positive direction of the x-axis, and pointing from top to bottom is the positive direction of the y-axis. 2.2.2 Size The size of the sprite refers to the width (W) and height (H) of the sprite, in pixels. 2.2.3 Anchor Before explaining the anchor point, you need to first know the concept of Pivot. The default pivot point of a Sprite object is located at its upper left corner. When setting the position of the Sprite object, it is positioned based on the upper left corner by default. The pivot point is the reference point, which determines the position of the Sprite on the stage. The pivot point is in pixels. The default X and Y coordinates are (0,0), which means the upper left corner of the picture is used as the reference point. When the default pivot point of the Sprite object is modified, and the position, scale, and rotation of the Sprite object are set, the pivot point is used as the basis, not the default coordinate value of the upper left corner of the Sprite object. Changing the pivot point can control the center of rotation and scaling, and also affects the object position, scaling center, and rotation center. The anchor point anchor and the pivot point pivot are both reference points, which determine the position of the Sprite on the stage. The anchor point is measured in multiples of the width and height of the Sprite, and the value range is 0~1. When the anchor point anchor is changed, the pivot point pivot will also change accordingly. Therefore, modifying the anchor point anchor is another simple way to change the pivot point pivot. 2.2.4 Scale The X and Y of Scale scale horizontally and vertically with the anchor point/pivot point as the center. The default is 1, no scaling; the larger the positive value, the larger the scaling size. Zoom to 0, invisible; -1 is a mirror. The larger the negative value, the larger the scaled size after mirroring. 2.2.5 Skew The X and Y of Skew are tilted horizontally and vertically with the anchor point/pivot point as the center. 2.2.6 Rotation The rotation is centered on the anchor/pivot point, with positive numbers representing clockwise rotation and negative numbers representing counterclockwise rotation. 2.2.7 Visialble This is a Boolean value. Checking means true and visible. Unchecking means false, which means it is invisible. If the sprite loads the image at this time, it will not be displayed on the canvas. 2.2.8 Transparency Alpha If the wizard loads an image, transparency can set the transparency of the image, ranging from 0 to 1. 2.3 Sprite’s unique properties (Figure 2-5) As shown in Figure 2-5, the attributes of the sprite are: Texture: Draw an image or render a texture. Graphics: Draw a graphic or a group of graphics. 2.3.1 Texture of Image First of all, Sprite's Texture supports drawing by dragging or loading a picture as a texture Texture. As shown in the animation 2-6, let’s understand the process of dragging a picture into the Texture property: (Animation 2-6) Note: During the project development process, if you only draw a picture, try to use the Spirte object to draw it through Texture, which has the highest performance. In 2D interface development, pictures need to be edited into \"sprite textures\". For details, please refer to \"Project Resource Panel Instructions\". 2.3.2 Texture of RenderTexture Render Texture is a special type of texture that is constantly updated and rendered at runtime. A typical use of a render texture is to set it as the camera's Target Texture property, which will cause the camera to render to the texture instead of rendering to the screen. It can then be used in Sprite objects like a normal texture. As shown in the animation 2-7, drag a created rendering texture (for the production method, please refer to Mixed use of 3D) to the Sprite's Texture property. (Animation 2-7) Note: The rendering texture can only be set through the Texture property of Sprite. The way of setting the rendering texture in any other display object component is incorrect 2.3.3 Graphics properties By using the Graphics property, we can draw rectangles, circles, polygons and other graphics, as shown in animation 2-8: (Animation 2-8) For the specific introduction to drawing each type of graphics and how to use the code, developers please refer to \"Drawing Graphics\". 2.4 Other attributes The Miscellaneous property panel includes other properties of the sprite, as shown in Figure 2-9: (Figure 2-9) Other attributes Function description Z Order Z sorting, changing this value will reorder all objects in the same container according to the size of the value. The larger the value, the higher it is. The default is 0. If not changed, it will be sorted according to the order of addition Blend Mode Specifies the blending mode to use. Currently only supports \"lighter\" Mouse Enabled Whether to accept mouse events Mouse Through Whether the collision detection of mouse events with this object is penetrable Hit Test Prior Specifies whether mouse event detection should prioritize itself or its sub-objects. DrawCallOptimize Whether to turn on DrawCall optimization Cache Ace Whether to enable static cache optimization Mask Set mask node object Hit Area Click area Filters UI filter effect Among them, Mouse Enabled, Mouse Through, Hit Test Prior, and Hit Area are all explained in \"2.4.6 Mouse Operation Related Properties\" 2.4.1 Set Z Order As shown in animation 2-10, we set the Z Order values ​​of two Sprites in the IDE. The default values ​​are both 0, and the ones added later are above. After the change, look at the running effect. It shows that the larger the value, the higher it is. (Animation 2-10) 2.4.2 Set BlendMode As shown in the animation 2-11, we set up two Sprites in the IDE. Originally, Sprite2 covered Sprite1. After using the BlendMode as \"lighter\", look at the running effect. The colors of the two Sprites are superimposed. . (Animation 2-11) Note: In the IDE, only the lighter mode is supported. Both the original graphics and the new graphics are displayed, and the intersection part is color overlaid 2.4.3 Setting Draw Call Optim If true, it means that DrawCall optimization is enabled. For the content of DrawCall, please refer to \"Performance Statistics and Optimization\". 2.4.4 Set Cache As (Figure 2-12) As shown in Figure 2-12, two types of static cache can be set up. Let’s take a look at some instructions for static cache: When there are a large number of UIs in the game, and one UI has multiple nodes and the changes are small, it is recommended to use cacheAs (most UIs can be used). For example, the LayaAir IDE we use, many panels in the software, such as property setter, resource manager, project manager, etc., have many node sub-objects, but they do not change frequently, so we all use cacheAs for caching. Improved rendering efficiency. For complex UI that changes frequently, the UI can be divided into two layers. The layer that changes less often uses cacheAs, and the layer that changes frequently does not use cacheAs. For example, if there is a UI with a \"countdown\" display, we can also divide it into the countdown part and other parts. The other parts will be cacheAs, and the countdown part will not be cacheAs. You need to study and understand carefully when using cacheAs during development. Wrong understanding and use of the cache mechanism will actually reduce performance. cacheAs: Cache component, whether to cache static images, reasonable function can improve performance. It has three optional values: \"None\", \"Normal\" and \"Bitmap\". \"None\": Indicates no caching. \"Normal\": Command caching, which is equivalent to only caching the sub-object traversal process and program command organization, without caching into a bitmap. When rendering each frame of the game, there is no need to traverse the sub-objects again, but Directly render the sub-objects on the graphics card according to the traversed levels. It will not reduce drawcalls and will not increase memory consumption. Rendering performance is average. \"Bitmap\": Perform renderTarget caching, which is equivalent to caching the UI composed of multiple sub-objects into a bitmap and submitting it to the graphics card for rendering each frame, reducing drawcalls. Maximum rendering performance. It should be noted that the cached bitmap will increase some additional memory overhead. The larger the cached bitmap, the greater the memory overhead. And the cache bitmap size cannot exceed 2048. This mode also increases CPU overhead when constantly redrawing. Tips: When cacheAs selects \"Normal\" and \"Bitmap\", the sub-object changes and will be automatically re-cached. At the same time, you can also manually call the reCache method to update the cache. 2.4.5 Set Mask Mask display is performed according to the shape of the object (bitmap and vector images are supported), and the coordinate system of the mask object is relative to the mask object itself. As shown in animation 2-13, let's take a look at the operation process of setting the mask. For example, we set a circular mask Sprite2 on the graphic drawn by Sprite1, where Sprite2 is a child node of Sprite1. (Animation 2-13) 2.4.6 Mouse operation related properties The properties related to mouse operations are described as follows: Properties Function description MouseEnabled Set to true to accept mouse events, set to false to not accept mouse events (the following attributes will be invalid) Hit Area Click on the area, the custom area only supports circles, rectangles, and polygons MouseThrough The default value is false. If set to true, clicking on a blank area (without setting Texture, Image, etc.) can penetrate through it, and is only valid for itself Hit Test Piror When the value is true and there is no penetration (Mouse Through is false), this node will be detected first. When the value is false, child nodes will be detected first until all nodes on the stage are recursively detected. 1. Mouse Enabled： The default is false. If you listen to mouse events in script code, the MouseEnabled attribute value of this object and the parent node will be automatically set to true. However, if the MouseEnabled value of the parent node is manually set to false, even if mouse event monitoring is performed, the MouseEnabled value of the parent node will still be false. Let's give an example to illustrate this special situation. As shown in Figure 2-14, \"Sprite1\" is the parent node, \"Sprite2\" is the child node, and the default MouseEnabled attribute value in the IDE is false. (Figure 2-14) At this point, you can add a custom component script under Scene2D and add the following code: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Sprite }) public sprite1: Laya.Sprite; @property({ type: Laya.Sprite }) public sprite2: Laya.Sprite; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.sprite2.on(Laya.Event.MOUSE_DOWN, this, this.test2);//Set up monitoring, either sprite1 or sprite2 can be used console.log(this.sprite1.mouseEnabled);//Print the value of MouseEnabled of parent node sprite1: true console.log(this.sprite2.mouseEnabled);//Print the value of MouseEnabled of child node sprite2: true } test2(e: Laya.Event) { console.log('mouseSprite2') } } Although the default MouseEnabled attribute value is false, because the listening mouse event this.sprite2.on is set up in the script, the MouseEnabled value of the parent node \"Sprite1\" and the child node \"Sprite2\" will automatically become true at this time. The code execution effect is as follows: (Animation 2-15) It can be seen that after setting the listener, the printed MouseEnabled value becomes true. But if the value of MouseEnabled of the parent node \"Sprite1\" is assigned to false in the code, then even if a listener is set for \"Sprite1\", its value will not change: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Sprite }) public sprite1: Laya.Sprite; @property({ type: Laya.Sprite }) public sprite2: Laya.Sprite; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.sprite1.mouseEnabled = false; //The MouseEnabled value of the parent node is false this.sprite1.on(Laya.Event.MOUSE_DOWN, this, this.test1);//Set up monitoring, sprite1 this.sprite2.on(Laya.Event.MOUSE_DOWN, this, this.test2);//Set up monitoring, sprite2 console.log(this.sprite1.mouseEnabled);//Print the value of MouseEnabled of parent node sprite1: false console.log(this.sprite2.mouseEnabled);//Print the value of MouseEnabled of child node sprite2: true } test1(e: Laya.Event) { console.log('mouseSprite1') } test2(e: Laya.Event) { console.log('mouseSprite2') } } However, it should be noted that the MouseEnabled of \"sprite2\" has not been manually assigned at this time, and still only has the default initial value, so setting a monitor for \"sprite2\" will make its MouseEnabled value become true. For event listening methods, refer to \"Events and Interaction\". 2. Hit Area： If we set a click event on an image, then the rectangle formed by the length and width of the Sprite is its click area. You can also use HitArea to set a customized click area Hit (circle, rectangle, polygon) and non-click area UnHit, as shown in the animation 2-16 to set the click area: (Animation 2-16) 3. Mouse Through： Give an example to illustrate this property. As shown in Figure 2-17, there are two Sprite nodes in the scene. In order to facilitate the observation of the effect, add a rectangle to the \"Graphics\" of Sprite1 and set it to white. Sprite2 is on the upper layer of Sprite1, and its size is slightly smaller than Sprite1. If \"Texture\", \"Graphics\", etc. are not set for it, Sprite2 is a blank area. (Figure 2-17) At this time, uncheck \"Mouse Through\" and listen for mouse press events in the code: onAwake(): void { this.sprite1.on(Laya.Event.MOUSE_DOWN, this, this.test1);//Set up monitoring, sprite1 this.sprite2.on(Laya.Event.MOUSE_DOWN, this, this.test2);//Set up monitoring, sprite2 } test1(e: Laya.Event) { console.log('mouseSprite1') } test2(e: Laya.Event) { console.log('mouseSprite2') } At runtime, since Sprite2 is a blank area, we cannot observe it. However, Sprite2 covers the upper layer of Sprite1. If you click the click area of ​​Sprite2, it will be monitored. The effect is as shown in animation 2-18: (Animation 2-18) As you can see, the console printed the log of mouseSprite2, but it did not monitor Sprite1 because Sprite2 covered Sprite1 where you clicked. Check \"Mouse Through\" of Sprite2 and run it again. The effect is as follows: (Animation 2-19) The area clicked is Sprite2, but the console prints mouseSprite1. The reason is that this event passes through Sprite2 (Mouse Through) and acts on the lower Sprite1. 4. Hit Test Prior： If the mouse is not within the mouse collision area of ​​the node, the detection of this node and its sub-nodes will be directly interrupted, which can reduce mouse collisions and improve performance. But because of this, the child node will not be able to respond to mouse events when it is outside the collision area of ​​its parent node. Let's take an example to illustrate. As shown in Figure 2-20, Sprite1 is the parent node and draws a white rectangle. The child node Sprite2 draws a red rectangle outside the parent node. (Figure 2-20) The script code in the above \"3. Mouse Through\" remains unchanged. First, uncheck the \"Hit Test Prior\" of Sprite1, click the sub-node Sprite2, and the console prints two logs of Sprite1 and Sprite2. The effect is as follows: (Figure 2-21) The effect in Figure 2-21 shows that when the \"Hit Test Prior\" value of the parent node is false, the child node will be detected first, and the parent node will respond recursively until the parent node is detected. Then check the \"Hit Test Prior\" of Sprite1. At this time, the child node Sprite2 is not within the mouse collision area of ​​the parent node Sprite1. If the mouse is placed on the child node Sprite2, the detection of Sprite1 and Sprite2 will be directly interrupted, and the mouse event cannot be responded to. , the effect is shown in the animation 2-22. (Animation 2-22) As you can see, clicking Sprite2 does not respond to mouse events. 2.4.7 Setting Filters Filters are mainly used to achieve various special effects on images to achieve the best artistic effect. There are many types of filters, but creating different effects requires different filter functions. There is a separate article to explain filters, please refer to \"UI Filter Effect\". 2.5 Script control properties In the Scene2D property settings panel, add a custom component script. Then, drag the Sprite node into its exposed property entrance, as shown in animation 2-23. (Animation 2-23) Then, you can use code to control the Sprite in the component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Sprite }) public sprite: Laya.Sprite; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.sprite.loadImage(\"atlas/comp/image.png\"); //Texture: image path this.sprite.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Position: screen center this.sprite.x = Laya.stage.width/2; //Set the positions of x and y respectively this.sprite.y = Laya.stage.height/2; this.sprite.size(512, 313); //Size this.sprite.width = 512; //Set the width and height respectively. this.sprite.height = 313; this.sprite.pivot(this.sprite.width/2, this.sprite.height/2); //Pivot point: the center of the sprite this.sprite.pivotX = this.sprite.width/2; //x and y set the pivot points respectively this.sprite.pivotY = this.sprite.height/2; this.sprite.anchorX = 0.5; //Anchor point: center of sprite this.sprite.anchorY = 0.5; this.sprite.scale(0.5, 0.5); //Scale size this.sprite.scaleX = 2; //Set scaling for x and y respectively this.sprite.scaleY = 2; this.sprite.skew(5, 5); //Slope this.sprite.skewX = 5; //x and y set the slope respectively this.sprite.skewY = 5; this.sprite.rotation = 45; //Rotation angle this.sprite.visible = true; //Is it visible: visible this.sprite.alpha = 0.5; //transparency } } 3. Used in code The Laya.Sprite class is located in the Core core class library and is encapsulated by the laya.display.Sprite class. The LayaAir engine API design is streamlined and ingenious, with only one Sprite as the core display class. 3.1 Create Sprite Create a Sprite object instance, the code is as follows: onAwake(): void { let sprite = new Laya.Sprite(); //Add to stage Laya.stage.addChild(sprite); } 3.2 Display pictures The display of images is the basis of game development. The Sprite class used to display images is Sprite.loadImage and Sprite.texture. 3.2.1 loadImage /** * Load and display an image. Equivalent to setting the texture attribute after loading the image * Note: Changes in 2.0: Called multiple times, only one picture will be displayed (1.0 will display multiple pictures), and the x, y, width, and height parameters are cancelled. * @param url The map's address. * @param complete (optional) loading completion callback. * @return Returns the sprite object itself. */ loadImage(url: string, complete?: Handler): Sprite; Let's take a look at the code example: let sprite = new Laya.Sprite(); // Load and display an image, centered sprite.loadImage(\"atlas/comp/image.png\", null); sprite.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Add to stage Laya.stage.addChild(sprite); 3.2.2 set texture /** * Set a Texture instance and display this image (if there was other drawing before, it will be cleared). * Equivalent to graphics.clear();graphics.drawImage(), but with higher performance * You can also assign an image address, and the image will be automatically loaded and then displayed. */ get texture(): Texture; set texture(value: Texture); Let's take a look at the code example: Laya.loader.load(\"atlas/comp/image.png\").then(() => { let sprite = new Laya.Sprite(); //The sprite sets the texture and displays it in the center let res = Laya.loader.getRes(\"atlas/comp/image.png\"); sprite.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); sprite.texture = res; //Add to stage Laya.stage.addChild(sprite); }); The two sample codes 3.2.1 and 3.2.2 have the same operating effect, as shown in Figure 3-1. Developers can use them according to their own needs. (Figure 3-1) 3.3 Basic attributes Let's look at it with some code examples: let sprite = new Laya.Sprite(); //Load and display an image sprite.loadImage(\"atlas/comp/image.png\", null); //Set the starting position of the picture sprite.pos(20, 20); //Set anchor point sprite.anchorX = 0.5; sprite.anchorY = 0.5; //Set zoom sprite.scale(2, 2); //Rotate sprite.rotation = 30; //Add to stage Laya.stage.addChild(sprite); The running effect is shown in Figure 3-2: (Figure 3-2) 3.4 Other attributes 3.4.1 Set zOrder The sample code for setting zOrder is as follows: let sp1 = new Laya.Sprite(); Laya.stage.addChild(sp1); sp1.pos(200, 190); //Load and display an image 1 sp1.loadImage(\"resources/layabox.png\", null); //You need to put the layabox.png image in the resources folder let sp2 = new Laya.Sprite(); Laya.stage.addChild(sp2); //Load and display an image 2 sp2.loadImage(\"atlas/comp/image.png\", null); //Set zOrder sp1.zOrder = 1; sp2.zOrder = 0; Let's take a look at the results: (Figure 3-3) It can be seen that sp1 was originally the child node added first, and sp2 was the child node added later. Originally sp2 would overwrite sp1, but by modifying zOrder, sp1 will be displayed at the top. 3.4.2 Set BlendMode The sample code for setting BlendMode is as follows: let sp1 = new Laya.Sprite(); Laya.stage.addChild(sp1); //Load and display an image 1 sp1.loadImage(\"atlas/comp/image.png\", null); let sp2 = new Laya.Sprite(); Laya.stage.addChild(sp2); //Load and display an image 2 sp2.loadImage(\"resources/layabox.png\", null); sp2.pos(200, 190); //Set blendMode sp2.blendMode = \"lighter\"; Let's take a look at the results: (Figure 3-4) Comparing with Figure 3-3, you can see that after using the blendMode of \"lighter\", the color of the sp2 picture and the color of sp1 are superimposed. 3.4.3 Set autoSize Specify whether to automatically calculate width and height data. The default value is false . Sprite width and height default to 0 and will not change as the drawing content changes. If you want to obtain the width and height based on the drawing content, you can set this property to true. The sample code is as follows: let sprite = new Laya.Sprite(); //Add to stage Laya.stage.addChild(sprite); sprite.autoSize = true; 3.4.4 Caching as static images The sample code is as follows: let sprite = new Laya.Sprite(); Laya.stage.addChild(sprite); //Cache as static image sprite.cacheAs = \"bitmap\" 3.4.5 Set mask The code example is as follows: let sprite = new Laya.Sprite(); Laya.stage.addChild(sprite); sprite.loadImage(\"atlas/comp/image.png\", null); //Create mask let mask = new Laya.Sprite(); sprite.addChild(mask); mask.graphics.drawCircle(200, 200, 100, \"#FFFFFF\"); //Add mask to image setTimeout(() => { sprite.mask = mask; //Wait for 1 second to perform masking }, 1000); The running effect is as follows: (Animation 3-5) 3.4.6 Set the click area hitArea There are many attributes related to mouse operations, but the code usage is similar. Here we take hitArea as an example. The sample code is as follows: let sp = new Laya.Sprite(); Laya.stage.addChild(sp); //Load and display an image sp.loadImage(\"atlas/comp/image.png\", null); //Set the click event of the image sp.on(\"click\", this, () => { Laya.Tween.to(sp, { scaleX: 0.5, scaleY: 0.5 }, 100); }); //Set the mouse click area let hitArea: Laya.HitArea = new Laya.HitArea(); hitArea.hit.drawRect(0, 0, 100, 100, \"#00ff00\"); sp.hitArea = hitArea; Let's take a look at the results: (Animation 3-6) It can be seen that the click area has a click effect, but other areas have no effect. If hitArea is not set, click events can be accepted as long as it is within the image range. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:34:00 "},"2D/displayObject/Animation/readme.html":{"url":"2D/displayObject/Animation/readme.html","title":"Animation","keywords":"","body":"Animation node (Animation)1. Preliminary understanding of Animation nodes2. Create Animation nodes through LayaAir IDE2.1 Create Animation2.2 Receive animation data source2.3 Set automatic play (autoPlay)2.4 Control the animation playback mode (wrapMode)2.5 Frame interval time of animation playback (interval)2.6 Set the starting position of playback (index)2.7 Script Control Animation3. Code to create AnimationAnimation node (Animation) 1. Preliminary understanding of Animation nodes Animation is node animation, which can easily create atlas animation and multi-frame animation. As shown in the animation 1-1, it is the animation effect created by Animation. For the API of the Animation node, please refer to Animation API. (Animation 1-1) Common properties of Animation nodes Properties Function description images Add animated images. source Add animation gallery. autoplay Whether the animated atlas automatically plays, the default is false. If set to true, the animation will play automatically after it is created and added to the stage. wrapmode Playback type: The default is 0 for positive sequence playback (POSITIVE), 1 for reverse sequence playback (REVERSE), and 2 for pingpong playback (PINGPONG). interval animation playback interval, unit is milliseconds, the default value is 50 milliseconds. index Playback position. 2. Create Animation nodes through LayaAir IDE 2.1 Create Animation As shown in animation 2-1, you can create an Animation node in the Hierarchy panel, click + or create it by right-clicking. (Animation 2-1) You can also drag Animation directly from Widgets' into the IDE'sScene EditororHierarchy` panel, as shown in animation 2-2. (Animation 2-2) 2.2 Receive animation data source There are two ways to receive animation data sources: Images and Source. 2.2.1 Images The first method is Images. You can hold down the ↓ arrow keys on the keyboard to quickly select a picture, or you can click on the picture to add it, as shown in the animation 2-3. (Animation 2-3) 2.2.2 Source The second method is simpler and faster, just put the packaged atlas into the Source property, as shown in Figure 2-4. (Figure 2-4) 2.2.3 Making an atlas Although the method of adding an atlas is relatively quick, the above-mentioned \"atlas\" resources need to be produced by the developer themselves. LayaAir IDE provides tools for creating atlases, as shown in Figure 2-5. Select Create atlas in the Tools menu bar of the navigation bar. (Figure 2-5) The atlas creation tool that opens after clicking is shown in Figure 2-6. (Figure 2-6) When making an atlas, you need to store a series of pictures that need to be included in the atlas in a folder (here they are stored in the folder \"role\"). Then set the parameter the folder where the picture is located to the folder \"role\" where the picture is stored, as shown in Figure 2-7. (Figure 2-7) If Power of Two Limit is checked, the width and height of the generated atlas image will be a full power of 2. Check Crop the white space around the picture, and the pictures in the generated atlas will be denser. Click the Make button, as shown in Figure 2-8, select the path where the atlas file is stored, name the atlas file, and then click Save. (Figure 2-8) After the atlas is created, a prompt with the words \"Success!\" will be displayed (Figure 2-9). (Figure 2-9) The final generated atlas files are .atlas files and .png files (role.atlas and role.png) with the same names. Among them, .atlas is the unique atlas format of LayaAir IDE and is only used for atlases. 2.3 Set automatic play (autoPlay) The autoPlay attribute can set whether to play automatically. The default is false, which means no automatic playback. If set to true, that is, when checked, the animation will automatically play after it is created and added to the stage. 2.4 Control the animation playback mode (wrapMode) The animation playback mode attribute wrapMode has three optional values. The default value is 0, positive sequence play (POSITIVE). When 1 is selected, play in reverse order (REVERSE). When selecting 2, pingpong mode (PINGPONG), which is more straightforward, means playing back and forth. The following demonstrates the three playback modes by loading the gallery. Note: When playing, you must check the AutoPlay parameter, that is, set it to true. 2.4.1 Play in forward sequence mode By default, the wrapMode attribute is not set or the wrapMode attribute value is set to 0, which is the positive sequence playback mode (POSITIVE). That is, the sequence diagram is played from front to back, as shown in animation 2-10. (Animation 2-10) 2.4.2 Play in reverse order mode When the wrapMode attribute value is set to 1, it is reverse playback mode (REVERSE). That is, the sequence diagram is played from back to front, which is completely opposite to the forward sequence playback mode, as shown in animation 2-11. (Animation 2-11) 2.4.3 Pingpong mode playback When the wrapMode attribute value is set to 2, it is pingpong playback mode (PINGPONG). In this mode, after the same set of actions has been played in the forward sequence, it will not directly return to the first frame set in the album and play again, but will play from the penultimate frame in reverse order, thus making the actions smoother and more complete. Therefore, the pingpong mode is also one of the modes frequently used in games. It can also significantly reduce the amount of art resources while ensuring the effect. The effect is shown in the animation 2-12. (Animation 2-12) 2.5 Frame interval time of animation playback (interval) The interval attribute can set the frame interval time (unit: milliseconds) for animation playback. The default value is 50 milliseconds. For example, we slow down the animation we just played by one time and set it to 100 milliseconds. The effect is shown in the animation 2-13. (Animation 2-13) Tips: If the animation is playing, the starting time of the frame loop timer will be reset to the current time after setting. In other words, if interval is set frequently, the time interval between animation frame updates will be longer than expected. Be slow or even not update at all. 2.6 Set the starting position of playback (index) The index attribute can specify the frame index of the animation. The default index is 0, which can be set to any frame in the animation. After setting, it will jump to the set animation frame, and the effect is as shown in animation 2-14. (Animation 2-14) Tips: This property is only used for static specification, such as manually switching animation frames through code or click events. If set to autoplay, it will still start playing from frame 0, regardless of the index setting. 2.7 Script Control Animation In the property settings panel of Scene2D, add a custom component script named \"Animation.ts\". Then, according to the animation in Figure 2-15, drag the Animation node into the attribute entrance exposed by \"Animation.ts\". (Animation 2-15) Then, you can use code to control Animation in the script file \"Animation.ts\". The sample code is as follows: const { regClass, property } = Laya; @regClass() export class Animation extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Animation }) //Display properties in the IDE panel ani: Laya.Animation; constructor() { super(); } //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.ani.source = \"resources/role.atlas\"; //Receive animation data source as atlas this.ani.autoPlay = true; //Turn on automatic play this.ani.wrapMode = 0; //The playback mode is positive sequence playback mode (POSITIVE) this.ani.interval = 50; //The frame interval time of animation playback is 50 milliseconds } } The running effect is shown in the animation 2-16: (Animation 2-16) 3. Code to create Animation Sometimes, you don't want the animation node to be on the stage from the beginning, but add it when you need it. This needs to be created through code. In the Scene2D property settings panel, add a custom component script and create Animation in the code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Animation extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.setup(); } private setup(): void { var Animation: Laya.Animation = new Laya.Animation(); Animation.pos(200, 200); //Set node position Animation.source = \"resources/role.atlas\"; //Receive animation data source as atlas Animation.size(600, 275); //Set the node size Animation.interval = 100; //The frame interval time of animation playback is 100 milliseconds Animation.autoPlay = true; //Turn on automatic play Animation.wrapMode = 2; //The playback mode is pingpong playback mode (PINGPONG) this.owner.addChild(Animation) //Add node } } The effect is shown in animation 3-1: (Animation 3-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:13:28 "},"2D/displayObject/Text/readme.html":{"url":"2D/displayObject/Text/readme.html","title":"Text","keywords":"","body":"Text1. Using Text in LayaAir IDE1.1 Create Text1.2 Attribute introduction1.3 Syntax attribute1.4 Script control Text2. Code to create TextText Text inherits from Sprite and is the basic component of static text. Here we introduce the component properties specific to Text. 1. Using Text in LayaAir IDE 1.1 Create Text As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) 1.2 Attribute introduction In the IDE, after we add the Text component to the scene editing view area, the exclusive properties of the Text component in the properties panel are as shown below: (Figure 1-2) Below we introduce these properties respectively: attribute name Property description text The actual content of the text font Text font, for example: Microsoft YaHei, here you can manually enter commonly used fonts, or bitmap font fontSize Text font size, for example: 50, directly fill in the positive integer color For the color of the text, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color style Whether \"B\" (bold) is bold, whether \"I\" (italic) is italic, whether \"U\" is underlined syntax Multi-style mixing, supporting part of HTML syntax and UBB syntax. You can also check the template to be able to use variables in strings align Alignment, horizontal alignment (align) is left (aligned to the left), center (aligned to the center), right (aligned to the right); vertical alignment (valign) is top (aligned to the top), middle (aligned to the center), bottom (bottom alignment) bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color borderColor Text border color. After checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color overflow Text overflow processing, there are five modes. visible: Default mode, no cropping is performed. hidden: Do not display characters beyond the text field. scroll: does not display character pixels outside the text area, and supports the scroll interface. See Section 1.4 for details. shrink: When the text exceeds the text area, the text shrinks as a whole to fit in the text box. ellipsis (display ellipsis): When the text field is exceeded, the text is truncated and an ellipsis is displayed at the end of the text becomeWrap Whether to automatically wrap lines, a Boolean option, the default is false, select true to enable automatic line wrapping leading Vertical line spacing, when automatic word wrapping is turned on, it is effective when the text content has multiple lines. The spacing is in pixels, just enter a positive integer padding Text margin, in pixels, consisting of 4 integer values. \"U\" represents the distance from the upper border, \"R\" represents the distance from the right border, \"D\" represents the distance from the bottom border, and \"L\" represents the distance from the left border underlineColor Underline color, you can enter the color value directly, for example: #ffffff, or you can click the color picker on the right side of the input bar to select the color stroke Stroke width, range is 0~100 strokecolor Stroke color, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color The above attributes are relatively easy to understand. Developers only need to adjust the parameters to see the corresponding effects in the IDE. The following only introduces the \"syntax\" attribute in detail. 1.3 Syntax attribute 1.3.1 HTML and UBB If HTML is checked, some HTML syntax is supported; if UBB is checked, UBB syntax is supported, and UBB syntax is more concise than HTML; if both are checked, both syntaxes are supported. The supported UBB syntax is shown in the following table: Grammatical structure Sample code Statement description [img]image_url[/img] [img]atlas/comp/image.png[/img] Show a picture [url=link_href]text[/url] [url='www.layabox.com']Layabox[/url] Display a hyperlink [b]text[/b] [b]These words are in bold[/b] Set text to bold [i]text[/i] [i]These words are in italics[/i] Set the file to italic [u]text[/u] [u]These words are underlined[/u] Set text underline [color=#FFFFFF]text[/color] [color=#FF0000]This is red text[/color] Set text color [size=10]text[/size] [size=60]This is a word with a font size of 60[/size] Set the font size of the text UBB supports nesting between tags. Multiple tags in the above table can be nested. For example, [color=#FF0000][size=60] red words with size 60[/size] [/color ]. The supported HTML syntax is shown in the following table: Grammatical structure Sample code Statement description Text This is bold Define bold text Text This is italics Define italics Text This is underlined text Define underline Text1 Text2 Text3 Apple Banana Orange definition list Displaying a picture is okay Specify image size using percentages link text Laya Box Show a hyperlink Text Outermost layer of text div container tag Text Multiple spans will not wrap automatically unless the width limit is reached Inline elements Text Lines will be automatically wrapped between multiple p tags, and each complete p tag is a separate paragraph Paragraph Text1Text2 Line breakThe following line breaks line feed &nbsp; Leave a blank space here space Let’s look at a specific example, as shown in Figure 1-3. After checking HTML and UBB, you can enter grammatical statements in the Text attribute: (Figure 1-3) The sample sentences entered in Text are as follows: [url='www.layabox.com']LayaBox[/url] [size=60]text[/size] [color=#FF0000]text[/color] [u]text[/u] [color=#FF0000][size=60]text[/size][/color] The above six statements respectively correspond to the six effects shown in Figure 1-3: loading images, displaying links, font size 60, font color red, underline, and nesting (size and color). There does not need to be a blank line between each statement. There are blank lines in the example to facilitate observation of the effect. 1.3.2 Template The \"syntax\" attribute can also check the template option. After checking, you can use variables in strings. For example, enter Text{n=100} in the Text attribute, and the effect is as shown in Figure 1-4: (Figure 1-4) The variable n can also be a string. For example, if you enter Text{n=Hello}, the displayed effect is as shown in Figure 1-5. Of course, this variable does not necessarily have to be n, developers can customize the variable name. (Figure 1-5) You can also use the setVar method to dynamically adjust variable n in the code. You can combine it with the script control in Section 1.3 and enter the following code in the script: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Text }) txt: Laya.Text; constructor() { super(); } onAwake(): void { this.txt.text = \"Page {n=1}\"; //Display the initialization content of the text } onStart(): void { let page: number = 1; Laya.timer.frameLoop(10, this, () => { page += 1; //In the timer, let the variable page increase by 1 each time this.txt.setVar(\"n\", page); //Use the setVar method to dynamically change the value of the variable n in the text. }); } } The effect is shown in the animation 1-6: (Animation 1-6) Note: Variable n can also be text obtained from a .json file. Developers can write a .json file themselves, then load it in the script, and finally use the setVar method to assign a value to variable n. A common situation in games is that, as shown in Figure 1-7, when each player enters the game, they will encounter a dialogue, and only the character names of different players are different. Then, after using the text template function, there is no need to modify the text as a whole, and you can directly change the variables in the text template. Make dynamic changes of local text easier to use. (Figure 1-7) 1.4 Script control Text In the Scene2D property settings panel, add a custom component script. Then, drag Text into its exposed property entry. Here is a sample code to implement script control Text: const { regClass, property } = Laya; @regClass() export class TextControl extends Laya.Script { //declare owner : Laya.Sprite3D; @property( { type : Laya.Text } ) public txt: Laya.Text; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.txt.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //position this.txt.size(500, 30); //Size this.txt.pivot(this.txt.width/2, this.txt.height/2); //pivot point this.txt.text = \"Hello everyone, welcome to all developers to use LayaAir IDE, here is the text content of Text, you can debug based on this text\"; //Text content this.txt.font = \"宋体\"; //Font this.txt.fontSize = 50; //Font size this.txt.color = \"#ff0000\"; //Font color this.txt.bold = true; //bold this.txt.italic = true; //italic this.txt.underline = true; //underline this.txt.underlineColor = \"#ff0000\"; //Underline color this.txt.stroke = 5; //stroke width this.txt.strokeColor = \"#000000\" ; //Stroke color this.txt.wordWrap = true; //Automatically wrap lines this.txt.leading = 20; //Vertical line spacing // this.txt.padding = [10, 10, 10, 10]; //Text margins this.txt.align = \"center\"; //Horizontal alignment this.txt.valign = \"top\"; //Vertical alignment this.txt.overflow = \"visible\"; //Text overflow } } Let’s look at another example. This is about the scrolling parameter in the overflow attribute. If the text exceeds the text box, set its overflow attribute to scroll, then you can add the following code to display the exceeded text by dragging the mouse: const { regClass, property } = Laya; let prevX = 0; let prevY = 0; @regClass() export class UI_Text extends Laya.Script { constructor() { super(); } @property({ type: Laya.Text }) txt: Laya.Text; onAwake(): void { this.txt.text = \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\\n\" + \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\\n\" + \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\\n\" + \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\\n\" + \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\\n\" + \"Layabox is an HTML5 engine technology provider and an excellent game publisher, providing HTML5 development technology solutions for AS/JS/TS developers!\"; this.txt.fontSize = 35; this.txt.size(400,150); this.txt.borderColor = \"#fa1515\"; this.txt.overflow = \"scroll\"; this.txt.on(Laya.Event.MOUSE_DOWN, this, this.startScrollText); } /* Start scrolling text */ startScrollText() { prevX = this.txt.mouseX; prevY = this.txt.mouseY; Laya.stage.on(Laya.Event.MOUSE_MOVE, this, this.scrollText); Laya.stage.on(Laya.Event.MOUSE_UP, this, this.finishScrollText); } /* Stop scrolling text */ finishScrollText() { Laya.stage.off(Laya.Event.MOUSE_MOVE, this, this.scrollText); Laya.stage.off(Laya.Event.MOUSE_UP, this, this.finishScrollText); } /* Mouse scroll text */ scrollText() { let nowX = this.txt.mouseX; let nowY = this.txt.mouseY; this.txt.scrollX += prevX - nowX; //Horizontal scroll distance this.txt.scrollY += prevY - nowY; //vertical horizontal scrolling distance prevX = nowX;//After the mouse moves, return to the original position prevY = newY; } } The effect is as follows: (Animation 1-8) This example shows that scrolling is different from hiding in that it does not crop the text that exceeds the text box. 2. Code to create Text Sometimes, you don't want the Text node to be on the stage from the beginning, but add it when you need it. This needs to be created through code. In the property settings panel of Scene2D, add a custom component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { let txt = new Laya.Text(); //Add to stage Laya.stage.addChild(txt); txt.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //position txt.size(500, 30); //size txt.pivot(txt.width/2, txt.height/2); //Pivot point txt.text = \"Hello everyone, developers are welcome to use LayaAir IDE. Here is the text content of Text. This method is to create Text with code\"; //Text content txt.wordWrap = true; //Automatically wrap lines } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:37:52 "},"2D/displayObject/SoundNode/readme.html":{"url":"2D/displayObject/SoundNode/readme.html","title":"Sound Node","keywords":"","body":"Audio node (SoundNode)1. Using audio nodes in LayaAir IDE1.1 Create SoundNode1.2 Attribute introduction1.3 Script control SoundNode2. Code to create SoundNodeAudio node (SoundNode) 1. Using audio nodes in LayaAir IDE 1.1 Create SoundNode As shown in Figure 1-1, you can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) 1.2 Attribute introduction In the IDE, after adding the SoundNode node to the view area of ​​the scene editor, the exclusive properties of the SoundNode in the property panel are as shown below: (Figure 1-2) These properties are introduced below: Attribute name Attribute description Source Add audio file source IsMusic Whether it is background music. After checking, the current audio is background music. If there are two audios with IsMusic checked, they cannot be played at the same time, only one can be played. If unchecked, the current audio file can be played simultaneously with background music and other audio Loop The number of times to loop. Set to 0, it is an endless loop; set to 1, it only plays once AutoPlay Whether to automatically play when running 1.3 Script control SoundNode In the Scene2D property settings panel, add a custom component script. Then, drag the SoundNode into its exposed property entry. Here is a sample code to implement script control of SoundNode: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.SoundNode }) public sound: Laya.SoundNode; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.sound.source = \"resources/sound.wav\"; //Audio path this.sound.loop = 0; //Loop times setting should be placed before autoPlay parameter setting this.sound.autoPlay = true; //Auto play this.sound.isMusic = false; //Whether it is background music } } 2. Code to create SoundNode The SoundNode node only has sound effects at runtime. If you don't want to add and drag it to the property entrance exposed by the decorator in the IDE and do such a cumbersome operation, you can create it through code. In the property settings panel of Scene2D, add a custom component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { let sound = new Laya.SoundNode(); //Add to stage Laya.stage.addChild(sound); sound.source = \"resources/sound.wav\"; //Audio path sound.loop = 0; //Loop times setting should be placed before autoPlay parameter setting sound.autoPlay = true; //Auto play sound.isMusic = false; //Whether it is background music } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:27:38 "},"2D/displayObject/VideoNode/readme.html":{"url":"2D/displayObject/VideoNode/readme.html","title":"Video Node","keywords":"","body":"Video node (VideoNode)1. Using video nodes in LayaAir IDE1.1 Create VideoNode1.2 Attribute introduction1.3 Script control VideoNode2. Code to create VideoNodeVideo node (VideoNode) 1. Using video nodes in LayaAir IDE 1.1 Create VideoNode As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) 1.2 Attribute introduction In the IDE, after adding the VideoNode node to the view area of ​​the scene editor, the exclusive properties of VideoNode in the properties panel are as shown below: (Figure 1-2) It has only one Source property, just add the video file to Source. 1.3 Script control VideoNode In Section 1.2, after adding a video file to Source, it cannot be played automatically and needs to be controlled with code. In the Scene2D property settings panel, add a custom component script. Then, drag the VideoNode into its exposed property entry. Here is a sample code to implement script control of VideoNode: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.VideoNode }) public video: Laya.VideoNode; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Mouse click triggers playback Laya.stage.on(Laya.Event.MOUSE_DOWN, () => { Laya.loader.load(\"resources/layaAir.mp4\").then(() => { this.video.play(); //Play video }); }) } } If running in LayaAir IDE, VideoNode does not need to trigger playback through events. But in Chrome, autoplay only allows silent autoplay. Allow sounds to play automatically only after user interaction (click, double click, etc.). 2. Code to create VideoNode If you don't want the VideoNode node to be on the stage from the beginning, but add it when you need it, you need to create it through code. In the property settings panel of Scene2D, add a custom component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { let video = new Laya.VideoNode; //Add to stage Laya.stage.addChild(video); video.pos(200,200); //Set the position video.source = \"resources/layaAir.mp4\"; //Set the video source file video.play(); //Start playing } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:39:10 "},"IDE/uiEditor/uiComponent/readme.html":{"url":"IDE/uiEditor/uiComponent/readme.html","title":"UIComponent","keywords":"","body":"Detailed explanation of UI components1. What are UI components?1.1 Basic UI components1.2 Container component1.3 Pop-up view component2. Creation of UI components2.1 Use components directly2.2 Right-click menu2.3 Directly recognized by IDE through component resource naming rules2.4 Creation and deletion of container components3. Relative layoutDetailed explanation of UI components Author: Charley UI components are the basic components in 2D editing. The editing of the 2D UI interface we develop daily is based on UI components. 1. What are UI components? From the structure of the engine class, the UIComponent class is the base class of UI components, which means that UI components have one thing in common, they are all components implemented by inheriting from the UIComponent class. UI components are divided into basic UI components and container UI components. The easier way to understand and identify is that Box and those inherited from Box are container components. Others are basic UI components. 1.1 Basic UI components There are 17 basic UI component display objects in total, which are directly or indirectly inherited from UIComponent, as shown in the highlighted part of Figure 1-1. (Picture 1-1) 1.2 Container component There are 9 container objects in total including the components inherited from Box and the Box container itself. As shown in the highlighted part of Figure 1-2. (Figure 1-2) These containers are meaningless on their own. They must include basic UI components as child nodes to make the components fully functional. For example, List must have a basic UI component as the rendering unit of the list, and a radio group (RadioGroup) is a container for multiple radio components. 1.3 Pop-up view component From the structure of the engine class, the pop-up view component Dialog does not belong to the UI component. Its inheritance relationship is shown in Figure 1-3. (Figure 1-3) This component is generally used for pop-up panels, is closely related to scene management, and is part of the UI widgets, so it is no longer listed as a separate category, only an explanation is given here. 2. Creation of UI components There are three ways to create UI components: drag and drop UI components from the Widgets panel, create them from the right-click menu of the Hierarchy panel, name the resources through the component resource naming rules, and then directly recognize them by the IDE. . 2.1 Use components directly The Widgets panel includes basic nodes and UI components, which can be directly dragged into the hierarchy panel or scene editing window. The effect is shown in the animation 2-1. (Animation 2-1) 2.2 Right-click menu Under the 2D node of the Hierarchy panel, you can also directly create UI components in the right-click menu, as shown in Figure 2-2. (Figure 2-2) 2.3 Directly recognized by IDE through component resource naming rules For some commonly used UI components, the LayaAir engine and IDE provide resource naming rules. When the image resource file is named according to the LayaAir engine UI component naming rules, it will be directly recognized by the IDE as a basic UI component. There are two types of naming for component resources: One type is that a resource corresponds to a regular resource of a UI component, for example, img_layabox.png, which will be recognized as an Image component. The other type is a combination of multiple resources corresponding to one UI component. For example, progress_loading.png and progress_loading$bar.png are combined to form a progress component. progress_loading.png is the component name and is the background of the progress bar. Resources, another one with a $bar after progress_loading is the progress resource of the progress bar. To summarize the above, we will find two rules: No matter what kind of resource it is, the underscore _ is preceded by the component rule name and must be placed at the beginning of the file name. Combined resources, after the main resource name, separated by the dollar sign $, have an auxiliary identification name to facilitate identification by the IDE and engine. The general resource naming rules are as follows: component name Chinese component name Resource file name prefix Resource file name prefix abbreviation Image Image image_ img_ Button button button_ btn_ ComboBox Drop-down box comboBox_ combo_ TextInput Text input textInput_ input_ TextArea Text area textArea_ area_ CheckBox Multiple check box checkBox_ check_ Label display text label_ No abbreviation RadioGroup Radio group radioGroup_ No abbreviation Radio radio button radio_ No abbreviation Tab Navigation tab group tab_ No abbreviation Clip bitmap slice clip_ No abbreviation FontClip Bitmap font slice fontClip_ No abbreviation Resource prefixes are not case sensitive The naming rules for combined resources are as follows: component name Chinese component name Resource file name prefix Resource file name prefix abbreviation Auxiliary identification name VScrollBar Vertical scroll bar vscrollbar_ vscroll_ Vertical sliding bar $bar, up click button $up, down click button $down HScrollBar Horizontal scroll bar hscrollbar_ hscroll_ Horizontal sliding bar $bar, left-click button $up, right-click button $down ProgressBar Progress bar progressbar_ progress_ Progress bar $bar VSlider Vertical slider vslider_ No abbreviation Vertical swipe button $bar, progress bar resource $progress (optional) HSlider Horizontal slider hslider_ No abbreviation Horizontal swipe button $bar, progress bar resource $progress (optional) Resource prefixes are not case sensitive Example description: Vertical scroll bar aa, composed of four resource files. They are vscroll_aa.png, vscroll_aa$bar.png, vsroll_aa$up.png, vscroll_aa$down.png respectively. The progress bar bb is composed of two resource files. They are progress_bb.png, progress_bb$bar.png respectively. Horizontal sliding bar cc, composed of two or three resource files. They are hslider_cc.png, hslider_cc$bar.png, hslider_cc$progress.png (optional). If the progress bar resource hslider_cc$progress.png is missing, an error will not be reported, but the progress will not be displayed. 2.4 Creation and deletion of container components After understanding the resource naming rules, I found that in addition to the RadioGroup and Tab components inherited from the UI group (UIGroup), they can be identified through the naming of resource prefix rules. Other container components do not support direct identification and creation through resource names. In addition to creating using methods 2.1 and 2.2, you can also convert one or more selected basic components into container components in the IDE using the Ctrl+B shortcut key. If you no longer want the container component, you can also use Ctrl+U to deactivate the currently selected container. Just have an impression here. When introducing specific container components, the creation method and process will also be described in detail. 3. Relative layout Relative layout is a unique attribute of UI components. As shown in Figure 3-1, every UI component has such relative layout attributes. However, basic display objects such as Sprite do not have relative layout, only absolute layout. (Figure 3-1) In a relative layout, UI components (such as buttons, text boxes, etc.) are positioned relative to their parent nodes. This layout brings great flexibility and ensures consistent UI layout across different screen sizes and orientations. At this point, we have a basic understanding of UI components, and we will start to introduce all UI components in detail. In order to avoid the document title being too long, UI components are classified and introduced according to the characteristics of use, not according to the inheritance relationship of component classes. Next, click on the UI component document through the left navigation to learn more~ Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:28:02 "},"IDE/uiEditor/uiComponent/Image/readme.html":{"url":"IDE/uiEditor/uiComponent/Image/readme.html","title":"Image","keywords":"","body":"Image component (Image)1. Create Image component through LayaAir IDE1.1 Create image1.2 Common attributes1.3 Script control Image2. Create Image component through codeImage component (Image) 1. Create Image component through LayaAir IDE 1.1 Create image Image is the most common component for displaying images in UI, and is used to display bitmap images. You can set the skin property of the Image component to change the image rendered by the Image component. The Image component supports nine-square data setting, which is used to achieve the effect of image display without distortion after image enlargement. For the script interface of the Image component, please refer to Image API. As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) After the Image component is dragged and dropped into the editing area, the display effect is shown in Figure 1-2: (Figure 1-2) 1.2 Common attributes The unique properties of the Image component are as follows: (Figure 1-3) Properties Function description skin The texture of the image component requires adding bitmap resources. use source size Use the original size of the bitmap resource. sizeGrid Valid scaling grid data of the bitmap (nine-square grid information): top margin, right margin, bottom margin, left margin, whether to repeat filling. color Change picture color. Group Load groups. After setting, resources can be managed by groups. Here is a detailed explanation of the settings of the Nine Palace Grid. Suppose there is a bitmap, as shown in Figure 1-4. Its border color exactly meets the requirements of a pop-up window (this is just an example, the specific color matching should be selected according to the needs), but the length of the picture is too short. To do The pop-up window needs to be elongated. (Figure 1-4) The effect after stretching is shown in Figure 1-5. You can see that the black border will be stretched accordingly. (Figure 1-5) If you only want to enlarge the red area and keep the black border at its original thickness, then you need to use sizeGrid. The specific settings are shown in the animation 1-6. Finally, you can see that the thickness of the enlarged pop-up window border remains unchanged, and the red part in the middle is the effective zoom area. (Animation 1-6) Repeat filling means that if checked, when the image is enlarged, the effective zoom area will repeatedly fill the enlarged area without enlarging it. The effect is shown in Figure 1-7. (Figure 1-7) 1.3 Script control Image Sometimes, to set Image-related properties through code, you need to use a script. In the Scene2D property settings panel, add a custom component script. Then, drag the Image component into its exposed property entry. Here is a sample code to implement script control of Image: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Image }) public img: Laya.Image; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.img.skin = \"resources/layaAir.png\";//Set the skin this.img.useSourceSize = true;//Set the image size to the source size this.img.color = \"#0000FF\";//Set the color to blue } } 2. Create Image component through code Sometimes, you don't want the image component to be on the stage from the beginning, but add it when you need it. This needs to be created through code. In the property settings panel of Scene2D, add a custom component script and create the Image in the code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Image extends Laya.Script { constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.setup(); } private setup(): void { let img: Laya.Image = new Laya.Image(\"resources/layaAir.png\"); img.pos(165, 62.5); this.owner.addChild(img); } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 12:00:17 "},"IDE/uiEditor/uiComponent/Label/readme.html":{"url":"IDE/uiEditor/uiComponent/Label/readme.html","title":"Label","keywords":"","body":"Display text component (Label)1. Create Label component through LayaAir IDE1.1 Create Label1.2 Label attribute1.3 Script control Label2. Create Label component through codeDisplay text component (Label) 1. Create Label component through LayaAir IDE The Label component is used to display a piece of text. For the script interface of Label component, please refer to Label API. 1.1 Create Label As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) After dragging the Label component into the editing area and setting the value of the text attribute to LayaAir IDE, the display effect is as follows: (Figure 1-2) 1.2 Label attribute (Figure 1-3) Properties Function description text The actual content of the text font The font name of the text, for example: Microsoft YaHei, here you can manually enter commonly used fonts, or it can be bitmap font fontSize Text font size, for example: 50, directly fill in the positive integer color For the color of the text, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color fit content No (\"no\"): No operation; Height and width (\"yes\"): The Label border can automatically adjust the height and width to the appropriate size according to the text size and quantity; Height (\"height\"): The Label border can only be automatically adjusted height style Whether \"B\" (bold) is bold, whether \"I\" (italic) is italic, whether \"U\" is underlined syntax Multi-style mixed arrangement, supports some HTML syntax and UBB syntax. You can also check the template to be able to use variables in strings align Alignment, horizontal alignment (align) is left (aligned to the left), center (aligned to the center), right (aligned to the right); vertical alignment (valign) is top (aligned to the top), middle (aligned to the center), bottom (bottom alignment) bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color bordercolor Text border color. After checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color overflow Text overflow processing, there are five modes. visible: Default mode, no cropping is performed. hidden: Do not display characters beyond the text field. scroll: does not display character pixels outside the text area, and supports the scroll interface. shrink: When the text exceeds the text area, the text shrinks as a whole to fit in the text box. ellipsis (display ellipsis): When the text field is exceeded, the text is truncated and an ellipsis is displayed at the end of the text becomeWrap Whether to automatically wrap lines, a Boolean option, the default is false, select true to enable automatic line wrapping leading Vertical line spacing, when automatic word wrapping is turned on, it is effective when the text content has multiple lines. The spacing is in pixels, just enter a positive integer padding Text margin, in pixels, consisting of 4 integer values. \"U\" represents the distance from the top border, \"R\" represents the distance from the right border, \"D\" represents the distance from the bottom border, and \"L\" represents the distance from the left border underlinecolor Underline color, you can enter the color value directly, for example: #ffffff, or you can click the color picker on the right side of the input bar to select the color stroke Stroke width, range is 0~100 strokeColor For the stroke color of text, you can enter the color value directly, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color 1.3 Script control Label In the Scene2D property settings panel, add a custom component script. Then, drag the Label into its exposed property entry. Here is a sample code to implement script control of Label: const { regClass, property } = Laya; @regClass() export class LabelControl extends Laya.Script { //declare owner : Laya.Sprite3D; @property( { type : Laya.Label } ) public lab: Laya.Label; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.lab.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Position this.lab.size(500, 30); //Size this.lab.pivot(this.lab.width/2, this.lab.height/2); //Pivot Point this.lab.text = \"Hello everyone, welcome to LayaAir IDE\"; //Text content this.lab.font = \"宋体\"; //Font this.lab.fontSize = 50; //Font size this.lab.color = \"#ff0000\"; //Font color this.lab.bold = true; //bold this.lab.italic = true; //italic this.lab.underline = true; //underline this.lab.underlineColor = \"#ff0000\"; //Underline color this.lab.stroke = 5; //Stroke width this.lab.strokeColor = \"#000000\" ; //Stroke color this.lab.wordWrap = true; //Automatically wrap lines this.lab.leading = 10; //vertical line spacing this.lab.align = \"left\"; //Horizontal alignment this.lab.valign = \"top\"; //Vertical alignment this.lab.overflow = \"visible\"; //Text overflow // this.lab.fitContent = \"yes\"; //Adaptive size this.lab.bgColor = \"#19a4f1\"; //Background color this.lab.borderColor = \"#f6ff03\" //Border color } } 2. Create Label component through code When developing a project, sometimes I don't want the Label to be on the stage at the beginning, but add it when it is needed. This needs to be created through code. In the property setting panel of Scene2D, add a custom component script, create the UI_Label class, and create the Label through code. Its other properties can also be set through code. The following sample code demonstrates how to create Labels of different skins (styles) through code. Developers can set Labels through code to create text effects that meet their own needs. Sample code: const { regClass, property } = Laya; const Label = Laya.Label; @regClass() export class UI_Label extends Laya.Script { constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.setup(); } private setup(): void { this.createLabel(\"#FFFFFF\", null).pos(30, 50); this.createLabel(\"#00FFFF\", null).pos(290, 50); this.createLabel(\"#FFFF00\", \"#FFFFFF\").pos(30, 100); this.createLabel(\"#000000\", \"#FFFFFF\").pos(290, 100); this.createLabel(\"#FFFFFF\", \"#00FFFF\").pos(30, 150); this.createLabel(\"#0080FF\", \"#00FFFF\").pos(290, 150); } private createLabel(color: string, strokeColor: string): Laya.Label { const STROKE_WIDTH: number = 4; var label: Laya.Label = new Label(); label.font = \"Microsoft YaHei\"; label.text = \"SAMPLE DEMO\"; label.fontSize = 30; label.color = color; if (strokeColor) { label.stroke = STROKE_WIDTH; label.strokeColor = strokeColor; } this.owner.addChild(label); return label; } } Effect preview: (Figure 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 12:02:41 "},"IDE/uiEditor/uiComponent/TextInput/readme.html":{"url":"IDE/uiEditor/uiComponent/TextInput/readme.html","title":"TextInput","keywords":"","body":"Input text component (TextInput)1. Using TextInput in LayaAir IDE1.1 Create TextInput1.2 TextInput property1.3 Script control TextInput2. Textinput code creationInput text component (TextInput) 1. Using TextInput in LayaAir IDE The text input box is a UI component often used in games. TextInput can be used whenever input is required. For the API of TextInput class, please refer to here. 1.1 Create TextInput As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) 1.2 TextInput property (Figure 1-2) Properties Function description text Initial displayed text content font The font name of the text, for example: Microsoft YaHei, here you can manually enter commonly used fonts, or it can be bitmap font fontSize Text font size, for example: 50, directly fill in the positive integer color For the color of the text, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color style Whether \"B\" (bold) is bold, whether \"I\" (italic) is italic, whether \"U\" is underlined syntax Multi-style mixed arrangement, supports some HTML syntax and UBB syntax. You can also check the template to be able to use variables in strings align Alignment, horizontal alignment (align) is left (aligned to the left), center (aligned to the center), right (aligned to the right); vertical alignment (valign) is top (aligned to the top), middle (aligned to the center), bottom (bottom alignment) bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color bordercolor Text border color. After checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color overflow Text overflow processing, there are five modes. visible: No cropping is done. hidden: Do not display characters beyond the text field. scroll: Default mode, does not display character pixels outside the text area, and supports the scroll interface. shrink: When the text exceeds the text area, the text shrinks as a whole to fit in the text box. ellipsis (display ellipsis): When the text field is exceeded, the text is truncated and an ellipsis is displayed at the end of the text becomeWrap Whether to automatically wrap lines, a Boolean option, the default is false, select true to enable automatic line wrapping leading Vertical line spacing, when automatic word wrapping is turned on, it is effective when the text content has multiple lines. The spacing is in pixels, just enter a positive integer padding Text margin, in pixels, consisting of 4 integer values. \"U\" represents the distance from the upper border, \"R\" represents the distance from the right border, \"D\" represents the distance from the bottom border, and \"L\" represents the distance from the left border underlinecolor Underline color, you can enter the color value directly, for example: #ffffff, or you can click the color picker on the right side of the input bar to select the color stroke Stroke width, range is 0~100 strokeColor For the stroke color of text, you can enter the color value directly, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color skin Set the skin and select the corresponding image resource. The address representing the skin in the code, expressed as a string sizeGrid Valid scaling grid data for the background image. Data format: \"Top margin, right margin, bottom margin, left margin, whether to repeat filling (value is 0: no repeated filling, 1: repeated filling)\", separated by commas. For example: \"4,4,4,4,1\" type Input box types, there are thirteen types: text, password, email, url, number, range, date, month, week, time, dateime, dateime-local, search. The effect is equivalent to HTML's input maxchars Maximum number of characters, default is 100000. When setting the character limit, a value less than or equal to 0 will limit the number of characters to 100000 restrict limits the characters that can be entered. Only these characters can be entered in TextInput. Not recommended to be turned on, suitable for simple text, backslash is not supported prompt Prompt text before input promptcolor Prompt text color editable Set editable status, default is true multiline Whether it is a text field. A value of true indicates that it is a text field and can be entered in multiple lines. Otherwise, it is not a text field. Defaults to false 1.3 Script control TextInput In the Scene2D property settings panel, add a custom component script. Then, drag the TextInput into its exposed property entry. Here is a sample code to implement script control of TextInput: const { regClass, property } = Laya; @regClass() export class TextInputControl extends Laya.Script { //declare owner : Laya.Sprite3D; @property( { type : Laya.TextInput } ) public txtin: Laya.TextInput; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.txtin.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Position this.txtin.size(500, 60); //Size this.txtin.pivot(this.txtin.width/2, this.txtin.height/2); //Pivot Point this.txtin.font = \"宋体\"; //Font this.txtin.fontSize = 50; //Font size this.txtin.color = \"#ff0000\"; //Font color this.txtin.bold = true; //bold this.txtin.italic = true; //italic this.txtin.underline = true; //underline this.txtin.underlineColor = \"#ff0000\"; //Underline color this.txtin.stroke = 5; //stroke width this.txtin.strokeColor = \"#000000\" ; //Stroke color this.txtin.wordWrap = true; //Automatically wrap lines this.txtin.overflow = \"scroll\"; //Text overflow // this.txtin.skin = \"atlas/comp/textinput.png\"; //Skin this.txtin.bgColor = \"#19a4f1\"; //Background color this.txtin.borderColor = \"#f6ff03\" //Border color this.txtin.editable = true; //Editable state // this.txtin.type = \"password\"; //Input box type // this.txtin.maxChars = 5; //Maximum number of characters // this.txtin.restrict = \"12345\"; //Input restrictions // this.txtin.prompt = \"Please enter\"; //Input prompt // this.txtin.promptColor = \"#a9a9a9\"; //Prompt word color // this.txtin.multiline = true; //Text field } } (In order to prevent cluttered effects, part of the code in the sample code is commented out first. Developers can uncomment themselves to observe the effect) 2. Textinput code creation Sometimes, you don't want the Textinput component to be on the stage from the beginning, but to add it when you need it. This needs to be created through code. In the property settings panel of Scene2D, add a custom component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Input extends Laya.Script { private SPACING: number = 100; private Y_OFFSET: number = 50; private skins: any[]; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.skins = [\"resources/res/ui/input (1).png\", \"resources/res/ui/input (2).png\", \"resources/res/ui/input (3).png\", \"resources/res/ui/input (4).png\"]; Laya.loader.load(this.skins).then( ()=>{ this.onLoadComplete(); } ); } private onLoadComplete(): void { for (var i: number = 0; i (The image resources in the code are from the \"Engine API Usage Example\" project, developers can create and download them by themselves) operation result: (Figure 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:18:39 "},"IDE/uiEditor/uiComponent/TextArea/readme.html":{"url":"IDE/uiEditor/uiComponent/TextArea/readme.html","title":"TextArea","keywords":"","body":"Multi-line input text component (TextArea)1. Using TextArea in LayaAir IDE1.1 Create TextArea1.2 Introduction to TextArea properties1.3 Script control TextArea2. Create TextArea through codeMulti-line input text component (TextArea) Since TextArea inherits from TextInput, the two have too many similarities. This article only introduces the differences between the two. The points introduced by TextInput will not be explained in detail here. For details, please refer to TextArea API. 1. Using TextArea in LayaAir IDE 1.1 Create TextArea As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) 1.2 Introduction to TextArea properties (Figure 1-2) Properties: text, font, fontSize, color, style, syntax, align, bgColor, bordercolor, overflow, wordWrap (default is true), leading, padding, underlinecolor, stroke, strokeColor, skin, sizeGrid, type, maxchars, restrict, prompt, promptcolor, editable, multiline (default is true); The above properties have been listed in Input Text Component and will not be described in detail here. The differences are marked in parentheses. TextArea has more properties than TextInput as follows: Properties Function description vscrollbarskin Add vertical scrollbar skin hscrollbarskin Add horizontal scroll bar skin scrolltype The scrolling type of the text field needs to be used with the corresponding scroll bar skin. There are four types: none: no scrolling (default), horizontal: horizontal scrolling, vertical: vertical scrolling, both: both horizontal and vertical scrolling TextArea is a text field for multiple lines. The difference compared to TextInput is that it can add vertical scroll bar skin and horizontal scroll bar skin. The horizontal scrolling effect is shown in the animation 1-3, and the vertical scrolling effect is shown in the animation 1-4. (Animation 1-3) (Animation 1-4) 1.3 Script control TextArea const { regClass, property } = Laya; @regClass() export class TextAreaControl extends Laya.Script { //declare owner : Laya.Sprite3D; @property( { type : Laya.TextArea } ) public txtarea: Laya.TextArea; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.txtarea.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Position this.txtarea.size(500, 200); //Size this.txtarea.pivot(this.txtarea.width/2, this.txtarea.height/2); //Pivot Point this.txtarea.text = \"Hello everyone, developers are welcome to use LayaAir IDE. Here is the text content of TextArea. You can debug based on this text\"; this.txtarea.font = \"宋体\"; //Font this.txtarea.fontSize = 50; //Font size this.txtarea.color = \"#ff0000\"; //Font color this.txtarea.bold = true; //bold this.txtarea.italic = true; //italic this.txtarea.underline = true; //underline this.txtarea.underlineColor = \"#ff0000\"; //Underline color this.txtarea.stroke = 5; //stroke width this.txtarea.strokeColor = \"#000000\" ; //Stroke color this.txtarea.wordWrap = true; //Automatically wrap lines this.txtarea.overflow = \"scroll\"; //Text overflow this.txtarea.skin = \"atlas/comp/textarea.png\"; //Skin this.txtarea.borderColor = \"#f6ff03\" //Border color this.txtarea.scrollType = Laya.ScrollType.Vertical; //Scrolling method this.txtarea.vScrollBarSkin = \"atlas/comp/vscroll.png\"; //Scroll bar skin } } Developers should pay attention to the scrolling mode setting code: Laya.ScrollType.Vertical, which is vertical scrolling; Laya.ScrollType.Horizontal, which is horizontal scrolling. Different scrolling methods require setting corresponding scroll bar skins. 2. Create TextArea through code const { regClass, property } = Laya; @regClass() export class UI_TextArea extends Laya.Script { private skin: string = \"resources/res/ui/textarea.png\"; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { Laya.loader.load(this.skin).then( ()=>{ this.onLoadComplete(); } ); } private onLoadComplete(e: any = null): void { let ta: Laya.TextArea = new Laya.TextArea(\"\"); ta.skin = this.skin; ta.font = \"Arial\"; ta.fontSize = 18; ta.bold = true; ta.color = \"#3d3d3d\"; ta.pos(100, 15); ta.size(375, 355); ta.padding = \"70,8,8,8\"; this.owner.addChild(ta); } } (The image resources in the code are from the \"Engine API Usage Example\" project, developers can create and download them by themselves) operation result: (Figure 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:16:57 "},"IDE/uiEditor/uiComponent/Clip/readme.html":{"url":"IDE/uiEditor/uiComponent/Clip/readme.html","title":"Clip","keywords":"","body":"Bitmap slice component (Clip)1. Create Clip component through LayaAir IDE1.1 Create Clip1.2 Common properties of Clip component1.3 Script Control Clip2. Create Clip component through codeBitmap slice component (Clip) The Clip component can be used to play slice animation and display a certain frame of the slice animation. Clip can divide a picture according to the number of horizontal divisions ClipX, the number of vertical divisions ClipY, or the width of each slice ClipWidth and the height of each slice ClipHeight, from left to right, top to bottom. Combined into a slice animation. For the script interface of Clip, please refer to Clip API. 1. Create Clip component through LayaAir IDE 1.1 Create Clip As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) In the created project, LayaAir will come with a resource example of the Clip component (clip_num.png), as shown in Figure 1-2. (Figure 1-2) 1.2 Common properties of Clip component The unique properties of the Clip component are as follows: (Figure 1-3) Properties Function Description autoPlay Boolean value, indicating whether to automatically play the current slice animation. clipWidth The width of each slice when splitting image resources horizontally. (Priority higher than clipX) clipHeight The height of each slice when splitting image resources vertically. (Priority higher than clipY) clipX When splitting image resources horizontally, the number of equal-width cuts. clipY When splitting image resources vertically, the number of equal-height cuts. index The slice animation currently displays the animation frame index. interval Playback time interval of slice animation. skin Texture for slice animation. sizeGrid Valid grid data of image resources (nine-square grid data). group Load groups. After setting, resources can be managed by groups. Here we use the resources that come with LayaAir to demonstrate the effects of clipWidth and clipX. As shown in the animation 1-4, the width of each number is 26, so set clipWidth to 26. At this time, adjusting the value of clipX will be invalid. (Animation 1-4) If clipWidth is not set and clipX is set to 10, ten numbers will be equally divided. The effect is as follows: (Figure 1-5) 1.3 Script Control Clip Sometimes, to set Clip-related properties through code, you need to use a script. In the Scene2D property settings panel, add a custom component script. Then, drag the Clip component into its exposed property entry. Here is a sample code to implement script control Clip: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Clip }) public clip: Laya.Clip; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.clip.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); // Position this.clip.skin = \"atlas/comp/clip_num.png\"; // Skin this.clip.interval = 1000; // The playback time interval of the slice animation is 1000 milliseconds this.clip.clipX = 10; // Number of slices on the x-axis this.clip.autoPlay = true; //Animation plays automatically } } 2. Create Clip component through code When writing code, it is inevitable to control the UI through code, create the UI_Clip class, and set Clip-related properties through code. Create a counter through code and run the sample effect: (Animation 2-1) Example description: (Figure 2-2) Other properties of Clip can also be set through code. The above example demonstrates how to obtain the updated clip.clipX slice every second through a timer, and realize the function of the timer by updating the number every second. Interested readers can set the Clip by themselves through code. , create a Clip that meets the needs of your project. Note: The texture type of the image resource needs to be set to \"Sprite Texture\". Sample code: const { regClass, property } = Laya; @regClass() export class UI_Clip extends Laya.Script { //The following resources are from \"Engine API Usage Example\" private buttonSkin: string = \"resources/res/ui/button-7.png\"; private clipSkin: string = \"resources/res/ui/num0-9.png\"; private bgSkin: string = \"resources/res/ui/coutDown.png\"; counter: any; controller: any; currFrame: any; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load([this.buttonSkin, this.clipSkin, this.bgSkin]).then( ()=>{ this.onSkinLoaded(); } ); } private onSkinLoaded(e: any = null): void { this.showBg(); this.createTimerAnimation(); this.showTotalSeconds(); this.createController(); } private showBg(): void { var bg: Laya.Image = new Laya.Image(this.bgSkin); bg.size(224, 302); bg.pos(Laya.stage.width - bg.width >> 1, Laya.stage.height - bg.height >> 1); this.owner.addChild(bg); } private createTimerAnimation(): void { this.counter = new Laya.Clip(this.clipSkin, 10, 1); this.counter.autoPlay = true; this.counter.interval = 1000; this.counter.x = (Laya.stage.width - this.counter.width) / 2 - 35; this.counter.y = (Laya.stage.height - this.counter.height) / 2 - 40; this.owner.addChild(this.counter); } private showTotalSeconds(): void { var clip: Laya.Clip = new Laya.Clip(this.clipSkin, 10, 1); clip.index = clip.clipX - 1; clip.pos(this.counter.x + 60, this.counter.y); this.owner.addChild(clip); } private createController(): void { this.controller = new Laya.Button(this.buttonSkin, \"Pause\"); this.controller.labelBold = true; this.controller.labelColors = \"#FFFFFF,#FFFFFF,#FFFFFF,#FFFFFF\"; this.controller.size(84, 30); this.controller.on('click', this, this.onClipSwitchState); this.controller.x = (Laya.stage.width - this.controller.width) / 2; this.controller.y = (Laya.stage.height - this.controller.height) / 2 + 110; this.owner.addChild(this.controller); } private onClipSwitchState(e: any = null): void { if (this.counter.isPlaying) { this.counter.stop(); this.currFrame = this.counter.index; this.controller.label = \"Play\"; } else { this.counter.play(); this.counter.index = this.currFrame; this.controller.label = \"Pause\"; } } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:47:58 "},"IDE/uiEditor/uiComponent/FontClip/readme.html":{"url":"IDE/uiEditor/uiComponent/FontClip/readme.html","title":"FontClip","keywords":"","body":"Font slice component (FontClip)1. Use LayaAir IDE to create FontClip1.1 Create FontClip1.2 Introduction to FontClip properties1.3 Script control FontClip2. Code to create FontClipFont slice component (FontClip) The FontClip component essentially cuts the bitmap proportionally from the direction. FontClip inherits from Clip. For the component script interface of FontClip, please refer to FontClip API. 1. Use LayaAir IDE to create FontClip 1.1 Create FontClip Creating FontClip is very simple and can be achieved through the visual operation of the IDE with just the mouse. As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) In LayaAir, it comes with a font slice image resource (fontClip.png), as shown in Figure 1-2. (Figure 1-2) 1.2 Introduction to FontClip properties The unique properties of FontClip are as follows: (Figure 1-3) Properties Function description skin The texture of the font slice component requires adding image resources. sizeGrid Valid scaling grid data (nine-square grid information) of the bitmap: top margin, right margin, bottom margin, left margin, whether to repeat filling. group Load groups. After setting, resources can be managed by groups. align There are three horizontal alignment methods. left: aligned to the left, center: aligned to the center, right: aligned to the right. sheet Bitmap content range. When the bitmap content has a line break, spaces need to be added at the line break position. value Bitmap digital content. spacex X direction item spacing, in pixels. spacey Y direction item interval, in pixels. direction Bitmap content arrangement direction, there are two options. horizontal: arranged in the horizontal direction, vertical: arranged in the vertical direction. FontClip is more suitable for font slicing than Clip, so it is called FontClip. FontClip is used more and more widely than Clip in games. FontClip is also recommended by us. FontClip will be used for some special texts or fonts. 1. How to use sheet and value attributes FontClip If the bitmap content is a graphic, it can be cut into equal parts into independent units and processed according to index. Demonstrate the use of the sheet attribute, as shown in Figure 1-4. The sheet value is filled in with the 15 characters shown in Figure 1-2 according to the bitmap content. The word \"sheep\" and the word \"monkey\" are divided into segments, so a space must be added between these two words to let the engine know that the bitmap text is arranged in multiple lines. Then enter the content you want to display in value to display it. (Figure 1-4) In short, the sheet is equivalent to a bitmap slicing template, and the value will be directly compared with the content in the sheet. The value is very convenient and flexible. 2. How to use SpaceX and SpaceY attributes SpaceX is used to adjust the interval in the X direction. It needs to be used in conjunction with Direction. As shown in Figure 1-5, set the Direction to horizontal. (Figure 1-5) SpaceY is used to adjust the interval in the Y direction. It needs to be used in conjunction with Direction. As shown in Figure 1-6, set the Direction to vertical. (Figure 1-6) 1.3 Script control FontClip In the Scene2D property settings panel, add a custom component script. Then, drag the FontClip into its exposed property entry. Here is a sample code to implement script control of FontClip: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property( { type : Laya.FontClip } ) public fontclp: Laya.FontClip; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.fontclp.pos(Laya.stage.width >> 1, Laya.stage.height >> 1); //Position this.fontclp.size(500, 60); //Size this.fontclp.pivot(this.fontclp.width/2, this.fontclp.height/2); //Pivot Point this.fontclp.skin = \"atlas/comp/fontClip_num.png\"; this.fontclp.sheet = \"0123456789\"; this.fontclp.value = \"5201314\"; this.fontclp.direction = \"horizontal\"; //Bitmap arrangement direction this.fontclp.spaceX = 50; //Horizontal spacing // this.fontclp.direction = \"vertical\"; //Bitmap arrangement direction // this.fontclp.spaceY = 10; //Vertical spacing } } 2. Code to create FontClip Sometimes, you don't want the FontClip component to be on the stage from the beginning, but add it when you need it. This needs to be created through code. In the property settings panel of Scene2D, add a custom component script and run the code example: (Figure 2-1) The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_FontClip extends Laya.Script { private TestClipNum: string = \"atlas/comp/fontClip_num.png\"; private _ClipNum: string = \"atlas/comp/fontClip_num.png\"; private _ClipNum1: string = \"atlas/comp/fontClip_num.png\"; private TestFontClip: string = \"atlas/comp/fontClip.png\"; private _FontClip: string = \"atlas/comp/fontClip.png\"; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load([this.TestClipNum, this.TestFontClip, this._ClipNum, this._FontClip, this._ClipNum1]).then( ()=>{ this.ShowContent(); } ); } private ShowContent(): void { var clipnum: Laya.FontClip = new Laya.FontClip(this._ClipNum); var fontClip: Laya.FontClip = new Laya.FontClip(this._FontClip); var testFontClip: Laya.FontClip = new Laya.FontClip(this.TestFontClip); var testClipNum: Laya.FontClip = new Laya.FontClip(this.TestClipNum); var clipnum1: Laya.FontClip = new Laya.FontClip(this._ClipNum1); clipnum.pos(240, 400); clipnum.size(250, 50); clipnum.sheet = \"0123456789\"; clipnum.value = \"114499\"; clipnum.spaceY = 10; testClipNum.pos(200, 300); testClipNum.sheet = \"0123456789\"; testClipNum.value = \"0123456789\"; clipnum1.pos(150, 100); clipnum1.direction = \"vertical\"; clipnum1.sheet = \"0123456789\"; clipnum1.value = \"223388\"; fontClip.pos(240, 200); fontClip.sheet = \"Happy Year of Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse and Goat, Monkey, Rooster, Dog and Pig\"; fontClip.value = \"Happy Year of the Pig\"; fontClip.spaceY = 10; testFontClip.pos(200, 100); testFontClip.sheet = \"Happy Year of Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse, Sheep, Monkey, Rooster, Dog and Pig\"; testFontClip.value = \"Happy Year of the Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse, Sheep, Monkey, Rooster, Dog and Pig\"; testFontClip.spaceY = 10; this.owner.addChild(clipnum); this.owner.addChild(fontClip); this.owner.addChild(testFontClip); this.owner.addChild(testClipNum); this.owner.addChild(clipnum1); } } Usually FontClip can already meet the basic needs of developers. If there are special circumstances, it can be achieved through BitmapFont bitmap font. For the content of bitmap fonts, please refer to \"Advanced Use of Text\". Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:53:47 "},"IDE/uiEditor/uiComponent/Button/readme.html":{"url":"IDE/uiEditor/uiComponent/Button/readme.html","title":"Button","keywords":"","body":"Button component (Button)1. Use Button component in LayaAir IDE1.1 Create Button component1.2 Button properties1.3 Script Control Button2. Button code creationButton component (Button) 1. Use Button component in LayaAir IDE The Button component is one of the most commonly used components and can display text labels, icons, or both at the same time. The button image (skin) resource naming in LayaAir IDE is usually prefixed with btn. For an introduction to the attribute interface of the Button component, please refer to Button API. 1.1 Create Button component It is very simple to create Button using LayaAir IDE. Through the visual operation of IDE, you can realize the creation and layout of components without any programming knowledge. This is also the recommended way to create components. As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) This process does not require any programming and can be completely left to the artist or planner to implement. This reduces communication costs with programmers and speeds up game development efficiency. 1.2 Button properties The unique properties of the Button component are as follows: (Figure 1-2) Properties Function description toggle Whether to switch the display state of the button. The default is false, and the button will return to its initial state directly after clicking it. When checked, it is true and you can click to switch the button display status. When the button component is clicked, the button will remain selected (continuously pressed) and can be restored by clicking again. state number The number of states of the button skin, supporting single-state (1), two-state (2) and three-state (3) buttons. selected Whether the button is selected, the default is false. After setting to true, the button will remain selected (continuously pressed) and will not change other states (unless the state is changed in code). skin Button skin texture resource. After setting, you need to set the stateNum skin state number according to the skin resource. sizeGrid Valid scaling grid data of the bitmap (nine-square grid information): top margin, right margin, bottom margin, left margin, whether to repeat filling. label The text label of the button. labelFont The font of the text label. labelSize The font size of the text label. labelBold Whether the text label is bold, the default is false. labelColors The color of the text label in each state when the mouse is released (up), when the mouse moves to the element (over), and when the mouse is pressed (down). labelAlign Horizontal alignment mode of text label: left, center, right, the default is center alignment. labelVAlign Vertical alignment mode of text label: top, middle, bottom, the default is center alignment. labelPadding Margins for text labels. Format: top margin, right margin, bottom margin, left margin. labelStroke The stroke width of the text label, in pixels. The default value is 0, which means no stroke. labelStrokeColor The color of the text label stroke, expressed as a string. The default value is #000000 (black). strokeColors After checking, you can set the stroke color of the text according to the status. It can be set in three states: when the mouse is released on the element (up), when the mouse moves to the element (over), and when the mouse is pressed (down). Different stroke colors can be set in the three states. The following will focus on the properties of the Button component that are difficult to understand through text. 1.2.1 Button skin (skin) The skin of the button is divided into single state (1), two states (2) and three states (3) due to different cutting methods. The state here refers to the state of the button skin. Three-state is often used in PC browsers, which divides skin pictures into three parts in equal proportions in the vertical direction. Figure 1-3 shows the button skin (button.png) that comes with LayaAir. From top to bottom: the status skin when the mouse bounces up or leaves, the status skin when the mouse passes by, and the status skin when the mouse is pressed and selected. status skin. (Figure 1-3) On mobile devices, only two states are usually used. The picture is cut into two parts in the vertical direction in equal proportions. The upper part is the state skin when the button is popped up or unselected, and the lower part is the skin when the button is selected and pressed. Status skin. Single-state buttons do not cut images. No matter what the state is, the button has only one skin and remains unchanged. 1.2.2 Specify the cutting state of the button skin (stateNum) The attribute value of stateNum determines the cutting method of the skin resource image. The default value is 3, which means that by default, you press the 3-state button to cut and divide it into 3 equal parts. If it is a two-state button, you need to set the attribute value of stateNum to 2 and cut it into two parts proportionally. The singleton button is set to 1 and no cutting is performed. What needs to be noted here is that the specified button state needs to correspond to the button skin. If it is a three-state button skin, stateNum is set to 2. After cutting, as shown in Figure 1-4, it is wrong. (Figure 1-4) 1.2.3 Set the text stroke color of the button according to the state (strokeColors) labelStrokeColor can set a uniform color for the text stroke of the button (the color is consistent in different states). The strokeColors property can set the stroke text color of the button according to different states. As shown in Figure 1-5, the sequence format for setting strokeColors colors is: upColor (the color of the pop-up or leaving state), overColor (the color of the passing state), downColor (the color of the pressed and selected states). (Figure 1-5) If you want to feel the change of stroke color more clearly, you can set the attribute values ​​such as button size, text label font size and stroke width to be larger. The effect is as shown in the animation 1-6. (Animation 1-6) 1.3 Script Control Button Sometimes, to set Button-related properties through code, you need to use scripts. In the Scene2D property settings panel, add a custom component script. Then, drag the Button component into its exposed property entry. Add the following sample code to the script file: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Button }) public btn: Laya.Button; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.btn.scale(5, 5); //Enlarge five times this.btn.skin = \"atlas/comp/button.png\"; //Skin this.btn.stateNum = 3; //Skin status this.btn.label = \"OK\"; //Text label this.btn.labelFont = \"宋体\"; //Text label font this.btn.labelSize = 20; //Text label font size this.btn.labelBold = true; //Text label bold this.btn.labelAlign = \"center\"; //The text label is horizontally aligned in the center this.btn.labelStroke = 3; //Text label font stroke width this.btn.labelStrokeColor = \"#ffffff\"; //Stroke color this.btn.strokeColors = \"#000000, #c6ff00, #001aff\"; //Stroke colors in each state this.btn.labelColors = \"#0100ff, #16fa0e, #ff0000\"; //Text color in each state // this.btn.toggle = true; //Whether to keep the click state // this.btn.selected = true; //Whether it is selected } } 2. Button code creation Creating a Button component using the LayaAir engine is relatively simple. It usually only requires a few steps, loading resources, creating a Button instance, adding the Button to the current scene, and finally setting the properties of the Button component. For specific implementation, please refer to the following code and comments: const { regClass, property } = Laya; @regClass() export class UI_Button extends Laya.Script { private COLUMNS: number = 2; private BUTTON_WIDTH: number = 147; private BUTTON_HEIGHT: number = 165 / 3; private HORIZONTAL_SPACING: number = 200; private VERTICAL_SPACING: number = 100; private xOffset: number; private yOffset: number; private skins: any[]; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //The following image resources are from the \"Engine API Usage Example\" project this.skins = [\"resources/res/ui/button-1.png\", \"resources/res/ui/button-2.png\", \"resources/res/ui/button-3.png\", \"resources/res/ui/button-4.png\", \"resources/res/ui/button-5.png\", \"resources/res/ui/button-6.png\"]; // Calculate the offset of Button to the center of the stage this.xOffset = (Laya.stage.width - this.HORIZONTAL_SPACING * (this.COLUMNS - 1) - this.BUTTON_WIDTH) / 2; this.yOffset = (Laya.stage.height - this.VERTICAL_SPACING * (this.skins.length / this.COLUMNS - 1) - this.BUTTON_HEIGHT) / 2; Laya.loader.load(this.skins).then(() => { this.onUIAssetsLoaded(); }); } private onUIAssetsLoaded(e: any = null): void { for (var i: number = 0, len: number = this.skins.length; i The running effect of the above code is shown in Figure 2-1: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:37:10 "},"IDE/uiEditor/uiComponent/scroll/readme.html":{"url":"IDE/uiEditor/uiComponent/scroll/readme.html","title":"scroll","keywords":"","body":"Scroll Bar ComponentScroll Bar Component Scroll bar components mainly include horizontal scroll bar and vertical scroll bar components Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:07:21 "},"IDE/uiEditor/uiComponent/HScrollBar/readme.html":{"url":"IDE/uiEditor/uiComponent/HScrollBar/readme.html","title":"HScrollBar","keywords":"","body":"Horizontal scroll bar component (HScrollBar)1. Create HScrollBar component through LayaAir IDE1.1 Create HScrollBar1.2 HScrollBar properties1.3 Script control HScrollBar2. Create HScrollBar component through codeHorizontal scroll bar component (HScrollBar) 1. Create HScrollBar component through LayaAir IDE The HScrollBar component is a horizontal scroll bar component. When there is too much data to fit in the display area, end users can use the HScrollBar component to control the portion of the data that is displayed. For the script interface of the HScrollBar component, please refer to HScrollBar API. 1.1 Create HScrollBar As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) The scroll bar consists of four parts: a track graph, a slider button, and two arrow buttons. The naming of the image resources of the HScrollBar component must comply with [Resource Naming Rules] (../readme.md). The resource examples provided by LayaAir are as follows: (Figure 1-2) Orbital diagram (Figure 1-3) Slider button (Figure 1-4) Arrow Button 1 (Figure 1-5) Arrow Button 2 The display effect after creating HScrollBar is as follows: (Figure 1-6) 1.2 HScrollBar properties The unique properties of HScrollBar are as follows: (Figure 1-7) Properties Function description skin The image resource address of the scroll bar track diagram. sizeGrid Valid scaling grid data (nine-square grid data) of the scroll bar track map resource. max represents the maximum scroll position of the slider (the value when the slider is at the far right). min represents the minimum scroll position of the slider (the value when the slider is at the far left). scrollSize Scroll amount on button click. The amount by which the scroll bar's value changes (the amount the slider moves) each time the scroll bar arrow button is clicked. value The current progress value of the scroll bar (current position of the slider). mouseWheelEnable Whether to enable mouse wheel scrolling, the default value is true. This property sets the scroll object target to be valid later. touchScrollEnable Whether to enable touch scrolling, the default value is true. This property sets the scroll object target and is valid in the future. hide Whether to hide the scroll bar, the default is false. When set to true, the scroll bar will not be displayed, but normal scrolling will be possible. autoHide Whether to automatically hide the scroll bar, the default value is false. After setting to true, the scroll bar will be hidden when scrolling is not required, and the scroll bar will be displayed when the content needs to be scrolled. showButtons Whether to display arrow buttons, the default value is true. When set to false, the arrow buttons will not be displayed. rollRatio Rolling attenuation coefficient, default is 0.97. elasticDistance The limit distance of the rubber band effect. 0 means there is no rubber band effect. elasticBackTime Rubber band rebound time, in milliseconds. The following shows the effects of some scroll bar property settings: After setting the value of the attribute max of HScrollBar to 10, the value of the attribute min to 0, and the value of the attribute value to 3, the display effect is as follows: (Figure 1-8) At runtime, you can control the scroll bar's value by dragging the slider or clicking the arrow buttons. Set the property scrollSize to 1, then every time you click the scroll bar arrow button, the value of the scroll bar changes by 1. The effect is as follows: (Animation 1-9) After setting the mouseWheelEnable attribute to true, you can enable mouse wheel scrolling. However, this property must be set to a scrolling object to be effective. The scrolling object here is Panel as an example. The effect is as shown in the animation 1-10. The horizontal scroll bar is controlled through the mouse wheel. (Animation 1-10) After setting the touchScrollEnable property to true, touch scrolling can be enabled. This property must also be set to a scroll object before it is valid. As shown in the animation 1-11, you can drag the Panel component and the horizontal scroll bar will scroll accordingly. (Animation 1-11) After setting the hide attribute to true, the scroll bar will not be displayed, but you can scroll normally. The effect is shown in the following animation: (Animation 1-12) After setting the autoHide attribute to true, the scroll bar will be automatically hidden. When the operation content is scrolled, the scroll bar will be displayed, and when the scrolling is stopped, the scroll bar will be automatically hidden. The effect is as follows: (Animation 1-13) Set the rollRatio attribute. The smaller the value, the smaller the change in scrolling speed. Animation 1-14 The left picture shows the effect of setting rollRatio to 1, and the right picture shows the effect of setting rollRatio to 0.1. Obviously, the larger the value of rollRatio, the faster the scrolling speed. (Animation 1-14) Horizontal scroll bars support rubber band technology. Animation 1-15 demonstrates the effect of setting the limit distance of the rubber band effect to elasticDistance to 200 and the rubber band rebound time to 500 milliseconds. (Animation 1-15) 1.3 Script control HScrollBar In the Scene2D property settings panel, add a custom component script. Then, drag the HScrollBar into its exposed property entry. You need to add the following sample code to implement script control of HScrollBar: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.HScrollBar }) public hscroll: Laya.HScrollBar; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.hscroll.skin = \"atlas/comp/hscroll.png\";//Scroll bar skin this.hscroll.width = 300;//The width of the scroll bar this.hscroll.pos(300, 300);//The position of the scroll bar this.hscroll.min = 0;//The minimum scroll position of the slider this.hscroll.max = 10;//Maximum scrolling position of the slider this.hscroll.scrollSize = 1; //Scroll amount of click button } } 2. Create HScrollBar component through code When writing code, it is inevitable to control the UI through code, create the UI_HScrollBar class, and set HScrollBar related properties through code. The following example demonstrates how to create an HScrollBar through code and display the scroll bar's value through a Text component. Developers can set the HScrollBar through code and create an HScrollBar that meets their own needs. Sample code: const { regClass, property } = Laya; @regClass() export class UI_HScrollBar extends Laya.Script { constructor() { super(); } // Text component, used to display the value of the scroll bar public text: Laya.Text; // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Create text component this.text = new Laya.Text(); this.text.pos(300, 260); this.owner.addChild(this.text); //Scroll bar skin resources var skins: any[] = []; skins.push(\"atlas/comp/hscroll.png\", \"atlas/comp/hscroll$bar.png\", \"atlas/comp/hscroll$down.png\", \"atlas/comp/hscroll$up.png\"); Laya.loader.load(skins).then(() => { //Create scroll bar var hs: Laya.HScrollBar = new Laya.HScrollBar(); hs.skin = \"atlas/comp/hscroll.png\"; hs.width = 300; hs.pos(300, 300); hs.min = 0; hs.max = 100; hs.changeHandler = new Laya.Handler(this, this.onChange); this.owner.addChild(hs); }); } private onChange(value: number): void { this.text.text = \"Scroll bar position: value=\" + value; } } running result: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:56:43 "},"IDE/uiEditor/uiComponent/VScrollBar/readme.html":{"url":"IDE/uiEditor/uiComponent/VScrollBar/readme.html","title":"VScrollBar","keywords":"","body":"Vertical scroll bar component (VScrollBar)1. Create VScrollBar component through LayaAir IDE1.1 Create VScrollBar1.2 VScrollBar properties1.3 Script control VScrollBar2. Create VScrollBar component through codeVertical scroll bar component (VScrollBar) 1. Create VScrollBar component through LayaAir IDE The VScrollBar component is a vertical scroll bar component. When there is too much data to fit in the display area, the end user can use the VScrollBar component to control the portion of the data that is displayed. For the script interface of the VScrollBar component, please refer to VScrollBar API. 1.1 Create VScrollBar As shown in Figure 1-1, you can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) The scroll bar consists of four parts: a track graph, a slider button, and two arrow buttons. The naming of the image resources of the VScrollBar component must comply with Resource Naming Rules. The resource examples provided by LayaAir are as follows: (Figure 1-2) Orbital diagram (Figure 1-3) Slider button (Figure 1-4) Arrow Button 1 (Figure 1-5) Arrow Button 2 The display effect after creating VScrollBar is as follows: (Figure 1-6) 1.2 VScrollBar properties The unique properties of VScrollBar are as follows: (Figure 1-7) Properties Function description skin The image resource address of the scroll bar track diagram. sizeGrid Valid scaling grid data (nine-square grid data) of the scroll bar track map resource. max represents the maximum scroll position of the slider (the value when the slider is at the highest position). min represents the minimum scroll position of the slider (the value when the slider is at the lowest position). scrollSize Scroll amount on button click. The amount by which the scroll bar's value changes (the amount the slider moves) each time the scroll bar arrow button is clicked. value The current progress value of the scroll bar (current position of the slider). mouseWheelEnable Whether to enable mouse wheel scrolling, the default value is true. This property sets the scroll object target to be valid later. touchScrollEnable Whether to enable touch scrolling, the default value is true. This property sets the scroll object target to be valid later. hide Whether to hide the scroll bar, the default is false. When set to true, the scroll bar will not be displayed, but normal scrolling will be possible. autoHide Whether to automatically hide the scroll bar, the default value is false. After setting to true, the scroll bar will be hidden when scrolling is not required, and the scroll bar will be displayed when the content needs to be scrolled. showButtons Whether to display arrow buttons, the default value is true. When set to false, the arrow buttons will not be displayed. rollRatio Rolling attenuation coefficient, default is 0.97. elasticDistance The limit distance of the rubber band effect. 0 means there is no rubber band effect. elasticBackTime Rubber band rebound time, in milliseconds. The following shows the effects of some scroll bar property settings: After setting the value of attribute max of VScrollBar to 10, the value of attribute min to 0, and the value of attribute value to 3, the display effect is as follows: (Figure 1-8) At runtime, you can control the scroll bar's value by dragging the slider or clicking the arrow buttons. Set the property scrollSize to 1, then every time you click the scroll bar arrow button, the value of the scroll bar changes by 1. The effect is as follows: (Animation 1-9) After setting the mouseWheelEnable attribute to true, you can enable mouse wheel scrolling. However, this property must be set to a scrolling object to be effective. The scrolling object here is Panel as an example. The effect is as shown in the animation 1-10. The vertical scroll bar is controlled through the mouse wheel. (Animation 1-10) After setting the touchScrollEnable property to true, touch scrolling can be enabled. This property must also be set to a scroll object before it is valid. As shown in the animation 1-11, you can drag the Panel component and the vertical scroll bar will scroll accordingly. (Animation 1-11) After setting the hide attribute to true, the scroll bar will not be displayed, but you can scroll normally. The effect is shown in the following animation: (Animation 1-12) After setting the autoHide attribute to true, the scroll bar will be automatically hidden. When the operation content is scrolled, the scroll bar will be displayed, and when the scrolling is stopped, the scroll bar will be automatically hidden. The effect is as follows: (Animation 1-13) Set the rollRatio attribute. The smaller the value, the smaller the change in scrolling speed. Animation 1-14 The left picture shows the effect of setting rollRatio to 1, and the right picture shows the effect of setting rollRatio to 0.1. Obviously, the larger the value of rollRatio, the faster the scrolling speed. (Animation 1-14) Vertical scrollbar supports rubber band technology. Animation 1-15 demonstrates the effect of setting the limit distance of the rubber band effect to elasticDistance to 200 and the rubber band rebound time to 500 milliseconds. (Animation 1-15) 1.3 Script control VScrollBar In the Scene2D property settings panel, add a custom component script. Then, drag the VScrollBar into its exposed property entry. You need to add the following sample code to implement script control of VScrollBar: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.VScrollBar }) public vscroll: Laya.VScrollBar; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.vscroll.skin = \"atlas/comp/vscroll.png\";//Scroll bar skin this.vscroll.width = 300;//The width of the scroll bar this.vscroll.pos(300, 300);//The position of the scroll bar this.vscroll.min = 0;//The minimum scroll position of the slider this.vscroll.max = 10;//Maximum scrolling position of the slider this.vscroll.scrollSize = 1; //Scroll amount of click button } } 2. Create VScrollBar component through code When writing code, it is inevitable to control the UI through code, create the UI_VScrollBar class, and set VScrollBar related properties through code. The following example demonstrates how to create a VScrollBar through code and display the value of the scroll bar through a Text component. Developers can set the VScrollBar through code and create a VScrollBar that meets their own needs. Sample code: const { regClass, property } = Laya; @regClass() export class UI_VScrollBar extends Laya.Script { constructor() { super(); } // Text component, used to display the value of the scroll bar public text: Laya.Text; // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Create text component this.text = new Laya.Text(); this.text.pos(300, 260); this.owner.addChild(this.text); //Scroll bar skin resources var skins: any[] = []; skins.push(\"atlas/comp/vscroll.png\", \"atlas/comp/vscroll$bar.png\", \"atlas/comp/vscroll$down.png\", \"atlas/comp/vscroll$up.png\"); Laya.loader.load(skins).then(() => { //Create scroll bar var vs: Laya.VScrollBar = new Laya.VScrollBar(); vs.skin = \"atlas/comp/vscroll.png\"; vs.height = 300; vs.pos(300, 300); vs.min = 0; vs.max = 100; vs.changeHandler = new Laya.Handler(this, this.onChange); this.owner.addChild(vs); }); } private onChange(value: number): void { this.text.text = \"Scroll bar position: value=\" + value; } } running result: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:24:47 "},"IDE/uiEditor/uiComponent/slider/readme.html":{"url":"IDE/uiEditor/uiComponent/slider/readme.html","title":"slider","keywords":"","body":"Swipe Bar ComponentSwipe Bar Component The swipe bar component includes two types: horizontal slide bar and vertical slide bar. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:05:03 "},"IDE/uiEditor/uiComponent/VSlider/readme.html":{"url":"IDE/uiEditor/uiComponent/VSlider/readme.html","title":"VSlider","keywords":"","body":"Vertical slider component (VSlider)1. Create VSlider component through LayaAir IDE1.1 Create VSlider1.2 VSlider properties1.3 Script control VSlider2. Create VSlider component through codeVertical slider component (VSlider) 1. Create VSlider component through LayaAir IDE The HSlider and VSlider components are both subclasses of the Slider component. They represent horizontal slide bars and vertical slide bars respectively. Users can select values ​​by moving the slider between slider tracks. Commonly used for example, player progress control, volume control, numerical adjustment on some UI, etc. The detailed properties of VSlider can be viewed in API. 1.1 Create VSlider As shown in Figure 1-1, you can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) Sliders can be made of two or three parts. If it is two parts, it includes the basemap resource vslider.png and the slider resource vslider$bar.png, as shown in Figure 1-2. Resources should have at least these two, otherwise the sliding function cannot be implemented. (Figure 1-2) If it is a three-part slide bar, it includes the slider resource vslider$bar.png, the progress bar resource vslider$progress.png, and the basemap resource vslider.png, as shown in Figure 1-3. If the progress bar resource component is missing, no error will be reported, but the progress will not be displayed. (Figure 1-3) The progress bar resource vslider$progress.png can be interchanged with the base map resource vslider.png. After the exchange, the progress can be displayed in reverse. The VSlider component created by LayaAir by default is composed of two parts. As shown in the animation 1-4, the VSlider component is arranged vertically. The slider track expands from top to bottom, and dragging the slider with the mouse will display numerical labels. (Animation 1-4) 1.2 VSlider properties The unique properties of VSlider are as follows: (Figure 1-5) Properties Function description max The value when the slider is dragged to the bottom, the default value is 100 min The value when the slider is dragged to the top, the default value is 0 showLabel Whether to display labels. The default is true. Dragging the slider during runtime will display the value. showProgress Whether to display the progress bar. The default is false. If there is a progress bar resource vslider$progress.png, you can check this item skin Basemap resource for slider skinGrid Valid scaling grid data (nine-square grid data) of the slider basemap resource tick The minimum unit of the slider scale value. The amount the value changes each time the slider is dragged. The default value is 1 value The current scale, that is, the current value of the slider, should be equal to max or min, or a value between them allowClickBack Whether to allow changing the value by clicking the slider. The default is false, which prohibits changing the value by clicking the slider. At this time, the only way to change the value is by dragging the slider. When it is true, you can click the target area of ​​the slider to quickly jump to the current scale and change the value After setting the value of attribute max of VSlider to 20, the value of attribute min to 0, and the value of attribute value to 5, the display effect is as follows: (Figure 1-6) Set the attribute showLabel to true, the attribute showProgress to true, and the attribute tick value to 3. The effect is as shown in the following animation: (Animation 1-7) The progress bar resource vslider$progress.png can be interchanged with the basemap resource vslider.png. The effect is as follows: (Animation 1-8) 1.3 Script control VSlider In the Scene2D property settings panel, add a custom component script. Then, drag the VSlider into its exposed property entry. You need to add the following sample code to implement script control VSlider: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({type:Laya.VSlider}) public vslider: Laya.VSlider; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.vslider.pos(300,300);//slider position this.vslider.skin = \"resources/vslider.png\";//slider basemap skin this.vslider.value = 0.5; this.vslider.max = 50; this.vslider.min = 0; this.vslider.tick = 1; this.vslider.showProgress = true;//The resource vslider$progress.png must exist, otherwise an error will be reported } } 2. Create VSlider component through code Sometimes, you need to control UI components with code, create the UI_VSlider class, and set the VSlider through code. The following example creates a VSlider component using code and outputs its value on the console. Sample code: const { regClass, property } = Laya; @regClass() export class UI_VSlider extends Laya.Script { constructor() { super(); } onAwake(): void { let skins: any[] = []; skins.push(\"vslider.png\", \"vslider$bar.png\"); //Image resources come from \"Engine API Usage Example\" Laya.loader.load(skins, Laya.Handler.create(this, this.placeVSlider)); } private placeVSlider(): void { let vs: Laya.Slider = new Laya.VSlider(); vs.skin = \"vslider.png\"; vs.height = 300; vs.pos(400, 50); vs.min = 0; vs.max = 100; vs.value = 50; vs.tick = 1; vs.changeHandler = new Laya.Handler(this, this.onChange); this.owner.addChild(vs); } private onChange(value: number): void { console.log(\"Slider position: \" + value); } } running result: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:26:14 "},"IDE/uiEditor/uiComponent/ProgressBar/readme.html":{"url":"IDE/uiEditor/uiComponent/ProgressBar/readme.html","title":"ProgressBar","keywords":"","body":"Progress bar component (ProgressBar)1. Create the ProgressBar component through LayaAir IDE1.1 Create ProgressBar1.2 ProgressBar property1.3 Script control ProgressBar2. Create ProgressBar through codeProgress bar component (ProgressBar) 1. Create the ProgressBar component through LayaAir IDE ProgressBar is often used to display the progress of an operation in the game, such as the progress of loading resources, character experience or blood volume. The script interface of ProgressBar refers to API. 1.1 Create ProgressBar As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) The ProgressBar component consists of two parts: the base image progress.png and the progress progress$bar.png. The resource example is shown in Figure 1-2. (Figure 1-2) The effect of the ProgressBar component created by LayaAir by default is as shown below: (Figure 1-3) 1.2 ProgressBar property The unique properties of ProgressBar are as follows: (Figure 1-4) Properties Function Description skin Basemap resource for progress bar sizeGrid Valid scaling grid data of the progress bar basemap resource (nine-square grid data) value The progress value of the progress bar, ranging from 0 to 1 After setting the attribute value of the ProgressBar component to 0.3, the display effect is as follows: (Figure 1-5) 1.3 Script control ProgressBar Sometimes, the progress of the loading process needs to be displayed in the form of a progress bar, which needs to be controlled by script code. In the Scene2D property settings panel, add a custom component script. Then, drag the ProgressBar into its exposed property entry. Add another Text component to describe the loading progress. The following sample code needs to be added: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.ProgressBar }) public progressBar: Laya.ProgressBar; @property({ type: Laya.Text }) public loadText: Laya.Text; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.progressBar.value = 0.01; //Initial progress value this.loadText.text = \"Resource loading...\"; //Test loading effect Laya.timer.loop(100, this, this.changeProgress); } //This only simulates the loading demonstration effect changeProgress(): void { this.progressBar.value += 0.05; //The amount of change of the progress bar each time if (this.progressBar.value == 1) { this.loadText.text = \"Resource loading completed\"; Laya.timer.clear(this, this.changeProgress); } } } The effect is as follows: (Animation 1-6) 2. Create ProgressBar through code When developing a project, it is inevitable to create the UI through code, create the UI_ProgressBar class, and set the ProgressBar-related properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_ProgressBar extends Laya.Script { private progressBar: Laya.ProgressBar; constructor() { super(); } onAwake(): void { // Load progress bar resources, image resources come from \"Engine API Usage Example\" Laya.loader.load([\"resources/res/ui/progressBar.png\", \"resources/res/ui/progressBar$bar.png\"]).then(() => { //Create progress bar this.progressBar = new Laya.ProgressBar(\"resources/res/ui/progressBar.png\"); this.progressBar.pos(100, 500); this.progressBar.width = 400; this.progressBar.sizeGrid = \"5,5,5,5\"; this.progressBar.changeHandler = new Laya.Handler(this, this.onChange); this.owner.addChild(this.progressBar); Laya.timer.loop(100, this, this.changeValue); }); } // Simulate progress bar loading private changeValue(): void { if (this.progressBar.value >= 1) this.progressBar.value = 0; this.progressBar.value += 0.05; } private onChange(value: number): void { //Console printout progress console.log(\"Progress: \" + Math.floor(value * 100) + \"%\"); } } The sample effect is as follows: (Animation 2-1) Other properties of ProgressBar can also be set through code. The above example demonstrates how to create a ProgressBar through code. Interested developers can set the ProgressBar through code and create a progress bar that meets their own needs. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:04:37 "},"IDE/uiEditor/uiComponent/Box/readme.html":{"url":"IDE/uiEditor/uiComponent/Box/readme.html","title":"Box","keywords":"","body":"Container component (Box)1. What is a container?2. What are the containers?3. Box attributes4. Differences in the use of Box and Sprite containersContainer component (Box) Author : Charley 1. What is a container? The so-called container is a storage device that can contain or load items. In the LayaAir engine, it refers to a component that is not used independently and is used to load other display objects. It is a common situation not to be used independently. In some cases, the container can also be used only to fill the background color, but this situation is not the real role of the container. For example, the List container component has no meaning without its loaded rendering unit subcomponent. Another example is the radio button group. Without the subcomponents of the radio button, the group itself will lose its meaning. Therefore, the main function of each container is to contain or load other sub-components in order to play its unique role. 2. What are the containers? The base class of container components is Box. Box itself and components inherited from Box all belong to the container. There are a total of 9 container objects used directly by developers. As shown in the yellow highlighted part of Figure 2-1. (Figure 2-1) 3. Box attributes To create a Box, you can right-click in the Hierarchy' window to create it, or you can drag and drop it from theWidgets' window. As shown below: (Figure 3-1) Since Box inherits from the base class UIComponent of UI components, the properties of the parent class will not be introduced again here. Since Box is a relatively pure container object, it has no function itself. Its function is mainly used to load other child nodes. If the only function that can be used independently is to fill the background color. The operation in the IDE is as shown in Figure 3-2. First check the Set background color status check box, then click the color picker input field, then pick or enter a color in the color picker window, and then close the color picker window. That’s it. (Figure 3-2) 4. Differences in the use of Box and Sprite containers Sprite and Box are both commonly used basic containers. Since Sprite is lower level, the performance consumption of Sprite is lower than that of Box. Without massive use, there isn't much of a difference. But in principle, performance comes first. When Sprite can be used, Sprite should of course be used first. So when to use Box? Since Box is a UI component, all UI components have a common feature, which is relative layout and setting data sources. For containers, we consider whether to use Box, depending on whether there is a need for relative layout. If there is a need for relative layout, use Box as the container, otherwise use Sprite. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:35:45 "},"IDE/uiEditor/uiComponent/VBox/readme.html":{"url":"IDE/uiEditor/uiComponent/VBox/readme.html","title":"VBox","keywords":"","body":"Vertical layout container component (VBox)1. Create VBox components through LayaAir IDE1.1 Create VBox1.2 VBox properties1.3 Script control VBox2. Create VBox through codeVertical layout container component (VBox) VBox is a container class component, inherited from Box. VBox is a container component used for vertical layout. Compared with Box, it adds more detailed functions. The detailed properties of VBox can be viewed in API. 1. Create VBox components through LayaAir IDE 1.1 Create VBox VBox can be created directly in the hierarchy panel through the visual operation of the IDE, as shown in Figure 1-1. You can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) 1.2 VBox properties The unique properties of VBox are as follows: (Figure 1-2) Properties Function bgColor Background color. After checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color space The vertical spacing between sub-objects, in pixels. align Horizontal alignment of layout elements. There are four options. none: No horizontal alignment, left: Horizontal alignment on the left, center: Horizontal alignment on the center, right: Horizontal alignment on the right, the default is none. The space attribute is to set the vertical spacing between sub-objects in pixels. You can enter the number yourself, or you can enter the value by pressing and holding the left mouse button and sliding. Assume that VBox has three Button component sub-objects. The effect of adjusting the space attribute is as shown in the animation 1-3. (Animation 1-3) No matter how the child nodes of VBox are arranged in the IDE, they will become the corresponding horizontal sorting after setting the align attribute, as shown in the animation 1-4. (Animation 1-4) 1.3 Script control VBox In the Scene2D property settings panel, add a custom component script. Then, drag the VBox into its exposed property entrance. Since there is only one VBox and the effect cannot be viewed, the developer can add some child nodes under the VBox. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.VBox }) public vbox: Laya.VBox; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.vbox.pos(100, 100); this.vbox.bgColor = \"#ffffff\"; this.vbox.space = 30; this.vbox.align = \"center\"; } } 2. Create VBox through code Sometimes, you need to manage the UI with code, and create the UI_VBox class to create VBox components. Since it doesn't make much sense to create a VBox component alone, three more Button components are created to demonstrate the effect. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_VBox extends Laya.Script { private vbox: Laya.VBox; private btn1: Laya.Button; private btn2: Laya.Button; private btn3: Laya.Button; // Button skin resources private skins: string = \"atlas/comp/button.png\"; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load(this.skins).then(() => { this.createBtn(); this.createvbox(); //Add VBox component this.owner.addChild(this.vbox); }); } //Create Button component private createBtn(): void { this.btn1 = new Laya.Button(this.skins); this.btn2 = new Laya.Button(this.skins); this.btn3 = new Laya.Button(this.skins); } //Create VBox component private createvbox(): void { this.vbox = new Laya.VBox; this.vbox.pos(100, 100); this.vbox.size(600, 300); this.vbox.bgColor = \"#ffffff\"; this.vbox.addChild(this.btn1); this.vbox.addChild(this.btn2); this.vbox.addChild(this.btn3); this.vbox.space = 80; this.vbox.align = \"center\"; } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:20:47 "},"IDE/uiEditor/uiComponent/Panel/readme.html":{"url":"IDE/uiEditor/uiComponent/Panel/readme.html","title":"Panel","keywords":"","body":"Panel container component (Panel)1. Create Panel component through LayaAir IDE1.1 Create Panel1.2 Panel properties1.3 Script Control Panel2. Create Panel component through codePanel container component (Panel) Panel is a panel container class with cropping function, which is often used to set the display area of ​​elements. You can directly add the elements to be displayed to the Panel container. The width and height of the Panel are the width and height of the elements to be displayed. The detailed properties of Panel can be viewed in API. 1. Create Panel component through LayaAir IDE 1.1 Create Panel Panels can be created directly in the hierarchy panel through the visual operation of the IDE, as shown in Figure 1-1. You can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) Set the width and height of the Panel (for example: 200*200). Then add child nodes to the Panel component and put a picture (512*313). The display effect and hierarchical structure are shown in Figure 1-2. (Figure 1-2) As can be seen from Figure 1-2, the inserted image is cropped, and the width and height of the final displayed image are the width and height of the Panel container (200*200). Developers can directly adjust the coordinates of the image to change its displayed content. 1.2 Panel properties The unique properties of the Panel component are as follows: (Figure 1-3) Properties Description bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color scrollType Scroll type, options are: no scrolling, horizontal scrolling, vertical scrolling, both horizontal and vertical scrolling. Different scroll types require corresponding scroll bar skins vScrollBarSkin Vertical scroll bar skin, not set by default. Scroll bar skin resources must comply with resource naming rules hScrollBarSkin Horizontal scroll bar skin, not set by default. Scroll bar skin resources must comply with resource naming rules elasticEnabled Whether to use the rubber band rebound effect, the default is false To set scroll bars for the Panel component, you can set only the vertical scroll bar VScrollBarSkin, only the horizontal scroll bar HScrollBarSkin, or both. If you only set the vertical scroll bar, you need to set the ScrollType to vertical scrolling; if you set only the horizontal scroll bar, you need to set the ScrollType to horizontal scrolling; if you set both, you need to set the ScrollType to both horizontal and vertical scrolling. scroll. Except the List component, Panel is the only container component that can set scroll bars. The effect of setting both horizontal and vertical scrolling on the Panel is as follows: (Animation 1-4) After the rubber band rebound effect ElasticEnabled is turned on, when the slider scrolls to the boundary, the slider will continue to scroll for a certain distance and then rebound. The rubber band effect is shown in the animation 1-5, which can increase the smoothness of scrolling and user experience. (Animation 1-5) 1.3 Script Control Panel In the Scene2D property settings panel, add a custom component script. Then, drag the Panel component into its exposed property entrance. Since there is only one Panel component and the effect cannot be viewed, the developer can add some child nodes under the Panel. You need to add the following sample code to implement script control Panel: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Panel }) public panel: Laya.Panel; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.panel.pos(100, 100); this.panel.size(200, 200); this.panel.scrollType = Laya.ScrollType.Both; //Scroll type: both horizontal and vertical scrolling this.panel.vScrollBarSkin = \"atlas/comp/vscroll.png\"; this.panel.hScrollBarSkin = \"atlas/comp/hscroll.png\"; this.panel.elasticEnabled = true; //Rubber band effect } } 2. Create Panel component through code In addition to the direct visual operations in the UI interface, Panel components are also very simple to create in code. Create the UI_Panel class and implement the code to create the Panel component. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Panel extends Laya.Script { constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Create Panel component let panel: Laya.Panel = new Laya.Panel(); panel.hScrollBarSkin = \"atlas/comp/hscroll.png\"; panel.size(600, 275); panel.pos(150, 150); this.owner.addChild(panel); //Create an Image component as a child node of Panel let img: Laya.Image; for (var i: number = 0; i The effect is shown in the following animation: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:04:08 "},"IDE/uiEditor/uiComponent/List/readme.html":{"url":"IDE/uiEditor/uiComponent/List/readme.html","title":"List","keywords":"","body":"List component (List)1. Create List component through LayaAir IDE1.1 Composition of List1.2 Create List1.3 Common properties of List component2. Create List component through codeList component (List) The List component can display a list of items, which defaults to a vertical list. Each list of List is usually the same, and you can also use the editor to customize list content items in different styles. For the script interface of the List component, please refer to List API. 1. Create List component through LayaAir IDE 1.1 Composition of List List usually consists of two parts: list rendering items (cells) and scroll bars. List rendering items can be Box objects or other custom page objects, also known as sub-item templates (Item Template). Label, Image and other components can be placed in sub-item templates. The scroll bar can be set to a vertical scroll bar, a horizontal scroll bar, or both at the same time. 1.2 Create List 1.2.1 Add List component As shown in Figure 1-1, you can right-click in the Hierarchy' window to create it, or you can drag and drop from theWidgets' window to add it. (Picture 1-1) 1.2.2 Add and specify list items of List Here we take the Box object as an example. As shown in Figure 1-2, add a Box component under the List component and adjust the size of the Box. Then add a Label component under the Box, name it m_label, and set the display effect of the Label to make it look better. (Figure 1-2) Then drag the created Box node into the Item Template property of the List, as shown in Figure 1-3, so that the list item of the List is designated as the child node Box. (Figure 1-3) 1.2.3 Add scroll bar skin Select the Scroll Type of the List property to scroll vertically. The V Scroll Bar Skin property is used to set the skin of the vertical scroll bar. Select vscroll.png from the resource panel to this property, and the scroll bar skin will be generated immediately. (Figure 1-4) Note: When the Scroll Type is no scrolling, even if the scroll bar skin is set, there will be no scrolling effect at runtime. Set Repeat Y to 6, which means that when the list item exceeds 6, it will start scrolling. (Figure 1-5) 1.2.4 Set data source The data source must be set for the List component in code. const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { @property({ type: Laya.List }) list: Laya.List constructor() { super(); } // Executed after the component is enabled, such as after the node is added to the stage onEnable(): void { //Assign value to List object var data: Array = []; for (var m: number = 0; m In the code, the name of m_label must be the same as the name of the Label component under the List item. 1.2.5 Run to see the effect Mount the script to the Scene2D scene, and then drag the List component into the properties exposed by the script, as shown in Figure 1-6. (Figure 1-6) The running effect is as follows: (Animation 1-7) 1.2.6 Set List effect You can also add code to the code in 1.2.4 to set the effect of the List component. For example, hide the scroll bar, set the dragging rubber band effect, etc. Please refer to Section 1.3 for specific attributes. const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { @property({ type: Laya.List }) list: Laya.List constructor() { super(); } // Executed after the component is enabled, such as after the node is added to the stage onEnable(): void { //Assign value to List object var data: Array = []; for (var m: number = 0; m The effect is as follows: (Figure 1-8) 1.3 Common properties of List component The unique properties of List are as follows: (Figure 1-9) Properties Function description bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color itemTemplate Child template, which is the rendered child of the list. This attribute specifies any child node under List as a child template, usually Box repeatX The maximum number of horizontal list rendering units. When the list data exceeds this value, if a horizontal scroll bar is set, the horizontal scrolling effect will be displayed repeatY The maximum number of vertical list rendering units. When the list data exceeds this value, if a vertical scroll bar is set, the vertical scrolling effect will be displayed elasticEnabled Whether to enable the rubber band rebound effect, the default is false spaceX Spacing between cells displayed horizontally (in pixels) spaceY Spacing between vertically displayed cells (in pixels) scrollType Scroll type, needs to be used with the corresponding scroll bar skin. There are four types: none: no scrolling (default), horizontal: horizontal scrolling, vertical: vertical scrolling, both: both horizontal and vertical scrolling vScrollBarSkin Vertical scroll bar skin hScrollBarSkin Horizontal scroll bar skin selectEnable Whether it can be selected. After enabling, selecting the list rendering unit will display the selected custom option box effect selectedIndex The index of the selected rendering unit in the current list disableStopScroll Disable scroll bar stopping. Used to control whether to stop the scroll bar when the array is updated. By default, the scroll bar will be stopped when updating data. When dynamically updating the cells of the List by sliding the scroll bar, setting it to true will make the list scroll smoothly 2. Create List component through code When writing code, it is inevitable to control the UI through code, create the UI_List class, and set List-related properties through code. Sample code: const { regClass, property } = Laya; @regClass() export class UI_List extends Laya.Script { public _list: Laya.List; constructor() { super(); } onAwake(): void { var list: Laya.List = new Laya.List(); list.itemRender = Item; list.repeatX = 1; list.repeatY = 4; list.x = (Laya.stage.width - Item.WID) / 2; list.y = (Laya.stage.height - Item.HEI * list.repeatY) / 2; //Set vertical scrolling of List list.scrollType = Laya.ScrollType.Vertical; // Set the vertical scrolling skin of the List. If you don't set it or \"\", there will be no scroll bar skin. list.vScrollBarSkin = \"\"; // Turn on the rubber band effect list.elasticEnabled = true; //Set the rubber band rebound time in milliseconds list.scrollBar.elasticBackTime = 300; //Set the rubber band limit distance list.scrollBar.elasticDistance = 50; //Set whether it can be selected list.selectEnable = true; list.selectHandler = new Laya.Handler(this, this.onSelect); //Cell rendering processing list.renderHandler = new Laya.Handler(this, this.updateItem); this.owner.addChild(list); //Set the data source to the path of the corresponding image var data: any[] = []; for (var i: number = 0; i running result: (Figure 2-1) Other properties of List can also be set through code. Interested readers can set List through code themselves to create a list that meets their own needs. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 19:07:26 "},"IDE/uiEditor/uiComponent/Tree/readme.html":{"url":"IDE/uiEditor/uiComponent/Tree/readme.html","title":"Tree","keywords":"","body":"Tree list component (Tree)1. Create Tree component through LayaAir IDE1.1 Composition of Tree1.2 Create Tree component1.3 Common properties of Tree component2. Create Tree component through codeTree list component (Tree) 1. Create Tree component through LayaAir IDE The Tree component is used to display a tree structure. Users can view hierarchical data arranged as an expandable tree. For the script interface of the Tree component, please refer to Tree API. 1.1 Composition of Tree 1.1.1 Tree component mainly consists of two parts: 1. Item cell (can be Box, custom page) Item cells usually consist of four parts: (1) A cell selection status slice animation Clip; (2) A folding arrow slice animation Clip; (3) A file status slice animation Clip; (4) Other content elements of the cell; 2. Vertical scroll bar VScrollBar 1.1.2 Image resource example of Tree component Cell selection state slice animation Clip resource (clip_selectBox.png): The number of slices is 2, and the slice index starts from 0 and represents: cell hover state chart (white), cell unselected state chart. (Picture 1-1) Folding arrow slice animation Clip resource (clip_tree_arrow.png): The number of slices is 2, and the slice index starts from 0 and represents in order: the folder node folded state diagram, and the folder node expanded state diagram. (Figure 1-2) File status slice animation Clip resource (clip_tree_folder.png): The number of slices is 3, and the slice index starts from 0 and represents in order: the folder node collapsed state diagram, the folder node expanded state diagram, and the non-folder node state diagram; (Figure 1-3) 1.2 Create Tree component 1.2.1 Edit the list items of the Tree component (1) First create a Clip component in Snce2D, set the name attribute value of this Clip component object to selectBox, set the value of the attribute ClipY to 2, and then animate the slice of a cell selection state from the project resource panel (clip_selectBox. png), drag it into the Skin property of the Clip component you just created, as shown in Figure 1-4. Note: The name attribute value of the selection state slice animation (Clip component) object here must be set to selectBox. Only in this way can the program recognize it and realize the function of the display state of this Clip component object changing following the selection state of the unit item. , otherwise this Clip object will be recognized as a normal display object of this unit item. (Figure 1-4) (2) Create a Clip component in Snce2D, set the name attribute value of this Clip component object to arrow, set the value of the attribute ClipY to 2, and then animate the folding arrow slice of a cell from the project resource panel (clip_tree_arrow.png ) and drag it into the Skin property of the Clip component just created, as shown in Figure 1-5. Note: The name attribute value of the folding arrow slice animation (Clip component) here must be set to arrow, only in this way can the program recognize it and realize the function of clicking this Clip object to open or collapse the tree node. Otherwise the Clip object will be recognized as a normal display object for this cell item. (Figure 1-5) (3) Create a Clip component in Scene2D, set the name attribute value of this Clip component object to folder, set the value of the attribute ClipY to 3, and then slicing the file status of a cell from the project resource panel (clip_tree_folder.png ) and drag it into the Skin property of the Clip component just created, as shown in Figure 1-6. Note: The name attribute value of the file status slice animation (Clip component) here must be set to folder. Only in this way can the program recognize it and realize that the display state of this Clip component object follows the folding, expansion, and node type of the unit item ( whether there are child nodes). Otherwise the Clip object will be recognized as a normal display object for this cell item. (Figure 1-6) (4) Drag in the normal display object of this unit item. Here we take Label as an example. Select and drag a Label component object from the resource panel. Here, set the attribute name value of this Label object to label (note that \"l\" is lowercase) to facilitate assigning it in the script. Then set the display-related properties of the Label object to make it look more beautiful. Note: The value of this name attribute can be customized (but it must be the same as the name assigned to the Tree object). (Figure 1-7) Then, drag the nodes created in steps (1) to (4) into a Box container component, and arrange them reasonably, as shown in Figure 1-8. (Figure 1-8) 1.2.2 Specify the list rendering items of the Tree component Create a Tree component and set the Item Template property of the Tree component to the Box just created in 1.2.1, as shown in Figure 1-9. (Figure 1-9) 1.2.3 Add scroll bars to the Tree component When the Tree has too many list items, you need to add a scroll bar. As shown in Figure 1-10, add a scroll bar skin to the Tree component property scrollBarSkin. (Figure 1-10) Attributes such as background color are also set here. For detailed description of attributes, see Section 1.3. 1.2.4 Assigning values ​​to Tree objects in code In the Scene2D property settings panel, add a custom component script. Then drag the Tree node into its exposed property entrance. An example of assigning a value to the Tree object in the code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Tree }) public tree: Laya.Tree; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Initialize the data source of the tree list let treeData: string = \"\"; //Assign values ​​to the Tree list treeData += \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" + \"\" ; //Data source data tag needs to be spliced ​​with an end tag treeData += \"\"; //Parse the string into an xml object and return it this.tree.xml = new Laya.XML(treeData); } } The values ​​assigned to the Tree list here are hard-coded simulation data. Among them, splicing simulation data can only have a two-layer structure at most, and deep-level structures are not supported. In the above code, the tag represents a folder, and represents a file. isOpen='true' indicates whether the initial state of the folder is open. label='XXX' is to assign value to the label component in step (4) in 1.2.1. Note: Developers can refer to the code in Section 2 for the simulated data created by the program to deepen their understanding of xml data rules. 1.2.5 Run in IDE to see the effect The effect of operation is as follows: (Animation 1-11) It can be seen that the display selection status slice changes with the selection status of the unit item, the folding arrow slice changes with the opening or collapsing of the tree node, and the file status slice changes with the folding or expansion of the unit item. 1.3 Common properties of Tree component The unique properties of the Tree component are as follows: (Figure 1-12) Properties Function description bgColor Background color. After checking, you can directly enter the color value, for example: #ffffff, or click the color picker on the right side of the input bar to select a color. itemTemplate Rendering unit, specific usage has been given in the steps in Section 1.2. scrollBarSkin Scroll bar skin. selectedIndex The index of the currently selected item. -1 means there is no selection in the initial state. spaceBottom The distance between each item. The unit is pixels. spaceLeft The left indent distance of the child items. The unit is pixels. keepstatus After the data source changes, whether to keep the previous open state, the default is true. true: Keep the previous open state. false: Do not keep the previously opened state. 2. Create Tree component through code When developers write code, they inevitably control the UI through code. In LayaAir IDE, create a custom component script, name it UI_Tree, and then set Tree-related properties through code. Example running effect: (Animation 2-1) Sample code: const { regClass, property } = Laya; @regClass() export class UI_Tree extends Laya.Script { constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { var res: any[] = [\"atlas/comp/vscroll.png\", \"atlas/comp/vscroll$bar.png\", \"atlas/comp/vscroll$down.png\", \"atlas/comp/vscroll$up.png\", \"resources/tree/clip_selectBox.png\", \"resources/tree/clip_tree_folder.png\", \"resources/tree/clip_tree_arrow.png\"]; Laya.loader.load(res).then(() => { this.onLoadComplete(); }); } private onLoadComplete(e: any = null): void { //Initialize the data source of the tree list var treeData: string = \"\"; //Simulation data created by the program, simulation tree list data, data source of splicing list for (let i: number = 0; i \"; for (let j: number = 0; j \"; } //The outer layer of each sub-item must have a complete closing tag. The tag name used at the beginning of the directory should be used at the end. treeData += \"\"; } //Data source data tag needs to be spliced ​​with an end tag treeData += \"\"; var tree: Laya.Tree = new Laya.Tree(); tree.scrollBarSkin = \"atlas/comp/vscroll.png\"; //Add list rendering items tree.itemRender = Item; // Parse tree data tree.xml = new Laya.XML(treeData); tree.size(300, 300); tree.x = (Laya.stage.width - tree.width) / 2; tree.y = (Laya.stage.height - tree.height) / 2; tree.bgColor = \"#d25454\"; this.owner.addChild(tree); } } class Item extends Laya.Box { constructor() { super(); this.right = 0; this.left = 0; var selectBox: Laya.Clip = new Laya.Clip(\"resources/tree/clip_selectBox.png\", 1, 2); selectBox.name = \"selectBox\";//When setting the name of selectBox to \"selectBox\", it will be recognized as the background of the item in the tree structure. selectBox.height = 32; selectBox.x = 13; selectBox.left = 12; this.addChild(selectBox); var folder: Laya.Clip = new Laya.Clip(\"resources/tree/clip_tree_folder.png\", 1, 3); folder.name = \"folder\";//When setting the name of folder to \"folder\", the folder opening status chart will be recognized as a tree structure. folder.x = 14; folder.y = 4; this.addChild(folder); var label: Laya.Label = new Laya.Label; label.name = \"title\";//When setting the name of label to \"title\", this value will be used for tree structure data assignment. label.fontSize = 20; label.color = \"#FFFFFF\"; label.padding = \"6,0,0,13\"; label.width = 150; label.height = 30; label.x = 33; label.y = 1; label.left = 33; label.right = 0; this.addChild(label); var arrow: Laya.Clip = new Laya.Clip(\"resources/tree/clip_tree_arrow.png\", 1, 2); arrow.name = \"arrow\";//When setting the name of arrow to \"arrow\", the folder opening status chart that is recognized as a tree structure will be opened. arrow.x = 0; arrow.y = 5; this.addChild(arrow); } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:20:10 "},"IDE/uiEditor/uiComponent/optionBox/readme.html":{"url":"IDE/uiEditor/uiComponent/optionBox/readme.html","title":"optionBox","keywords":"","body":"Option BoxOption Box Common option boxes include drop-down option boxes, radio button boxes, radio button groups, and multi-select boxes. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:01:01 "},"IDE/uiEditor/uiComponent/ComboBox/readme.html":{"url":"IDE/uiEditor/uiComponent/ComboBox/readme.html","title":"ComboBox","keywords":"","body":"Drop-down option box component (ComboBox)1. Create ComboBox component through LayaAir IDE1.1 Create ComboBox1.2 ComboBox properties1.3 Script control ComboBox2. Create ComboBox component through codeDrop-down option box component (ComboBox) 1. Create ComboBox component through LayaAir IDE ComboBox is a drop-down option box component. For the script of ComboBox, please refer to ComboBox API. 1.1 Create ComboBox As shown in Figure 1-1, click to select the ComboBox component in the widget panel, drag it to the page editing area, or create it by right-clicking in the hierarchy window to add the ComboBox component to the page. (Picture 1-1) An example of the image resource of the ComboBox component is shown below: (Figure 1-2) The ComboBox component consists of drop-down button (upper part 1 of Figure 1-3) and drop-down option (lower part 2 of Figure 1-3). Clicking the drop-down button during runtime will pop up the drop-down option. In the property settings These two items are set separately. (Figure 1-3) 1.2 ComboBox properties The unique properties of ComboBox are as follows: (Figure 1-4) Properties Function description skin Component's image resource sizeGrid Valid scaling grid data for component image resources (nine-square grid data) state number The state value of the drop-down button labels The component's label text content collection string, separated by commas (English input method) labelFont The font of the text in the drop-down button labelSize The size of the font in the drop-down button labelBold In the drop-down button, whether the text is displayed in bold labelColors A collection of text color values ​​in each state in the drop-down button. UP: when the mouse is released on the element (raise and move away); OVER: when the mouse moves over the element; DOWN: when the mouse is pressed labelPadding The margin of the text in the drop-down button. U: Top margin; R: Right margin; D: Bottom margin; L: Left margin itemSize In the drop-down options, the font size itemHeight The height of the option box within the drop-down option itemPadding The margin of the text within the drop-down option. U: Top margin; R: Right margin; D: Bottom margin; L: Left margin itemColors In the drop-down options, you can set the colors of the three parts. Background color, UP: when the mouse is released on the element (lift and move away); OVER: when the mouse moves over the element. Label color, UP: when the mouse is released on the element (lift and move away); OVER: when the mouse moves over the element. border color, only one status color visibleNum The maximum number of rows that can be displayed in the list of drop-down options (maximum number of options) scrollType The scrolling type of the drop-down option list can only be set: no scrolling, vertical scrolling scrollBarSkin The scroll bar image resource of the drop-down option list, only the vertical scroll bar skin can be set selectedIndex Represents the index of the currently selected item selectedLabell According to the label text labels, set the default option value of the drop-down list, that is, the option displayed by the drop-down button defaultLabell When the drop-down list option value is not set (selectedIndex is -1), the text used for prompts in the drop-down button display box Among them, the labelFont, labelSize, labelBold, labelColors, and labelPadding attributes are the attributes of the drop-down button, and the itemSize, itemHeight, itemPadding, itemColors, visibleNum, scrollType, and scrollBarSkin attributes are the attributes related to the drop-down option. Use the default skin attribute, set stateNum to 3, and set the labels attribute to \"item0,item1,item2,item3,item4,item5,item6,item7,item8\". After setting selectedIndex to 0, selectedLablel will change to item0, and the effect is shown in Figure 1-5. (Figure 1-5) Since visibleNum is set to 6, up to 6 options are displayed. Next, set the Drop-down option related properties, as shown in Figure 1-6. Set the font size of the drop-down option to 30, the height of the option box to 50, and set the text margin of the drop-down option to an appropriate size. The itemColors attribute remains default, and developers can observe accordingly. The item1 option is in the OVER state. Add another vertical scroll bar to display item6, item7, and item8. (Figure 1-6) Then set the relevant attributes of the drop-down button, as shown in the animation 1-7. Set the font size in the drop-down button to 50, imitate Song font and display it in bold. labelColors remain default and labelPadding is set to an appropriate size. (Animation 1-7) 1.3 Script control ComboBox In the Scene2D property settings panel, add a custom component script. Then, drag the ComboBox into its exposed property entry. You need to add the following sample code to implement script control ComboBox: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.ComboBox }) public combobox: Laya.ComboBox; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.combobox.pos(100, 100); this.combobox.labels = \"item0,item1,item2,item3,item4,item5,item6,item7\"; this.combobox.labelColors = \"#32556b,#32cc6b,#ff0000\"; this.combobox.itemHeight = 60; // itemColors format: \"Background color when hovering or selected, label color when hovering or selected, label color, border color, background color\" this.combobox.itemColors = \"#5e95b6,#ffffff,#000000,#ff0000,#ffffff\"; this.combobox.selectedIndex = 1; this.combobox.scrollBarSkin = \"atlas/comp/vscroll.png\"; } } 2. Create ComboBox component through code When writing code, it is inevitable to control the UI through code, create the UI_ComboBox class, and set the properties related to ComboBox through code. The following example demonstrates how to set drop-down options through code and obtain the options by clicking. Example running effect: (Animation 2-1) Sample code: const { regClass, property } = Laya; @regClass() export class UI_ComboBox extends Laya.Script { private skin: string = \"resources/res/ui/combobox.png\"; //Resources come from \"Engine API Usage Example\" pageWidth: number; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load(this.skin).then(() => { let ComboBox: Laya.ComboBox = new Laya.ComboBox(this.skin, \"item0,item1,item2,item3,item4,item5\"); ComboBox.labelSize = 30; ComboBox.itemSize = 25 this.owner.addChild(ComboBox); ComboBox.autoSize = true; ComboBox.pos(200, 200); }); } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:51:02 "},"IDE/uiEditor/uiComponent/Radio/readme.html":{"url":"IDE/uiEditor/uiComponent/Radio/readme.html","title":"Radio","keywords":"","body":"Radio button component (Radio)1. Create Radio components through LayaAir IDE1.1 Create Radio1.2 Radio attribute1.3 Script control Radio2. Create Radio component through codeRadio button component (Radio) Radio inherits from Button, and many of its properties are also inherited from Button, so I won’t go into detail here about what was introduced in Button earlier. For detailed usage of Radio, please refer to Radio API. 1. Create Radio components through LayaAir IDE 1.1 Create Radio It is very simple to create Radio using LayaAir IDE. Through the visual operation of IDE, you can realize the creation and layout of components, which is also the recommended way to create components. You can create it by right-clicking on the hierarchy panel, or you can select the Radio component in the widget panel and drag and drop to add it, as shown in Figure 1-1. (Picture 1-1) 1.2 Radio attribute The unique properties of the Radio component are as follows: (Figure 1-2) Properties Function description state number The number of states of the radio button skin, supporting single state (1), two states (2) and three states (3) selected Whether the radio button is selected, the default is false. After setting to true, the radio button will remain selected (continuously selected) and will not change other states (unless the state is changed in the code) skin The skin texture resource of the radio button. After setting, you need to set the stateNum skin state number according to the skin resource sizeGrid Valid scaling grid data of bitmap (nine-square grid information): top margin, right margin, bottom margin, left margin, whether to repeat filling label Text label for radio button labelFont Font for text labels labelSize Font size of text labels labelBold Whether the text label is bold, the default is false labelColors The color of the text label in each state when the mouse is released (up), when the mouse moves to the element (over), and when the mouse is pressed (down) labelAlign Horizontal alignment mode of text label: left, center, right, default is left aligned labelVAlign Vertical alignment model of text label: top, middle, bottom, the default is top alignment labelPadding Margins for text labels. Format: top margin, right margin, bottom margin, left margin labelStroke The stroke width of the text label, in pixels. The default value is 0, which means no stroke labelStrokeColor The color of the text label stroke, expressed as a string, the default value is #000000 (black) strokecolors After checking, you can set the stroke color of the text according to the status. It can be set in three states: when the mouse is released on the element (up), when the mouse moves to the element (over), and when the mouse is pressed (down). Different stroke colors can be set in the three states Radio inherits from Button and is a radio button component. Compared with the button component, the characteristic of the radio button component is that the state will not be restored after clicking, as shown in the animation 1-3. (Animation 1-3) The remaining properties are the same as Button. Developers can understand according to the documentation of Button Component. 1.3 Script control Radio In the Scene2D property settings panel, add a custom component script. Then, drag the Radio component into its exposed property entry. You need to add the following sample code to implement script control of Radio: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Radio }) public radio: Laya.Radio; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.radio.skin = \"atlas/comp/radio.png\"; //Skin this.radio.stateNum = 3; //skin status this.radio.label = \"OK\"; //Text label this.radio.labelFont = \"宋体\"; //Text label font this.radio.labelSize = 20; //Text label font size this.radio.labelBold = true; //Text label bold this.radio.labelVAlign = \"middle\"; //Text label vertically aligned in the center this.radio.labelStroke = 3; //Text label font stroke width this.radio.labelStrokeColor = \"#ffffff\"; //Stroke color this.radio.strokeColors = \"#000000, #c6ff00, #001aff\"; //Stroke colors in each state this.radio.labelColors = \"#0100ff, #16fa0e, #ff0000\"; //Text color in each state // this.radio.selected = true; //Whether it is selected } } 2. Create Radio component through code When writing code, it is inevitable to control the UI through code, create the UI_Radio class, and set Radio-related properties through code. The following example demonstrates how to create a Radio component and set its properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Radio extends Laya.Script { constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { let radio: Laya.Radio = new Laya.Radio(); radio.pos(200, 200); radio.size(160, 64); radio.stateNum = 3; radio.selected = false; radio.skin = \"atlas/comp/radio.png\"; radio.label = \"LayaAir\"; radio.labelSize = 20; radio.labelBold = true; radio.labelVAlign = \"top\"; this.owner.addChild(radio); } } The effect is shown in the animation 2-1: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:05:31 "},"IDE/uiEditor/uiComponent/RadioGroup/readme.html":{"url":"IDE/uiEditor/uiComponent/RadioGroup/readme.html","title":"RadioGroup","keywords":"","body":"Radio group component (RadioGroup)1. Create RadioGroup component through LayaAir IDE1.1 Create RadioGroup1.2 RadioGroup properties1.3 Script control RadioGroup2. Create a custom RadioGroup component2.1 Prepare art resources2.2 Create Radio component in IDE2.3 Convert to RadioGroup container3. Create RadioGroup through codeRadio group component (RadioGroup) RadioGroup is a radio button button group. The component options within the button group are mutually exclusive. The user can only select one radio button (Radio) component at a time, as shown in animation 1. (Animation 1) The difference between Radio and RadioGroup is that Radio is a radio button, and RadioGroup can add radio buttons by modifying the labels attribute. For detailed usage of the RadioGroup component, please refer to RadioGroup API. 1. Create RadioGroup component through LayaAir IDE 1.1 Create RadioGroup As shown in Figure 1-1, click to select the RadioGroup component in the widget panel, drag and drop it into the page editing area, or create it by right-clicking in the hierarchy window to add the RadioGroup component to the page. (Picture 1-1) The default skin resources of the RadioGroup component are as shown below: (Figure 1-2) The skin of the RadioGroup component cannot use the nine-square grid attribute, so the actual application size must be determined during resource design. 1.2 RadioGroup properties The unique properties of RadioGroup are as follows: (Figure 1-3) Properties Function description bgColor The background color of the radio button group. After checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color skin The skin texture resource of the radio button. After setting, you need to set the stateNum skin state number according to the skin resource state number The number of states of the radio button skin, supporting single state (1), two states (2) and three states (3) labels A collection of text labels for the radio button group. The number of radio button boxes in the radio button group can be determined based on the number of text labels space Spacing between radio button boxes, in pixels direction The arrangement direction of radio button boxes. There are two types: vertical (vertical arrangement) and horizontal (horizontal arrangement) selectedIndex Select index, default is -1. Once set, the radio button will remain selected. The number of indexes will dynamically change based on the number of labels (number of radio button boxes) labelFont Font for text labels labelSize Font size of text labels labelBold Whether the text label is bold, the default is false labelColors The color of the text label in each state when the mouse is released (up), when the mouse moves to the element (over), and when the mouse is pressed (down) labelStroke The stroke width of the text label, in pixels. The default value is 0, which means no stroke labelStrokeColor The color of the text label stroke, expressed as a string, the default value is #000000 (black) labelAlign Horizontal alignment mode of text label: left, center, right, default is left aligned labelPadding Margins for text labels. Format: top margin, right margin, bottom margin, left margin strokecolors After checking, you can set the stroke color of the text according to the status. It can be set in three states: when the mouse is released on the element (up), when the mouse moves to the element (over), and when the mouse is pressed (down). Different stroke colors can be set in the three states You can increase the number of radio button boxes by setting the labels attribute. As shown in the animation 1-4, there are only two radio button boxes in the default radio button group. If you want to add a radio button, just add a new label in the labels attribute, and modify the content of the text label also set in this attribute. (Animation 1-4) You can also change the layout direction and spacing of the radio group RadioGroup. The default layout of RadioGroup is horizontal (horizontal). By changing the direction attribute, vertical layout (vertical) is achieved. Setting the spacing can be achieved through the space attribute, as shown in Figure 1-5. (Figure 1-5) To set the default selected options of the radio group RadioGroup, you need to set it through the selectedIndex attribute. This property changes the index value of the radio button group. When the default setting is -1, no option box is selected. Set to 0 for the 1st radio button, 1 for the 2nd...and so on. Assume that when the attribute value is set to 1, the effect is as shown in Figure 1-6. (Figure 1-6) 1.3 Script control RadioGroup In the Scene2D property settings panel, add a custom component script. Then, drag the RadioGroup into its exposed property entry. You need to add the following sample code to implement script control of RadioGroup: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.RadioGroup }) public radiogroup: Laya.RadioGroup; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.radiogroup.pos(100, 100); this.radiogroup.labels = \"label0,label1,label2\"; this.radiogroup.space = 20; this.radiogroup.selectedIndex = 0; this.radiogroup.direction = \"vertical\"; } } 2. Create a custom RadioGroup component In the previous section, the same radio button resource was used, and three radio button boxes were generated by setting labels in RadioGroup. However, in actual games, there are different requirements for radio button styles in the same RadioGroup component, so this requirement cannot be fulfilled by setting labels. At this time, you need to use a custom RadioGroup component. Here are the specific steps: 2.1 Prepare art resources Use three different Raido radio button art resources to form a custom RadioGroup component. The resources are shown in Figure 2-1. (Figure 2-1) Tips： Pay special attention to the naming rules of skin pictures here. In the custom RadioGroup component, you cannot use RadioGroup or RadioGroup_ as the prefix. Because the Radio radio button component is used as its child component, the image resource in this example is named with the radio_ prefix. 2.2 Create Radio component in IDE Copy the resources to the resource folder of the project, and then in the IDE, drag the Radio components to the scene editor one by one, from left to right (or from top to bottom). Then modify the name attribute of each Radio component to \"item0, item1, item2...\" in order (if the name attribute is not added according to this rule, the generated RadioGroup component will be an invalid component and cannot run normally) . After setting the skin, text, size, position and other properties of each Radio component, the effect is as shown in Figure 2-2. (Figure 2-2) 2.3 Convert to RadioGroup container After modifying the sub-item properties, select all sub-components, right-click to bring up the settings panel, click Convert to Container->RadioGroup, and finally convert to the RadioGroup container type, the steps are shown in the animation 2-3. (Animation 2-3) After the conversion is successful, as shown in Figure 2-4, you need to ensure that the value of the skin attribute of RadioGroup is empty. In this way, the three radio button styles in the same RadioGroup component are all different. (Figure 2-4) Developers can also adjust the properties of the RadioGroup component, and the final effect is as shown in the following animation: (Animation 2-5) 3. Create RadioGroup through code When writing code, it is inevitable to control the UI through code, create the UI_RadioGroup class, and set RadioGroup-related properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_RadioGroup extends Laya.Script { private SPACING: number = 150; private X_OFFSET: number = 200; private Y_OFFSET: number = 80; private skins: any[]; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.skins = [\"resources/res/ui/radioButton (1).png\", \"resources/res/ui/radioButton (2).png\", \"resources/res/ui/radioButton (3).png\"]; Laya.loader.load(this.skins).then(() => { this.onLoadComplete(); }); } private onLoadComplete(e: any = null): void { for (let i: number = 0; i The effect is as shown in the figure: (Figure 3-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:06:28 "},"IDE/uiEditor/uiComponent/CheckBox/readme.html":{"url":"IDE/uiEditor/uiComponent/CheckBox/readme.html","title":"CheckBox","keywords":"","body":"Multiple selection box component (CheckBox)1. Create the CheckBox component through LayaAir IDE1.1 Create CheckBox1.2 CheckBox attribute1.3 Script control CheckBox2. Code to create CheckBoxMultiple selection box component (CheckBox) CheckBox is a multi-select box component, inherited from Button. It consists of two parts, the selection status box and the content description label. The selection status box is an image resource, and the content description label is text. For an introduction to the property interface of the CheckBox component, please refer to CheckBox API. 1. Create the CheckBox component through LayaAir IDE 1.1 Create CheckBox As shown in Figure 1-1, click to select the CheckBox component in the widget panel, drag it to the page editing area, or create it by right-clicking in the hierarchy window to add the CheckBox component to the page. (Picture 1-1) The selection state box of the CheckBox component is an image resource, usually a three-state or two-state image resource. The default skin resources are as shown below: (Figure 1-2) 1.2 CheckBox attribute The unique properties of CheckBox are as follows: (Figure 1-3) Attribute name Function description toggle Whether to switch the display state of the component when pressed. When true, the display state can be switched by clicking. When it is false, the initial state will be restored directly after clicking. Generally do not change this attribute to false, otherwise it will never be selected state number The number of skin states of the selection box. It supports two states and three states. The multi-select box defaults to three states. If the art resource of the multi-select box is changed to two states, the state value needs to be set to 2. Under normal circumstances, the multi-select box should have at least 2 states. In special cases, you can also use monomorphic selected Whether the multi-select box is selected, the default is false. After setting to true, the initial state of the multi-select box will change to remain selected skin The image resource of the selection box. After setting, the stateNum skin state number needs to be set according to the skin resource sizeGrid The nine-square grid is invalid in the CheckBox component. The actual size of the multi-select box needs to be set when creating art resources label Text label for checkbox labelFont Font for text labels labelSize Font size of text labels labelBold Whether the text label is bold, the default is false labelColors When the mouse moves out (up), the mouse hovers (over), and the mouse is pressed down (down), the color of the text label in each state labelAlign Horizontal alignment mode of text label: left, center, right, default is left aligned labelVAlign Vertical alignment mode of text label: top, middle, bottom, the default is top alignment labelPadding Margins for text labels. Format: top margin, right margin, bottom margin, left margin labelStroke The stroke width of the text label, in pixels. The default value is 0, which means no stroke labelStrokeColor The color of the text label stroke, expressed as a string, the default value is #000000 (black) strokeColors After checking, you can set the stroke color of the text according to the status. It can be set in three states: mouse out (up), mouse hover (over), mouse down (down). Different stroke colors can be set in the three states Compared with the radio button component, the feature of the multi-select box component is that the state can be restored after selection, as shown in the animation 1-4. (Animation 1-4) The remaining properties are the same as Button. Developers can understand according to the documentation of Button Component. 1.3 Script control CheckBox In the Scene2D property settings panel, add a custom component script. Then, drag the CheckBox component into its exposed property entry. You need to add the following sample code to implement script control CheckBox: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.CheckBox }) public checkbox: Laya.CheckBox; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.checkbox.pos(300, 300); // this.checkbox.selected = true; this.checkbox.label = \"Multiple checkbox\"; this.checkbox.labelBold = true; this.checkbox.labelSize = 30; this.checkbox.labelColors = \"#0100ff, #16fa0e, #ff0000\"; //Text color in each state this.checkbox.labelStroke = 3; this.checkbox.strokeColors = \"#000000, #c6ff00, #001aff\"; //Stroke colors in each state } } 2. Code to create CheckBox When writing code, it is inevitable to control the UI through code, create the UI_CheckBox class, and set CheckBox related properties through code. The following example demonstrates how to create a CheckBox component and set its properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_CheckBox extends Laya.Script { private COL_AMOUNT: number = 2; private ROW_AMOUNT: number = 3; private HORIZONTAL_SPACING: number = 200; private VERTICAL_SPACING: number = 100; private X_OFFSET: number = 100; private Y_OFFSET: number = 50; //Image resources come from \"Engine API Usage Example\" private skins: any[] = [ \"resources/res/ui/checkbox (1).png\", \"resources/res/ui/checkbox (2).png\", \"resources/res/ui/checkbox (3).png\", \"resources/res/ui/checkbox (4).png\", \"resources/res/ui/checkbox (5).png\", \"resources/res/ui/checkbox (6).png\" ]; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { Laya.loader.load(this.skins).then(() => { this.onCheckBoxSkinLoaded(); }); } private onCheckBoxSkinLoaded(e: any = null): void { let cb: Laya.CheckBox; for (let i: number = 0; i The running effect is shown in the following animation: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:46:15 "},"IDE/uiEditor/uiComponent/navigationMenu/readme.html":{"url":"IDE/uiEditor/uiComponent/navigationMenu/readme.html","title":"Navigation Menu","keywords":"","body":"Navigation menu componentNavigation tab group componentNavigation container componentNavigation menu component The navigation menu is composed of two container components, namely the navigation label group component and the navigation container component. Navigation tab group component Navigation container component Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 09:58:19 "},"IDE/uiEditor/uiComponent/Tab/readme.html":{"url":"IDE/uiEditor/uiComponent/Tab/readme.html","title":"Tab","keywords":"","body":"Navigation label group component (Tab)1. Create Tab component through LayaAir IDE1.1 Create Tab1.2 Tab attribute1.3 Script control Tab2. Create Tab component through codeNavigation label group component (Tab) Tab is a navigation label group component, which is used to define a tab button group, such as multi-page switching display. The effect is shown in animation 1. For detailed attributes of Tab, please refer to Tab API. (Animation 1) 1. Create Tab component through LayaAir IDE 1.1 Create Tab It is very simple to create Tab using LayaAir IDE. Through the visual operation of IDE, you can realize the creation and layout of components, which is also the recommended way to create components. You can create it by right-clicking on the hierarchy panel, or you can select the Tab component in the widget panel and drag and drop to add it, as shown in Figure 1-1. (Picture 1-1) The skin of the Tab component is generally a vertically divided two-state diagram or a three-state diagram. The default skin resource is three-state, as shown in Figure 1-2. (Figure 1-2) Note: The skin of the Tab component cannot use the nine-square grid attribute, so the actual application size must be determined during resource design. 1.2 Tab attribute The unique properties of the Tab component are as follows: (Figure 1-3) Properties Description bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color skin The component's skin texture resource. After setting, you need to set the stateNum skin state number according to the skin resource state number The number of states of the component skin, supporting single state (1), two states (2) and three states (3) labels Collection of text tags, separated by commas (English input method). The number of labels in the navigation label group can be determined based on the number of text labels space The space between labels, in pixels direction The arrangement direction of navigation labels. There are two types: vertical (vertical arrangement) and horizontal (horizontal arrangement) selectedIndex Select index, default is 0. Once set, the navigation label remains selected. The number of indexes will dynamically change based on the number of labels (number of labels) labelFont Font for text labels labelSize Font size of text labels labelBold Whether the text label is bold, the default is false labelColors When the mouse moves out (up), the mouse hovers (over), and the mouse is pressed down (down), the color of the text label in each state labelStroke The stroke width of the text label, in pixels. The default value is 0, which means no stroke labelStrokeColor The color of the text label stroke, expressed as a string, the default value is #ffffff (white) labelAlign Horizontal alignment mode of text label: left, center, right labelPadding Margins for text labels. Format: top margin, right margin, bottom margin, left margin strokeColors After checking, you can set the stroke color of the text according to the status. It can be set in three states: mouse out (up), mouse hover (over), mouse down (down). Different stroke colors can be set in the three states The Tab component can add labels through labels, as shown in the animation 1-4. There are only two labels in the default Tab component. If you want to add labels, just add them in the labels attribute, and modify the text content in the labels also set in this attribute. (Animation 1-4) To change the layout direction and spacing of the Tab component, you can set it by changing the direction attribute. The default is horizontal layout (horizontal), and the vertical layout is vertical. Setting the spacing between labels can be achieved through the space attribute. The operation is shown in the animation 1-5. (Animation 1-5) Setting the default options of Tab can be achieved through the selectedIndex attribute. The selectedIndex attribute is used to change the index value of the Tab component. When it is not set by default, no option is selected. 0 is the first tab, 1 is the second tab...and so on. The effect is shown in the animation 1-6. (Animation 1-6) 1.3 Script control Tab In the Scene2D property settings panel, add a custom component script. Then, drag the Tab component into its exposed property entry. You need to add the following sample code to implement script control Tab: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.Tab }) public tab: Laya.Tab; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { this.tab.pos(200, 200); this.tab.labelBold = true; this.tab.labelSize = 20; this.tab.labelStrokeColor = \"#000000\"; this.tab.labels = \"Tab 1,Tab 2,Tab 3\"; this.tab.labelColors = \"#32556b,#8FB299,#ff0000\"; this.tab.selectedIndex = -1; } } 2. Create Tab component through code When writing code, it is inevitable to control the UI through code, create the UI_Tab class, and set Tab-related attributes through code. The following example demonstrates how to create a Tab component and set its properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Tab extends Laya.Script { //Image resources come from \"Engine API Usage Example\" private skins: any[] = [\"resources/res/ui/tab1.png\", \"resources/res/ui/tab2.png\"]; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load(this.skins).then( ()=>{ this.onLoadComplete(); } ); } private onLoadComplete(e: any = null): void { let tabA: Laya.Tab = this.createTab(this.skins[0]); tabA.pos(40, 120); tabA.labelColors = \"#000000,#d3d3d3,#333333\"; let tabB: Laya.Tab = this.createTab(this.skins[1]); tabB.pos(40, 220); tabB.labelColors = \"#FFFFFF,#8FB299,#FFFFFF\"; } private createTab(skin: string): Laya.Tab { let tab: Laya.Tab = new Laya.Tab(); tab.skin = skin; tab.labelBold = true; tab.labelSize = 20; tab.labelStrokeColor = \"#000000\"; tab.labels = \"Tab Control 1,Tab Control 2,Tab Control 3\"; tab.selectedIndex = 1; this.onSelect(tab.selectedIndex); tab.selectHandler = new Laya.Handler(this, this.onSelect); this.owner.addChild(tab); return tab; } private onSelect(index: number): void { console.log(\"The currently selected tab index is \" + index); } } The running effect is shown in the following animation: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:15:33 "},"IDE/uiEditor/uiComponent/ViewStack/readme.html":{"url":"IDE/uiEditor/uiComponent/ViewStack/readme.html","title":"ViewStack","keywords":"","body":"Navigation container component (ViewStack)1. Create ViewStack1.1 Prepare art resources1.2 Create page1.3 Set the name attribute of the ViewStack component subpage1.4 Set ViewStack’s page index selectedIndex1.5 Create control Tab tags1.6 Control ViewStack component switching display through code2. ViewStack propertyNavigation container component (ViewStack) This article will involve some knowledge of the Tab component. Please read the documentation of Tab component first. The ViewStack component is a navigation container component, mainly used for multi-page view switching. It contains multiple subpages, but only one is displayed by default. The display can be switched through the subpage index. Under normal circumstances, it is used in combination with the Tab tag to create a tab switching page, and the effect is as shown in animation 1. For detailed usage of the ViewStack component, please see ViewStack API. (Animation 1) 1. Create ViewStack 1.1 Prepare art resources Prepare the page background image and the page art resources that need to be switched, as shown in Figure 1-1, and place them in the project directory of LayaAir IDE. (Picture 1-1) The resources in the picture are from \"2D Getting Started Example\". Then set the background’s Jiugongge attribute, as shown in Figure 1-2. (Figure 1-2) 1.2 Create page As shown in Figure 1-3, drag the background image with the nine-square grid just set into the scene, then create the sub-node ViewStack page, and then drag the basic UI components involved in the page to the ViewStack component as its sub-page. And adjust the UI layout of the page. (Figure 1-3) The ViewStack component is a container component and does not have independent component resource specifications. In this example, the Image component resource is used directly. In actual game development, various UI components can be used according to actual development needs. 1.3 Set the name attribute of the ViewStack component subpage The naming rules for the name attribute of ViewStack subpages are item0, item1, item2....\" If there are more pages, the same applies, as shown in Figure 1-4. (Figure 1-4) If you do not add the name attribute according to this rule, the generated ViewStack component will be an invalid component and cannot run normally. 1.4 Set ViewStack’s page index selectedIndex The ViewStack component displays item0 by default. You can change the default display page of the ViewStack component by adjusting the selectedIndex attribute value. The effect is as shown in animation 1-5. (Animation 1-5) 1.5 Create control Tab tags Usually, the ViewStack component requires a corresponding control label, and a Tab label is created to control the switching display of ViewStack's subpages. Click to select the Tab resource in the resource panel and drag it to the scene to generate the Tab component. Then, adjust the position to align with the background image. Set labels to \"Page 0, Page 1, Page 2\", and set the selected button index selectedIndex to 0. Finally, set the font size, boldness, font status color and other properties. The display effect after setting is shown in Figure 1-6: (Figure 1-6) 1.6 Control ViewStack component switching display through code After creating a Tab, you need to associate the Tab label with the ViewStack's subpage switching display through program code. In the Scene2D property settings panel, add a custom component script. Then, drag the ViewStack and Tab components into their exposed property entries. The following sample code needs to be added: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { @property({ type: Laya.ViewStack }) public viewstack: Laya.ViewStack; @property({ type: Laya.Tab }) public tab: Laya.Tab; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Click the Tab selection button processing this.tab.selectHandler = new Laya.Handler(this, this.onSelecte); } //Switch pages based on the index of the selected tab private onSelecte(index: number): void { //Switch ViewStack subpage this.viewstack.selectedIndex = index; } } The final effect is shown in the animation 1-7: (Animation 1-7) 2. ViewStack property The unique properties of ViewStack are as follows: (Figure 2-1) Properties Description bgColor Background color, after checking, you can directly enter the color value, for example: #ffffff, or you can click the color picker on the right side of the input bar to select a color selectedIndex Select index, default is 0, indicating the first item. -1 means there are no selected items. The number of indexes will dynamically change based on the number of sub-items (number of items) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:22:39 "},"IDE/uiEditor/uiComponent/ColorPicker/readme.html":{"url":"IDE/uiEditor/uiComponent/ColorPicker/readme.html","title":"ColorPicker","keywords":"","body":"Color picker component (ColorPicker)1. Create ColorPicker through LayaAir IDE1.1 Create ColorPicker1.2 ColorPicker properties2. Create ColorPicker through codeColor picker component (ColorPicker) ColorPicker inherits from UIComponent. The ColorPicker component will display a list of multiple color samples from which the user can select a color. For detailed usage of ColorPicker, please refer to ColorPicker API. 1. Create ColorPicker through LayaAir IDE 1.1 Create ColorPicker As shown in Figure 1-1, click to select the ColorPicker component in the widget panel, drag and drop it into the page editing area, or create it by right-clicking in the hierarchy window to add the ColorPicker component to the page. (Picture 1-1) 1.2 ColorPicker properties The unique properties of ColorPicker are as follows: (Figure 1-2) Properties Function bgColor Color picker panel background color borderColor Color picker panel border color inputBgColor The background color of the color picker panel text box inputColor The color of the text font in the color picker panel text box selectedColor ColorPicker currently selected color skin The skin texture resource of the component will change according to the selected color at runtime After the ColorPicker component gets the color value, it can be assigned in the project. It is very simple under the visual operation of the IDE. Just click on the color that needs to be adjusted and select it in the color panel. 2. Create ColorPicker through code When writing code, it is inevitable to control the UI through code, create the UI_ColorPicker class, and set ColorPicker related properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_ColorPicker extends Laya.Script { private skin: string = \"atlas/comp/colorPicker.png\"; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { Laya.loader.load(this.skin).then( ()=>{ this.onColorPickerSkinLoaded(); } ); } private onColorPickerSkinLoaded(e: any = null): void { let colorPicker: Laya.ColorPicker = new Laya.ColorPicker(); colorPicker.selectedColor = \"#ff0033\"; colorPicker.skin = this.skin; colorPicker.pos(100, 100); colorPicker.changeHandler = new Laya.Handler(this, this.onChangeColor, [colorPicker]); this.owner.addChild(colorPicker); this.onChangeColor(colorPicker); } private onChangeColor(colorPicker: Laya.ColorPicker, e: any = null): void { console.log(colorPicker.selectedColor); } } The running effect is shown in the following animation: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:48:50 "},"IDE/uiEditor/uiComponent/OpenDataContextView/readme.html":{"url":"IDE/uiEditor/uiComponent/OpenDataContextView/readme.html","title":"OpenDataContextView","keywords":"","body":"Open data domain (OpenDataContextView)1. Create OpenDataContextView in LayaAir IDE2. Code to create OpenDataContextView3. Function and effectOpen data domain (OpenDataContextView) 1. Create OpenDataContextView in LayaAir IDE As shown in Figure 1-1, you can right-click in the 'Hierarchy' window to create it, or you can drag and drop from the 'Widgets' window to add it. (Picture 1-1) After adding the OpenDataContextView component to the view area of ​​the scene editor, the exclusive properties of the OpenDataContextView component in the properties panel are as shown below: (Figure 1-2) It has only one attribute, FPS, which represents sharedCanvas (an off-screen canvas that can be accessed by both the main domain and the open data domain, see here) updated to the frame rate of the main domain. In addition to the IDE, you can also use script code to adjust its properties. In the property settings panel of Scene2D, add a custom component script. Then, drag the OpenDataContextView into its exposed property entry. Here is a sample code to implement script control of OpenDataContextView: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.OpenDataContextView }) public opendata: Laya.OpenDataContextView; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { this.opendata.pos(100,100); this.opendata.size(500,500); } } 2. Code to create OpenDataContextView Sometimes, you don't want the OpenDataContextView to be on the stage from the beginning, so you have to create it through code. In the property settings panel of Scene2D, add a custom component script. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { let opendata = new Laya.OpenDataContextView(); Laya.stage.addChild(opendata); opendata.pos(100,100); opendata.size(500,500); } } 3. Function and effect The open data domain is generally used to display friend rankings. It needs to be published as a WeChat mini-game, and then the WeChat developer tools can be used to see the effect. For detailed procedures, please refer to \"WeChat Mini Game\". Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:00:22 "},"IDE/uiEditor/Dialog/readme.html":{"url":"IDE/uiEditor/Dialog/readme.html","title":"Dialog","keywords":"","body":"Pop-up view component (Dialog)1. Create Dialog through LayaAir IDE1.1 Create Dialog1.2 Introduction to Dialog attributes1.3 Script control Dialog2. Create Dialog through codePop-up view component (Dialog) Dialog is a pop-up view component, mainly used for pop-up panels. 1. Create Dialog through LayaAir IDE 1.1 Create Dialog As shown in Figure 1-1, click to select the Dialog component in the widget panel, drag and drop it into the page editing area, or create it by right-clicking in the hierarchy window to add the Dialog component to the page. (Picture 1-1) 1.2 Introduction to Dialog attributes The unique attributes of Dialog are as follows: (Figure 1-2) Properties Function autoDestoryAtClosed Whether the scene is automatically destroyed (destroying nodes and used resources) after the scene is closed. The default is false dearArea Drag area (format: x,y,width,height), the default value is \"0,0,0,0\" isModal Whether it is a modal window, the default is false. When it is a modal window, click on the blank space of the pop-up window to automatically close the pop-up window isShowEffect Whether to display the pop-up effect, the default is on. When false, there is no pop-up effect and the pop-up window is displayed directly isPopupCenter Specifies whether the dialog box pops up in the center, the default is true. When it is false, the coordinate origin of the upper left corner will pop up group Set the group ID of resources. After setting, resources can be loaded or cleaned by group. After setting the dragArea attribute, the Dialog can be dragged within the set value range. Set it to \"0,0,100,100\", the effect is as shown in the animation 1-3, the red area is the draggable area. After setting, you can only drag within the set value. Dragging in the area beyond the value is invalid. (Animation 1-3) 1.3 Script control Dialog 1.3.1 Create pop-up window Dialog's pop-up effect requires it to be used as the root node. You can create a 2D prefab Prefab2D in the project resource panel, as shown in Figure 1-4. (Figure 1-4) Double-click Prefab2D to enter the editing interface. Right-click the root node, select \"Convert Node Type\", and select UI->Dialog, as shown in the animation 1-5. (Animation 1-5) Then, you can create a pop-up page in the editing interface of the prefab. The result is shown in Figure 1-6. (Figure 1-6) The UI image resources in the picture are from \"2D Getting Started Example\". 1.3.2 Set the close button In the pop-up page, there is a close button (closeBtn), and a script needs to be added to implement the logic of closing the page. As shown in the animated picture 1-7, check the define variable option of closeBtn, and then double-click \"UI Runtime\" of Prefab2D to create a UI component script. (Animation 1-7) After saving the scene, add the following code in RuntimeScript.ts: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { this.closeBtn.on(Laya.Event.CLICK, this, () => { this.close(); }); } } 1.3.3 Related scenarios After setting up the pop-up window, you need to use code to associate the Dialog with the scene tube that needs to use the Dialog. Return to the initial scene Scene and add a custom component script in the property settings panel of Scene2D. Add the following code to pop up the Dialog page after a mouse click: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { //Execute after mouse click onMouseClick(): void { //Using Prefab, you need to convert the root node to Dialog Laya.loader.load(\"resources/Prefab2D.lh\").then(res => { let dlg: Laya.Dialog = res.create(); dlg.show(); }); } } The running effect is as follows: (GIF) 2. Create Dialog through code When writing code, it is inevitable to control the UI through code, create the UI_Dialog class, and set Dialog-related properties through code. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class UI_Dialog extends Laya.Script { private DIALOG_WIDTH: number = 220; private DIALOG_HEIGHT: number = 275; private CLOSE_BTN_WIDTH: number = 43; private CLOSE_BTN_PADDING: number = 5; private assets: any[]; private dialog: Laya.Dialog; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Image resources come from \"Engine API Usage Example\" this.assets = [\"resources/res/ui/dialog (1).png\", \"resources/res/ui/close.png\"]; Laya.loader.load(this.assets).then( ()=>{ this.onSkinLoadComplete(); } ); } private onSkinLoadComplete(e: any = null): void { this.dialog = new Laya.Dialog(); let bg: Laya.Image = new Laya.Image(this.assets[0]); this.dialog.addChild(bg); let button: Laya.Button = new Laya.Button(this.assets[1]); button.name = Laya.Dialog.CLOSE; button.pos(this.DIALOG_WIDTH - this.CLOSE_BTN_WIDTH - this.CLOSE_BTN_PADDING, this.CLOSE_BTN_PADDING); this.dialog.addChild(button); this.dialog.dragArea = \"0,0,\" + this.DIALOG_WIDTH + \",\" + this.DIALOG_HEIGHT; this.dialog.show(); } onDestroy(): void { if (this.dialog) { this.dialog.close(); } } } The effect is shown in the following animation: (Animation 2-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 10:48:58 "},"IDE/uiEditor/uiComponent/skeleton/readme.html":{"url":"IDE/uiEditor/uiComponent/skeleton/readme.html","title":"skeleton","keywords":"","body":"Skeletal animationSkeletal animation The skeletal animation of the LayaAir engine includes two major categories: One is to convert third-party skeletons (keel and spine) into the engine's built-in skeleton animation file format. The other is to directly encapsulate Spine's skeletal animation action library. The built-in skeletal animation has better performance, but is limited by the version of the conversion tool and only supports spine versions prior to 3.8. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:12:54 "},"IDE/uiEditor/uiComponent/skeleton/spine/readme.html":{"url":"IDE/uiEditor/uiComponent/skeleton/spine/readme.html","title":"spine","keywords":"","body":"Spine skeleton animation1. Overview2. Using Spine animation in IDE2.1 Copy spine resources to the project2.2 Add spine animation component to the scene2.3 Set animation resources2.4 Preview animation in IDE2.5 Basic animation operations3. Spine animation in codeSpine skeleton animation 1. Overview Spine skeletal animation is one of the skeletal animations often used in games. Spine tools are used to bind pictures to bones and then control the bones to achieve animation. How to make Spine skeleton animations will not be introduced here. Interested developers can check it out on the Spine official website. http://zh.esotericsoftware.com/ LayaAir IDE supports adding, previewing and running Spine animation. Before use, you need to check the class library in the IDE and select the Spine version (Picture 1-1) Check the laya.ani class library Check the laya.spine class library Select the Spine version used by this project LayaAir currently supports versions 3.7, 3.8 and 4.0. Next, we will explain the use in the IDE by using the Spine animation of version 3.8. 2. Using Spine animation in IDE 2.1 Copy spine resources to the project As shown in Figure 2-1, we put the completed Spine animation resources into the assets directory. Here we use the example downloaded from the Spine official website. (Figure 2-1) 2.2 Add spine animation component to the scene There are two ways to add Spine animation components to the scene in the IDE. Drag directly into the Spine animation component, as shown in animation 2-2 (Animation 2-2) Create a Spine animation component through Scene2D or any node, as shown in animation 2-3 (Animation 2-3) At this point, the Spine animation component is ready. The next step is to drag in the animation resources. 2.3 Set animation resources Let’s first take a look at the Spine animation component and what properties it has, as shown in Figure 2-4. (Figure 2-4) Source: configuration file of spine animation, that is, .skel file Skin Name: skeleton animation name Animation Name: Play animation name Loop: Whether to loop playback Preview: Preview in IDE First, we drag the .skel file into the Source property, and we will see the animation in the IDE, as shown in animation 2-5 (Animation 2-5) 2.4 Preview animation in IDE By checking the Preview option, we can preview the Spine animation effect directly in the IDE, as shown in animation 2-6 (Animation 2-6) At the same time, you can check Loop to set whether to loop the animation, or you can select the animation name to switch the animation. 2.5 Basic animation operations In the IDE, you can perform basic operations on the position, size, and scaling of the animation, as shown in animation 2-7. (Animation 2-7) 3. Spine animation in code When used in code, we need to reference the specified classes when using Spine: Laya.SpineSkeleton and Laya.SpineTemplet Among them, Laya.SpineSkeleton is a class that must be referenced for spine skeletal animation. The runtime library of spine is encapsulated here. Laya.SpineTemplet is used for resource processing. Code example: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { private skeleton: Laya.SpineSkeleton; private index: number = -1; onStart() { console.log(\"Game start\"); //Load Spine animation resources Laya.loader.load(\"spine/spineboy-pma.skel\", Laya.Loader.SPINE).then((templet: Laya.SpineTemplet) => { //Create SpineSkeleton object this.skeleton = new Laya.SpineSkeleton(); this.skeleton.temple = temple; this.owner.addChild(this.skeleton); this.skeleton.pos( Laya.stage.width / 2, Laya.stage.height / 2 + 100); this.skeleton.scale(0.4, 0.4); this.skeleton.on(Laya.Event.STOPPED, this, this.play); this.play(); }); } //Play Spine animation private play(): void { if (++this.index >= this.skeleton.getAnimNum()) { this.index = 0 } this.skeleton.play(this.index, false, true) } } You can view the specific effects in the LayaAir 2D Getting Started Example. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:11:31 "},"IDE/uiEditor/uiComponent/skeleton/sk/readme.html":{"url":"IDE/uiEditor/uiComponent/skeleton/sk/readme.html","title":"sk","keywords":"","body":"Built-in skeletal animation1. Overview2. Use built-in skeletal animation in IDE2.1 Copy animation resources to the project2.2 Add built-in skeletal animation components to the scene2.3 Set animation resources2.4 Preview animation in IDE2.5 Basic animation operations3. Built-in skeletal animation in the codeBuilt-in skeletal animation 1. Overview Spine skeletal animation and DragonBones (dragon bone) skeletal animation are commonly used skeletal animations in games. Using LayaAir's built-in skeletal conversion tool, these two formats can be converted into skeletal animation formats supported by the LayaAir engine. LayaAir IDE supports adding, previewing and running skeletal animation. Before use, you need to check the laya.ani class library in the IDE, as shown in Figure 1-1 (Picture 1-1) 2. Use built-in skeletal animation in IDE 2.1 Copy animation resources to the project As shown in Figure 2-1, we put the completed animation resources into the assets directory. (Figure 2-1) 2.2 Add built-in skeletal animation components to the scene There are two ways in the IDE to add built-in skeletal animation components to the scene. Drag the skeletal animation component directly, as shown in animation 2-2 (Animation 2-2) Create a skeletal animation component through Scene2D or any node, as shown in animation 2-3 (Animation 2-3) At this point the skeletal animation component is ready. The next step is to drag in the animation resources. 2.3 Set animation resources Let’s first take a look at the skeletal animation components and what properties they have, as shown in Figure 2-4 (Figure 2-4) Source: skeletal animation configuration file, that is, .sk file Skin Name: skeleton animation name Animation Name: Play animation name Loop: Whether to loop playback Preview: Preview in IDE First, we drag the .sk file into the Source property, and we will see the animation in the IDE, as shown in animation 2-5 (Animation 2-5) 2.4 Preview animation in IDE By checking the Preview option, we can preview the skeletal animation effect directly in the IDE, as shown in animation 2-6 (Animation 2-6) At the same time, you can check Loop to set whether to loop the animation, or you can select the animation name to switch the animation. 2.5 Basic animation operations In the IDE, you can perform basic operations on the position, size, and scaling of the animation, as shown in animation 2-7. (Animation 2-7) 3. Built-in skeletal animation in the code When used in code, we need to reference and specify the Laya.Skeleton and Laya.Templet classes when using skeletal animation Among them, Laya.Skeleton is a class that must be referenced for skeletal animation, and Laya.Templet is used to process resources. Code example: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { private mCurrIndex: number = 0; private mArmature: Laya.Skeleton; onStart() { console.log(\"Game start\"); //Load built-in skeletal animation resources Laya.loader.load(\"skeleton/Dragon/Dragon.sk\").then((templet: Laya.Templet) => { //Creation mode is 1, you can enable dress-up this.mArmature = templet.buildArmature(0); this.mArmature.x = 300; this.mArmature.y = 350; this.mArmature.scale(0.5, 0.5); this.owner.addChild(this.mArmature); //After setting the animation to complete, call completeHandler to continue playing the next animation. this.mArmature.on(Laya.Event.STOPPED, this, this.completeHandler); this.play(); }); } private completeHandler(): void { this.play(); } //Play skeleton animation private play(): void { //Each time to the next animation this.mCurrIndex++; if (this.mCurrIndex >= this.mArmature.getAnimNum()) { this.mCurrIndex = 0; } this.mArmature.play(this.mCurrIndex, false); } } The operation effect is as follows (Animation 3-1) You can view the specific effects in the LayaAir 2D Getting Started Example. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:09:41 "},"IDE/uiEditor/Filter/readme.html":{"url":"IDE/uiEditor/Filter/readme.html","title":"Filter","keywords":"","body":"UI filter effect1. Overview1.1 Create filters in IDE1.2 Effective at the same time2. Color filter2.1 Basic attributes2.2 Code implementation3. Blur filter3.1 Basic attributes3.2 Code implementation4. Glow filter4.1 Basic attributes4.2 Code implementationUI filter effect 1. Overview Filters are mainly used to achieve various special effects on images to achieve the best artistic effect. There are many types of filters, but creating different effects requires different filter functions. LayaAir provides three effects: color filter, blur filter, and glow (or shadow) filter. The blur filter and glow filter consume a lot of performance. 1.1 Create filters in IDE In LayaAir 3.0, in addition to Sprite objects, filters can be applied to any display object, and developers usually use the Image component the most. Select the Image component, and in the miscellaneous items of the property settings panel, add the Filters attribute of the filter, as shown in the animation 1-1, which demonstrates how to use filters on the Image component. (Animation 1-1) As shown in Figure 1-2, you can create a color filter (ColorFilter), a blur filter (BlurFilter), and a glow filter (GlowFilter). (Figure 1-2) 1.2 Effective at the same time As shown in Figure 1-3, different filter effects can be superimposed and take effect at the same time, and developers can set them as needed. (Figure 1-3) 2. Color filter ColorFilter is a color filter. Color filter is a very important part of image post-processing. It can change various parameters in the original image, so that it can present different styles without changing the general image. In actual operation, the main parameters changed by the color filter are brightness, contrast, saturation, hue, etc. Generally speaking, it only changes the color and does not perform any deformation on the image. Correct use of color filters can correct abnormal image exposure and alleviate image distortion, thereby highlighting main details and weakening some not-so-good parts. In the field of art, color filters are also used to present different aesthetic styles. 2.1 Basic attributes As shown in Figure 2-1, color filters have 5 attributes: (Figure 2-1) Color: Set filter color. Brightness: Adjust brightness. Contrast: Adjust contrast. Saturation: Adjust saturation. Hue: Adjust the hue. 2.2 Code implementation There are two types of code control filters: Use the ColorFilter class to create a filter directly. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { // Get the Image component @property({ type: Laya.Image }) public img: Laya.Image; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Create a color filter object let colorFilter: Laya.ColorFilter = new Laya.ColorFilter(); //Add color filter to Image component this.img.filters = [colorFilter]; //Set filter color colorFilter.color(0.5, 0.5, 0.5, 1); //Set filter brightness colorFilter.adjustBrightness(-50); //Set filter contrast colorFilter.adjustContrast(8); //Set filter saturation colorFilter.adjustSaturation(30); //Set filter contrast colorFilter.adjustHue(-15); } } Use code to adjust the Image component that has added filter effects. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { // Get the Image component @property({ type: Laya.Image }) public img: Laya.Image; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Get the color filter object of the Image (the color filter has been added to the Image component in the IDE) let colorFilter: Laya.ColorFilter = this.img.filters[0]; //Set filter color colorFilter.color( 0.5, 0.5, 0.5, 1 ); //Set filter brightness colorFilter.adjustBrightness(-50); //Set filter contrast colorFilter.adjustContrast(8); //Set filter saturation colorFilter.adjustSaturation(30); //Set filter contrast colorFilter.adjustHue(-15); } } The usage of other filters is similar to this. Only the first method, that is, an example of directly creating a filter will be given below. 3. Blur filter BlurFilter is a blur filter that produces a blurry effect. 3.1 Basic attributes As shown in Figure 3-1, the blur filter has only one attribute: (Figure 3-1) Strength: The blur strength value of the blur filter. The larger the value, the blurrier it is. 3.2 Code implementation Use the BlurFilter class to create filters directly. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { // Get the Image component @property({ type: Laya.Image }) public img: Laya.Image; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { let blurFilter: Laya.BlurFilter = new Laya.BlurFilter(); //Set blur intensity blurFilter.strength = 5; //Add a blur filter to the Image component this.img.filters = [blurFilter]; } } 4. Glow filter GlowFilter is a glow filter, which creates a glow or shadow effect, such as outer glow. 4.1 Basic attributes As shown in Figure 4-1, the glow filter has three attributes: (Pic 4-1) Offset: The offset of the luminous filter relative to the component, in the X-axis direction and Y-axis direction. Blur: The edge blur size of the glow filter. The larger the value, the blurrier the edge. Color: The color of the glow filter. 4.2 Code implementation Use the GlowFilter class to create filters directly. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { // Get the Image component @property({ type: Laya.Image }) public img: Laya.Image; //Execute after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Create a glow filter and initialize the filter when creating it let glowFilter: Laya.GlowFilter = new Laya.GlowFilter(\"#ffff00\", 10, 0, 0); // Add a glow filter to the Image component this.img.filters = [glowFilter]; } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:07:25 "},"IDE/uiEditor/runtime/readme.html":{"url":"IDE/uiEditor/runtime/readme.html","title":"runtime","keywords":"","body":"UI runtime1. Overview1.1 Functional division method1.2 UI management method2. UI runtime2.1 IDE automatically generates code2.2 Check UI component declaration2.3 Using UI components in code3. Differences from custom component scripts3.1 Different inheritance classes3.2 Different life cycles3.3 Different ways of using UI components4. Mixed use of UI runtime and custom component scripts4.1 Simple usage4.2 Advanced usageUI runtime 1. Overview During the project development process, developers often do not have clear ideas about UI development, and the development methods are also diverse, which will cause certain confusion on the structure and usage of the project. This article can help developers clarify some ideas. We will expand on these aspects: UI component script (UI runtime, Runtime class) The difference between UI component scripts and custom component scripts Advanced usage of mixing UI component scripts and custom component scripts This article has previously introduced all UI widgets, and in ECS Component System explains how custom component scripts manage UI widgets. In fact, there is another UI management method, which is the UI introduced previously in Project Entry Instructions together with the custom component script Component script, although I have told you how it is created in the IDE, it has not introduced under what circumstances this method is used, so let's first talk about the situations you will encounter in the process of 2D UI development, and then Introducing an in-depth explanation of UI component scripts. 1.1 Functional division method First of all, our project has more than one set of UI. For example, in game development, there is a login interface, loading interface, hero attribute interface, backpack interface, combat interface, etc. So for reasonable planning of these interfaces, we recommend dividing the scenes Or prefab to solve it. As shown in Figure 1-1, there are many UI scenes here. Because the functions of these UIs are different, they are divided into scenes. (Picture 1-1) As shown in Figure 1-2, there are many Prefabs (Prefabs) here. Because the functions of these UIs are the same and can be reused, they are divided into prefabs. (Figure 1-2) Therefore, we usually use scenes to plan each set of UI with different functions; we use prefabs to plan reusable functional UIs. 1.2 UI management method During the UI development process, we will use Image, Box, Tab, etc. UI components provided by LayaAir. For a relatively complex UI interface, it is inconvenient to manage a large number of UI components using custom component scripts. Each component needs to be dragged and dropped into a custom attribute, which is cumbersome and laborious. Therefore, we recommend that developers use UI component scripts to manage UI components. We will talk about the difference between UI component scripts and custom component scripts later. The purpose of UI component script design is to create it at the root node of the scene or prefab, so that all internal components can be more conveniently managed. As shown in Figure 1-3, this is a set of complex UI prefabs, which are managed through UI component scripts (Runtime). (Figure 1-3) As you can see from Figure 1-3, this UI does not use a custom component script, but uses a UI component script (Runtime). Add \"BagListRT.ts\" to the Runtime attribute on the root node View of the prefab. \"Managed by code. 2. UI runtime UI component scripts can only be added to the Runtime entry on the property settings panel of the Scene2D node or the root node of the 2D prefab. If added to Scene2D, its parent class inherits from Laya.Scene; if added to the root node of a 2D prefab, its parent class inherits from the class of the UI widget (according to the node type of the root node of the 2D prefab Certainly). Therefore, the UI component script is the UI runtime, also called the Runtime class, which can conveniently manage all UI components inside the scene or prefab. The creation of UI component scripts in the IDE has been introduced in Project Entry Instructions. Its use is introduced below. 2.1 IDE automatically generates code As shown in Figure 2-1, after creating the UI component script, in addition to generating RuntimeScript.ts, you can see an additional RuntimeScript.generated.ts in the project project. (Figure 2-1) Figure 2-2 shows the code generated by RuntimeScript.ts by default. Its class name RuntimeScript is the file name when it is created. It automatically inherits from the RuntimeScriptBase class when it is generated. (Figure 2-2) Figure 2-3 shows the code generated by RuntimeScript.generated.ts by default. The name of this class is RuntimeScriptBase. It inherits \"Laya.Scene\", indicating that it has scene management capabilities. (Figure 2-3) Note: Please do not modify this code. As we continue to add new UI components and delete UI components during the development process, this code will be automatically updated. This class is named based on the runtime class name xxx. The named file name is xxx.generated.ts and the class name is xxxBase. 2.2 Check UI component declaration To manage UI components in a UI component script, you need to associate the UI components first. Create a new scene, create a UI component script, and add several UI components to the scene (Figure 2-4). (Figure 2-4) To manage these UI components, you need to check the Define variables option for these components, as shown in animation 2-5. (Animation 2-5) After checking the Define Variables option, save the scene. At this time, the IDE will automatically recognize that the declaration of the component has changed. Look at the RuntimeScript.generated.ts code (as shown in Figure 2-6). There are a few more This attribute corresponds to the component just checked. (Figure 2-6) By doing this, UI components and code are automatically associated. 2.3 Using UI components in code At this time, we can use the UI components that have been checked in this scenario in the UI component script and use this. directly. For example the following code: onAwake(): void { //Button adds mouse events so that the Image is not displayed this.Button.on( Laya.Event.MOUSE_DOWN, this, ()=>{ this.Image.visible = false; }); } Run this scene to see the effect, as shown in animation 2-7. (Animation 2-7) The UI component script has been introduced. No matter how complex the UI is, you can check the component declaration and let the IDE automatically create an association and provide it to the Runtime class for use. There is no need to establish associations like custom component scripts, so UI component scripts will be more convenient in managing scenes**. 3. Differences from custom component scripts 3.1 Different inheritance classes If the UI component script is added to Scene2D, its parent class will inherit from Laya.Scene (Figure 3-1); if it is added to the root node of the 2D prefab, its parent class will inherit from the UI widget class. For example, Laya.Box (Figure 3-2). The custom component script inherits from Laya.Scirpt (as shown in Figure 3-3). (Figure 3-1) (Figure 3-2) (Figure 3-3) 3.2 Different life cycles The life cycle of the customized component script is shown in Figure 3-4. (Figure 3-4) The life cycle of UI component scripts has only the following methods: /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. * This method is a virtual method and can be overridden when used. */ onAwake(): void { } /** * Executed after the component is enabled, such as after the node is added to the stage * This method is a virtual method and can be overridden when used. */ onEnable(): void { } /** * Executed when the component is disabled, such as after the slave node is removed from the stage * This method is a virtual method and can be overridden when used. */ onDisable(): void { } /** * Executed when destroyed * This method is a virtual method and can be overridden when used. */ onDestroy(): void { } /** * After the shutdown is completed, call this method (if there is a shutdown animation, it will be executed after the animation is completed) * @param type If it is triggered by clicking the default close button, pass in the name of the close button, otherwise it is null. */ onClosed(type: string = null): void { } /**After the scene is opened, call this method (if there is a pop-up animation, it will be executed after the animation is completed)*/ onOpened(param: any): void{ } Note 1: Whether it is the Scene2D node or the root node of the 2D prefab, their Runtime does not have onStart, onUpdate, and onLateUpdate methods. Note 2: The onOpened and onClosed methods are only available in the Runtime of the Scene2D node, but not in other situations. 3.3 Different ways of using UI components Compared with custom component scripts, UI component scripts can directly use UI-defined properties (by checking Define Variables in the IDE, so it does not need the @property decorator to expose properties), and then directly pass \"this.\" Method usage, such as this.Button, this.Image, has a code prompt effect. Customized component scripts can only be obtained by defining attributes through code, and then dragging nodes into the IDE to obtain nodes or components. Therefore, it is recommended that developers: Generally use custom scripts. Only when there are many components that need to be managed in the page, it can be more convenient to use UI component scripts. 4. Mixed use of UI runtime and custom component scripts 4.1 Simple usage In the above example (Figure 2-4), the UI component script has been created in the Scene scene, and the code added is as follows: const { regClass } = Laya; import { RuntimeScriptBase } from \"./RuntimeScript.generated\"; @regClass() export class RuntimeScript extends RuntimeScriptBase { onAwake(): void { //Button adds mouse events so that the Image is not displayed this.Button.on( Laya.Event.MOUSE_DOWN, this, ()=>{ this.Image.visible = false; }); } } Secondly, you can add custom component scripts under the Scene2D node, as shown in Figure 4-1. (Pic 4-1) At this time, there are both UI component scripts (Runtime) and custom component scripts in the Scene. By adding the following code to the custom component script \"NewScript.ts\", let's see how to use the Runtime function in the custom component script. import { RuntimeScript } from \"./RuntimeScript\"; const { regClass, property } = Laya; @regClass() export class NewScript extends Laya.Script { private ui : RuntimeScript; onStart() { // Get the Runtime object of the scene this.ui = this.owner.scene as RuntimeScript; //Button adds mouse events so that the Image is not displayed this.ui.Button.on( Laya.Event.MOUSE_DOWN, null, ()=>{ this.ui.Image.visible = false; }); } } The ui attribute obtains the Runtime object directly from the script through the code this.owner.scene as RuntimeScript, then the UI components under Runtime can also be obtained directly (this.ui.). After commenting out the \"Button adds mouse event\" code added at the beginning of this section (Section 4.1), run the project, and the effect will still be the one shown in animation 2-7. It shows that the running effect of the above code is consistent with the running effect of the code shown at the beginning. Through the mixed use of UI component scripts and custom component scripts, developers can conveniently use UI components in custom component scripts. 4.2 Advanced usage In the above solution, the custom component script can already obtain the Runtime object of the scene. So in a complex project, if there are many UI interfaces, can we manage all UI interfaces uniformly? For example, find and process all UI-related Buttons in a unified way, so that all Buttons can automatically scale when clicked. Another example is the more advanced use of unifying the adaptive functions of all UIs. Let’s take a look below. 4.2.1 Create multiple scenes So taking the example of \"unifiedly finding and processing all UI Buttons and allowing all Buttons to automatically scale when clicked\", we need to create another UI scene with multiple Buttons and name it \"Button_Scene\", as shown in Figure 4-2. (Figure 4-2) Because different UIs hold different UI components. For example, scene A has components a1 and a2, and scene B has components b1, b2, and b3. Then different scenarios require different runtimes to associate with each UI. s component. Then next step, for this Button_Scene scene, create a UI component script at the Runtime entrance and rename it to \"ButtonRuntime.ts\", as shown in animation 4-3. (Animation 4-3) Next, we need to check the `Define Variables' attribute for Button1, Button2, and Button3 in Button_Scene, and then save the scene. This operation is similar to the animation in Figure 2-5 and will not be described in detail. Finally, we need to add a custom component script to Button_Scene, named \"ButtonScript.ts\", as shown in Figure 4-4. (Figure 4-4) 4.2.2 Create script parent class After the above operations, both scenarios have UI component scripts and custom component scripts. So how to handle them uniformly? We found that the Runtime class is used to associate UI components, because they all inherit from their respective generated scripts (RuntimeScript inherits from RuntimeScriptBase, ButtonRuntime inherits from ButtonRuntimeBase), and they can no longer inherit a certain class uniformly. The custom component script classes (NewScript, ButtonScript) all inherit from Laya.Script, so we can inherit one more layer so that both NewScript and ButtonScript can inherit from a new class \"Main\" (this class is the default when creating a project Generated Main.ts), the Main class inherits from Laya.Script (Figure 4-5), thereby achieving the purpose of unified processing. (Figure 4-5) In addition, add a method baseUI() to the Main class: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { //Used to handle UI things in a unified manner, such as adapting and scaling all Buttons public baseUI(ui: Laya.Scene){ } } Next, modify NewScript and ButtonScript to inherit from Main, obtain the Runtime object, and call Main's baseUI() method, passing in the runtime object, as follows: import { Main } from \"./Main\"; import { RuntimeScript } from \"./RuntimeScript\"; const { regClass, property } = Laya; @regClass() export class NewScript extends Main { private ui: RuntimeScript; onStart() { console.log(\"Game start\"); this.ui = this.owner.scene as RuntimeScript; super.baseUI(this.ui); } } import { Main } from \"./Main\"; import { ButtonRuntime } from \"./ButtonRuntime\"; const { regClass, property } = Laya; @regClass() export class ButtonScript extends Main { private ui: ButtonRuntime; onStart() { console.log(\"Game start\"); this.ui = this.owner.scene as ButtonRuntime; super.baseUI(this.ui); } } Finally, add the code for clicking the zoom Button in Main, as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { //Used to handle UI things in a unified manner, such as adapting and scaling all Buttons public baseUI(ui: Laya.Scene) { this.searchButton(ui); } //Find all Buttons under ui including child nodes searchButton(ui: Laya.Node) { for (let i = 0; i Run the two scenarios separately to see the effect: (Animation 4-6) Scene Button can be clicked to zoom (Animation 4-7) All three Buttons of Button_Scene can be clicked to zoom. At this point, we understand what the UI runtime is, the difference between the UI runtime and the custom component script class, as well as the mixed use method, and the advanced usage of unified management of the UI. Developers can study further and there are more mixed usages. Welcome to communicate with us~ Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:27:21 "},"IDE/uiEditor/use3D/readme.html":{"url":"IDE/uiEditor/use3D/readme.html","title":"use3D","keywords":"","body":"Mix with 3D1. Overview2. Mixing 3D in IDE2.1 Create RenderTexture file in IDE2.2 Add rendering objects to 3D scene2.3 Set the camera’s target texture2.4 Set the Texture of Sprite2.5 Modify rendering texture attributes3. Mixed use of 3D in codeMix with 3D 1. Overview During the development process of 2D projects, developers often need to display 3D scenes or 3D objects on the UI interface. For example, in game development, 3D characters run on the 2D background map, and the 3D hero model will be displayed in the hero attribute interface, etc., such as As shown in animation 1-1, (Animation 1-1) GIF 1-1 is a \"Hybrid 3D\" example in the 2D Getting Started example created by LayaAir. First of all, this function can be easily implemented using RenderTexture in the LayaAir engine. RenderTexture is a special type of texture that is constantly updated and rendered at runtime. A typical use of a render texture is to set it as the camera's \"Target Texture\" property, which will cause the camera to render to the texture instead of rendering to the screen. It can then be used in the Sprite object under 2D UI like a normal texture. Now we will explain how to use rendering textures to mix 3D in the IDE and code. 2. Mixing 3D in IDE 2.1 Create RenderTexture file in IDE As shown in Figure 2-1, first create a render texture (RenderTexture) file in the assets resource of the IDE. (Figure 2-1) Click on the newly created RenderTexture file. In the properties panel, the property information will be displayed, as shown in Figure 2-2. (Figure 2-2) Width: The pixel width of the rendering texture. Height: The pixel height of the rendering texture. Color Format: The color format of the rendering texture. Depth Format: The depth format of the rendering texture. Generate Mipmap: If checked, multi-level progressive texture levels will be automatically generated. Multi Samples: Multiple sampling. sRGB: Whether this render texture uses sRGB read/write conversion (read-only). AnisoLevel: Anisotropy value. FilterMode: Sampling filter mode. WrapModeU: U direction sampling mode. WrapModeV: V direction sampling mode. For this article, the width, height, color format and depth format of the rendering texture have a certain impact on the effect. The default settings are used for the time being. 2.2 Add rendering objects to 3D scene In the 3D scene in the IDE, add the 3D object you want to display. In this example, add LayaMonkey to the 3D scene, as shown in Figure 2-3. (Figure 2-3) The camera is facing LayaMonkey, and the Clear Flag in the Render component of the camera is defined as \"SolidColor\", and the Clear Color is defined as \"#000000\". Then, as shown in Figure 2-4, change the camera to orthogonal projection and adjust the camera's display ratio. (Figure 2-4) 2.3 Set the camera’s target texture Drag the previously created render texture file (RenderTexture) into the camera's target texture (Render Target) property. At this point the camera will render to the texture instead of the screen. As shown in Figure 2-5, (Figure 2-5) 2.4 Set the Texture of Sprite Create a Sprite in Scene2D as a carrier for displaying 3D objects. Drag the previously created rendering texture into the Sprite's Texture property, as shown in animation 2-6. (Animation 2-6) As you can see, LayaMonkey has been displayed in the 2D Sprite, but the background is black. The color format of the rendering texture needs to be modified again to support transparent colors. 2.5 Modify rendering texture attributes As shown in the animation 2-7, modify the color format (Color Format) of the rendering texture to \"R16G16B16A16\", and the background will change from black to transparent. (Note that in Section 2.2, the A value of Clear Color in the camera Render component is set to 0). (Animation 2-7) Observe LayaMonkey carefully. The image is rough. The main reason is that the resolution of the rendering texture (Width×Height) is 256x256 which is too low. The resolution is modified to 1024x1024 below, as shown in the animation 2-8. (Animation 2-8) In this way, LayaMonkey suddenly becomes clear, and now we mix the 3D objects into the UI interface by rendering textures. The running effect is shown in Figure 2-9: (Animation 2-9) 3. Mixed use of 3D in code The \"2D Getting Started Example\" provided by the LayaAir engine has a complete 3D mixed usage code example. The core code is to use Laya.RenderTexture to create a rendering texture and apply the rendering texture to the camera object and Sprite object respectively: // Draw the 3D camera view onto a 256 width and height texture _camera.renderTarget = new Laya.RenderTexture(256, 256, Laya.RenderTargetFormat.R8G8B8A8, Laya.RenderTargetFormat.DEPTHSTENCIL_24_8); // Then draw the off-screen 3D to the 2D node. At this point, the basic rendering process of drawing 3D to 2D is completed. sp.texture = new Laya.Texture(_camera.renderTarget); The running effect is shown in the animation 1-1 at the beginning of this article. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:29:10 "},"IDE/uiEditor/textureCompress/readme.html":{"url":"IDE/uiEditor/textureCompress/readme.html","title":"textureCompress","keywords":"","body":"Texture compression1. Overview1.1 The purpose of texture compression1.2 Texture format types1.3 Summary2. Using texture compression in IDE2.1 Image texture compression2.2 Atlas texture compression3. Code loading texture compression3.1 Loading of image texture compression3.2 Loading of Atlas Texture Compression4. What is the optimization effect?Texture compression 1. Overview Texture refers to the appearance effects such as the pattern and fineness of the surface of an object. In computer graphics, two-dimensional graphics are often used to describe surface patterns of three-dimensional models. The image formats we see and use daily are mainly PNG and JPG. Although in some cases of three-dimensional and two-dimensional images, these images are also called textures, they are not texture formats and cannot be directly read by the GPU. and display. Therefore, these image files must first be decoded by the CPU into texture format and then transferred to the GPU for use. The texture format is naturally a format that can be directly read and displayed by the GPU. Therefore, on the one hand, avoiding CPU decoding can reduce the performance pressure caused by calculations. On the other hand, reading and rendering directly can also avoid the overhead of decompressing the image into memory. 1.1 The purpose of texture compression Reduce memory, especially for mobile applications. The memory usage should not be too large, otherwise low-end machines will easily crash. Reduce bandwidth. For mobile game applications, a large number of textures will be transferred to the GPU during rendering. If there is no limit, it will not only seriously affect the rendering performance, but also cause serious heat generation. 1.2 Texture format types 1.2.1 ASTC ASTC (Adaptive Scalable Texture Compression) is a world-leading new texture compression format. ASTC was jointly developed by ARM and AMD and released in 2012. It is a block-based lossy compression algorithm. Its compression blocks from 4x4 to 12x12 can ultimately compress each pixel to occupy less than 1 bit, and the ASTC format supports RGBA. Taking ASTC 4x4 Block Size as an example, you can see that each pixel occupies 8 bits or 1 byte. Therefore, a 1024x1024 RGBA image will occupy 1MB of memory after being compressed in this format. If your texture chooses to generate mipmap, then the final resource size needs to be multiplied by 1.333, which is approximately 1.333MB. Correspondingly, if ASTC 8x8 format is used for compression, the final texture resource size should be 1024 × 1024 × 2 × 1.333333 ÷ 8 ≈ 341K. So if you want to use smaller compression formats such as 10x10 or 12x12, choosing these two formats basically means giving up the basic requirements for image quality. Therefore we recommend using the 6x6 compression format. Applicable models: iOS: Apple has supported ASTC starting from the A8 processor, which is supported by iPhone 6 and iPad mini 4 and above. The display effect of ASTC format on iOS devices is much better than that of PVRTC (PVRTC format has two big problems: firstly Transparent maps are blurry and distorted when displayed on iOS. Another point is that for pictures with rich colors, especially UI, color scale problems will occur in areas with large color transitions. The current solution is generally to split the Alpha channel. Therefore, in the current situation ASTC can be used as the texture format entirely on iOS. Android: All devices in Android that support OpenGL ES 3.1 and above, and most devices that support OpenGL ES 3.0, support ASTC. Therefore, the texture compression format needs to be set according to the specific situation on Android. Generally speaking, if the project still needs to consider low-end models, it is necessary to use the ETC2 format for compression. 1.2.2 ETC ETC (Ericsson Texture Compression) was originally developed for mobile devices. Today it is the standard compression scheme for Android. ETC1 is supported in OpenGL and OpenGL ES. RGB ETC1 4 bit: 4 bits/pixel, RGB compression ratio 6:1, does not support Alpha, most Android devices support it. RGB ETC2 4 bit: 4 bits/pixel, RGB compression ratio 6:1. Alpha is not supported. ETC2 is compatible with ETC1. The compression quality may be higher, but the error will also be greater for blocks with large chroma changes. OpenGL ES 3.0 and OpenGL 4.3 or above are required. RGBA ETC2 8bit: 8 bits/pixel, RGBA compression ratio 4:1. Supports complete transparent channels, the version requirements are the same as above. 1.2.3 PVR PVRTC (PowerVR Texture Compression) is designed by Imagination specifically for the PowerVR graphics card core. Due to patent reasons, it is generally only used in Apple devices and is only supported by iPhone, iPad and some PowerVR Android machines. 1.2.4 BC1 DXTC (or BC) is a block-based texture compression format launched by Microsoft for DX. It mainly uses the principle of palette for compression. BC1 (Block Compression) is the smallest variant and the one with the highest conversion ratio. It can be used when high precision and a value are not required. It stores 64-bit data as a block of 4x4 pixels, without alpha channel. Each block records two 16-bit colors as the base color, and then uses the two base colors to modulate the other two during decompression. The colors are used as 4 compressed colors within the block. 1.2.5 BC3 BC3 supports alpha channel based on BC1. First of all, the color is stored in the same way as BC1, requiring 64bits; for the alpha part, it is processed using the same strategy as the color part. Store two baseline alpha values ​​in the block, and then interpolate based on them to obtain other 6 alpha values ​​in total, which are used as the alpha palette; then store a 3-bits index for each texel to point to One of these 8 alphas. 1.3 Summary ASTC is quite good in terms of compression rate, image quality, and variety, and is gradually replacing ETC and PVR. The biggest disadvantage may be that the compatibility is not perfect enough and the decoding time is long, but judging from the current development trend of mobile terminals, GPU It is becoming increasingly difficult for computing power to become a bottleneck, so it is very promising that it will become a unified compression format in the future. Collate some information on the Internet: Desktop: Use BC1 if a transparent channel is not required, and BC3 if a transparent channel is required. Android: There is no problem with using ETC2; ASTC is supported after Android 5.0/OpenGL ES 3.1, and is supported by most models in the market. You can consider choosing it. iOS: ASTC is supported on iPhone6 ​​and above (included), and PVRTC2 can be selected on iPhone6 ​​and below. The LayaAir 3.0 engine and tools have also updated this situation, fully supporting the ASTC standard, and still supporting ETC1, ETC2_RGB, ETC2_RGBA, and no longer supporting PVR. Therefore, we recommend using ASTC 6x6 as the unified compressed texture format for Android and iOS, and the two platforms only require one compressed texture file, which also saves project space. 2. Using texture compression in IDE 2.1 Image texture compression As shown in Figure 2-1, LayaAir 3.0 can directly operate images in the IDE and perform texture compression conversion. (Figure 2-1) Click on the \"layabox.png\" picture, you can see in the properties panel on the right that the Default option is used by default, and the texture format selected is \"Bitmap with transparent channel (32-bit)\". Before texture compression, images used this format on all platforms. Texture compression is different on PC and mobile phones. As shown in the animation 2-2, if you select \"Texture Compression (BC1 and ASTC_6×6)\" in the Default option, then PC will use BC1 by default, and Android and IOS uses ASTC_6×6 by default. (Animation 2-2) The Default option here only provides a general setting. If developers have needs, they can also set it separately. The following will introduce the PC and mobile versions respectively. After setting the texture compression format, the corresponding compressed file will not actually be generated in the assets directory. In other words, it cannot be used in preview mode. Compressed textures can only be used after publishing. For publishing methods, please refer to the document \"Web Publishing\". 2.1.1 Desktop Take BC1 as an example on the PC side (BC3 is also possible, but the PC side does not support the ASTC format). Set it as shown in Figure 2-3. After checking PC Platform Settings, you can set the texture format independently. The same applies to setting up other platforms separately. You only need to check the corresponding options, which will be introduced later. (Figure 2-3) As shown in the animation 2-4, after setting up, you can use the image as the skin of the Image component, and then build and publish it. (Animation 2-4) As shown in Figure 2-5, there is a layabox@0.dds file in the released directory, which is an image in the BC1 texture compression format. There is also a .png image generated at the same time, because when setting the texture compression format, although the PC platform is set to BC1, the Android and iOS settings are still \"bitmap with transparent channel (32-bit)\", so it is generated. layabox.png\" is a texture format that runs on Android and iOS. (Figure 2-5) You can find a \"fileconfig.json\" file in the release directory. This file records some image attribute setting information, including texture compression information. Open the .json file as follows: { \"files\": { \"resources\": [ \"layabox.png\" ] }, \"config\": [ { \"sRGB\": true, \"filterMode\": 1, \"mipmap\": true, \"pma\": false, \"files\": [ { \"file\": \"0\", \"ext\": \"dds\", \"format\": 3 }, { \"file\": \"\", \"ext\": \"png\", \"format\": 1 } ], \"platforms\": { \"0\": 0, \"1\": 1, \"2\": 1 }, \"t\": 0, \"i\": 0 } ] } platforms indicates the platform used by the image, 0 indicates the PC platform, 1 and 2 point to the Android and iOS platforms respectively. Run the published Web project (you can use anywhere to start the local server, refer to the document \"Web Publishing\"), and open it in the Chrome browser after startup DevTools tools. As shown in Figure 2-6, click the \"Network\" option, you can see that the BC1 texture format is used, @0 means running on the PC platform. (Figure 2-6) 2.1.2 Mobile version If we want to use ASTC_6x6 for Android and iOS platforms, the setting method is as shown in animation 2-7: (Animation 2-7) ASTC format can set the texture quality, sometimes, lower quality will be more blurry than higher quality. Select the ASTC_6x6 texture compression format for Android and iOS respectively, and click Apply. Then use the set image as the skin of the Image component, and then build and publish it. By publishing the web platform, as shown in Figure 2-8, look at the published files: (Figure 2-8) Publish two files \"layabox.png\" and \"layabox@1.ktx\". Among them, \"layabox@1.ktx\" is the texture compression file generated by the above operation. Because ASTC_6x6 is used, only one compressed texture file is generated. If the Android and iOS platforms are configured for different formats, two different files will be generated. There is also a .png image generated at the same time, because when setting the texture compression format, the default setting of the PC platform is \"Bitmap with transparent channel (32-bit)\", which has not changed. The \"fileconfig.json\" file in the release directory records some image attribute setting information, including texture compression information. Open the .json file as follows: { \"files\": { \"resources\": [ \"layabox.png\" ] }, \"config\": [ { \"sRGB\": true, \"filterMode\": 1, \"mipmap\": true, \"pma\": false, \"files\": [ { \"file\": \"\", \"ext\": \"png\", \"format\": 1 }, { \"file\": \"1\", \"ext\": \"ktx\", \"format\": 19 } ], \"platforms\": { \"0\": 0, \"1\": 1, \"2\": 1 }, \"t\": 0, \"i\": 0 } ] } platforms indicates the platform used by the image. 1 and 2 point to the Android and iOS platforms respectively. Both platforms use texture compression files with the ktx suffix in the files information. Run the published Web project. After starting, take an Android phone as an example to see the actual running effect. Enter the URL of the launched Web project in the Chrome browser of the phone, then connect the USB data cable, turn on the developer mode of the phone, then enter chrome://inspect/#devices in the Chrome browser of the PC, and then clickinspect. The operation after entering chrome://inspect/#devices is similar to the debugging method of Xiaomi Quick Game. After clicking, it will appear as shown below: (Figure 2-9) You can see that \"layabox@1.ktx\" is being used, where @1 means running on the Android platform. Note: Mobile terminal debugging must use a real device. If you do not use a real machine, but just use the mobile phone mode under Chrome on the PC platform (as shown in Figure 2-10), the texture compression format cannot be used. Because although the mobile phone mode is used, the LayaAir engine will determine that the current running platform is still win32. (Figure 2-10) 2.2 Atlas texture compression Not only can images be texture compressed, but the atlases we usually use in 2D development can also use texture compression formats, as shown in Figure 2-11: (Figure 2-11) For how to use the automatically generated atlas, please refer to \"Web Publishing\". Taking the Android platform as an example, in LayaAir IDE, configure the texture compression for the automatic atlas settings, and then use the image as the skin of the Image component in the scene. After publishing, you can see that the atlas can also use texture compression format, as shown in Figure 2-12. @1.ktx is the texture compression format of the Android platform, .atlas is the atlas file, and .png is the default for other platforms. texture format. (Figure 2-12) Then use the Android phone to see the running situation. The atlas texture compressed file \"@1.ktx\" is successfully used, as shown in Figure 2-13: (Figure 2-13) At this point, the introduction to configuring image texture compression and atlas texture compression in the IDE is complete. Developers can give it a try themselves! 3. Code loading texture compression After configuring texture compression through the IDE, the LayaAir engine itself can automatically identify the running platform and use the corresponding compressed texture. This improvement is very convenient for developers. The same is true if the developer wants to use code to load dynamically. 3.1 Loading of image texture compression Just like normal image loading, just use the path of the image directly in the code. Take adding a skin to the Image component as an example. The sample code is as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { onAwake(): void { let img = new Laya.Image; Laya.stage.addChild(img); img.pos(500,100); img.skin = \"resources/layabox.png\"; //The path of the texture compressed image } onStart() { Laya.Stat.show(0, 0); //Performance panel } } After publishing, the image used is the compressed image. 3.2 Loading of Atlas Texture Compression For the 2D atlas, just preload the atlas file. When the engine loads the atlas, it will detect whether the texture compression conversion information is included. If it is included, it will automatically identify the platform and load the corresponding texture compression format file. No. Developers need to determine the platform in the code. Sample code looks like this: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { onAwake(): void { Laya.loader.load([\"resource/AtlasConfig.atlas\"], Laya.Handler.create(this, () => { let img = new Laya.Image; Laya.stage.addChild(img); img.pos(500, 100); img.skin = \"resources/img_bg.png\"; //Pictures in the atlas })); } onStart() { Laya.Stat.show(0, 0); } } Through the sample code, we can see that the texture compression code of the atlas is insensitive and exactly the same as the ordinary atlas. 4. What is the optimization effect? Since the texture compression format does not require CPU decoding, the instantaneous performance pressure caused by decoding is gone. However, if there is not a lot of processing, this process is not continuous, so it is not obvious. The more significant optimization is still in the video memory. Let us still give an example to illustrate. Using the picture that comes with the Image component in the IDE, we change the width and height to 512*512, When there is nothing displayed on the stage, the initial video memory occupation is 2.31M. Using the texture compression format, only 170K is added, and the final size is 2.48M after adding the initial size. The original image increased by 1024K to 3.31M. As shown in Figure 4-1. Therefore, the effect of video memory optimization is still very obvious, with a reduction of about 83%. (Pic 4-1) Performance display panel introduction reference document \"Performance Statistics and Optimization\". Some developers still don't quite understand the relationship between video memory usage and files. Let me tell you a simple calculation basis here. If it is a non-texture compressed image, such as PNG and JPG, directly use the width*height*4 of the image pixels to determine the video memory usage. Therefore, some games, in order to reduce the usage of video memory, make the width and height pixels of the picture smaller, and then use scaling to enlarge the display. However, in this way, although the memory usage is small, the quality loss is also large. Although texture compression is also lossy compression, it occupies less video memory for the same quality. Even when the quality is similar to the original image, it occupies less memory than stretching. Therefore, texture compression is a commonly used solution by developers to save video memory. How to calculate the video memory usage of texture compression? In addition to the information on the statistics panel, there is also a relatively simple statistical solution. Just check the size of the texture compressed file directly. For example, if the texture compressed file is 170k, then the video memory occupied is also 170k. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 11:34:38 "},"IDE/uiEditor/3DUI/readme.html":{"url":"IDE/uiEditor/3DUI/readme.html","title":"3D UI","keywords":"","body":"Use 3DUI1. Overview1.1 The essence of 3D UI1.2 Classification of 3D UI2. Using UI3D components in IDE2.1 Create a 2D Prefab2.2 Create Sprite3D and add UI3D components2.3 Add 2D Prefab resources2.4 Change UI3D properties2.5 Adjust UI3D position2.6 Script control UI3DUse 3DUI 1. Overview 2D UI is a pure 2D image displayed in layers, and there will be no three-dimensional effect, so it is directly attached to the window. The principle of 3D UI is that the created UI controls are all in a three-dimensional space, and the camera is a perspective camera. This is completely different from 2D UI, because 2D UI is an orthogonal camera. Therefore, if you want the UI to have a three-dimensional transformation effect, you must use a 3D UI. 1.1 The essence of 3D UI 3D UI is also a UI, so it needs to assume the interactive functions of the UI. For example, when we click a button on the UI, the button will bring interactive feedback and trigger set events to achieve logical operation. (Animation 1-1) 1.2 Classification of 3D UI Scenery UI 3D UI is a UI that is located in a 3D scene and moves without following the movement of the window. It is more like an object located in a 3D scene with UI interactive features. (Animation 1-2) Perspective UI The 3D UI is always located on the window, just like the regular UI. But 3D UI can carry out movement on the three axes of XYZ, bringing obvious perspective changes. (Animation 1-3) 2. Using UI3D components in IDE 2.1 Create a 2D Prefab To use a 3D UI in an IDE, we first need to create a 2D UI for display in a 3D scene, which must be implemented using Prefab2D. First, we create a Prefab2D and build a 2D UI in Prefab2D that we want to implement. For example, we want to make a health bar above the head of a character in the game during battle, as shown in Figure 2-1. (Figure 2-1) In Prefab2D, create a Progress component. Because the health bar consists of the current blood volume and the overall blood volume, Progress exactly meets our requirements. And a label is used on the health bar to display the character's name. Also note that the size of the Prefab root node Box is best changed to the power of 2, which is in line with the principle of the power of 2 of the texture. 2.2 Create Sprite3D and add UI3D components Under the Scene3D node of the IDE, create a Sprite3D object and add UI3D components, as shown in animation 2-2. (Animation 2-2) In the Sprite3D node properties panel, click Add Component, select Rendering, and select the UI3D component. You can see that after adding the UI3D component, there is an additional display texture (black) at the position of the Sprite3D node in the scene. This texture is used to display the UI. 2.3 Add 2D Prefab resources After preparing the UI3D component, the next step is to drag the previously prepared 2D Prefab UI into the Prefab property of the UI3D component, as shown in the animation 2-3. (Animation 2-3) After dragging into the Prefab, the texture immediately displays the 2D UI. But the default is OPAQUE rendering mode, and the texture has a black background color. The following introduces the properties of UI3D to adjust the texture effect. 2.4 Change UI3D properties For UI3D components, as shown in Figure 2-4, there are the following properties: (Figure 2-4) Prefab: 2D Prefab resource file that needs to be displayed. Resolution Rate: The resolution of the texture. When dragged into the Prefab, the size of the node under the Prefab will be automatically recognized to dynamically adjust the resolution of the texture. Scale: Texture width and height scaling. Based on the scaling ratio of the texture resolution, by controlling the scaling, the power of 2 texture matches the width and height of the UI resource. Billboard: Whether to use billboard mode. If checked, the UI will always face the camera; if not checked, the UI will always face the Z-axis direction, which is the perspective effect of the UI in the scene. Enable Hit: Whether to respond to mouse events, not checked by default. After checking, you can realize the response of buttons, dragging of slide bars, sliding of List components, etc. Render Mode: Rendering mode. OPAQUE (opaque), CUTOUT (cropping), TRANSPARENT (transparent), ADDTIVE (effect overlay), ALPHABLENDED (transparency mixing). Cull: Culling mode. Off (do not eliminate), Front (remove the front side and only display the back side), Back (eliminate the back side and only display the front side). The commonly used rendering mode is TRANSPARENT, which supports transparent colors. As shown in Figure 2-5, the background becomes transparent. (Figure 2-5) 2.5 Adjust UI3D position Our need is to make the character's health bar. First, drag the Dante character we have made into the scene and set it to the (0,0,0) point, as shown in Figure 2-6. (Figure 2-6) However, you can see that since the previously created Sprite3D is also at the (0,0,0) point, the position will be at the character's feet. At this time, the position of the Sprite3D needs to be adjusted to match the effect of the health bar, as shown in the animation 2-7 shown. (Animation 2-7) Now let’s take a look at the running effect: (Animation 2-8) You can see that as the character moves in and out in front of the camera, the health bar becomes larger and smaller, which is very consistent with the actual effect. If it is implemented with a 2D UI, it will need to dynamically calculate the position of the character relative to the camera to scale the size of the UI, and the effect will definitely not be good. Of course, we can also uncheck the Billboard property of UI3D and adjust the rotation of the XYZ axis so that the health bar changes direction as the character rotates. (Animation 2-9) 2.6 Script control UI3D Usually we need to operate the content in the UI. In this example, the change of the blood volume ratio in the health bar, the upward floating damage number, etc., are all achieved by controlling the UI components in the 2D Prefab. The UI3D component is usually used to control display effects, such as perspective effects, position information, etc. In Prefab2D in Section 2.1, add a Text node, name it \"value\", rename the ProgressBar to \"bar\", and then check the `Define Variables' option of value and bar. After saving the scene, just like handling 2D UI operations, add the Runtime class on the root node and add the logic code as follows: const { regClass } = Laya; import { BloodBarBase } from \"./BloodBar.generated\"; import { Main } from \"./Main\"; @regClass() export class BloodBar extends BloodBarBase { onAwake(): void { this.bar.value = 1; this.value.visible = false; Laya.stage.on( Laya.Event.CLICK, this, this.onHurt ); } onHurt(): void { this.bar.value = this.bar.value - 0.1; this.value.y = 35; this.value.visible = true; Main.instance.animator.play(\"Stun\"); Laya.Tween.to( this.value, { y : -20 }, 500, null, Laya.Handler.create(this, this.end)) } private end(): void { this.value.visible = false; } } Main.instance.animator.play(\"Stun\"); in the above code means changing the animation state, the purpose is to play the animation of being attacked when the blood volume is reduced. The following script needs to be added to the Scene2D of the scene: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { /** Set up singleton */ static instance: Main; constructor() { super(); Main.instance = this; } @property({ type: Laya.Sprite3D }) private target: Laya.Sprite3D; public animator: Laya.Animator; onAwake(): void { //Get state machine this.animator = this.target.getComponent(Laya.Animator); } } Finally, let’s take a look at the running effect: (Animation 2-10) So far, the UI3D component has been introduced. Developers can use UI3D components in their projects to achieve more 3D UI effects. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-23 10:46:13 "},"IDE/sceneEditor/readme.html":{"url":"IDE/sceneEditor/readme.html","title":"Scene Editor","keywords":"","body":"3D scene editorBasic interaction for 3D scene editingUse 3D sprite3D basic display objectUse 3D Camera3D Lights and Shadows3D scene environment settingsImport and use of 3D models and animations3D scene editor Author: Charley The 3D scene editor is the core module of 3D visual editing, which mainly includes the environment settings of the 3D scene, the import and use of models, the transformation of 3D node objects, the visual use of 3D basic components such as cameras and lights. Basic interaction for 3D scene editing Use 3D sprite 3D basic display object Use 3D Camera 3D Lights and Shadows 3D scene environment settings Import and use of 3D models and animations Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 19:00:35 "},"IDE/sceneEditor/basic/readme.html":{"url":"IDE/sceneEditor/basic/readme.html","title":"Basic Interaction","keywords":"","body":"Basic interaction of 3D scene editing1. Operate the window camera1.1 Rotate window camera: right mouse button1.2 Spatial displacement window camera1.3 Displace the window camera in the screen: Q \\ middle mouse button1.4 Window camera zoom: mouse wheel1.5 Rotate the window camera around the focus center: Alt + left-click drag1.6 Save window camera position1.7 Perspective projection and orthogonal projection1.8 Local coordinates and global coordinates1.9 Display settings1.10 Scene view refresh frequency2. Operation model2.1 Model displacement tool: W2.2 Model rotation tool: E2.3 Model scaling tool: R2.4 Model tool collection: T2.5 Multiple selection of models2.6 Model adsorption3. Alignment3.1 Align 3D objects to the window camera with one click: Ctrl+Shift+F3.2 Align the window camera to a 3D object with one click: Shift+FBasic interaction of 3D scene editing Author: Charley, Meng Xingyu The basic interactions in 3D scenes mainly include two types of basic operations: First, changing the camera position and angle of the scene window allows developers to observe the 3D scene world just like their own eyes. The second is to change the position and angle of the model and place the model in an appropriate position in the scene. We can use the basic tools shown in Figure 1, (figure 1) You can also use shortcut keys to switch to the corresponding tool. In this article, we break it down step by step to let you understand all the basic interactive operations of 3D scene editing. 1. Operate the window camera 1.1 Rotate window camera: right mouse button In a 3D scene, just keep pressing the 'right mouse button' to enter the window camera rotation mode, and release the 'right mouse button' to exit the window camera rotation mode. In this mode, by moving the mouse in the direction of the screen, you can change the angle of the window camera and observe the entire scene from any angle. The effect is as shown in the animation 1-1. (Animation 1-1) 1.2 Spatial displacement window camera When you hold down the right mouse button + keyboard function keys, you can press the camera up, down, left, and back. The specific function keys are as follows: Function description Operation Camera up displacement Right mouse button + E Camera Down displacement Right mouse button + Q Camera left displacement Right mouse button + A Camera right displacement Right mouse button + D Camera forward displacement Right mouse button + W Camera backwards displacement Right mouse button + S The effect of shifting the window camera is shown in the animation 1-2. (Animation 1-2) Up, down, front, left, right, is a relative direction. No matter it is rotated to any angle, it will be displaced in this relative direction. Displacement window camera acceleration: On the basis of the displacement window camera, hold down Shift to superimpose, and you can accelerate the movement based on the original function. The operation keys are: right mouse button + shift + (E, Q, A, D, W, S) 1.3 Displace the window camera in the screen: Q \\ middle mouse button In addition to using the right mouse button + keyboard function keys (E, Q, A, D) to move the window camera up, down, left, and right, you can also use the shortcut key Q or the middle mouse button to start the screen displacement in any direction. When using the shortcut key Q, press the left mouse button and drag it to move the window camera in any direction on the screen. The effect is as shown in the animation 1-3. (Animation 1-3) To exit this mode, you need to use the shortcut keys of other modes, unless you need to continuously use this mode to move the window camera. Otherwise, it is recommended to use the middle mouse button to initiate screen displacement in any direction. The middle mouse button mode will only enter this mode when pressed and dragged. Release the middle mouse button and it will automatically return to other modes. 1.4 Window camera zoom: mouse wheel Window camera zoom is essentially the front-to-back displacement of the window camera. Because during the displacement process, the object is observed based on the perspective principle of near and far, and there is an illusion of zooming, so it is called a zoom window camera. The effect is shown in the animation 1-4. (Animation 1-4) 1.5 Rotate the window camera around the focus center: Alt + left-click drag When observing or operating a specific model, we may need to find a suitable angle that is not frontal. At this point, none of the methods introduced before are inconvenient. So any rotation around the target is the most suitable operation. Before rotating the window camera, the first thing we have to do is focus (select the 3D object, shortcut key F) and place the model in the center of the window camera. After focusing, use the combination of Alt + Left Click and drag the left button to any angle to rotate around the focus center. The effect is as shown in the animation 1-5. (Animation 1-5) 1.6 Save window camera position Shortcut keys Function Ctrl + Shift +1/2/3/4/5/6/7/8/9 Each number can store a camera position and 9 positions can be saved 1/2/3/4/5/6/7/8/9 Stored camera positions can be quickly switched by pressing the corresponding number keys As shown in the animation 1-6, in the scene panel, after moving the camera to the appropriate position, press the shortcut key Ctrl + Shift +1. At this time, the camera position is saved under the number 1. Move the camera Finally, if you want to return to the position of 1, press the numeric key 1. (Animation 1-6) The operations for the remaining positions 2 to 9 are the same as 1, and developers can save them according to needs. 1.7 Perspective projection and orthogonal projection As shown in the animation 1-7, Perspective Projection/Orthogonal Projection in the basic tools indicates: whether the projection mode of the current scene preview camera is orthogonal projection or perspective projection. (Animation 1-7) 1.8 Local coordinates and global coordinates As shown in the animated picture 1-8, rotate the Cube 45 degrees around the x-axis. At this time, you can observe the difference between the mobile model relative to the local coordinates and the global coordinates. (Animation 1-8) 1.9 Display settings Click the display settings shown in Figure 1-9 to set the Camera and Gizmos properties. (Figure 1-9) 1.9.1 Camera Parameters Function Field Of View Field of view in perspective mode Near Plane The clipping plane closest to the camera's field of view Far Plane The clipping plane farthest from the camera's field of view Zoom Speed Camera zoom speed Transform Speed ​​ Camera displacement speed Post Process After checking, turn on Post-processing Depth Texture When checked, turn on depth texture 1.9.2 Gizmos Parameters Function 3D Icons Set the size of the camera icon in the scene Show Grid When checked, horizontal grid lines will be displayed in the scene Selection Outline When checked, the selected model will display an outer border 1.10 Scene view refresh frequency Click on the scene view refresh frequency shown in Figure 1-10 to choose between responsive and real-time. Responsive, it is the current mode, it will be refreshed when there are changes; real-time, it is the scene view refreshed at a frame rate of 30fps. (Figure 1-10) 2. Operation model There are four tools for operating models, namely displacement, rotation, scaling, and mixed use. Different tool modes can be started through the shortcut keys W, E, R, T. Shortcut key name Button Model Displacement Tool W Model Rotation Tool E Model scaling tools R Hybrid Edit Model T 2.1 Model displacement tool: W After entering the model displacement tool mode through the shortcut key W, red, green and blue axes and pieces will appear on the model. The three axes of red, green, and blue represent the three directions of X, Y, and Z respectively. The color of the axis corresponds to the coordinate axis in the upper right corner. The direction pointed by the arrow is the positive direction. Dragging one of the axes will cause the model to move in the positive and negative directions of the axis. The effect is as shown in the animation in Figure 2-1. (Animation 2-1) Pay attention to the attribute panel. If the model does not have any rotation (rotation is all 0), drag one of the axes, and only the attribute value of that axis will change. If there is rotation, it will affect other axis attribute values. Three adjacent faces, blue is the XY face, green is the XZ face, and red is the YZ face. By dragging one of the faces, the model can be displaced arbitrarily within the range of the face, as shown in the animation in Figure 2-2. (Animation 2-2) 2.2 Model rotation tool: E After entering the model rotation tool mode through the shortcut key E, red, green and blue intersecting arcs and an outer white circle will appear on the model. When the mouse is drawn over the model, a translucent circle will also appear. The red, green, and blue arcs represent the directions of the X, Y, and Z axes respectively, and the colors correspond to the coordinate axes in the upper right corner. After selecting one of the arcs, it will turn into a complete circle, which means rotation along that axis. The effect is as shown in the animated picture 2-3. (Animation 2-3) The outer white circle is based on the vertical rotation of the screen, and the effect is shown in the animation 2-4. (Animation 2-4) If the mouse is dragged on the translucent circle, it can be rotated at any angle, and the effect is as shown in the animation 2-5. (Animation 2-5) 2.3 Model scaling tool: R After entering the model zoom tool mode through the shortcut key R, there are not only red, green and blue axes on the model, but also a central white block and an outer white circle. The red, green, and blue axes represent the directions of the X, Y, and Z axes respectively. Pulling one of the axes will scale the mode on that axis. The effect is as shown in the animation 2-6. (Animation 2-6) The white block in the center and the white circle in the outer layer are both scaled on three axes at the same time. The only difference between the two is the difference in scaling rate. The effect is shown in the animation 2-7. (Animation 2-7) 2.4 Model tool collection: T After entering the model tool collection through the shortcut key T, the model operation tools introduced above will be gathered together. The only thing to note is that in blending mode, the scaling of the center block is no longer retained. It can only be scaled overall through the outer white circle, and scaled from a single axis by pulling the squares on each axis. The effect is shown in the animation 2-8. (Animation 2-8) 2.5 Multiple selection of models The multi-selection methods are box selection, Shift, and Ctrl. The frame selection of the model is to use the mouse to pull up the rectangular area of ​​the screen. As long as it is within the rectangular area, it will be selected regardless of the distance. In addition to box selection, you can also use Shift or Ctrl combined with mouse clicks to perform continuous multiple selections. Whether it is single selection or multiple selection, the selected model will have a red border. 2.6 Model adsorption 2.6.1 Lower adsorption: End Assume there are two cubes, Cube1 is on the top and Cube2 is on the bottom. Select Cube1 and press the End key (Mac: fn + right arrow key). As shown in the animation 2-9, Cube1 will fall directly to Cube2 below. (Animation 2-9) 2.6.2 Point adsorption: V Point adsorption refers to adsorption and alignment based on the vertices of the model and the vertices of the target model. After selecting the model, keep pressing the shortcut key V to enter point adsorption mode. At this time, the mouse can be moved to any vertex of the current model, then continue to hold the vertex and drag it to the target model to adsorb and align it with the vertices of the target model. As shown in the animation 2-10, there are two Cubes in the scene. Select one of them, press the V key without releasing it, and move to the vertex of the other Cube. Do not release the V key during the movement , you can align the vertices of two Cubes. (Animation 2-10) 2.6.3 Face adsorption: Ctrl+Shift Surface adsorption refers to aligning the model based on the mesh surface of the target model. After selecting the model, keep pressing the shortcut key Ctrl+Shift (Mac: control+shift) to enter the surface adsorption mode. Keep pressing the mouse on the model and dragging it to the target model. The center point of the model will be aligned with the grid surface of the target model. At this time, you can move on all sides of the target model, but the center point must not leave the grid surface unless you exit. Surface adsorption mode. As shown in the animation 2-11, move the center point of one Cube to the side of another Cube. The Cube will not move during the mouse movement. It will only move when the center point is dragged to the surface of another Cube. move. (Animation 2-11) If you continue to hold down the shortcut key Ctrl+Shift (Mac: control+shift) and continue to press V, you can turn on the combination mode of surface adsorption. In combination mode, Ctrl+Shift+V (Mac: control+shift+V) is no longer limited to the center point. The mouse can be moved to any vertex of the current model, and then continued to hold the vertex, which can be combined with the mesh of the target model. Align the surface. As shown in the animated picture 2-12, in the combination mode of surface adsorption, move the vertex of one Cube to the side of another Cube. The Cube will not move during the mouse movement. You can only drag the vertex to the side of the other Cube. It will only move when it is on the surface. (Animation 2-12) 3. Alignment 3.1 Align 3D objects to the window camera with one click: Ctrl+Shift+F This method directly changes the position of the target object. A more common situation is that after selecting the camera, you can use the Ctrl+Shift+F shortcut keys to directly align the camera (Main Camera) to the position of the window camera with one click, as shown in GIF 3-1 (pay attention to the Main Camera in the lower right corner) Camera viewport changes). In this way, whatever the window camera sees, the camera (Main Camera) can also see directly. It is convenient for users to adjust, making camera lens adjustment more convenient and precise. (Animation 3-1) As shown in GIF 3-2, Ctrl+Shift+F can be applied to other 3D objects. (Animation 3-2) 3.2 Align the window camera to a 3D object with one click: Shift+F This method does not change the target object position. A common situation is that after selecting a camera, you can use the Shift+F shortcut keys to directly align the window camera to the position of the camera (Main Camera) with one click, as shown in the animation 3-3. In this way, you can quickly transfer to the viewport of the camera (Main Camera). (Animation 3-3) As shown in the animation 3-4, you can also align the window camera to other 3D objects with one click (Shift+F), so that it can quickly have the first-person viewport of the editor. (Animation 3-4) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:58:09 "},"3D/Sprite3D/readme.html":{"url":"3D/Sprite3D/readme.html","title":"Sprite3D","keywords":"","body":"Use 3D sprite (Sprite3D)1. Overview2. Properties and functions2.1 Node name2.2 Whether to activate2.3 Whether it is static2.4 Mask layer2.5 Transformation3. Child-parent relationship4. Clone5. Add components6. Add script7. Introduction to various rendering sprites7.1 MeshSprite3D sprite7.2 SkinnedMeshSprite3D sprite7.3 Particle3D sprite7.4 PixelLine sprite7.5 Trail spriteUse 3D sprite (Sprite3D) 1. Overview Sprite3D is the basic node object of 3D, just like Sprite is the basic node object of 2D. It is the parent class of all 3D nodes in LayaAir3D. It contains many basic functional attributes of 3D sprites. In addition, it is also the container of all 3D components and scripts. . In the LayaAir 3.0 editor, we can create a Sprite3D by right-clicking the mouse, as shown in animation 1-1 (Animation 1-1) The created Sprite3D will have an empty node under Scene3D in the editor scene, as shown in Figure 1-2 (Figure 1-2) Basically, the most important purpose of creating a Sprite3D empty node is to serve as a root node. There will be many root nodes with different functions in a project for our management. In addition, you can also use Sprite3D to add components. Below we will introduce the use of Sprite3D in detail. 2. Properties and functions (Figure 2-1) In Figure 2-1, you can see what attributes Sprite3D, as the most basic 3D node, has. Other richer 3D nodes have these attributes. 2.1 Node name (Figure 2-2) In Figure 2-2, any node has a name. You can easily find out whether there is a child node with a certain name under a node by using the name. The following method is usually called to get the child node: getChildByName(\"xxx\") /** * Get the child node object based on the name of the child node. * @param name The name of the child node. * @return node object. */ getChildByName(name: string): Node { for (let child of this._children) { if (child && child.name === name) return child; } return null; } When we find the child node, we can also do some basic operations on the node, such as deleting its own method removeSelf() /** * Delete itself from the parent container. If it has been deleted, no exception will be thrown. * @return current node (Node) object. */ removeSelf(): Node { this._parent && this._parent.removeChild(this); return this; } For specific basic methods of a Sprite3D, you can refer to [Basic properties of Node nodes] (../../basics/common/Node/readme.md). 2.2 Whether to activate (Figure 2-3) In Figure 2-3, any node can be activated in the scene by checking whether it is activated. When a node is not activated, all the following child nodes will also be inactivated along with the root node. Of course we can also control it through code /** * Get whether it is activated. * @return Whether it is activated. */ get active(): boolean /** * Set whether to activate. * @param value whether to activate. */ set active(value: boolean) 2.3 Whether it is static (Figure 2-4) As shown in Figure 2-4, whether it is static. In the game scene, each Sprite3D has two states: static or dynamic. When an object is marked as static, it ensures that the object is a static and non-moving object in the game scene, and then during the running process of the game Let the game have a smoother running experience. Generally speaking, it is better to mark objects that are completely stationary in the scene as static. This static means that no movement, scaling, rotation, etc. occurs during the running of the game. Generally, the nodes used for baking are marked as static. Marking static is often done to improve efficiency. For example, collision detection of static objects is faster. At the same time, multiple static objects using the same material only use one drawcall when drawing, thus saving CPU. In terms of lighting calculation, static objects are also faster. In addition, when Static is checked, the editor will ask whether to change the static flags of all sub-objects at the same time, as shown in Figure 2-5 (Figure 2-5) Of course, you can also use code to control /** * Whether it is static. */ get isStatic(): boolean /** * Whether to set it to static. */ set isStatic(value: boolean) 2.4 Mask layer (Figure 2-6) In Figure 2-6, it is the layer Layer where the sprite is located. The rendering camera can control the visible mask layer and control whether the sprite is rendered or not. You can refer to the camera documentation. There are examples of the camera selecting different mask layers after setting different object mask layers. As shown in animation 2-7 (Animation 2-7) As shown in Figure 2-8, by clicking Layer, you can select Default, Layer1, etc. that have been customized by the editor, or you can edit the Layer layer again. (Figure 2-8) It can also be set through code /** * Mask layer. */ get layer(): number set layer(value: number) //Add a display layer (add a mask for the camera) this.camera.addLayer(5); 2.5 Transformation Transform components determine the position, rotation, and scale of each sprite in the scene. At the same time, it has the same relationship between child and parent nodes as the Node node, making the transformation operation more flexible. Each sprite has a Transform3D. (Figure 2-9) We can also manually adjust the transformation of the sprite in the editor (Figure 2-10) (Figure 2-11) Figure 2-10 is used to adjust the rotation of the sprite, and Figure 2-11 is used to adjust the scaling of the sprite. (Figure 2-12) Figure 2-12 can be used to adjust the position, rotation and scaling of the sprite at the same time. Transform through code //Translation this.position1.setValue(-1.5, 0, 0.0); this.sprite3d.translate(this.position1); //Rotate this.rotate1.setValue(0, 60, 0); this.sprite3d.rotate(this.rotate1, false, false); //Zoom var scale = this.sprite3d.localScale; scale.setValue(0.1, 0.1, 0.1); this.sprite3d.localScale = scale; 3. Child-parent relationship Sprite3D inherits from Node node and is the parent class of all 3D objects in LayaAir3D. With some examples, we can understand the child-parent relationship. (Animation 3-1) By clicking the button, the parent node moves and you can see that the child nodes also move accordingly. this.layaMonkeyParent.transform.translate(new Laya.Vector3(-0.2, 0, 0); (Animation 3-2) By clicking the button to move the child node, you can see that the parent node has not moved. this.layaMonkeySon.transform.translate(new Laya.Vector3(-0.2, 0, 0); 4. Clone Regarding cloning, several interfaces are provided in LayaAir3D. The more commonly used method is the clone method /** * clone. * @return Clone copy. */ clone(): Node { var dstSprite3D: Node = Sprite3D._createSprite3DInstance(this); Sprite3D._parseSprite3DInstance(this, dstSprite3D, this, dstSprite3D); return dstSprite3D; } (Animation 4-1) Clone a monkey through code //Clone a monkey let sp = this.layaMonkeyParent.clone() as Laya.Sprite3D; //Set the coordinates of the cloned monkey sp.transform.position = new Laya.Vector3(1,0,0); //Add to scene this.scene.addChild(sp); Secondly, here is a detailed explanation of the unique cloning interface instantiate in Sprite3D. /** * Create a clone instance of the sprite. * @param original The original sprite. * @param parent parent node. * @param worldPositionStays Whether to maintain its own world transformation. * @param position world position, effective when worldPositionStays is false. * @param rotation World rotation, effective when worldPositionStays is false. * @return Clone instance. */ static instantiate(original: Sprite3D, parent: Node = null, worldPositionStays: boolean = true, position: Vector3 = null, rotation: Quaternion = null): Sprite3D { var destSprite3D: Sprite3D = (original.clone()); (parent) && (parent.addChild(destSprite3D)); var transform: Transform3D = destSprite3D.transform; if (worldPositionStays) { var worldMatrix: Matrix4x4 = transform.worldMatrix; original.transform.worldMatrix.cloneTo(worldMatrix); transform.worldMatrix = worldMatrix; } else { (position) && (transform.position = position); (rotation) && (transform.rotation = rotation); } return destSprite3D; } original: original sprite. parent: parent node. worldPositionStays: Whether to maintain its own world transformation. position: world position, effective when worldPositionStays is false. rotation: world rotation, effective when worldPositionStays is false. This method can carry parent node information, world position information and world rotation information when cloning. (Animation 4-2) Instantiate a monkey through code //sprite3d instantiate cloning method let layaMonkey_clone1 = Laya.Sprite3D.instantiate(this.layaMonkeyParent, this.scene, false, new Laya.Vector3(-2, 0, 0), new Laya.Quaternion(0, -90, 0)); this.scene.addChild(layaMonkey_clone1); 5. Add components In LayaAir, you can add the Component component to any 3D object, as shown in animation 5-1 (Animation 5-1) Component Component is the base class for content attached to all 3D objects. Components can also be added through code, and the object needs to use the addComponent method. //Add Rigidbody3D component let rigidBody = this.layaMonkeyParent.addComponent(Laya.Rigidbody3D) as Laya.Rigidbody3D; //Create a box shape collider var boxShape = new Laya.BoxColliderShape(1, 1, 1); //Set the collision shape of the box rigidBody.colliderShape = boxShape; //use gravity rigidBody.overrideGravity = true; //Gravity is downward -10 rigidBody.gravity = new Laya.Vector3(0,-10,0); (Animation 5-2) As shown in Figure 5-2, add the Rigidbody3D component and set the effect of gravity (you need to check the physics-related \"Engine Module\" in the \"Project Settings\"). 6. Add script In the development of the 3D world, the script class will be used in many places. Add a script to Sprite3D. As shown in animation 6-1. (Animation 6-1) We can add a script to the Main Camera to control the camera through the mouse and keyboard. This script is very practical in the actual development process. In Figure 6-2, this script is added to the display camera. (Figure 6-2) The code of the script is: const { regClass, property } = Laya; @regClass() export class CameraMoveScript extends Laya.Script3D { /** @private */ protected _tempVector3: Laya.Vector3 = new Laya.Vector3(); protected lastMouseX: number = 0; protected lastMouseY: number = 0; protected yawPitchRoll: Laya.Vector3 = new Laya.Vector3(); protected resultRotation: Laya.Quaternion = new Laya.Quaternion(); protected tempRotationZ: Laya.Quaternion = new Laya.Quaternion(); protected tempRotationX: Laya.Quaternion = new Laya.Quaternion(); protected tempRotationY: Laya.Quaternion = new Laya.Quaternion(); protected isMouseDown: boolean = false; protected rotaionSpeed: number = 0.00006; protected camera: Laya.BaseCamera = new Laya.Camera; protected scene: Laya.Scene3D = new Laya.Scene3D; speed: number = 0.01; constructor() { super(); } /** * @private */ protected _updateRotation(): void { if (Math.abs(this.yawPitchRoll.y) this.owner); } /** * Monitor keyboard events */ onUpdate(): void { var elapsedTime: number = Laya.timer.delta; if (!isNaN(this.lastMouseX) && !isNaN(this.lastMouseY) && this.isMouseDown) { Laya.InputManager.hasKeyDown(87) && this.moveForward(-this.speed * elapsedTime);//W Laya.InputManager.hasKeyDown(83) && this.moveForward(this.speed * elapsedTime);//S Laya.InputManager.hasKeyDown(65) && this.moveRight(-this.speed * elapsedTime);//A Laya.InputManager.hasKeyDown(68) && this.moveRight(this.speed * elapsedTime);//D Laya.InputManager.hasKeyDown(81) && this.moveVertical(this.speed * elapsedTime);//Q Laya.InputManager.hasKeyDown(69) && this.moveVertical(-this.speed * elapsedTime);//E var offsetX: number = Laya.stage.mouseX - this.lastMouseX; var offsetY: number = Laya.stage.mouseY - this.lastMouseY; var yprElem: Laya.Vector3 = this.yawPitchRoll; yprElem.x -= offsetX * this.rotaionSpeed * elapsedTime; yprElem.y -= offsetY * this.rotaionSpeed * elapsedTime; this._updateRotation(); } this.lastMouseX = Laya.stage.mouseX; this.lastMouseY = Laya.stage.mouseY; } /** * Release monitoring */ onDestroy(): void { Laya.stage.off(Laya.Event.MOUSE_DOWN, this, this.mouseDown); Laya.stage.off(Laya.Event.MOUSE_UP, this, this.mouseUp); } protected mouseDown(e: Laya.Event): void { this.camera.transform.localRotation.getYawPitchRoll(this.yawPitchRoll); this.lastMouseX = Laya.stage.mouseX; this.lastMouseY = Laya.stage.mouseY; this.isMouseDown = true; } protected mouseUp(e: Laya.Event): void { this.isMouseDown = false; } protected mouseOut(e: Laya.Event): void { this.isMouseDown = false; } /** * Move forward. * @param distance moving distance. */ moveForward(distance: number): void { this._tempVector3.x = this._tempVector3.y = 0; this._tempVector3.z = distance; this.camera.transform.translate(this._tempVector3); } /** * move to the right. * @param distance moving distance. */ moveRight(distance: number): void { this._tempVector3.y = this._tempVector3.z = 0; this._tempVector3.x = distance; this.camera.transform.translate(this._tempVector3); } /** * Move up. * @param distance moving distance. */ moveVertical(distance: number): void { this._tempVector3.x = this._tempVector3.z = 0; this._tempVector3.y = distance; this.camera.transform.translate(this._tempVector3, false); } } The runtime effect is shown in Figure 6-3. (Animation 6-3) 7. Introduction to various rendering sprites 7.1 MeshSprite3D sprite MeshSprite3D is the most commonly used static mesh sprite in the engine, which can render models based on pre-made or customized mesh data in art software. For example, the various building models and mountain rocks in the scene in Figure 7-1 are generally MeshSprite3D (Figure 7-1) Usually we create simple Mesh grid 3D objects in practice, as shown in Figure 7-2 (Figure 7-2) These Mesh grids can also be added through code //cube var box = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createBox(0.5, 0.5, 0.5)); this.scene.addChild(box); box.transform.position = new Laya.Vector3(2.0, 0.25, 0.6); box.transform.rotate(new Laya.Vector3(0, 45, 0), false, false); //sphere var sphere = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createSphere(0.25, 20, 20)); this.scene.addChild(sphere); sphere.transform.position = new Laya.Vector3(1.0, 0.25, 0.6); //Cylinder var cylinder = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCylinder(0.25, 1, 20)); this.scene.addChild(cylinder); cylinder.transform.position = new Laya.Vector3(0, 0.5, 0.6); //capsule body var capsule = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCapsule(0.25, 1, 10, 20)); this.scene.addChild(capsule); capsule.transform.position = new Laya.Vector3(-1.0, 0.5, 0.6); //Cone var cone = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCone(0.25, 0.75)); this.scene.addChild(cone); cone.transform.position = new Laya.Vector3(-2.0, 0.375, 0.6); //flat var plane = new Laya.MeshSprite3D(Laya.PrimitiveMesh.createPlane(6, 6, 10, 10)); this.scene.addChild(plane); 7.2 SkinnedMeshSprite3D sprite SkinnedMeshSprite3D is the Skinned Animation Mesh Sprite in the engine, which can generate motion deformations based on the mesh data pre-produced by the art software and the animation data of the Animator component. Commonly used for characters, monsters, etc. with skin animation. Compared with MeshSprite3D, it has the ability to generate mesh deformation. (Figure 7-3) 7.3 Particle3D sprite Particle3D is the 3D particle wizard in the engine, which can produce wonderful and cool particle effects based on the particle parameters edited by artists. Generally used for various character skill special effects or scene special effects such as flames and smoke. (Animation 7-4) 7.4 PixelLine sprite PixelLine is the pixel line wizard in the engine, which can generate pixel lines of any color based on the drawing data of the script. Generally used for guidance effects in scenes or project debugging data. (Figure 7-5) 7.5 Trail sprite Trail is the tailing sprite in the engine, which can produce dynamic trailing effects based on the movement trajectory of the sprite. Generally used to display various trajectory trailing effects. (Animation 7-6) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:01:43 "},"3D/displayObject/readme.html":{"url":"3D/displayObject/readme.html","title":"Display Object","keywords":"","body":"3D basic display object1. Overview2. Creation and use in IDE2.1 Create objects2.2 Basic transformation usage2.3 Property settings2.4 Add components2.5 Add materials and textures3. Code Creation and Use3.1 Code Creation3.2 Basic transformation usage3.3 Property settings3.4 Add components3.5 Add materials and textures3D basic display object 1. Overview 3D basic display objects are very important auxiliary tools in the 3D development environment. They are the foundation that can help developers learn and use them in 3D scenes. Often for beginners, by creating and operating 3D basic display objects, they can quickly Understand the basic knowledge of 3D and be familiar with the 3D development environment. At the same time, when there are no other model resources, you can quickly establish concepts, build scenes, add different components, and quickly become familiar with code development. For skilled developers, through 3D basic display objects, they can easily simulate and implement some development needs, or use them to display some development logic, which can greatly improve work efficiency. Currently, the types of 3D basic display objects that can be created in LayaAir IDE are: Cube Sphere Cylinder Capsule Cone Plane (Picture 1-1) As shown in Figure 1-1, let’s take a look at how to create and use these 3D basic objects in the IDE and code. 2. Creation and use in IDE For junior developers, learning to simply create and use 3D basic objects in the IDE is a very important step! 2.1 Create objects In the Hierarchy panel of a 3D scene, you can create a 3D display object under any node or in a blank position by right-clicking the mouse, as shown in animation 2-1. (Animation 2-1) The creation of these six basic objects will not be demonstrated one by one. We can choose to create them through the menu as shown in Figure 2-2. (Figure 2-2) 2.2 Basic transformation usage Movement, rotation, and scaling are the most basic transformation operations for 3D objects, as shown in animation 2-3. (Animation 2-3) 2.3 Property settings Each 3D basic object has a MeshRenderer component. Shadow effects are created by setting Receive Shadow to the plane that receives the shadow and Cast Shadow to the cube that generates the shadow, as shown in animation 2-4. (Animation 2-4) For shadows, in addition to setting the MeshRenderer of the 3D basic object, you also need to ensure that the Shadow Mode of the Direction Light is not None. 2.4 Add components Each 3D basic object can add components to achieve advanced functions. By adding the 3D physical component Rigidbody3D to the cube, checking the gravity attribute, and finally adding a collision box, the effect of simulating free fall can be achieved, as shown in animation 2-5. Show, (Animation 2-5) You can see the effect of the cube falling when running. (Animation 2-6) To run the physical component, you need to check the corresponding engine module in the project settings panel. 2.5 Add materials and textures Each 3D basic object can set the albedo Texture texture by creating Material and specifying the newly created material in the MeshRenderer component, as shown in animation 2-7. (Animation 2-7) 3. Code Creation and Use Creating and using 3D basic objects through code is also the process by which we understand and become familiar with the LayaAir engine. 3.1 Code Creation 3.1.1 PrimitiveMesh Class for creating simple grids NOTE: This is not yet the Sprite3D seen in the final scene. Use createBox as an example to see how the API creates a grid: /** * Create Box grid. * @param long radius * @param height number of vertical layers * @param width number of horizontal layers * @return */ static createBox(long: number = 1, height: number = 1, width: number = 1): Mesh As you can see, through the createBox method, you can create a Box grid, and you can also create different vertical and horizontal heights Therefore, different types of Mesh grids can be created through code: //cube let box = Laya.PrimitiveMesh.createBox(0.5, 0.5, 0.5); //sphere let sphere = Laya.PrimitiveMesh.createSphere(0.25, 20, 20); //Cylinder let cylinder = Laya.PrimitiveMesh.createCylinder(0.25, 1, 20); //capsule body let capsule = Laya.PrimitiveMesh.createCapsule(0.25, 1, 10, 20); //Cone let cone = Laya.PrimitiveMesh.createCone(0.25, 0.75); //flat let plane = Laya.PrimitiveMesh.createPlane(6, 6, 10, 1)); The created object is a Mesh grid. If we want to create a Sprite3D object that can be seen in the scene, we also need to use the Laya.MeshSprite3D class 3.1.2 MeshSprite3D Using the MeshSprite3D class, you can pass in the Mesh object through the constructor method to create a Sprite3D object that can be seen in the scene, and it is also a Sprite3D with a Mesh shape. The construction method is as follows: /** * Create a MeshSprite3D instance. * @param mesh mesh, the default material used by the mesh will be loaded at the same time. * @param name name. */ constructor(mesh: Mesh = null, name: string = null) { super(name); this._meshFilter = this.addComponent(MeshFilter); this._render = this.addComponent(MeshRenderer); (mesh) && (this._meshFilter.sharedMesh = mesh); } The MeshSprite3D object creates MeshFilter (mesh filter) and MeshRenderer (mesh renderer) components. Finally, we create and add it to the scene through MeshSprite3D, the code is as follows: //cube //Create Box network let box: Laya.Mesh = Laya.PrimitiveMesh.createBox(0.5, 0.5, 0.5); //Create MeshSprite3D network let boxMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(box); //Add to scene this.scene.addChild(boxMeshSprite3D); // 3D transformation boxMeshSprite3D.transform.position = new Laya.Vector3(2.0, 0.25, 0.6); boxMeshSprite3D.transform.rotate(new Laya.Vector3(0, 45, 0), false, false); //sphere let sphere: Laya.Mesh = Laya.PrimitiveMesh.createSphere(0.25, 20, 20); let sphereMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(sphere); this.scene.addChild(sphereMeshSprite3D); sphereMeshSprite3D.transform.position = new Laya.Vector3(1.0, 0.25, 0.6); //Cylinder let cylinder:Laya.Mesh = Laya.PrimitiveMesh.createCylinder(0.25, 1, 20); let cylinderMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(cylinder); this.scene.addChild(cylinderMeshSprite3D); cylinderMeshSprite3D.transform.position = new Laya.Vector3(0, 0.5, 0.6); //capsule body let capsule:Laya.Mesh = Laya.PrimitiveMesh.createCapsule(0.25, 1, 10, 20); let capsuleMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(capsule); this.scene.addChild(capsuleMeshSprite3D); capsuleMeshSprite3D.transform.position = new Laya.Vector3(-1.0, 0.5, 0.6); //Cone let cone:Laya.Mesh = Laya.PrimitiveMesh.createCone(0.25, 0.75); let coneMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(cone); this.scene.addChild(coneMeshSprite3D); coneMeshSprite3D.transform.position = new Laya.Vector3(-2.0, 0.375, 0.6); //flat let plane:Laya.Mesh = Laya.PrimitiveMesh.createPlane(6, 6, 10, 10); let planeMeshSprite3D: Laya.MeshSprite3D = new Laya.MeshSprite3D(plane); this.scene.addChild(planeMeshSprite3D); The runtime effect is as follows: (Figure 3-1) 3.2 Basic transformation usage Using the Transform3D class, you can perform basic transformations on 3D basic objects. The code example is as follows: The cube in the code is boxMeshSprite3D in Section 3.1.2. //Change the world coordinates of the cube cube.transform.position = new Laya.Vector3(0, 0, 0); //Translation of cube cube.transform.translate( new Laya.Vector3(1, 1, 1)); //Rotation of cube cube.transform.rotate(new Laya.Vector3(0, 45, 0), false, false); //Scale of cube cube.transform.setWorldLossyScale( new Laya.Vector3(2, 2, 2)); 3.3 Property settings By setting the properties of the MeshRenderer component, you can set Receive Shadow for the plane that receives the shadow and Cast Shadow for the cube that generates the shadow to create a shadow effect. The code example is as follows: //cube creates shadow cube.meshRenderer.castShadow = true; //Create plane let plane = this.scene.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createPlane(6, 6, 10, 10))); //Plane receives shadow plane.meshRenderer.receiveShadow = true; It is necessary to ensure that the Shadow Mode of Direction Light is not None. 3.4 Add components Each 3D basic object can achieve advanced functions by adding components through code. By adding the 3D physical component Rigidbody3D to the cube, setting the gravity attribute, and finally adding a collision box, the effect of simulating free fall can be achieved. The code example is as follows: //Add Rigidbody3D component let rigidbody3D : Laya.Rigidbody3D = cube.addComponent(Laya.Rigidbody3D); //Set gravity rigidbody3D.overrideGravity = true; //Create a box shape collider let boxShape: Laya.BoxColliderShape = new Laya.BoxColliderShape(1, 1, 1); //Set the collision shape of the box rigidbody3D.colliderShape = boxShape; To run the physical component, you need to check the corresponding engine module in the project settings panel. 3.5 Add materials and textures Each 3D basic object can add materials and textures through code. The code example is as follows: //Preload texture resources let resource: string = \"layabox.png\"; Laya.loader.load(resource).then( ()=>{ //Create BlinnPhong material let materialBill: Laya.BlinnPhongMaterial = new Laya.BlinnPhongMaterial; cube.meshRenderer.material = materialBill; //Load texture for material let tex = Laya.Loader.getTexture2D(\"layabox.png\"); //Set the texture materialBill.albedoTexture = tex; } ); The runtime effect is as follows: (Figure 3-2) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:55:35 "},"3D/Camera/readme.html":{"url":"3D/Camera/readme.html","title":"Camera","keywords":"","body":"Article Learn to use a 3D camera1. Overview2. Camera in IDE3. Transformation3.1 Movement and rotation3.2 Follow the move4. Projection4.1 Perspective perspective mode4.2 Orthographic Orthographic mode5. Render5.1 Clear flag5.2 High dynamic lighting rendering5.3 Anti-aliasing5.4 Culling Mask6. Output6.1 View rectangle6.2 Depth map6.3 Target texture6.4 Others7. Using the camera through code7.1 How to create a ray from a camera7.2 Visible mask layer7.3 Capture target7.4 aspect ratio7.5 Target TextureArticle Learn to use a 3D camera 1. Overview We all know that movies present stories and images to the audience through cameras. The virtual 3D world also requires a virtual camera to present three-dimensional images and plots to users or players. In 3D games, the Camera is equivalent to the eye, through which you see the world, and all scenes are rendered through the Camera. That is to say, if there is no camera in the scene, no objects will be displayed in the game screen. The camera in the scene can also be placed in a child node in the scene, such as being added to the protagonist character model, which can also present a 3D picture. In the LayaAir engine, we can have one camera or multiple cameras working at the same time, depending on the actual needs of our developers. In this article, we will learn how to control the LayaAir engine 3D camera and introduce the functions of daily use of the camera. 2. Camera in IDE Let's first understand what the parameters of the camera in a 3D scene are, and refer to it by creating a 3D-RPG project, as shown in Figure 2-1 (Figure 2-1) When we create a new 3D scene, the engine automatically adds a main camera Main Camera under the Scene3D node. Of course, you can also add more cameras. When we select the main camera as shown in Figure 2-1, a Camera Preview window will appear in the Scene window to display the field of view seen by the main camera. This is convenient for us to preview when we move or rotate the camera. , the field of view in the preview will change accordingly, and of course other parameter settings will also change, which we will explain in detail later. As shown in Figure 2-2, the camera in LayaAir has the following parameter settings. These parameters can well meet the needs of the project. The red parameters will be our commonly used settings. (Figure 2-2) 3. Transformation As shown in Figure 2-2, the parameters in the top red area are the position and rotation of the camera. They are different from objects in other scenes. The position and rotation of the camera are not only their own parameters, but can also affect our Vision changes. 3.1 Movement and rotation Usually we can adjust the position of the camera by moving and rotating under the Scene window, as shown in animation 3-1. (Animation 3-1) You can also position the camera in another way, as shown in the animation 3-2. First move the scene in the Scene window, find the position and angle that suits you, click the Main Camera node, and press Ctrl+Shift+F at the same time. The camera's position and angle will change to the point you positioned. (Animation 3-2) The above is just adjusting the position of the camera in the editor, probably the initial position of the camera when initializing the scene. 3.2 Follow the move In 3D games, we often need to adjust the camera position through code. For example, the camera always follows the movement and rotation of the protagonist to make adjustments, as shown in animation 3-3. (Animation 3-3) It can be handled through code. Add the CameraControll script under the Main Camera node. As the protagonist moves, the position of the camera also moves synchronously. The code is as follows: const { regClass, property } = Laya; @regClass() export default class CameraControll extends Laya.Script { @property( { type: Laya.Sprite3D } ) public target: Laya.Sprite3D; private camera: Laya.Camera; public distanceUp: number = 0.5; //Vertical height parameter between camera and target public distanceAway: number = 10; //Horizontal distance parameter between camera and target public smooth: number = 2;//Position smooth movement interpolation parameter value public camDepthSmooth: number = 20 public curpos: Laya.Vector3; private delatpos: Laya.Vector3; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. * This method is a virtual method and can be overridden when used. */ onAwake(): void { this.curpos = new Laya.Vector3(); } /** * Executed before executing update for the first time, it will only be executed once * This method is a virtual method and can be overridden when used. */ onStart(): void { this.camera = this.owner as Laya.Camera; if (this.target) { this.target.transform.position.cloneTo(this.curpos); this.delatpos = new Laya.Vector3(); } } /** * Executed when each frame is updated, try not to write large loop logic here or use the getComponent method * This method is a virtual method and can be overridden when used. */ onUpdate(): void { if (!this.target || !this.camera) return; this.target.transform.position.vsub(this.curpos, this.delatpos); this.camera.transform.position.vadd(this.delatpos, this.delatpos); this.camera.transform.position = this.delatpos; this.target.transform.position.cloneTo(this.curpos); } } 4. Projection (Pic 4-1) There are two options for the projection method of the camera phase effect, namely the default perspective mode and the orthogonal mode Orthographic. In LayaAir IDE, choose which method to use by checking Orthographic. 4.1 Perspective perspective mode When we do not check Orthographic, we use the Perspective method, which is also the most commonly used method. The observation volume of perspective projection is the viewing frustum, which uses a set of radial projection lines generated by the projection center to project three-dimensional objects onto the projection plane. This perspective mode is a camera imaging mode that simulates the human eye's near-large and far-small visual effects, as shown in animation 4-2. (Animation 4-2) Field of view is the field of view, as you can see from the animation picture 4-2. By modifying Field Of View, you can adjust the field of view range in perspective mode, from 4 to 120 degrees. Field Of View is only available when perspective projection is used. efficient. The clipping plane is the plane perpendicular to the direction of the camera's field of view. Use the two sub-parameters of the near clipping plane and the far clipping plane to set the camera rendering range. The parts beyond the range will not be rendered and displayed, as if they were cropped. Near Plane is the near clipping plane, which refers to the clipping plane closest to the direction of the camera's field of view. Anything smaller than this distance will not be rendered. Far Plane is a far clipping plane, which refers to the clipping plane farthest from the camera's field of view. Anything larger than this distance will not be rendered. These two parameters are also only valid when using perspective projection. As shown in the animation 4-3, let’s take a look at the effect of modifying these two parameters. (Animation 4-3) 4.2 Orthographic Orthographic mode The observation volume in orthogonal projection mode is a regular cuboid, which uses a set of parallel projections to project three-dimensional objects onto the projection plane, as shown in Figure 4-4. (Figure 4-4) Orthographic Vertical Size is the field of view size, used to set the field of view size in orthogonal mode, as shown in animation 4-5. Orthographic Vertical Size is only effective in Orthogonal mode. (Animation 4-5) 5. Render (Figure 5-1) 5.1 Clear flag When rendering, each camera will first store the color and depth information, that is, ColorBuffer and DepthBuffer, and then directly read the color and depth information in the buffer in the next frame instead of calculating it in real time. When using multiple cameras, a large amount of rendering data will accumulate since each camera stores its own color and depth information in the buffer. Therefore, Clear Flags (clear flag) can determine whether to clear the buffer information stored before the current rendering. This property function has four options (Sky, SolidColor, DepthOnly, Nothing). The specific buffer information they clear is introduced below. . -Sky sky box Skybox is the default option, which means clear the color and depth information of all camera buffers before the current rendering and use the skybox instead. If no skybox is specified, the default clear color (the color of the Clear Color property) is displayed. SolidColor solid color Indicates clearing the color and depth information of all camera buffers before the current rendering, using the clear color (the color of the Clear Color attribute) instead, and any empty part on the screen will display the current camera s color. Nothing does not clear Indicates that this option does not clear the camera buffer information, and color and depth information are all retained. Doing so will cause the results of each frame of rendering to be superimposed on the next frame. It seems that this option is not necessary. In fact, it is not commonly used, but it is still used in some specific situations, such as using it in conjunction with a custom shader. DepthOnly Depth only It means that only clear the depth information of all camera buffers before the current rendering, and retain the color information of all camera buffers. This function is very practical. If you want to render the images from multiple cameras into the same image, you can use the DepthOnly option. For example, add a new camera Camera2 to the scene, use DepthOnly for Clear Flag, set the field of view of Camera2 toward the protagonist, and click Run. As you can see, the rendering of the scene remains unchanged, and the skybox is still used, but the main camera is the field of view seen by the protagonist, but the protagonist is also displayed on the screen, which is what Camera2 sees, that is, the depth information is retained. . When Clear Flags' DepthOnly is turned on, the LayaAir engine will be controlled by the camera's rendering sequence. The default rendering order is the rendering order of nodes. Developers can also change the rendering order through the renderingOrder of the LayaAir engine camera. If the Clear Flags of the first camera are set to Skybox, then the Clear Flags of the second camera are set to DepthOnly. At this time, the rendering order of the first camera needs to be before the rendering order of the second camera, as shown in Figure 5-2, Main Camera The node is above the Camera2 node, so the renderings of the two cameras will be merged together. (Figure 5-2) If the order is reversed and Camera2 renders first, although only the depth information is cleaned up, the color information is retained. However, the post-rendered Main Camera will clear all the depth and color of the previous buffer, so there is no way to see the merged images. Multiple cameras can be used in the same scene, and when loaded into the scene, they will produce their own game views. In the games we have encountered before, such as the two-player 3D game, two 3D cameras are used. The left half of the screen displays one player and the right half of the screen displays the other, which greatly enriches the gameplay. However, the disadvantage of multiple cameras is that it consumes a lot of performance. The number of model triangles and the number of DrawCalls will increase exponentially. Several more cameras will cause several times more performance loss, so developers need to consider it appropriately. 5.2 High dynamic lighting rendering High dynamic range image (High-Dynamic Range) is referred to as HDR. HDR can provide more dynamic range and image details than ordinary images, and it can better reflect the visual effects in the real environment. Enable HDR is used to turn on the high dynamic range rendering function of the camera. The default is unchecked, which means HDR is not turned on by default. Since HDR needs to be based on webGL 2.0, when we release products on some platforms that do not support webGL 2.0, we need to remove this option or turn off the camera's HDR in the engine. Turning on HDR will also invalidate the anti-aliasing function of the LayaAir engine. If you need to turn on the anti-aliasing function, you cannot turn on HDR. 5.3 Anti-aliasing MSAA: Multisampled anti-aliasing. MSAA first comes from OpenGL. Specifically, MSAA only performs super-sampling anti-aliasing processing on the data in the Z-buffer (Z-Buffer) and the stencil buffer (Stencil Buffer). It can be simply understood as anti-aliasing only the edges of polygons. FXAA: Fast approximate anti-aliasing. The basic principle of FXAA is the same as MSAA, which is to eliminate aliasing caused by high-contrast interfaces by extracting color information around the pixel interface and completing blending. However, FXAA leaves the pixel extraction and mixing process to the ALU in the GPU, so the memory bandwidth it occupies is much lower than traditional MSAA. 5.4 Culling Mask In LayaAir, you can set the corresponding Layer for each node. If not set, it will be the default Default layer. As shown in Figure 5-3, it is the protagonist node, which uses the Default layer by default. (Figure 5-3) Culling Mask is a setting for layer rendering culling, usually used in conjunction with DepthOnly. For example, if the Cube node is set to an independent cube layer and the Culling Mask selects the cube layer, then during rendering, other node objects of the camera will be eliminated, just like the mask effect, only the node objects on the cube layer will be retained. In this way, when the cameras are merged and displayed, only the node objects on the retained layer will be merged. As shown in Figure 5-4, (Figure 5-4) When setting the Culling Mask in the code, you can specify a single layer or mix multiple layers, for example: xx.cullingMask=Math.pow(2,0)|Math.pow(2,1); //This code represents the rendering display of layer 0 and layer 1. 6. Output (Figure 6-1) 6.1 View rectangle The view rectangle is a function that controls the position and size of the camera's view on the screen through the four values ​​X\\Y\\W\\H. These four values ​​all use the screen coordinate system. The value range is 0~1, and decimals can be set. The specific parameter description is: X: starting point of horizontal position Y: vertical position starting point W: Width H: height It should be noted that in LayaAir, it represents the position of the upper left corner of the screen (0,0). As shown in Figure 6-2, (Figure 6-2) If we set the starting point of the horizontal position of the screen (Figure 6-3) 6.2 Depth map Depth Texture Mode: Depth texture mode. None: Do not generate depth map. Depth: Generate depth map. This mode causes the depth texture generated by the camera to only carry depth information. The depth texture contains the distance (depth value) of each pixel relative to the camera. DepthNormals: Generate depth + normal map. In this mode, the depth texture generated by the camera not only carries depth information, but also contains normal information of the object surface. DepthAndDepthNormals: This mode is a combination of Depth and DepthNormals. In this mode, the camera will generate a texture containing both depth information and depth normal information. This type of depth texture stores not only the depth value (distance from the camera) of each pixel, but also the normal information. Depth Texture Format: The default value of camera depth format and depth texture is DEPTH_16. With the widespread use of depth, some developers will find that 16-bit depth is no longer enough. Now 24-bit and 32-bit depth modes have been added. value. Used to set the depthTextureFormat property. (Figure 6-4) 6.3 Target texture The target texture refers to the RenderTarget property of the camera. It places the camera's view on a texture that can be applied to another object. This makes it easy to create effects such as mirrors and surveillance cameras. Note that cameras using this property will disable rendering to the screen. Related functions include Rendering Texture. 6.4 Others Opaque Pass: After turning on opaquePass, non-transparent object maps will be generated. u_cameraOpaqueTexture can be introduced in Shader to obtain non-transparent pictures of the camera rendering pipeline. Using the non-transparent object mapping function, you can achieve effects such as glass refraction, water surface refraction, and heat waves. Enable Blit Depth: Set whether to use the built-in depth map (if turned on, the depth map can only be used in post-production, not in the rendering process). 7. Using the camera through code 7.1 How to create a ray from a camera Create a ray from the camera using the camera's viewportPointToRay method. The generated ray starts from a point on the near clipping plane of the camera and goes to a point on the far clipping plane. The reverse extension of this ray passes through the camera's origin. /** * Computes rays generated from screen space. * @param point The position of screen space. * @param out Output ray. */ viewportPointToRay(point: Vector2, out: Ray): void { this._rayViewport.x = this.viewport.x; this._rayViewport.y = this.viewport.y; this._rayViewport.width = ILaya.stage._width; this._rayViewport.height = ILaya.stage._height; Picker.calculateCursorRay(point, this._rayViewport, this._projectionMatrix, this.viewMatrix, null, out); } Referring to the 3D-RPG project, we add a piece of code. When the mouse clicks on the screen, a ray will be emitted. The point where this ray hits will create a cube. The code and effect are as follows: //In the onStart() method under the CameraControll.ts class, add mouse press monitoring //Laya.stage.on(Laya.Event.MOUSE_DOWN,this, this.onMouseDown); //Mouse click event, processing emitted rays, detecting collision objects onMouseDown(e: Laya.Event) { let point = new Laya.Vector2(); point.x = Laya.stage.mouseX; point.y = Laya.stage.mouseY; //generate ray let ray = new Laya.Ray(new Laya.Vector3(0, 0, 0), new Laya.Vector3(0, 0, 0)); this.camera.viewportPointToRay(point,ray); //Get the object that the ray collides with let outs : any[] = []; this.scene.physicsSimulation.rayCastAll(ray,outs); //If it collides with an object if (outs.length !== 0) { for (let i = 0; i (Animation 7-1) 7.2 Visible mask layer The use of Culling Mask was also mentioned in Section 5.4 earlier. When we make games, we can also use code to achieve the \"invisibility\" effect. Still using the 3D-RPG project as an example, we first set up two Layers. (Figure 7-2) Then change the Layers of these two rooms to Building1 and Building2, as shown in Figures 7-3 and 7-4. (Figure 7-3) (Figure 7-4) We add the following code to the CameraControll.ts class: private layerIndex: number = 0; onMouseDown(e: Laya.Event) { //Clear all layers this.camera.removeAllLayers(); this.layerIndex++; //Set the visual layer this.camera.addLayer(this.layerIndex%2+ 1); } The effect is shown in the animation 7-5. (Animation 7-5) 7.3 Capture target When creating a camera, we often need to adjust the position of the camera to align and display a certain three-dimensional object or display a certain area. For beginners, spatial thinking has not yet formed a habit, and it will take a lot of time to adjust the position. LayaAir's 3D transformation provides a lookAt() method for capturing the target and automatically adjusting the 3D object to the target point. The camera can also use it to achieve our purpose of adjusting the viewing angle. /** * Observe the target location. * @param target Observation target. * @param up up vector. * @param isLocal Whether it is local space. */ lookAt(target: Vector3, up: Vector3, isLocal: boolean = false, isCamera: boolean = true): void Similarly, in our 3D-RPG project, we switch the visible area by clicking the mouse. The code is as follows: //In the CameraControll.ts class script, add 3 node objects and drag 3 different houses and buildings into the properties. @property( { type: Laya.Sprite3D } ) public target1: Laya.Sprite3D; @property({ type: Laya.Sprite3D }) public target2: Laya.Sprite3D; @property({ type: Laya.Sprite3D }) public target3: Laya.Sprite3D; private _up = new Laya.Vector3(0, 1, 0); private index: number = 0; //Similarly, add mouse events to modify the camera's orientation to the three buildings onMouseDown(e: Laya.Event) { this.index++; if (this.index % 3 === 1 ){ //Camera captures model target this.camera.transform.lookAt(this.target1.transform.position, this._up); } else if (this.index % 3 === 2){ //Camera captures model target this.camera.transform.lookAt(this.target2.transform.position, this._up); } else{ //The camera captures the model target this.camera.transform.lookAt(this.target3.transform.position,this._up); } } The effect is as follows: (Animation 7-6) 7.4 aspect ratio We generally do not set the aspect ratio of the screen manually. The aspect ratio is automatically set through calculation during operation. However, in some special cases when you need to manually set the aspect ratio, you can set it manually. If you need to reset the aspect ratio and go back to automatically changing the aspect ratio, just set this value to 0. //Manually set aspect ratio camera.aspectRatio = 2; //reset camera.aspectRatio = 0; 7.5 Target Texture We still use the 3D-RPG project as an example. Main Camera is the main rendering camera of the scene, and a new renderTargetCamera is added as the camera with the RenderTarget attribute turned on. At the same time, add a Plane to the scene, facing the main camera, as shown in Figure 7-7. (Figure 7-7) Next, we add Plane and renderTargetCamera to the CameraControll.ts script, @property({ type: Laya.Camera }) public renderTargetCamera: Laya.Camera; @property({ type: Laya.Sprite3D }) public plane: Laya.Sprite3D; And add code in onStart(): //Select the rendering target as texture this.renderTargetCamera.renderTarget = Laya.RenderTexture.createFromPool(512, 512, Laya.RenderTargetFormat.R8G8B8A8, Laya.RenderTargetFormat.DEPTH_16, false, 1); //Rendering order this.renderTargetCamera.renderingOrder = -1; //Clear mark this.renderTargetCamera.clearFlag = Laya.CameraClearFlags.Sky; //Create an UnlitMaterial material var mat1: Laya.UnlitMaterial = new Laya.UnlitMaterial(); mat1.albedoColor = new Laya.Color(1.0, 1.0, 1.0, 1.0); mat1.cull = Laya.RenderState.CULL_NONE; //Specify the plane's material as the created material this.plane.getComponent(Laya.MeshRenderer).sharedMaterial = mat1; //Specify the texture as the render target of the camera mat1.albedoTexture = this.renderTargetCamera.renderTarget; In the LayaAir engine, the smaller the rendering order renderingOrder is, the higher the rendering priority is. The running effect is shown in the animation 7-8. There is an additional camera view in the scene and is placed on the Plane as a texture. (Animation 7-8) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:53:26 "},"3D/Light/readme.html":{"url":"3D/Light/readme.html","title":"Light","keywords":"","body":"Use 3D lights and shadows1. OverviewSecond, PointLight2.1 Create point light source2.2 Component properties2.3 Use code settings3. DirectionLight3.1 Create directional light3.2 Component properties3.3 Use code settings4. SpotLight4.1 Create spotlight4.2 Component properties4.3 Use code settings5. AreaLight5.1 Create area light5.2 Component properties6. How to add shadows to lights7. Multi-light renderingUse 3D lights and shadows 1. Overview Light sources are an important part of every scene. Grids and textures determine the shape and appearance of an object, but light sources determine the color and mood of your environment. There are many types of lights. Different light sources present different effects and different parameters can be set. The current types of light sources include: DirectionLight (parallel light) PointLight SpotLight AreaLight This article will explain these four light sources one by one. Second, PointLight PointLight (point light source) is a light source that emits light in all directions, also known as omnidirectional light or spherical light. In reality, point light sources such as light bulbs and candles can feel that point light sources have intensity, color, and attenuation radius attributes. As shown in Figure 2-1, in a building surrounded by walls, the point light source created in it can set the light source effect by setting the intensity, color, and radius. (Figure 2-1) 2.1 Create point light source (Animation 2-2) As shown in the animation 2-2, under Scene3D or any node, right-click the mouse and select Light, then click PointLight to create a point light source in the scene. 2.2 Component properties 2.2.1 Basic attributes As shown in Figure 2-3, after creating a PointLight, there will be the following properties in the Inspector property panel (Figure 2-3) Color: the color of the point light source (Figure 2-4) Intensity: The intensity of the point light source (Figure 2-5) Range: Set the range of the point light source, which is equivalent to the illumination range of the point light source. The larger the value, the greater the illumination range. (Figure 2-6) Lightmap Bake Type: Light source mode Mixed: mixed light source Hybrid lights combine real-time lights and light baking. You can use Mixed Lights to combine dynamic shadows with baked lighting from the same light source, or use Mixed Lights when you want a light to provide direct realtime illumination and baked indirect lighting. The properties of a blended light can be changed at runtime. Doing so will update the light's realtime lighting, but not the baked lighting. Since blended lights always combine at least some real-time and some baked lights, blended lights always involve more runtime calculations than fully baked lights and use higher memory than fully real-time lights. Realtime: real-time light source LayaAir performs lighting calculations for real-time lights at runtime, once per frame. You can change the properties of a real-time light source at runtime, creating effects such as a flickering light bulb or a torch passing through a dark room. Real-time lights can be used to provide lighting and cast shadows on characters or movable geometry. Performing runtime calculations for real-time lights can be expensive. Baked: Baked light source LayaAir performs calculations for baked lights and saves the results to disk as lighting data. This process is called baking. At runtime, LayaAir will load the baked lighting data and use this data to light the scene. Since complex calculations are performed upfront, baking lights reduces shading costs at runtime and reduces shadow rendering costs. Baked lights can be used to illuminate objects that do not change at runtime, such as scenes. 2.2.2 Baking properties As shown in Figure 2-7, when the Lightmap Bake Type is selected as Baked, three parameters will appear below. This function is for setting the baking effect in advance. Since the baking effect can only be seen after baking is executed, it is possible to repeatedly adjust the following parameters to continuously bake the best results. (Figure 2-7) Box: cubic skybox Dome: spherical skybox Material: Specifies the material of the sky box Power: Light intensity for baking Radius: baked lighting radius Max Bounces: The maximum number of bounces of baked light (Figure 2-8) Figure 2-8 shows the baked effect of adding multiple point light sources to an architectural scene. 2.3 Use code settings //Create point light source var pointLight: PointLight = (this.scene.addChild(new PointLight())); //Color of point light source pointLight.color = new Color(1.0, 0.5, 0.0, 1); pointLight.transform.position = new Vector3(0.4, 0.4, 0.0); //Set the range of point light source pointLight.range = 3.0; //Set the intensity of the point light source pointLight.intensity = 2; 3. DirectionLight Direction Light is quite different from point light. It has a fixed direction, which can be set by the radian value. It also has no attenuation and illumination range, and will illuminate all models in the entire scene. In the 3D world, it is often used to simulate fixed-direction sunlight. When creating a new 3D scene, DirectionLight comes by default. As shown in Figure 3-1, in a scene, by adjusting the angle of parallel light, the lighting effect of the scene can be adjusted. (Animation 3-1) 3.1 Create directional light (Animation 3-2) As shown in the animation 3-2, under Scene3D or any node, right-click the mouse and select Light, then click DirectionLight to create a directional light in the scene. 3.2 Component properties 3.2.1 Basic attributes As shown in Figure 3-3, after creating a DirectionLight, there will be the following properties in the Inspector property panel (Figure 3-3) Color: the color of directional light (Figure 3-4) Intensity: the intensity of parallel light (Figure 3-5) Lightmap Bake Type: Light source mode, the same as point light source Shadow Mode: Shadow mode Shadow Cascades Mode: Shadow cascade mode (Animation 3-6) As shown in the animated picture 3-6, you can turn on the shadow mode effect and adjust the angle of the parallel light at the same time. You can see the shadow change accordingly. We will introduce shadows in Chapter 6 3.2.2 Baking properties As shown in Figure 3-7, when the Lightmap Bake Type is selected as Baked, three parameters will appear below. This function is for setting the baking effect in advance. (Figure 3-7) Power: Light intensity for baking Radius: the lighting angle for baking Max Bounces: The maximum number of bounces of baked light 3.3 Use code settings //Color of directional light this.directionLight.getComponent(Laya.DirectionLightCom).color.setValue(1, 1, 1, 1); //Set the direction of parallel light var mat: Matrix4x4 = this.directionLight.transform.worldMatrix; mat.setForward(new Vector3(-1.0, -1.0, -1.0)); this.directionLight.transform.worldMatrix = mat; setForward The direction of parallel light represents the direction on the x, y, and z axes respectively. Negative numbers are the negative axis, positive numbers are the positive axis. The value range is -1-0-1, and -1 after exceeding the range. Or 1, beginners can set the value within this range to observe changes in direction. (Animation 3-8) As shown in the animated picture 3-8, set the parallel light rotation to see the effect. 4. SpotLight SpotLight Spotlight refers to the light emitted from the direction of a specific light source, such as flashlights, stage downlights, etc. The illuminated area gradually enlarges according to the distance factor, and there is also attenuation at the edge of the illuminated area. As shown in Figure 4-1, in a scene, by adjusting the cone angle of the spotlight, the lighting effect of the scene can be adjusted. (Animation 4-1) 4.1 Create spotlight (Animation 4-2) As shown in the animation 4-2, under Scene3D or any node, right-click the mouse and select Light, then click SpotLight to create a spotlight in the scene. 4.2 Component properties 4.2.1 Basic attributes As shown in Figure 4-3, after creating a SpotLight, there will be the following properties in the Inspector property panel (Figure 4-3) Color: the color of the spotlight (Figure 4-4) Range: The irradiation range of spotlight, similar to point light. The difference is that spotlight has direction, while point light has no direction. (Figure 4-5) Spot Angle: The cone angle of the spotlight. The smaller the value, the smaller the focusing aperture, and vice versa. (Figure 4-6) 4.2.2 Baking properties As shown in Figure 4-7, when the Lightmap Bake Type is selected as Baked, five parameters will appear below. This function is for setting the baking effect in advance. (Figure 4-7) Power: Light intensity for baking Radius: baked lighting radius Max Bounces: The maximum number of bounces of baked light Spot Size: The size of the spotlight Blend: blending ratio, between 0-1 4.3 Use code settings //spotlight var spotLight = scene.addChild(new Laya.SpotLight()) as Laya.SpotLight; //Set spotlight color spotLight.color = new Laya.Vector3(1, 1, 0); //Set the spotlight position spotLight.transform.position = new Laya.Vector3(0.0, 1.2, 0.0); //Set the spotlight direction var mat = spotLight.transform.worldMatrix; mat.setForward(new Laya.Vector3(0.15, -1.0, 0.0)); spotLight.transform.worldMatrix = mat; //Set the spotlight range spotLight.range = 6.0; //Set the spotlight cone angle spotLight.spotAngle = 32; setForward The direction of parallel light represents the direction on the x, y, and z axes respectively. Negative numbers are the negative axis, positive numbers are the positive axis. The value range is -1-0-1, and -1 after exceeding the range. Or 1, beginners can set the value within this range to observe changes in direction. (Animation 4-8) As shown in the animation in Figure 4-8, set the spotlight to rotate to see the effect. 5. AreaLight AreaLight Area lights can be defined by one of two shapes in space: a rectangle or a disk. An area light emits light from one side of the shape. The emitted light spreads evenly in all directions over the surface area of ​​the shape. The intensity of illumination provided by an area light decreases at a rate determined by the inverse square of the distance from the light source (see the inverse square law). Because this lighting calculation is very processor intensive, area lights are not available at runtime and can only be baked into lightmaps. Because area lights illuminate objects from several different directions at once, shadows tend to be softer and more detailed than other light types. You can use this light source to create a realistic street light or a row of lights close to the player. Small area lights can simulate smaller light sources (such as indoor lighting), but the effect is more realistic than point lights. As shown in Figure 5-1, in a scene, the lighting effect of the scene can be adjusted by adjusting the size and diffusion of the area light. (Animation 5-1) 5.1 Create area light (Animation 5-2) As shown in the animation 5-2, under Scene3D or any node, right-click the mouse and select Light, then click AreaLight to create an area light in the scene. 5.2 Component properties 5.2.1 Basic attributes As shown in Figure 5-3, after creating an AreaLight, there will be the following properties in the Inspector property panel (Figure 5-3) Color: the color of the area light Intensity: The intensity of the area light Shape: the shape of the area light Rect: rectangle Elliptic: circle Spread: spread 5.2.2 Baking properties Max Bounces: The maximum number of bounces for baking 6. How to add shadows to lights The shadow is the instant shadow produced when the light shines on the model, which can change with the change of light angle, light intensity, model position, etc. Projection is one of the most important factors in the 3D world, which can produce a stronger three-dimensional sense. Real-time shadowing consumes very much performance and cannot be used too much, especially in game scenes where the model volume is large. Generally, we do not use real-time projection, but use static light maps. 6.1 Shadow properties of light To create shadows in the scene, we need to understand the following properties of light, which are possessed by every light source 6.1.1 Shadow Mode (Figure 6-1) ShadowMode: Shadow mode, divided into four modes: None: no shadow is generated Hard: Hard shadow, lower performance requirements (Figure 6-1-1) SoftLow: low-intensity soft shadow, with average performance requirements (Figure 6-1-2) SoftHigh: high-intensity soft shadows with high performance requirements (Figure 6-1-3) The best effect The difference between hard shadow and soft shadow: Hard shadow refers to a dark, uniform and well-defined shadow produced by an ideal electric light source (i.e. a single light source with good light gathering performance). It only contains the umbra of the object. . Soft shadows are shadows with soft boundaries and a certain degree of excessive light and dark produced by line, surface or volume light sources. It includes the umbra and penumbra of the object. When an object is completely in shadow, it is in the umbra domain, and when an object is partially illuminated, it is in the penumbra domain. 6.1.2 Shadow properties When we select a shadow mode, we can see the properties for setting the shadow (Figure 6-2) shadowStrength: Shadow strength. The larger the value, the more obvious the shadow. (Animation 6-2-1) shadowDistance: The range of shadows generated by the light. The range refers to the distance from the camera to the model. Models beyond this range will not generate shadows or accept shadows. Developers can set it according to the scene size. (Figure 6-2-2) In Figure 6-2-2, the effect when shadowDistance is 8 shadowDepthBias: The shadow map is offset based on depth. Offsetting the depth can effectively solve shadow acne (\"shadow acne\"). But it needs to be reminded that when shadowDepthBias is too large, it will cause the shadow to separate from the object, that is, the \"Peter Panning\" phenomenon occurs. shadowNormalBias: The shadow map is based on the normal offset, which offsets the surface of the shadow Caster in the opposite direction of the normal direction to prevent the appearance of self-shadow (\"shadow acne\") artifacts. Larger values ​​provide better protection against \"shadow acne\", but at the cost of making the shadow shape smaller than the actual object. shadowNearPlane: The near plane of the shadow frustum. You can set the near plane of the shadow frustum. 6.1.3 Cascade mode of shadows (Figure 6-3) shadowCascadesMode: The cascade mode of shadows. The larger the number, the more sub-view frustum the view frustum is divided into when generating shadow maps, the more corresponding shadow maps there are, and the better the shadow quality will be. TwoCascades: Two-level cascade shadow segmentation ratio. (Figure 6-3-1) In Figure 6-3-1, the effect of TwoCascades FourCascades: Four-level cascade shadow division ratio, X, Y, Z are their division ratios in order, Z must be greater than Y, Y must be greater than X. (Figure 6-3-2) In Figure 6-3-2, the effect of FourCascades 6.2 Projection properties of the model In addition to the shadow settings of the light source, the projection properties need to be set on the model: as shown in Figure 6-4 (Figure 6-4) receiveShadow: Whether to accept shadows. When this property of the model is true, the calculated shadow will be displayed on this model. In the game, we can set the castShadow property of the ground of the scene and the model in the walkable area of ​​the scene to true. castShadow: Whether to generate shadows. When this attribute of the model is true, the light performs shadow calculations based on the position of the model that generates shadows, the shape and size of the model mesh, and the angle with the light, etc., and then generates shadows on the model that accepts shadows. For example, active game elements such as characters and NPCs in the scene can turn on this attribute. As shown in the animation 6-5, it shows the effect of real-time shadows of parallel light. (Animation 6-5) As shown in the animation 6-6, it shows the effect of real-time shadows of spotlights. (Animation 6-6) 6.3 Use code settings Lighting settings: // Use soft shadow. directionLight.shadowMode = ShadowMode.SoftLow; // Set shadow max distance from camera. directionLight.shadowDistance = 3; // Set shadow resolution. directionLight.shadowResolution = 1024; // Set shadow cascade mode. directionLight.shadowCascadesMode = ShadowCascadesMode.NoCascades; // Set shadow normal bias. directionLight.shadowNormalBias = 4; Turn on the ground to receive shadows and the model to generate shadows: // A plane receive shadow. var grid: Sprite3D = scene.addChild(Loader.getRes(\"res/threeDimen/staticModel/grid/plane.lh\")); (grid.getChildAt(0)).meshRenderer.receiveShadow = true; // A sphere cast/receive shadow. var sphereSprite: MeshSprite3D = this.addPBRSphere(PrimitiveMesh.createSphere(0.1), new Vector3(0, 0.2, 0.5), scene); sphereSprite.meshRenderer.castShadow = true; 7. Multi-light rendering As shown in Figure 7-1, in the project settings of the IDE, you can set the support for multiple light sources. (Figure 7-1) Enable Multi Light: Whether to support multiple light sources Max Light Count: The maximum number of light sources supported, currently the maximum is 50 Light Cluster Count: The number of lighting clusters in the X, Y, and Z axes The number of lighting clusters in the The average amount of light received in the area. If the average number of light sources affected by each Cluster is greater than this value, the farther Cluster will ignore the excess light effects. (Animation 7-2) Animation 7-2 is an example of multiple light sources. The following is the code to create multiple light sources. export class MultiLight extends BaseScript { constructor() { super(); } onAwake(): void { var moveScript: LightMoveScript = this.camera.addComponent(LightMoveScript); var moverLights: LightSprite[] = moveScript.lights; var offsets: Vector3[] = moveScript.offsets; var moveRanges: Vector3[] = moveScript.moveRanges; moverLights.length = 15; //Add 15 point light sources for (var i: number = 0; i this.scene.addChild(new PointLight())); pointLight.range = 2.0 + Math.random() * 8.0; pointLight.color.setValue(Math.random(), Math.random(), Math.random(), 1); pointLight.intensity = 6.0 + Math.random() * 8; moverLights[i] = pointLight; offsets[i] = new Vector3((Math.random() - 0.5) * 10, pointLight.range * 0.75, (Math.random() - 0.5) * 10); moveRanges[i] = new Vector3((Math.random() - 0.5) * 40, 0, (Math.random() - 0.5) * 40); } //Add a spotlight var spotLight: SpotLight = (this.scene.addChild(new SpotLight())); spotLight.transform.localPosition = new Vector3(0.0, 9.0, -35.0); spotLight.transform.localRotationEuler = new Vector3(-15.0, 180.0, 0.0); spotLight.color.setValue(Math.random(), Math.random(), Math.random(), 1); spotLight.range = 50; spotLight.intensity = 15; spotLight.spotAngle = 60; } } //Light source moving script class LightMoveScript extends Laya.Script { forward: Vector3 = new Vector3(); lights: LightSprite[] = []; offsets: Vector3[] = []; moveRanges: Vector3[] = []; onUpdate(): void { var seed: number = Laya.timer.currTimer * 0.002; for (var i: number = 0, n: number = this.lights.length; i Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:59:01 "},"IDE/sceneEditor/environment/readme.html":{"url":"IDE/sceneEditor/environment/readme.html","title":"environment","keywords":"","body":"3D scene environment settings1. Overview2. Scene sky2.1 Component properties2.2 Use code to set the scene sky material2.3 Create skybox in IDE3. Ambient light3.1 Component properties3.2 Fixed color3.3 Spherical harmonic lighting4. Environmental reflection4.1 Component properties4.2 Skybox as reflection source4.3 Custom reflection source as reflection source4.3 Introduction to IBL5. Scene fog5.1 Component properties5.2 Code usage6. Light map6.1 Component properties6.2 Create lighting settings file6.3 Detailed explanation of attributes6.4 Baking7. Scene management7.1 Create a new scene7.2 Scene renaming7.3 Set as startup scene8. Scene switching and loading resources8.1 Code switching scenario8.2 Scene resource loading3D scene environment settings In this article, we will fully understand the powerful functions of LayaAir3.0 3D scene editing (Picture 1-1) 1. Overview The scene is the 3D world container of the LayaAir engine, which is used to present the 3D picture of the game and load various 3D elements. The cameras, lights, characters, items, etc. in the game need to be placed in the scene to display the picture, which is equivalent to a game. 3D player or 3D view. In the LayaAir3.0 engine, 3D and 2D can be mixed, and the created Scene 3D scenes and Scene 2D containers or elements can be loaded onto the stage at the same time. Let's first understand what the parameters of a 3D scene are. In order to achieve a good effect in a 3D scene, all factors need to be considered. We refer to it by creating a 3D-RPG project, as shown in Figure 1-2 (Figure 1-2) The created 3D-RPG project is shown in Figure 1-3. The project itself is a scene. From the Hierarchy window, you can see the Scene3D and Scene2D root nodes. Here we only explain the Scene3D scene, which includes important components of the 3D scene, 3D cameras, 3D sprites, etc. We will explain them in other documents (Figure 1-3) When we click on the Scene3D node, look at the parameter information under the Inspector, as shown in Figure 1-4 (Figure 1-4) From Figure 1-4, we can see several components, which are the contents we need to care about. Next, we will explain the contents involved in the scene: Environment Sky Ambient light Environment Reflection Environmental Fog Lightmap (baking) 2. Scene sky The way to realize the sky of the scene is the sky box. The sky box is a visual technology that makes the scene look wider and boundless. It uses a seamless closed texture to wrap the camera's viewport 360 degrees without dead ends. The sky box also It is the sky in the 3D world. In Figure 2-1 we can see the skybox. The idea of ​​a skybox is to draw a large cube and then place the observer in the center of the cube. When the camera moves, the cube also moves with the camera, so that the camera never moves to the edge of the scene. This is the same as the situation in our real world. We can see that the distant sky touches the horizon, but no matter how we move in that direction, we cannot reach that place. (Figure 2-1) The Sky Renderer component Sky Renderer is the default component of the Scene3D scene and is used to specify the network shape of the sky box. (Figure 2-2) 2.1 Component properties Mesh Type: Mesh shape. Currently, the engine provides two common skybox meshes: cube and spherical. Among them, cubic grid is more commonly used. Box: cubic skybox Dome: spherical skybox Material: Specifies the material of the sky box (Figure 2-3) Expand DefaultSkyMaterial, as shown in Figure 2-3, which is the skybox material being used. Currently we use LayaAir’s built-in SkyPanoramic shader. The color and texture of SkyPanoramic are the two most important settings. We will discuss them in the material chapter. Detailed introduction to the three sky box materials provided by LayaAir3.0 SkyPanoramic, Skybox, and SkyProcedural Note: If you need to use a SkyProcedural procedural sky, you can only use a spherical sky. Because this material uses vertex shading, it requires detailed vertex information. About the material SkyProcedural used in the sky box, the programmed sky material and the SkyBox sky box material will be explained later in the Material material article Regarding the SkyPanoramic material, let’s see how to set it up. Tint Color: Color, as shown in Figure 2-4, change the color, and you can see that the changed color is superimposed on the texture. (Figure 2-4) Rotation: Rotation, from 0 to 360 degrees, rotation can help us adjust the position of the skybox The skybox changes as the perspective is rotated, and we can observe distant views in all directions. Of the two meshes currently provided, the box-shaped sky has less vertex data, so the performance of this type of sky is better. Panoramic Texture: The texture map of the sky box (a map corresponding to the spherical model) 2.1.1 Cube Sky The six seamlessly connected texture references used in the cube skybox are shown in Figure 2-5. (Figure 2-5) 2.1.2 Spherical Sky It is composed of a spherical model and a corresponding texture. The example used is a texture corresponding to a spherical model, as shown in Figure 2-6 (Figure 2-6) Basically, after using textures and colors, and configuring the sky box material, we can add a good sky effect to our scene. (Animation 2-7) Run the 3D-RPG project, rotate the camera, and you can see the effect of the sky box, as shown in the animation 2-7 2.2 Use code to set the scene sky material Of course, we can also load and specify the skybox through code var skyRenderer = this.scene.skyRenderer; //Load camera skybox material Laya.Material.load(\"sky2.lmat\", Laya.Handler.create(null, function(mat: any) { //Modify the skybox material of the skybox renderer skyRenderer.material = mat; })); 2.3 Create skybox in IDE 2.3.1 Change the IDE’s default spherical skybox When we use the IDE to create a 3D scene, the default is a spherical skybox using the SkyPanoramic material, as shown in Figure 2-8 (Figure 2-8) Since the system's material is inside the IDE, it cannot be modified directly. If you need to modify it, you can copy the same skybox material to the assets directory by cloning, as shown in animation 2-9. (Animation 2-9) Then prepare a new spherical skybox texture, as shown in Figure 2-10 (Figure 2-10) Drag the new texture into the cloned material, as shown in animation 2-11 (Animation 2-11) At this time, whether in the IDE scene or the preview effect, the skybox has been replaced with a new one. 2.3.2 Change cube skybox If the developer wants to use a cube skybox, first we change the material of the above skybox to Skybox, as shown in animation 2-12 (Animation 2-12) The Laya.SkyBox material supports 6 seamlessly connected textures, but you need to create a Cube Texture first. As shown in the animation 2-13, create a Cube Texture in the assets directory. (Animation 2-13) In Cube Texture, add the 6 pre-prepared textures and click Apply, as shown in Figure 2-14 (Figure 2-14) Finally, drag the Cube Texture with the map configured into the skybox Texture of the skyBox material. The cube skybox is configured and you can see the effect by running the scene. (Figure 2-15) 3. Ambient light Ambient light, also called diffuse ambient light, is the light that exists around the scene. and does not come from any specific light source. It can make an important contribution to the overall look and brightness of a scene. Ambient light can be useful in many situations, depending on the art style you choose. This can also be used if you need to increase the overall brightness of the scene without adjusting individual lights. As shown in Figure 3-1, the EnvironmentLight component is used to specify the ambient light in the 3D-RPG project. (Figure 3-1) 3.1 Component properties Ambient Mode: ambient light mode, divided into two types Ambient Color: Fixed color. Use Ambient Color as ambient light source Ambient Intensity: Color intensity. Spherical Harmonics: Spherical harmonic lighting. The spherical harmonic data generated by the sky box is directly applied to the object. It will be introduced later that when spherical harmonic lighting is selected, IBL is used to adjust the effect. 3.2 Fixed color Figure (3-2) We use a simple scene as a reference, when we turn off the Direction Light (Figure 3-2) GIF (3-2) You can see how the color changes to the ambient light when using Ambient Color, as shown in animation 3-2. 3.1.1 Code usage The ambient light color AmbientColor is a color fusion dyeing of the material to make the material tend to a certain color tone. It can also brighten the material and simulate the lighting effect of a light box. If the sky box is set and the AmbientColor of the Scene3D scene is not set, LayaAir3.0 will default to ambient light coming from the sky box, which is spherical harmonic lighting. We can also modify the ambient light of the current scene through code //Set the scene environment light scene.ambientColor = new Laya.Color(0,0,0,0); 3.3 Spherical harmonic lighting You can see the effect of using spherical harmonic lighting. The surface of the object is affected by the sky box, as shown in the animation 3-3. In the next section, we will introduce the specific usage of using spherical harmonic lighting to affect the environment reflection IBL method. GIF (3-3) 4. Environmental reflection The Ambient Reflections feature provides effective smooth reflections everywhere in the scene. Some important materials, such as metal, rely on reflections in all directions, which is what ambient reflections provide. There are two types of scene environment reflection, skybox reflection and custom reflection. If you want to have a reflection effect, you must have a reflection material in the object Shader. If there is no reflection material, there will be no effect. The default BlinnPhong does not support it. The PBR material supports environmental reflection. ReflectionProbe is the environmental reflection component of the Scene3D scene, as shown in Figure 4-1 (Pic 4-1) 4.1 Component properties Source: reflection source Skybox: Select this option to use a skybox as a reflection source Custom: Select this option to use a custom reflection source Resolution: If you select skybox reflection, you can set the resolution 4.2 Skybox as reflection source The effect of spherical harmonic lighting in the previous chapter, animation (3-3), shows the use of the sky box set by the scene as an environmental reflection 4.3 Custom reflection source as reflection source Cubemap: If you choose custom reflection, cubemap will be used, which is a collection of six independent square textures. It combines multiple textures and maps them to a single texture, as shown in Figure 4-2 (Figure 4-2) Note: The texture map must be set to the texture shape of the Cube (Figure 4-3) Drag the cubemap image into cubemap and configure Cubemap As shown in Figure 4-4, then click Generate Light to generate the reflection effect (Figure 4-4) As shown in Figure 4-5, the reflection of the sphere uses the specified skybox texture instead of the scene’s skybox. (Figure 4-5) No matter what kind of sky box it is, we can use IBL to better handle the reflection effect, but the first step is to generate lighting Generate Light Start generating environment reflections by clicking the Generate Light button, as shown in Figure 4-6 (Figure 4-6) After the generation process is introduced, from the ReflectionProbe component, you can see that IBL Tex has additional sky box textures, as shown in Figure 4-7 (Figure 4-7) 4.3 Introduction to IBL IBL is an important source of realism based on physical rendering and is a solution for environmental lighting. For most cases, the ambient light comes from the skybox, also known as the cubemap map. Therefore, the focus of IBL is how to obtain lighting information from the image. iblSamples: The adoption rate of image-based lighting. The more samples, the closer to reality ibl Tex: Environment Cubemap (Cubemap) ibl Tex RGBD: RGB depth map is used by default When using IBL, the ambient light must use the Spherical Harmonics method. When you click Generate Light, you can see that the IBL Tex texture will be automatically generated, and the reflection effect can be adjusted in the material of the 3D object. 5. Scene fog The fog effect plays an important role in the project. The fog effect is equivalent to turning on the atmosphere. It looks hazy and makes the scene more realistic. The LayaAir 3.0 engine can set the fog effect visible distance (equivalent to density) and fog effect color of the scene. Proper use of atomization can not only improve game performance, but also increase the gaming experience. The fog component Fog is the default component of the Scene3D scene, as shown in Figure 5-1 (Figure 5-1) 5.1 Component properties Fog Start: starting position of fog Fog Range: the distance from where the fog is thickest Fog Color: Fog color First check the fog properties, then adjust the range of fog and the color of fog 5.2 Code usage //atomization code this.scene.enableFog = true; //Set the color of the fog this.scene.fogColor = new Laya.Color(0,0,0.6); //Set the starting position of fog, relative to the distance from the camera this.scene.fogStart = 10; //Set the distance of the densest fog point. this.scene.fogRange = 40; 6. Light map In 3D game scenes, relying on real-time rendering of lights and models to produce projection and color effects is very performance-intensive. Especially on mobile platforms, the graphics card function of mobile phones is not powerful. If all real-time light shading is used, the performance overhead will be very large and the game will become laggy. Scene light mapping is designed to solve this problem. Its advantage is that it can make static scenes look more realistic, rich, and three-dimensional with less performance consumption. The disadvantage is that dynamic lighting cannot be processed in real time. Let's compare the effect of not using light maps and using light maps. (Figure 6-1) No light map used (Figure 6-2) Light map is used We see that the difference is obvious, now let's explain how to generate light maps. 6.1 Component properties When we create a new scene, the default Lighting component does not have any settings, as shown in Figure 6-3 (Figure 6-3) Lightmaps: Lightmap, which can be a set of maps. If there is no baking, there is no need to click the plus sign + Lighting Setting: Light map settings file, we will create this file below Bake: The Bake button is used to generate baking 6.2 Create lighting settings file Next create a LightingSetting file, if 6-4 (Figure 6-4) Drag the generated file into Lighting Settings (Figure 6-5) 6.3 Detailed explanation of attributes Below we can see all the properties of LightingSettings (Figure 6-6) Max lightmap size: The maximum size of the lightmap. The larger the size, the clearer it is. Mode： Bake: mode will generate baking pictures (several pictures will be allocated according to the scene) View: mode will generate a rendering (only one) Max sample: sampling value. The larger the value, the better the effect and the longer the time. Denoise: Eliminate noise in light maps, denoising settings Enable: whether to enable prefillter: denoising method, optional `accurate` fine `fast` fast `none` None Denoise Type: Denoising method, you can choose `optix` denoising optix method `openimagedenoise` denoising openimagedenoise method, the best method in the industry `none` None AO: Controls the relative brightness of surfaces in baked ambient occlusion. Indirect lighting used for lightmap calculations of baked lighting. Bounces: The number of AO bounces. The larger the value, the slower it is. Default: 8 Factor: AO influence parameters. Default: 1 Distance: The maximum distance that affects AO. The larger the value, the better the effect, but the slower the baking speed. Default: 6 Bounce: the number of light bounces Diffuse bounce: The number of bounces of diffuse reflection light. Default: 4 Transmission bounce: The number of bounces of transmission light. Default: 12 Glossy bounce: The number of glass bounces. Default: 4 Total bounce: The number of bounces. Default: 3 Sample_clamp_direct: Default: 0, used to reduce direct light noise Sample_clamp_indirect: Default: 10, used to reduce indirect light noise, but the light will become darker Margin: Rendering extended edges, used to solve the problem of black seams on borders, generally choose 16 Margin higher filter: Whether the boundary is sampled with high precision Scene Module Scale: Scaling of the entire scene lightmap size 6.4 Baking After setting the parameters, click Bake. After a few minutes, the baked light map will be automatically generated and added to Lightmaps, as shown in Figure 6-7 (Figure 6-7) Light mapping generates a new texture based on the texture of the object itself, as shown in Figure 6-8 (Figure 6-8) The baked scene has lighting effects and shadow effects on the trees, as shown in Figure 6-9 (Figure 6-9) Through comparison, we can see the effect brought by light mapping, and the rendering efficiency is very high, without the need for real-time lighting. Figure 6-10 is a comparison picture without light mapping. (Figure 6-10) 7. Scene management The 3D-RPG project is just a 3D project with only one scene. Large-scale projects are composed of multiple scenes. Reasonable management of 3D scenes will improve our development efficiency. 7.1 Create a new scene Open the Project resource directory of the 3D-RPG project, and you can see that there is a scene folder here, as shown in Figure 7-1. It is a good habit to store other scene files here, and it looks clearer. (Figure 7-1) For example, in a 3D-RPG project, if you have a Game scene, you may also need a game login scene, so let’s create a Login scene, as shown in animation 7-2 (Animation 7-2) You can also create a scene from New Scene in the editor's File menu and save it to the scene directory, as shown in animation 7-3. (Animation 7-3) 7.2 Scene renaming If you want to rename the scene, you can rename the scene file directly in Project, as shown in animation 7-4. (Animation 7-4) 7.3 Set as startup scene Usually the Login scene is the startup scene, so we can set the startup scene in Project Settings, as shown in animation 7-5 (Animation 7-5) 8. Scene switching and loading resources In the process of 3D game development, we often need to create multiple scenes. The main program of the game needs to load scenes for switching, and at the same time release old scene resources and memory. 8.1 Code switching scenario The sample code is as follows: //Open the specified scene and display Scene2D and Scene3D at the same time Laya.Scene.open(\"scene/Game.ls\",true, null, Laya.Handler.create(this, this.onLoaded), Laya.Handler.create(this, this.onLoading)); //Close the specified scene Laya.Scene.close(\"scene/Login.ls\") //Destroy the specified scene Laya.Scene.destroy(\"scene/Login.ls\") 8.2 Scene resource loading The sample code is as follows: //Load using Laya.Scene3D Laya.Scene3D.load('scene/Game.ls', Laya.Handler.create(null, function (res:any){ Laya.stage.addChild(res); })); //Load using Laya.loader. After loading, the root node is Scene2D. Laya.loader.load('scene/Game.ls', Laya.Handler.create(this, this.onLoaded), Laya.Handler.create(this, this.onLoading)).then( (res)=>{ let scene = res.create(); //scene.scene3D can obtain Scene3D resources Laya.stage.addChild(scene.scene3D); }); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 19:00:06 "},"3D/useModel/readme.html":{"url":"3D/useModel/readme.html","title":"useModel","keywords":"","body":"Import and use of 3D models and animations1. Skeleton skinning animation1. Import model files2. Texture setting association3. Import and use of skeleton skin animation4. Use of multiple individual bone skinning animation files5. Code running example2. Rigid body animation1. Import glTF or fbx files2. Import and use of animationImport and use of 3D models and animations The model suffixes supported by LayaAir are fbx and gltf, and the imported 3D animations supported are skeleton skin animation and rigid body animation 1. Skeleton skinning animation Only relatively simple animations can be produced in LayaAir. If you want complex animations, such as animations of characters running, you must create them in external software and import them into LayaAir for use. Usually we need to use 3dMax software to make models and animations, and export them to Fbx format files. The following will introduce how to import 3D models and animations. 1. Import model files Put Fbx into the Assets directory (figure 1) Open LayaAir IDE. The IDE will recognize the Fbx file and can expand the Fbx file. You will see the file information in Figure 2. Take_001 is the skeleton skin animation file that comes with Fbx and is also its own standby animation. Drag Fbx into the Scene3D scene, you can see the model, but there are no textures and animations. Let’s first introduce how to add materials and textures to LayaMonkey. (figure 2) 2. Texture setting association Place the texture file under Assets (image 3) You need to create a material file to configure textures and other information for the model. (Figure 4) Click on the newly created Material file. You can see a lot of configuration information on the right. Here we only need to drag the texture file into the material file. (Figure 5) Drag the material file into the Materials of LayaMonkey's SkinnedMeshRenderer component (Figure 6) You can see that the model already has texture effects (Figure 7) 3. Import and use of skeleton skin animation Here's how to add animation to LayaMonkey When the Fbx file is dragged into the Scene3D scene, the Animator component will be automatically added. If not, you can add the Animator component yourself and ensure the AlwaysAnimate mode. (Figure 8) At this point, we need to create an AnimationController file, which is the 3D animation state machine (Figure 9) Drag the newly created Animation Controller file into the Animator component (Figure 10) After double-clicking the AnimatorController, drag the Take_001 animation file into the Animator window (Figure 11) Click the Scene window again and click on the animation file preview below to see the animation effect. (Figure 12) When you run the IDE at this time, you can play LayaMonkey animations, or you can drag LayaMonkey into the Assets directory as a prefab for easy reuse or code implementation. (Figure 13) 4. Use of multiple individual bone skinning animation files In most cases, the Fbx file exported by a model containing animation will contain both mesh information and animation information, but there are also some cases where the Fbx file only needs to export animation information. For example, if there are many animations in the same model, only one mesh information is needed, and other animation information can be exported through separate model files (without mesh information). When making animations, you should consider the reuse of animations for similar models in the scene. For example, different humanoid characters might all use the same walking and running animations. Animations can be reused as long as the skeletal structure is kept consistent. In Figure 14, taking girl as an example, we put the Fbx file without animation information and multiple Fbx files with only animation into Assets (Figure 14) After creating the AnimatorController, drag the standby and running animations into the Animator window to modify the animation name. (Figure 15) Note: The idle animation is the default animation at this time As shown in Figure 16, we can preview the standby and running animations separately, and set whether to loop. (Figure 16) Multiple individual bone skinning files are set successfully, and individual animations can also be set to other models for reuse. 5. Code running example With the following code, we can load the girl prefab in any scene, add it to the scene, and click the screen with the mouse to switch animations import { MainBase } from \"./Main.generated\"; import KeyBoardManager = Laya.InputManager; import Keyboard = Laya.Keyboard; const { regClass, property } = Laya; @regClass() export class Main extends MainBase { private _animator: Laya.Animator; private _isRun: boolean; onAwake() { console.log(\"Game start\"); //Load the specified model prefab and add it to the Scene3D scene Laya.loader.load(\"girl/girl.lh\").then(res => { let girl : Laya.Sprite3D = res.create(); this.scene3D.addChild(girl); //Get Animator this._animator = girl.getComponent(Laya.Animator); }); this.on( Laya.Event.MOUSE_DOWN, this, this.switchAni ); } switchAni(): void { if (this._isRun) { //Play the corresponding animation this._animator.play(\"idle\"); } else { this._animator.play(\"run\"); } this._isRun = !this._isRun; } } 2. Rigid body animation 1. Import glTF or fbx files Put glTF into the Assets directory and open LayaAir IDE. The IDE will recognize the glTF file and expand the glTF file. You will see the file information in Figure 17, where Animation_0 is the rigid body animation file that comes with glTF. (Figure 17) Drag glTF into the Scene3D scene, you can see the model, but there is no animation. Let’s first introduce how to use animation. (Figure 18) 2. Import and use of animation When the glTF file is dragged into the Scene3D scene, the Animator component will be automatically added. If not, you can add the Animator component yourself and ensure the AlwaysAnimate mode. (Figure 19) At this point, we need to create an AnimationController file, which is the 3D animation state machine (Figure 20) Drag the newly created Animation Controller file into the Animator component (Figure 21) After double-clicking the AnimatorController, drag the Take_001 animation file into the Animator window (Figure 22) When you run the IDE at this time, you can play rigid body animation, or you can drag BoxAnimated into the Assets directory as a prefabricated body for easy reuse or code implementation. (Figure 23) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:02:59 "},"IDE/animationEditor/readme.html":{"url":"IDE/animationEditor/readme.html","title":"Animation Editor","keywords":"","body":"Animation editorAnimation editor Animation editor, including 2D timeline animation editing, 3D timeline animation editing, animation controller (state machine) Detailed explanation of timeline animation editing (2D+3D) Detailed explanation of animation state machine (2D+3D) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:13:06 "},"IDE/animationEditor/timelineGUI/readme.html":{"url":"IDE/animationEditor/timelineGUI/readme.html","title":"timeline GUI","keywords":"","body":"Detailed explanation of timeline animation editing1. Open the timeline animation editor1.1 Create animation1.2 Directly start the animation panel1.3 Nodes that do not support animation components1.4 Add animation component2. Basic concepts of timeline animation editor2.1 Key frames and empty frames2.2 Current frame2.3 Playback frame rate2.4 Animation node properties2.5 Curve, tangent, weight2.6 scale3. Basic interaction of the timeline animation editing panel3.1 Multiple selection3.2 Left mouse button3.3 Right mouse button3.4 Scroll wheel operation4. Attribute settings4.1 Added attributes4.2 Keyframe attribute settings5. General operations of frame panel5.1 Keyframe management5.2 Keyframe batch management5.3 Blank frame insertion5.4 Animation events5.5 Keyframe jump5.6 Frame panel scaling6. Curve mode operation6.1 Animation Curve Adjustment6.2 Curve positioning6.3 Curve display filtering7. Play animation7.1 Animation panel playback7.2 Check the running effect7.3 Loop playback during runtime8. Others8.1 Save animation8.2 Exit animation editor8.3 Summary of shortcut keys9. Use animation events9.1 Property settings9.2 Monitoring in scriptsDetailed explanation of timeline animation editing Author：charley The timeline animation editor of LayaAir IDE is suitable for editing 2D and 3D animations. For the function introduction in this article, if it is a common operation between 2D and 3D, 3D will be used as an example by default. If there are differences between 2D and 3D, additional explanations will be given for the differences. As the version is upgraded, some details of the screenshots in the document may be slightly different. The actual version of the IDE shall prevail. If the changes are major, we will make adjustments in time. If the changes are not made in time, please contact the official customer service for feedback. 1. Open the timeline animation editor 1.1 Create animation 1.1.1 Node creation animation in the scene Any node added to the scene can create animations. The following introduction takes cube as an example. First create a cube node in the scene. After selecting the cube node, you can see the \"Create\" button in the Timeline Animation Panel (Timeline) below the editor. As shown in Figure 1-1: (Picture 1-1) Click the Create button in Figure 1-1, and the interface shown in Figure 1-2 will pop up, reminding the user to set the animation name (here renamed to \"ani3d.lani\"). (Figure 1-2) [!Tip] The suffix of 3D animation files is .lani, and the suffix of 2D animation files is .mc After saving the name, you can see the timeline animation editing panel, animation components, state machine, and animation files, which means the animation is created successfully. As shown in Figure 1-3: (Figure 1-3) 1.1.2 Creating animations in prefabs Not only can we create animations on nodes in the scene, we can also create animations in prefabs. If you don’t understand prefabs, please check the > document first. From an operational point of view, there is no essential difference between creating animations on the scene and creating animations in prefabs. The main differences are: Animations created by nodes in the scene are suitable for situations where only one animation is used. Animations created in prefabs are suitable for situations where animations need to be reused multiple times. 1.1.3 Animation file suffix The suffix name of animation files created by 3D is .lani, and the file suffix of 3D animation controller (also called animation state machine) is .controller The suffix of animation files created in 2D is .mc, and the suffix of 2D animation state machine files is .mcc. When publishing WeChat mini games and other platforms that have restrictions on suffixes, the IDE publishing function will automatically modify the suffix. Developers only need to know it and still use relative paths according to the above standards. The engine will automatically adapt the file suffix according to different platforms. 1.1.4 Naming rules for animation state machine files When creating an animation for a node for the first time, not only an animation file named by the developer will be created, but an animation state machine file will also be automatically created. The state machine file naming is composed of animation node name_animation name. The effect is shown in Figure 1-4. (Figure 1-4) 1.2 Directly start the animation panel If the animation component has been bound to the node, there is no need to create animation, just click the Start Animation Panel button below. As shown in Figure 1-5: (Figure 1-5) 1.3 Nodes that do not support animation components Scene root nodes Scene2D and Scene3D do not support animation creation. 1.4 Add animation component When an animation has been created and you just want to reuse the created animation on a certain node, you can directly open the existing animation by adding an animation component. Take the Sphere node as an example for introduction. First, select the sphere node, click Add Component in the property panel on the right, and select the Animator component. You can only see Animator in the 3D node. If it is a 2D node, you can only select Animator2D. [!Tip|label:Tips] Animator2D is a 2D animation component, and Animator is a 3D animation component. The operation sequence is shown in the animation 1-6: (Figure 1-6) Then, the Animator component can be seen in the properties panel. Click the Controller in the Animator component and select the existing animation state machine. As shown in Figure 1-7: (Figure 1-7) 1.4.1 When there is an animation state machine and animation files: Take the \"Sphere_ani3d1\" animation state machine as an example. After selection, the animation will be bound to the Sphere node. If there is an animation state machine and an animation file, click Start Animation in the animation editing panel after refreshing. As shown in Figure 1-8: (Figure 1-8) 1.4.2 When there is an animation state machine but no animation file: If there is no animation in the animation state machine, after adding the animation component and setting up the state machine, and then click Start, you will be reminded that there is no animation file, and a window to create a new animation file will automatically pop up. As shown in Figure 1-9: (Figure 1-9) If you want to use an existing animation, just drag the animation file from the resource window to the state machine view window. The effect is shown in Figure 1-10. (Figure 1-10) 2. Basic concepts of timeline animation editor 2.1 Key frames and empty frames 2.1.1 Key frames The key frame refers to the frame where the key action occurs in the change of object movement, that is, the frame where the attribute values ​​are stored. (Figure 2-1) 2.1.2 Empty frame An empty frame means that nothing is set in this frame, usually the frame between two adjacent key frames. (Figure 2-2) 2.1.3 The difference between key frames and empty frames Keyframes: Determine the effect changes of the animation based on the attribute values ​​stored in the keyframes. Empty frame: The engine will calculate the attribute value during playback based on the interpolation algorithm, which is used for the transition between two key frames of the animation. 2.2 Current frame The frame where the current frame pointer is located is also the frame selected by the current mouse click. In addition, the location of the current frame pointer is also displayed at the bottom of the editor window. Taking the example shown in Figure 2-3, the current frame is located at frame 6. (Figure 2-3) 2.3 Playback frame rate Refers to the number of animation frames played per second. As shown in Figure 2-4, the default value is 60. (Figure 2-4) 2.4 Animation node properties The properties of the animation node are shown on the left side of Figure 2-5. When pointing to a certain key frame, and then adjusting the property value, the adjusted property value can be stored in the frame and used as the basis for changing the key frame effect. (Figure 2-5) 2.5 Curve, tangent, weight 2.5.1 Curve definition: A curve is an interpolation algorithm connection between two keyframes used for frame transition. effect: An attribute interpolation algorithm used between two key frames to adjust the transition effect between animation key frames. Exterior: Curve lines are the transition algorithm effect of attribute values ​​between key frames. The IDE uses the cubic Bezier curve (also called third-order Bezier curve) algorithm to draw. The drawing principle is shown in the animation 2-6. (Animation 2-6) In the animation 2-6, the red line is the appearance of the final interpolation algorithm curve effect, p0 is the starting frame, p3 is the ending frame, and the vertical red pointer is the movement speed of the current frame based on the curve. The adjustment of the curve is determined by p1 and p2, which in turn are determined by the tangent and weight. The appearance of the curve can be expressed in a curve form or a straight line form, as shown in Figure 2-7, both of which are drawn using the cubic Bezier curve algorithm. (Figure 2-7) [!Tip|label:Tips] The curves drawn by the Bezier curve algorithm mentioned above are all adjustable curves. The built-in easing curve template of 2D animation is not a Bezier curve algorithm. 2.5.2 Curve tangent In the animation 2-6 above, the line segment from p0 to p1 is the tangent to p0, and the line segment from p2 to p3 is the tangent to p3. The position of the tangent will affect the shape of the curve. The effect corresponding to the animation editor is shown in animation 2-8. (Animation 2-8) 2.5.3 Curve weight Curve weight refers to the length of the tangent to the curve. The shortest value cannot be lower than 0, and the longest value cannot exceed 1. That is, the length between the two key frames p0 to p3 in the animation 2-6 above. Pay attention to the animation in Figure 2-9. When the weight length is changed, the third line of the tips will also display the current weight value. (Animation 2-9) Here we only demonstrate the concept of weight adjustment. Section 6.1.2 below will introduce in detail how to adjust the curve weight. 2.6 scale The scale is divided into horizontal scale and vertical scale. The horizontal scale refers to the scale of the animation frame, and the vertical scale refers to the scale of the animation attribute value. As shown in Figure 2-10. (Figure 2-10) 3. Basic interaction of the timeline animation editing panel 3.1 Multiple selection 3.1.1 Frame selection Keep pressing the left mouse button to make a frame selection and select all within the mouse selection. 3.1.2 Multiple selection of consecutive areas Shift + mouse click to select all within the specified first and last frames and attribute range. 3.1.3 Interval multiple selection ctrl + mouse click, whichever one you click selects. 3.1.4 Exclusion ctrl + mouse click. When selected, hold down ctrl + mouse click to exclude the item. 3.1.5 Multiple selection release Universal: selected first and last frames Curve: Displays the selected highest and lowest attribute values, as well as the first and last frames. As shown in Figure 3-1: (Figure 3-1) 3.2 Left mouse button 3.2.1 Click (change current frame) Change the current frame position, the mouse click is the current frame. 3.2.2 Double click Add animation event: Double-click the area shown in Figure 3-2 to add animation events. Multiple animation events can be dispatched in one frame. (Figure 3-2) Add Keyframes: Double-click the area shown in Figure 3-3 to add keyframes. (Figure 3-3) 3.2.3 Drag and drop Drag single frame: Select a keyframe and drag it to change the position of the current keyframe. Batch drag and drop multiple frames: You can also select multiple keyframes in batches and drag them to change the overall position. 3.3 Right mouse button 3.3.1 Keyframe mode Add keyframes: Right-click the keyframe panel area to bring up the keyframe addition menu. For example, in the red 1 area shown in Figure 3-4, the number in brackets represents the frame on which it is added. (Figure 3-4) Add animation events: Right-click the area between the frame scale and the keyframe panel, as shown in Figure 3-5, to bring up the 'Add animation event' menu. The number in brackets represents the frame on which it is added. (Figure 3-5) Click to select a keyframe, and right-click to bring up the current keyframe function menu. As shown in Figure 3-6: (Figure 3-6) Right-click the area (3) to bring up the attribute addition menu. As shown in Figure 3-7: (Figure 3-7) 3.3.2 Curve mode In curve mode, right-click the blank area to bring up the curve automatic positioning menu. As shown in Figure 3-8: (Figure 3-8) In curve mode, right-click the keyframe to bring up the curve function menu. As shown in Figure 3-9: (Figure 3-9) In curve mode, right-click the curve to bring up the curve positioning menu. As shown in Figure 3-10: (Figure 3-10) 3.4 Scroll wheel operation 3.4.1 Frame display scaling In keyframe mode, use the scroll wheel directly to zoom the frame scale panel with the mouse pointer as the center. As shown in animation 3-11: (Animation 3-11) 3.4.2 Attribute display scaling In curve mode, use Ctrl+Scroll Wheel to zoom the attribute scale panel with the mouse pointer as the center. As shown in animation 3-12: (Animation 3-12) 3.4.3 Frame and attribute scaling at the same time In curve mode, directly scrolling the wheel will zoom the frame and attribute scale panels simultaneously with the mouse pointer as the center. As shown in animation 3-13: (Animation 3-13) 3.4.3 Vertical scrolling of animation properties panel When there are multiple properties beyond the display area of ​​the property panel, you can directly use the mouse wheel to scroll the property panel vertically for ease of operation. As shown in animation 3-14: (Animation 3-14) 3.4.4 Vertical scrolling of animation frame panel When the mouse is on the animation frame panel, rolling the mouse wheel directly will only zoom the frame panel. When we also need to scroll vertically, we can press and hold Ctrl + scroll mouse wheel in the animation frame panel to perform vertical scrolling operation, as shown in animation 3-15: (Animation 3-15) 4. Attribute settings 4.1 Added attributes 4.1.1 Add via button As shown in Figure 4-1: (Pic 4-1) 4.1.2 Add by right-clicking As shown in Figure 4-2: (Figure 4-2) 4.1.3 Add by recording First, click the red recording button. When the scale bar turns red, it means that it has entered the recording state. At this time, by adjusting the Transform parameter on the right, you can add the corresponding attributes in the timeline animation editor. The operation is shown in Figure 4-3: (Figure 4-3) Differences between 2D animation properties and 3D animation properties: [!Note] Each property value in 2D animation allows a single setting. The Vector attribute is indispensable in 3D animation, and it will be automatically added if deleted. 2D animation is in recording mode by default. For 3D animation, you need to click the record button to turn on the recording mode. 4.2 Keyframe attribute settings 4.2.1 Direct input in attribute input box Enter the value directly in the input box. As shown in Figure 4-4: (Figure 4-4) 4.2.2 Swipe input in attribute input box Place the mouse on the input box. When the cursor changes to a two-way arrow, hold down the left button and drag the mouse left or right to change the value. 4.2.3 Synchronous input in recording mode Method 1: In recording mode, drag and drop input in the view window. As shown in Figure 4-5: (Figure 4-5) Method 2: In recording mode, enter in the properties window. As shown in Figure 4-6: (Figure 4-6) 5. General operations of frame panel 5.1 Keyframe management 5.1.1 Added Add in the Animation Frames panel: When there are already attributes in the animation frame panel, add keyframes by double-clicking or right-clicking the area shown in Figure 5-1. (Figure 5-1) Add in animation properties panel: Click the \"+\" sign on the right side of the property in the animation properties panel to add, as shown in Figure 5-2: (Figure 5-2) 5.1.2 Delete Select the keyframe with the mouse and delete it through the \"delete\" shortcut key or the \"Delete selected shortcut key\" button in the right-click menu. 5.1.3 Copy Select the keyframe with the mouse and copy it with \"ctrl+C\". 5.1.4 Paste Select a blank frame with the mouse and copy it with \"ctrl+V\". 5.1.5 Mobile Select the keyframe with the mouse, hold down the left button and drag it. 5.2 Keyframe batch management 5.2.1 Batch panning Batch panning refers to moving the selected keyframes horizontally as a whole, while the spacing between keyframes remains unchanged. The operation method is to batch select keyframes, and then hold down the left mouse button to perform batch panning. As shown in animation 5-3: (Animation 5-3) 5.2.2 Insert move Inserting movement means inserting a blank frame between every two key frames among all selected key frames. Therefore, the position of the first frame remains unchanged, but the spacing between all subsequent key frames becomes larger or smaller. Increased spacing: Select multiple keyframes and insert blank frames. As shown in animation 5-4: (Animation 5-4) In order to facilitate the understanding of animation 5-4, right-click operation is adopted, but it is recommended to use the shortcut key F5 to insert a blank frame. Spacing reduction: Select multiple keyframes and delete blank frames. When all blank frames between two key frames are deleted, deletion will stop. But it does not affect the continued deletion of other keyframes. As shown in animation 5-5: (Animation 5-5) In order to facilitate the understanding of animation 5-5, right-click operation is used, but it is recommended to use the shortcut key Shift + F5 to insert a blank frame. 5.2.3 Batch deletion Select keyframes in batches, and then delete them in batches through the shortcut key \"delete\" or the Delete selected keyframes option in the right-click menu. As shown in animation 5-6: (Animation 5-6) 5.3 Blank frame insertion 5.3.1 Single insertion of blank frame Add: Select a keyframe and use the shortcut key \"F5\" or the \"Insert Blank Frame\" button in the right-click menu. Delete: Select a keyframe and use the shortcut key \"shift + F5\" or the \"Delete Blank Frame\" button in the right-click menu. 5.3.2 Batch insertion of blank frames Added: Select multiple keyframes through the shortcut key \"F5\" or the \"Insert Blank Frame\" button in the right-click menu. Delete: Select multiple keyframes and use the shortcut key \"shift + F5\" or the \"Delete Blank Frames\" button in the right-click menu. 5.4 Animation events 5.4.1 Added In the area shown in Figure 5-7 in the frame panel, you can add animation events by double-clicking or clicking the \"Add Animation Event\" button in the right-click menu. (Figure 5-7) 5.4.2 Delete When the animation event is selected with the mouse, the animation event can be deleted through the shortcut key \"delete\" or \"Remove Animation Event\" in the right-click menu. Please see Part 9 for the specific use of animation events. 5.5 Keyframe jump (Figure 5-8) Jump to first frame Click the button shown in (1) in Figure 5-8 to quickly jump to the first frame. Jump to previous keyframe Click the button shown in (2) in Figure 5-8 to quickly jump to the previous frame. Jump to next keyframe Click the button shown in (3) in Figure 5-8 to quickly jump to the next frame. Jump to last frame Click the button shown in (4) in Figure 5-8 to quickly jump to the last frame. 5.6 Frame panel scaling 5.6.1 Scroll bar scaling Left zoom: Pull the left scroll bar to zoom the frame scale to the left of the current keyframe. Right zoom: Pull the right scroll bar to zoom the frame scale to the right of the current key frame. The scroll bar is shown in Figure 5-9: (Animation 5-9) 5.6.2 Wheel zoom Place the mouse on the frame scale and slide the wheel. At this time, the frame scale will zoom in and out with the current scale where the mouse is located as the center. As shown in animation 5-10: (Animation 5-10) Place the mouse on the attribute scale and slide the wheel. At this time, the attribute scale will be zoomed with the current scale where the mouse is located as the center. As shown in animation 5-11: (Animation 5-11) Regarding locking a certain scale panel for wheel zoom, please scroll up to see section 3.5 Shortcut Keys. 6. Curve mode operation 6.1 Animation Curve Adjustment 6.1.1 Using animation curve template Animation curve templates can be divided into two types, namely built-in curve algorithms and custom curve algorithms. After using the built-in curve algorithm, the curve cannot be adjusted at will. Using a custom curve algorithm, the curve can be adjusted at will. How to open the curve template: Right-click the keyframe in curve mode and click \"Use Animation Curve Template\" in the right-click menu to open the curve template interface. [!Tip|label:Tips] The built-in curve algorithm only supports 2D animation. Built-in curve algorithm: Linear:Linear animation, that is, uniform speed. Start at the same speed and end at the same speed. The animation curve is shown in Figure 6-1: (Figure 6-1) EaseIn: Entry easing curve, the animation starts at a low speed and continues to accelerate during the process. The animation curve is shown in Figure 6-2: (Figure 6-2) EaseOut: The exit easing curve, which keeps decelerating during the animation and ends at a low speed. The animation curve is shown in Figure 6-3: (Figure 6-3) EaseInOut:Ease the curve on both sides. The animation starts at a low speed, accelerates and then decelerates, and exits at a low speed. The animation curve is shown in Figure 6-4: (Figure 6-4) Customized curve algorithm: Custom： If the built-in curve template cannot meet the needs, developers can directly select the Custom curve mode and then modify the curve trajectory in the panel area. As shown in Figure 6-5: After modification, you can save it for reuse. (Figure 6-5) 6.1.2 Tangential adjustment (Figure 6-6) Weights: Default weight: The default value of the curve weight is one-third of the total length of the weight, which is the engine optimization position. The Hermite interpolation algorithm is used, which has better performance. Recommended Use. (Figure 6-7) Custom weight: When the lock weight is not checked, it is a custom weight. Custom weights are more flexible, but the performance is not as good as the default weights. (Animation 6-8) Lock weight: After using a custom weight, if you want to keep this weight, you can lock the weight and only adjust the tangent position. (Animation 6-9) Function: Left tangent: adjust the tangent setting parameters on the left side of the current keyframe. Right tangent: adjust the tangent setting parameters on the right side of the current keyframe. Two tangents: Adjust the tangent setting parameters on both sides of the current keyframe. Interpolation Transition: Linear: Adjust the curve angle to make the curve appear as a straight line. (Figure 6-10) constant: Adjust the curve angle to make the curve appear as a right-angled polyline. (Figure 6-11) 6.1.3 Smoothing Unchecked state: Both sides of the keyframe can be adjusted by setting the left and right tangent lines of the curve respectively without affecting each other. However, the transition may not be smooth enough and form a sharp angle. As shown in Figure 6-12: (Figure 6-12) Checked state: The curve tangents are set simultaneously on both sides of the keyframe. When checked, the transition will be smoother. 6.1.4 Level Unchecked state: Custom curve tangent. Checked state: After checked, the tangent line of the curve will quickly return to the horizontal position. (Animation 6-13) 6.2 Curve positioning 6.2.1 Position input on curve Right-click the curve and click the \"Locate to Input\" option in the right-click menu to quickly locate the parameter represented by the curve. Taking the green curve as an example, after clicking \"Locate to Input\", you can find that the green curve represents the change of the X parameter. As shown in Figure 6-14: (Animation 6-14) 6.2.2 Automatic positioning When the curve cannot be seen in the display area of ​​the curve panel due to a series of mouse operations, right-click and select \"Auto Position\" to quickly display the curve. As shown in animation 6-15: (Animation 6-15) 6.3 Curve display filtering 6.3.1 Filter specified curves in the animation properties panel Double-click the parameter in the animation properties panel to quickly find the specified curve. As shown in animation 6-16: (Animation 6-16) 6.3.2 Filter specified curves in the curve panel In the curve panel, select a curve, right-click, and select \"Show only current curve\" in the right-click menu to filter to the specified curve. As shown in animation 6-17: (Animation 6-17) 7. Play animation 7.1 Animation panel playback 7.1.1 Single playback Click the play button to play the animation, which defaults to a single playback. Click the button as shown in Figure 7-1 to play the animation. (Figure 7-1) 7.1.2 Loop playback The animation preview defaults to single play mode. When we see a number 1 in the middle of the loop icon, it means it is in single play mode. As shown in Figure 7-2. (Figure 7-2) After clicking the single playback state button, the button is in the loop icon state, as shown in Figure 7-3. At this time, the animation can be played in an infinite loop. (Figure 7-3) 7.1.3 Cancel loop playback After clicking the loop playback status button, the current loop playback status will be stopped. At this time, the number 1 can be seen in the middle of the loop icon, indicating that the loop playback has been canceled and returned to the single playback mode. (Figure 7-3) Please note that when the single playback mode is changed to the loop playback mode, since it is not currently in the playback state, it will not automatically change to the loop playback state. 7.2 Check the running effect The playback preview in the IDE is just the basic effect of the animation. In most cases, the animation is also combined with code interaction logic. At this time, it needs to be run in the browser to view the final running effect. Click the button shown in Figure 7-4 to view the preview effects on different platforms. (Figure 7-4) Since the animation component cannot be played independently and must be hung in the scene, the animation can be played by directly running the scene where the animation is located. If you want to view the animation effect independently, you need to create a test scene with animation effect and hang it in the test scene. 7.3 Loop playback during runtime The loop playback preview in the IDE has nothing to do with whether it loops during runtime. If you need to loop playback during runtime, you need to check the loop state in Figure 7-5. (Figure 7-5) If loop is unchecked, it will be played once during runtime. 8. Others 8.1 Save animation As shown in Figure 8-1, click the save icon below the timeline animation editor. It should be noted here that if you do not save it, the animation will be played according to the unsaved effect at runtime. (Figure 8-1) 8.2 Exit animation editor Click the exit icon below the timeline animation editor to exit the animation editor. As shown in Figure 8-2: (Figure 8-2) 8.3 Summary of shortcut keys Shortcut keys Function F5 Insert blank frame Shift + F5 Delete blank frames Delete Delete keyframes Ctrl + c Copy keyframes Ctrl + v Paste keyframes Ctrl+Scroll Wheel In keyframe mode, the animation property panel and animation frame panel scroll vertically at the same timeIn curve mode, the frame scale panel is locked (no zooming), with the mouse pointer as the center, and there is no limit to the accuracy of the scaling attribute scale panel. Alt+scroll wheel In curve mode, the attribute scale panel is locked (no scaling), with the mouse pointer as the center, and the accuracy of the frame scale panel is unlimited. (Unlimited zoom will cause the zoom to no longer be centered on the mouse pointer before zooming when the zoom is stretched to 0 frames visible) Alt+Shift+Scroll Wheel In curve mode, lock the attribute scale panel (without zooming), center the mouse pointer, and limit the accuracy of the zoom frame scale panel. (Always keep the mouse pointer as the center for zooming. When the zoom is stretched to 0 frames and visible, the scale precision is prohibited from being reduced, and only the scale precision is allowed to be enlarged) Shift In curve mode, keep holding down the Shift key to move keyframes and always maintain horizontal displacement. Both single and batch movements are valid. Ctrl In curve mode, keep holding down the Ctrl key to move keyframes and always maintain vertical displacement. Both single and batch movements are valid. 9. Use animation events In Section 5.4, we introduced the operations of adding and deleting animation events. Let’s take a look at how to use animation events. 9.1 Property settings After adding the animation event, click the white event icon to set the animation event properties in the property panel on the back side of the IDE, as shown in Figure 9-1 (Figure 9-1) Event Name: The name of the event method called in the script Params: Parameters (strings) passed when calling the event method in the script. You can set multiple As shown in Figure 9-2, for example, add an \"event1\" method name to this event, add two parameters, \"a\", \"1\", and click Save below (Figure 9-2) 9.2 Monitoring in scripts After setting the animation event properties, in order to listen to the events and parameters, you need to add a script to the animation node. Let’s look at how to add a script to an animation node through animation 9-3. (Animation 9-3) After adding the script, you can monitor the events and parameters in the script. The script code is as follows: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { //declare owner : Laya.Sprite3D; constructor() { super(); } event1(p1:any, p2:any): void { console.log(\"event1\",p1,p2); } } Create the event1 method in the script and receive two parameters. Finally, we run the animation and see the results: (Figure 9-4) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:12:04 "},"IDE/animationEditor/aniController/readme.html":{"url":"IDE/animationEditor/aniController/readme.html","title":"Animation Controller","keywords":"","body":"Detailed explanation of animation state machine1. Overview2. Animation state machine component3. Animation state machine file4. Animation status5. Animation switching6. Animation playback and scripts7. Sub-state machineDetailed explanation of animation state machine LayaAir IDE's animation state machine, suitable for 2D and 3D. For the function introduction in this article, if it is a common operation between 2D and 3D, 3D will be used as an example by default. If there are differences between 2D and 3D, additional explanations will be given for the differences. As the version is upgraded, some details of the screenshots in the document may be slightly different. The actual version of the IDE shall prevail. If the changes are major, we will make adjustments in time. If the changes are not made in time, please contact the official customer service for feedback. 1. Overview Let’s first understand what an animation state machine is and its components, and then we’ll learn more about each part later. First of all, the animation state machine Animator allows us to define animation states and switching conditions between animation states to drive 3D objects to play different animations and show different behaviors. Then the animation state machine consists of the following parts: Animation state machine component Animator Component: It is a component on Sprite3D, used to control the interface of the animation state machine. Animation state machine file Animator Controller: It is a file used to execute the entire state machine logic, drive the animation state to run, and perform state switching. At the same time, the driving parameters are defined. These parameters can be driven by code logic, and then the animation can be driven by these parameters. Animation state Animator State: It is an animation state of the state machine. It is used to execute the logic of animation, define the properties of animation playback, and can change the playback position, time, level, etc. of a single animation. Animator Transition Animator Transition: consists of parameters and comparison conditions. When the conditions are met, it will switch to the corresponding animation state. For each state, multiple transitions to other states can be created. Through the following figure, you can clearly understand the relationship between these four parts, as shown in Figure 1-1: (Picture 1-1) 2. Animation state machine component Objects that we need to play animations and use animation state machines need to add the Animator component. This component is an interface for controlling the animation state machine. Let's take a look at the Animator component. 2.1 Node addition in the scene Any node added in the scene can add animation state machine components. The following introduction takes cube as an example. First create a cube node in the scene. After selecting the cube node, you can add the Animator component in the Add Component panel of the editor. As shown in animation 2-1: (Animation 2-1) 2.2 Added to prefab We can not only add animation state machine components to nodes in the scene, but also create them in prefabs. If you don’t understand prefabs, please check the prefab documentation first >. From an operational point of view, there is no essential difference between creating on the scene and creating in a prefab. The main differences are: Node creation in the scene is suitable for animations only used once. Created in prefabs, suitable for situations where animations need to be reused multiple times. 2.3 Added by default In some cases, the Animator component will be automatically added to the node, as shown in Figure 2-2. When we import an FBX model file into the scene, the Animator component has been added by default. (Figure 2-2) 2.4 Component properties The properties of the Animator component are shown in Figure 2-3: (Figure 2-3) Controller: The Animator Controller file used. When there is an Animator component, the animation state machine still cannot be opened. We need to create an animation state machine file, which will be introduced in detail in the next chapter. Culling Mode: Culling mode, Always Animate means that animation playback updates will be performed even if the camera is invisible, Cull Completely means that all updates of the animation will be stopped when the camera is invisible. Sleep: Whether to stop updating when the animation is completed. Because in LayaAir, the last frame will still be looped after the animation is completed, so check Sleep to stop the update. For example, add a translation animation to a cube in the scene, as shown in animation 2-4. Finally, you will see that the cube is no longer moving. (Animation 2-4) At this time, uncheck the Sleep option and add an animation script to the CubeAnimation animation node. The added code is as follows: ... import Vector3 = Laya.Vector3; ... export class AnimationScript extends Laya.AnimatorStateScript { ... private model: Laya.Sprite3D; /**@internal */ setPlayScriptInfo(animator: Laya.Animator | Laya.Animator2D, layerindex: number, playstate: Laya.AnimatorState | Laya.AnimatorState2D) { ... this.model = animator.owner as Laya.Sprite3D;//Get the Cube node } ... /** * Executed when the animation state exits. */ onStateExit(): void { console.log(\"Animation exited\"); //Translation operation let position = new Vector3(1, 1, 1); this.model.transform.translate(position); } } In the script, when the animation ends, the model is translated. However, since the Sleep option is not checked, the last frame will still be looped continuously after the animation is played, which is the final still state of animation 2-4. Therefore, it is impossible to control the position of the Cube to achieve the translation effect. When Sleep is checked, after the animation is completed, the panning effect can be displayed. 3. Animation state machine file Animator Controller is a file used to execute the entire state machine logic, drive the animation state to run, and perform state switching. 3.1 Create animation state machine file In the Project panel, an animation state machine file can be created in any directory. As shown in animation 3-1: (Animation 3-1) 3.2 Automatically create animation state machine files For an Fbx model file with mesh and animation information, as shown in Figure 3-2, during the import process of the Fbx file, the LayaAir 3.0 editor has recognized that the Fbx file has the Animator attribute, and can set whether it can be Turn on compression. (Figure 3-2) When we drag the Fbx model into the scene, the animation state machine component is automatically added. Open the Timeline Animation panel and the animation state machine file will be automatically created, as shown in Figure 3-3: (Figure 3-3) In this case, LayaAir 3.0 has automatically created the Animator Controller file for us, and the next step is to edit the animation state machine. 3.3 Open animation state machine When we click on the animation state machine file, we can click on the Animation State Machine panel to open the animation state machine, as shown in Figure 3-4. (Figure 3-4) The Sprite3D class of the LayaAir 3D engine provides the getComponent() method to obtain components on the model. When an animated model is loaded and created, the engine assigns the Animator (animation state machine) animation component by default, so we can get it like this: //Get state machine this.animator = this.target.getComponent(Laya.Animator); Note: This code comes from the \"Animator\" scene of \"3D Getting Started Example\". 3.4 Edit animation state machine In the Animation State Machine panel, you can perform some regular operations, as shown in the animation 3-5. In the next chapter, we will introduce the introduction and operation of the animation state. (Animation 3-5) 3.5 Animation state machine layering By default, an animation state machine file has only one default layer BaseLayer, as shown in Figure 3-6. For example, for the regular actions of a character model (standby, running, attacking), we only need one default layer. . (Figure 3-6) But we can also create more layers. What kind of problems can multiple layers be used to solve? Just imagine if you want to develop a third-person shooting game, then you definitely want the animation of the body to be divided into upper and lower parts. The upper part will animate based on the aiming position and whether to shoot, and the lower part will animate based on movement. Therefore, more complex requirements can be solved by layering. As shown in Figure 3-7, we added another layer and named it Layer1. (Figure 3-7) 3.5.1 Layer properties Each layer has some parameter attributes, as shown in Figure 3-8: (Figure 3-8) 1.Name: The name of the layer. 2.Play On Wake: Whether to play the animation of this layer by default. 3.Blending Mode: Animation blending method: Override: Override, which means that the animation of the current layer will overwrite the animation of other layers. For example, when shooting and playing, the right hand cannot play other animations; Additive: Add, indicating that the amount of the animation of the current layer is added to the animation of other layers. For example, when shooting is played, the shaking of the hand running or standing will also be retained. 4.Default Weight: The weight of the animation layer, the default Base Layer must be 1. If it is set to 0, the animation of the current layer will not play, and if it is 1, it will play. Between 0 and 1, a similar fusion situation will be used to play the animation, such as the situation of shooting while moving as mentioned before. If it is set to 0.5, it will shoot. When the animation is playing, the hand will only be raised to near the neck. Through code, we can get the desired layer by using Animator's animator.getControllerLayer(layerIndex) method, which is defined as follows: /** * Get the controller layer. */ getControllerLayer(layerInex: number = 0): AnimatorControllerLayer { return this._controllerLayers[layerInex]; } To give an example of using this method: //Get the BaseLayer layer AnimatorControllerLayer let animatorControllerLayer : Laya.AnimatorControllerLayer = this.animator.getControllerLayer(0); //Get the default animation state of the current BaseLayer layer let defaultState = animatorControllerLayer.defaultState; 5.Avatar Mask: Action mask. After masking, the selected upper layer action will block the lower layer action. Let’s illustrate with a specific example: Suppose there are two layers, as shown in Figure 3-9, fight and congratulate, (Figure 3-9) After setting the Blending Mode attribute to overwrite, the action of the congratulate layer will overwrite the action of the fight layer. The congratulate effect is shown in Figure 3-10. (Animation 3-10) The coverage at this time is to cover all the fight actions. If you want the upper body to be in fight action and the lower body to be in congratulate action, then action masking is needed. First, let’s take a look at the fight action in Figure 3-11 for easy comparison. . (Animation 3-11) In the project resource panel, after adding AvatarMask, as shown in Figure 3-12, you can add prefab or model resources. Here, select the prefab and click the Import Skeleton button. (Figure 3-12) After importing the skeleton, the selected part is the place to be masked. As shown in Figure 3-13, the skeleton of the lower body is checked here, so the movement of the lower body needs to be blocked. (Figure 3-13) Originally, the action of the congratulate layer would block the action of the fight layer, and all would be blocked. Now, add AvatarMask to the congratulate layer. According to the settings just made, the congratulate layer only blocks the lower body movements of the fight layer. That is, the upper body is still the movements of the fight layer and is not covered, and the movements of the lower body are blocked and become the movements of the congratulate layer. The effect is shown in the animation 3-14. (Animation 3-14) As you can see, the upper body is in fight action and the lower body is in congratulate action. This is how action masking is used. This is just the most basic usage. If there is only one animation layer, such as adding an animation mask to the lower body of the fight animation layer, then only the lower body animation will be displayed at this time. 3.5.2 Layer parameters Each layer can add some parameters, as shown in Figure 3-15. These parameters are specifically used in animation switching. We will introduce them in Chapter 5 Animation Switching. (Animation 3-15) Currently in LayaAir, we can add these three parameters: Float: floating point number Bool: Boolean Trigger: Trigger 4. Animation status Animation state Animator State is an animation state in the animation state machine. Each state corresponds to an animation, so it is called animation state. It is used to execute the logic of animation, define the properties of animation playback, and can change the playback position, time, etc. of a single animation. Our game logic state may consist of a series of animation states. 4.1 System status When the animation state machine is created, 2 system states will be created by default, as shown in Figure 4-1: (Pic 4-1) Any state AnyState: When we need to perform a switch when the condition is met, no matter which state it is, we can define the switch to start from this state. Enter Entry: Enter the state. When entering an animation state machine, the switch from this state to the default state will be performed first. When creating a sub-state machine, one more exit state will be created by default, as shown in Figure 4-2: (Figure 4-2) Please refer to Chapter 7 for the content of sub-state machines. Exit Exit: When you need to exit the sub-state machine, you can perform a switch to this state. 4.2 Create animation state 4.2.1 Create new animation state In the animation state machine panel, right-click on a blank space and click Create Empty Node. As shown in animation 4-3: (Animation 4-3) 4.2.2 Drag into an animation state In the Project panel, you can drag an action file under Fbx to the Animator panel, as shown in animation 4-4: (Animation 4-4) At this point, we can already play an animation automatically. This is the most basic and simple usage. No additional work is required to make LayaMonkey move! (Animation 4-5) 4.3 Animation state attributes As each animation state in the animation state machine, we can make separate settings for this state, as shown in Figure 4-6: (Figure 4-6) 4.3.1 Basic attributes Name: The name of the animation state, which can be used to play animations in code. Is Looping: Whether to loop. Speed: animation playback speed. Cycle Offset: Cycle offset, an offset value based on the start time of playback, only applies to the first playback of the animation (between 0-1). Clip Start: The starting playback position of the animation file (between 0-1). Clip End: The stop position of the animation file (between 0-1). Clip: animation file (.lani). Note: The parameter \"Cycle Offset\" does not affect the integrity of animation playback. For example, if \"Clip Start\" is set to 0, \"Clip End\" is set to 1, and \"Cycle Offset\" is set to 0.8, then the animation will start playing from the position 0.8. Playing to the 0.8 position counts as a loop. Usually the animation files contained in the Fbx file will be automatically associated by dragging them into Animator, as shown in Figure 4-7: (Figure 4-7) 4.3.2 Switch list AnimatorTransition: Lists all animation switches that connect this animation state to other animation states, as shown in Figure 4-8: (Figure 4-8) Standalone New State -> New State 0 can open the AnimatorTransition detailed panel. Double-click New State -> New State 0 to rename it, as shown in animation 4-9: (Animation 4-9) 4.3.3 solo and mute Solo and mute: Two check boxes. Solo means that only this switch is effective. Mute is equivalent to disabling this animation switch, as shown in Figure 4-10: (Figure 4-10) Notice: Both solo and mute can be multi-selected, but the priority is in the order of addition, which will be explained in 5.5 Switching Priority. If the condition is met, it takes precedence over Solo/Mute. When the condition is not met, there will still be no transition. This will be explained in 5.5 Switching Priority. 5. Animation switching The process of transitioning from one state to another is animation switching, which consists of parameters and comparison conditions. When the conditions are met, it will switch to the corresponding animation state. For each state, multiple transitions to other states can be created. 5.1 Create animated transitions After we create the animation state, by right-clicking the mouse on the previous state and selecting Connection, a point of connection will be created. Drag the mouse to the subsequent animation state and lift the mouse to create an animation switch. Click When this connection is established, click the delete key on the keyboard to delete the connection. As shown in animation 5-1: (Animation 5-1) When we connect New State 0, New State 1, and New State 2 from New State, New State will continue to switch to New State 0 without adding any conditions, because New State 0 is the first to connect. 5.2 Set as default When we create multiple animation states, if we want to set a certain animation state as the entry state, we can right-click the animation state and select Set as Default, as shown in Figure 5-2: (Animation 5-2) Note: When we create the first animation state, this state will be set as the default state by default. Of course, we can change other animation states to the default state at any time. 5.3 Animation switching properties When you click on a connection, you can see the properties of animation switching, as shown in Figure 5-3, which are used to handle the animation adjustment effect of animation switching. (Figure 5-3) Exit Time: This time is a normalized time of 0-1, used to define the percentage of time during animation playback. For example, 0.85 means that when the animation reaches 85%, the animation will start switching. The logical function of Exit Time is similar to the float parameter, but it cannot be set. Transstartoffset: This time is a normalized time of 0-1, the time offset of the target state, that is, the time point from which the target state animation starts to be played. For example, 0.5 means that the target state starts playing animation from 50%. Transduration: This time is a normalized time of 0-1, used to define the percentage of time that the next animation state will continue to play when the state switches to the target state. For example, 0.15 means that when the animation reaches 15% of the target animation, the switching animation will stop. Notice: During the transition time, animation 1 and animation 2 play at the same time. When the transition time ends, animation 1 stops playing completely, and animation 2 enters the next switching period. When the transition time is 0, animation 1 will switch directly to animation 2. Exit By Time: Whether to enable Exit Time to take effect. If not checked, the animation will switch directly to the next animation. Animation 5-3-1 and Animation 5-3-2 are the comparison effects of checking Exit Time and not checking it respectively. Obviously, if not checking, the animation will not be connected. (Animation 5-3-1) (Animation 5-3-2) 5.4 Animation switching conditions State switching can have one condition, multiple conditions, or no conditions. If there is no condition for switching, the animation system will also use Exit Time as the only condition and trigger the switch when the time is reached. If there are multiple conditions, all conditions must be met before switching is triggered. Currently in LayaAir, we can add these three parameters: 5.4.1 Float: Floating point number As shown in the animated picture 5-4, let's take a look at how to set the Float condition. First, we must define a Float parameter. Secondly, in the condition, you can select the Float parameter. Less or Greater will be selected on the right, and finally you can fill in the value. Then the meaning of animation 5-4 is that when Float is greater than 0.5, switch New State to New State0. Note: When defining this Float parameter, you can set a default value, such as 1. Then if the condition is that the Float parameter is Greater 0.5, the condition will be directly entered and the state will be switched directly during runtime. (Animation 5-4) The conditions can be met through code, the code is as follows: //Set the value of the \"Float\" parameter to meet the conditions for switching states. this.animator.setParamsNumber( \"Float\" , 2 ); The running effect is as shown in Figure 5-5: (Animation 5-5) 5.4.2 Bool：Boolean As shown in the animated picture 5-6, let's take a look at how to set the Bool condition. First, we must define a Bool parameter (either true or false). Secondly, in the condition, we can select the Bool parameter, and finally we can check true or false. . Then the meaning of animation 5-6 is that when Bool is true, switch New State to New State0. Note: When defining this Bool parameter, you can set a default value, such as true. Then if the condition is the Bool parameter true, the condition will be directly marked, and the state will be switched directly during runtime. (Animation 5-6) The conditions can be met through code, as follows: //Set the value of the \"Bool\" parameter to meet the conditions for switching states. this.animator.setParamsBool( \"Bool\" , true ); The running effect is as shown in Figure 5-7: (Animation 5-7) 5.4.3 Trigger: As shown in the animated picture 5-8, let's take a look at how to set the Trigger condition. First, we must define a Trigger parameter (either true or false). Secondly, in the condition, we can select the Trigger parameter. Then we can use triggers through code later to switch New State to New State0. (Figure 5-8) The conditions are met through code, as follows: //Trigger \"Trigger\" to meet the conditions for switching states this.animator.setParamsTrigger( \"Trigger\" ); The running effect is as shown in Figure 5-9: (Animation 5-9) 5.4.4 Use of multiple parameters Of course we can define multiple parameters, but in this case it is more efficient to name the parameters. Modify the name as shown in the animation 5-10: (Animation 5-10) After modifying the name, you can edit the switching conditions more clearly, as shown in Figure 5-11: (Figure 5-11) Note: As long as one of these conditions is met, the animation switch can be triggered, not the relationship between AND 5.5 Switch priority If there are multiple animation states in one animation state, let's take a look at the priority. When there are no conditions or when all conditions are met, solo and mute are not selected, as shown in Figure 5-12: (Figure 5-12) At this time, the Stand animation will be played after the Attack animation is played, because the Stand animation is the first one. When there are no conditions or when all conditions are met, if someone chooses solo, as shown in Figure 5-13: (Figure 5-13) At this time, the Run animation will be played after the Attack animation is played, because solo is selected for the Run animation. When there are no conditions or when all conditions are met, if solo is selected, as shown in Figure 5-14: (Figure 5-14) At this time, the Stand animation will be played after the Attack animation is played, because even if solo is selected, only one animation switch can be selected, and Stand is the first one in sequence. If the conditions for Attack->Stand are not met, the conditions for Attack->Run are met, but solo is still selected as shown in Figure 5-14 above. At this time, the Run animation will be played after the Attack animation is played, because the conditions of Attack->Stand are not met. When there are no conditions or when all conditions are met, if solo is selected and mute is selected in Attack->Stand, as shown in Figure 5-15: (Figure 5-15) At this time, the Run animation will be played after the Attack animation is played, because Attack->Stand selects mute. When there are no conditions or when all conditions are met, if solo and mute are both selected, as shown in Figure 5-16: (Figure 5-16) At this time, the Attack animation will not switch to any state after playing. 6. Animation playback and scripts In the above chapters, we only need to use simple code to control the state machine to meet the conditions and play the specified animation state. In addition, we can also control the animation playback through code. 6.1 Playback Control After obtaining the animation state machine component and adding multiple animation states, how to play one of the animations? There are several ways to control and switch actions: 6.1.1 Play() Check out the play() method in the Animator animation component. The specific method parameters are as follows: /** * Play animation. * @param name If null, the default animation will be played, otherwise the animation clip will be played by name. * @param layerIndex layer index. * @param normalizedTime Normalized playback start time. */ play(name: string | null = null, layerIndex: number = 0, normalizedTime: number = Number.NEGATIVE_INFINITY) This is the most basic way to play animation in the animation state machine, through the following code: //Animation state machine, directly play the Run animation state this.animator.play(\"Run\"); Take a look at the running effect, as shown in animation 6-1: (Animation 6-1) The starting position of the animation can also be specified through the parameters of Play(): //Animation state machine, directly plays the Stand animation state, starting from the 50% position this.animator.play(\"Stand\", 0 , 0.5); Take a look at the running effect, as shown in Figure 6-2. Every time the mouse clicks the button, the Stand animation can start playing from the 50% position. (Animation 6-2) Of course, we can also modify the properties of the animation state through code to play different effects: //Get the BaseLayer layer of the animation state machine, and you can also get other layers let acl: Laya.AnimatorControllerLayer = this.animator.getControllerLayer(0); //Get an animation state let state = acl.getAnimatorState(\"Stand\"); //Set the name of the action state state.name = \"Stand_new\"; //Set the start time of action state playback (the start time and end time are set to a percentage value of 0-1) The time point to be intercepted / the total duration of the animation state.clipStart = 10/40; //Set the end time of action state playback state.clipEnd = 20/40; //Whether animation playback loops state.clip.islooping = true; //Animation state machine, directly play the Stand_new animation state this.animator.play(\"Stand_new\"); Take a look at the running effect, as shown in Figure 6-3: (Animation 6-3) 6.1.2 crossFade() Animation over blending is used to smoothly transition from one animation state to another within a given amount of time. If one animation jumps to another completely different animation in a short amount of time, the transition usually behaves satisfactorily. Let’s first take a look at the crossFade() method in the Animator animation component. The specific method parameters are as follows: /** * Perform fusion transition playback between the current animation state and the target animation state. * @param name Target animation state. * @param transitionDuration transition time, this value is the normalized time of the current animation state, the value is between 0.0~1.0. * @param layerIndex layer index. * @param normalizedTime Normalized playback start time. */ crossFade(name: string, transitionDuration: number, layerIndex: number = 0, normalizedTime: number = Number.NEGATIVE_INFINITY) Called through code as follows: //Animation state machine, transition and merge into Run animation state this.animator.crossFade(\"Run\", 0.3); Take a look at the running effect, as shown in Figure 6-4, mixing the standby animation and running animation. (Animation 6-4) 6.1.3 Pause animation Now that we’ve talked about playing the animation, let’s talk about the pause animation. You can directly use the playback speed of the animation to control the pause and playback of the animation. You can directly set the playback speed of the animation to be paused to 0. To continue playing, you only need to reset the speed to 1. //pause animation this.animator.speed = 0.0; //Play animation this.animator.speed = 1.0; //Play animation at half speed this.animator.speed = 0.5; Take a look at the running effect, as shown in the animation 6-5: (Animation 6-5) 6.2 Get playback status To obtain animation playback status, you need to first use Animator's animator.getControllerLayer(layerIndex) method: /** * Get the controller layer. */ getControllerLayer(layerInex: number = 0): AnimatorControllerLayer { return this._controllerLayers[layerInex]; } After obtaining AnimatorControllerLayer, use the getCurrentPlayState() method: /** * Get the current playback status. * @return animation playback status. */ getCurrentPlayState(): AnimatorPlayState { return this._playStateInfo!; } After obtaining AnimatorPlayState, there are three commonly used methods to obtain the playback state as follows: /** * The normalized time of the playback state, the integer is the number of loops, and the decimal is the single playback time. */ get normalizedTime(): number { return this._normalizedTime; } /** * The duration of the current animation, in seconds. */ get duration(): number { return this._duration; } /** * Animation state machine. */ get animatorState(): AnimatorState { return this._currentState!; } Usually we can use normalizedTime to determine whether an animation state has finished playing, such as the following code: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { @property( { type: Laya.Label } ) private label: Laya.Label; @property( { type: Laya.Sprite3D } ) private target: Laya.Sprite3D; private animator : Laya.Animator; onStart() { this.label.on( Laya.Event.CLICK, this, this.test ); //Get state machine this.animator = this.target.getComponent(Laya.Animator); } //To run the running animation of the state machine, you can use the action fusion method test(e: Laya.Event) { //Animation state machine, transition and merge into Run animation state this.animator.crossFade(\"Run\", 0.1); //Wait for the animation to complete Laya.timer.frameLoop(1,this,()=>{ //If the current playback state has been played once if(this.animator.getControllerLayer(0).getCurrentPlayState().normalizedTime >= 1){ //Return to standing state this.animator.crossFade(\"Stand\", 0.1); Laya.timer.clearAll(this); } }); } } Take a look at the running effect, as shown in the animation 6-6: (Animation 6-6) 6.3 Using status scripts For our development needs, being able to play and switch animation states is not enough. We may also need to implement more requirements in each state. For example, when entering or leaving the next state, playing different sound effects, then by adding animation State scripts can be easily implemented, as shown in Figure 6-7. One or more state scripts can be added to each state. (Figure 6-7) 6.3.1 Create script Let's look at animation 6-8 to see how to create an animation script for a standing state. First, create an animation script in the Project Resources->src directory, then select the Stand state, and click the + button under Scripts to hang the animation script you just created. (Animation 6-8) 6.3.2 Script usage Let's take a look at the animation script we just created. The initial code is as follows: const { regClass } = Laya; interface AnimatorPlayScriptInfo { animator: Laya.Animator | Laya.Animator2D; layerindex: number; playState: Laya.AnimatorState | Laya.AnimatorState2D; } /** * Inherited from AnimatorStateScript (animation state script) * @author ... */ @regClass() export class AnimationScript extends Laya.AnimatorStateScript { /**Animation status information */ playStateInfo: AnimatorPlayScriptInfo = { animator: null, layerindex: -1, playState: null }; /**@internal */ setPlayScriptInfo(animator: Laya.Animator | Laya.Animator2D, layerindex: number, playstate: Laya.AnimatorState | Laya.AnimatorState2D) { this.playStateInfo.animator = animator; this.playStateInfo.layerindex = layerindex; this.playStateInfo.playState = playstate; } constructor() { super(); } /** * Executed when the animation state starts. */ onStateEnter(): void { console.log(\"Animation started playing\"); } /** * Animation status is running * @param normalizeTime 0-1 animation playback status */ onStateUpdate(normalizeTime: number): void { console.log(\"Animation status updated\"); } /** * Executed when the animation state exits. */ onStateExit(): void { console.log(\"Animation exited\"); } } The AnimationScript script inherits from Laya.AnimatorStateScript. setPlayScriptInfo is a life cycle function through which the animation components, animation state machine hierarchy, and animation state machine of the current script can be obtained. /**illustrate * setPlayScriptInfo is a life cycle function. If you want to obtain animation state machine information, you must call it. * @param animator animation component of the current script * @param layerindex The animation state machine level where the current script is located * @param playState the animation state machine of the current script */ setPlayScriptInfo(animator: Laya.Animator | Laya.Animator2D, layerindex: number, playstate: Laya.AnimatorState | Laya.AnimatorState2D) { this.playStateInfo.animator = animator; this.playStateInfo.layerindex = layerindex; this.playStateInfo.playState = playstate; } This script also has three methods: onStateEnter: executed when the animation state starts; onStateUpdate: The animation state is running, and the length of time for the current state execution can be obtained in the method normalizeTime; onStateExit: Executed when the animation state exits; We can override these methods to execute our own logic when the animation state changes. Simply add some code to see the effect: const { regClass } = Laya; interface AnimatorPlayScriptInfo { animator: Laya.Animator | Laya.Animator2D; layerindex: number; playState: Laya.AnimatorState | Laya.AnimatorState2D; } /** * Inherited from AnimatorStateScript (animation state script) * @author ... */ @regClass() export class AnimationScript extends Laya.AnimatorStateScript { /**Animation status information */ playStateInfo: AnimatorPlayScriptInfo = { animator: null, layerindex: -1, playState: null }; private isShow: boolean = false; private _label: Laya.Label; /**@internal */ setPlayScriptInfo(animator: Laya.Animator | Laya.Animator2D, layerindex: number, playstate: Laya.AnimatorState | Laya.AnimatorState2D) { this.playStateInfo.animator = animator; this.playStateInfo.layerindex = layerindex; this.playStateInfo.playState = playstate; this._label = animator.owner.scene.scene2D.getChildByName(\"Label\"); } constructor() { super(); } /** * Executed when the animation state starts. */ onStateEnter(): void { console.log(\"Animation started playing\"); this._label.text = \"Start animation\"; } /** * Animation status is running * @param normalizeTime 0-1 animation playback status */ onStateUpdate(normalizeTime: number): void { console.log(\"Animation status updated: \" + normalizeTime); if (normalizeTime > 0.5 && !this.isShow) { this.isShow = true; this._label.text = \"Run the animation halfway\"; } } /** * Executed when the animation state exits. */ onStateExit(): void { console.log(\"Animation exited\"); this._label.text = \"Exit running animation\"; } } The actual operation effect is as shown in the animation 6-9. (Animation 6-9) 7. Sub-state machine A sub-state machine is to create a new state machine inside the state machine. This new state machine is called a sub-state machine. The function of this state machine is to create another set of states to facilitate the management of complex animation states. For example, the character in the game has standby/run/attack/defense when standing, and another set of standby/run/attack/defense when crouching. Then squatting is a sub-state, because squatting, running, squatting and attacking are all based on the squatting state, so they can independently become a sub-state machine. 7.1 Create sub-state machine As shown in the animation in Figure 7-1, right-click the blank position of the state machine and select Create Node Directory. A node named \"New StateMachine\" will be generated, which is the sub-state machine. Double-click the sub-state machine to enter the sub-state machine panel. In this panel, you can see three states: enter, any state and exit. These three states belong to the sub-state machine, not the parent state machine. The parent state machine only has entry and any states. (Animation 7-1) Similarly, we can rename the sub-state machine, as shown in Figure 7-2: (Animation 7-2) 7.2 Edit sub-state machine For example, we want to put all the character's attack and skill animations into the child state machine and classify them into one category as the character's attack state, while the parent state machine is only used to handle states such as standby, running, dizziness, death, and victory. Then we enter the child state machine, drag in animations such as attacks and skills and connect them, the same as the previous parent state machine. As shown in animation 7-3: (Animation 7-3) 7.3 Entering the sub-state machine Drag an Attack (Take 001) animation into it. At this time, the Enter state will be connected to this animation, indicating that the default state of the sub-state machine is Attack. As shown in Figure 7-4: (Figure 7-4) Then return to the parent state machine and connect Idle to the child state machine, which is actually equivalent to connecting the enter state in the child state machine. Operate as shown in Figure 7-5: (Animation 7-5) 7.4 Exit sub-state machine If we hope that after the Attack animation ends, the function of the child state machine is completed, and the child state machine exits, returns to the parent state machine, and returns to the Idle state, this process belongs to exiting the child state machine. In the parent state machine, after returning to the state of the child state machine, you need to continue connecting to other states to make the animation continuous, as shown in animation 7-6: (Animation 7-6) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:08:33 "},"IDE/animationEditor/aniBake/readme.html":{"url":"IDE/animationEditor/aniBake/readme.html","title":"Animation Bake","keywords":"","body":"Detailed explanation of animation baking1. Using animation baking in IDE2. Baking multiple animationsDetailed explanation of animation baking The above two documents introduce how to use timeline animation and animation state machine in LayaAir3.0. This article will introduce a special animation optimization solution, animation baking. What is animation baking? Animation baking is a method in which all animations are calculated in advance; all bone nodes are precalculated and stored in memory; the GPU directly reads the matrix values ​​of the corresponding nodes through the memory; and rendering is performed. By using animation baking, CPU consumption can be reduced, because GPU animation efficiency is higher than CPU animation, and performance can be greatly improved for scenes that use a large number of skeletal animations. 1. Using animation baking in IDE Since all objects that play animation in the LayaAir project need to add the Animator component, we first prepare an animation object with an Animator, as shown in Figure 1-1 (Picture 1-1) Configure the animation state and animation clips in the animation state machine, as shown in Figure 1-2 (Figure 1-2) Run the scene at this time and you can see the character doing standby animation, as shown in animation 1-3. (Animation 1-3) The animation at this time uses the CPU to calculate the skeleton information to play the animation. Next, we will use animation baking and use the GPU to calculate the animation data. In the menu bar, click \"Tools\" and select \"Animation Baking\", as shown in Figure 1-4 (Figure 1-4) You can open the \"Animation Baking\" tool, as shown in Figure 1-5 (Figure 1-5) You can learn from the tool that if you want to bake the above animation with Animator, you need to drag the node containing the Animator component into the tool. As shown in the animation 1-6, let’s drag in the node. (Animation 1-6) After clicking Bake, animation baking starts. Animation baked animation does not support animation fusion. The animation baked data file will be generated in the directory with the node name \"DanDing\". Note: The directory name of the generated data file is the name of the node Let’s take a look at what data files are generated, as shown in Figure 1-7 (Figure 1-7) Among them, in the Danding directory anim directory: save animation .lani files (can have multiple animation files) mesh directory: save model files DanDing.ktx: Baked data file, using ktx texture image format, used to store calculated animation data DanDing.controller: 3D animation state machine file renamed after node name DanDing.lh: Save the baked prefab and can be used directly. Click on the prefab, and you can see from the back of Figure 1-7 that the SimpleSkinnedMeshRenderer component is configured on the model node, and the baked data file is configured. At this time, we can directly use the code or directly drag the prefab into the scene. In the LayaAir example, you can see that a large number of baked animations are loaded, and the efficiency is greatly improved, as shown in Figure 1-8 Pre-baked skeletal animation example: https://layaair.com/3.x/demo/?category=3D&group=8&name=6 2. Baking multiple animations Usually multiple animations are configured in Animator, so all animations can be baked at once, as shown in Figure 2-1 (Figure 2-1) Next, re-animate the DanDing node, as shown in animation 2-2. (Animation 2-2) At this point, multiple animations are baked, as shown in Figure 2-3 (Figure 2-3) Multiple animation lani files are generated in the anim directory. After opening the controller file, you can see that all animation states have been created, and you can just use the prefab directly later. So far, animation baking has been introduced. Developers can use the animation baking tool provided by LayaAir3.0 during the project optimization process to further improve performance. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:01:42 "},"IDE/particleEditor/readme.html":{"url":"IDE/particleEditor/readme.html","title":"Particle Editor","keywords":"","body":"3D particle editor1. Basics of 3D particle editorWhat are 3D particles?Flame effect display2. Create 3D particles in the LayaAir engine3. Use of 3D particlesThe use of 3D particles consists of three partsParticle System ComponentParticle Rendering ModuleParticle Shader3.1 Particle system component ParticleSystem3.2 Particle rendering module ShurikenParticleRenderer3.3 Particle shader PARTICLESHURIKEN4. Flame effect production example5. Application scenarios and code examples5.1 Custom Particle3D class5.2 Custom object pool class5.3 Code call3D particle editor 1. Basics of 3D particle editor What are 3D particles? In the encyclopedia, a particle refers to the smallest component of matter that can exist in a free state. In the LayaAir engine, particles in the 3D particle system can be used to simulate non-fixed natural phenomena such as smoke, fog, water, fire, rain, snow, and streamers. Since the shapes of the above-mentioned natural objects have no fixed shapes, they cannot be simulated and implemented with fixed models. Multiple models need to be combined into a complete visual effect, and 3D particles are the smallest unit of the combined effect, but it needs to be noted. What's interesting is that the particles are not a three-dimensional model, but a patch model. Flame effect display (Animation 1) 2. Create 3D particles in the LayaAir engine 2.1 Particle Node Under the Scene3D node in the scene, you can create 3D particles by right-clicking the mouse. (Figure 2.1.1-1) Default particle system adds finishing effects (Animation 2) 2.2 Prefab If you consider that 3D particles need to be reused, it is recommended to use prefabs. Create the prefab under Assets. After double-clicking to open the prefab, create 3D particles by right-clicking on the Sprite3D node. (Figure 2.1.2) 3. Use of 3D particles The use of 3D particles consists of three parts Particle System Component Particle Rendering Module Particle Shader (Figure 3.0) As you can see from Figure 3.0, when a 3D particle is created, these three components will be added automatically. Let’s learn more about the use of each system. 3.1 Particle system component ParticleSystem The particle system is the basis for the special effects performance of the LayaAir engine. Usually the position and movement of the particle system in the three-dimensional space are controlled by the emitter. The emitter is mainly represented by a set of particle behavior parameters and its position in three-dimensional space. Particle behavior parameters can include particle generation speed (i.e., the number of particles generated per unit time), particle initial velocity vector (such as when to move in which direction), particle lifetime (how long it takes for the particle to annihilate), particle color, particle life cycle changes in and other parameters, etc. Classification of particle system components In the LayaAir editor, the particle system component consists of five parts (Figure 3.1) 3.1.1 Basic panel General The default is the general module of the particle system, which is used to set the basic settings of the particle system. This module is an inherent module and cannot be disabled. This module defines a series of basic parameters such as the duration, cycle mode, emission speed, and size of particles during initialization. (Figure 3.1.1-1) Duration: The duration for which the particle system continues to emit particles, or particles can be emitted multiple times within a cycle. After the set time is reached, the particles stop emitting. Note: It is not the life cycle time of a particle. The life cycle time of a particle will be introduced below (Animation 3) The effect when Duration is 5. When 5 seconds is reached, particles will no longer be emitted, and the Loop must be set to not start. Loop: If enabled, at the end of the above duration, the particle system starts again and continues to repeat the loop Play On Awake: If enabled, the particle system will automatically start when the object is created Start Delay: Delay time before the system starts transmitting after enabling it. Two delay methods can be selected. Constant fixed time Random Between Two Constant Randomly selects values ​​from the minimum to the maximum two times (Animation 4) shows the random method using a minimum of 2 to a maximum of 5 seconds. You can see that at the 4th second, the particles start to emit. Start Lifetime: Controls the life cycle of each particle, that is, how long it takes for the particle to disappear after it occurs. It can be a random value between two numbers. (Animation 5) shows the effect of using Start Lifetime of 3, showing that it takes 3 seconds for each particle to be emitted and disappear. Start Speed: The initial speed of each particle in the appropriate direction, two delay methods can be selected Constant fixed value Random Between Two Constant Randomly selects values ​​from the smallest to the largest Animation 5 shows the speed effect when using Start Speed ​​of 5 Start Size: The initial size of each particle. If you want to control the size of each axis separately, please enable the 3D option. Two delay methods are available Constant fixed value Random Between Two Constant Randomly selects values ​​from the smallest to the largest (Figure 3.1.1-2) It shows that the Start Size is randomly between 1 and 5. You can see that the particles on the left are large and small. Note: The size of the particle has nothing to do with the size of the texture it uses. The same particle drawn by a 100-pixel texture and a 500-pixel texture is almost the same size. It can be seen that StartSize specifies the diameter of the particle. , instead of texture scaling Start Rotation: The initial rotation angle of each particle. If you want to control the rotation of each axis individually, enable the 3D option. Two delay methods are available Constant fixed value Random Between Two Constant Randomly selects values ​​from the smallest to the largest (Figure 3.1.1-3) It shows that Start Rotation is randomly between 1 and 360. You can see that the particles on the left rotate in various directions. Start Color: the initial color of each particle (Figure 3.1.1-4) shows the effect of the Start Color being red Note that even if the particles are specified to be red in StartColor, the displayed effect is not pure red. The particles, the sky, and the places where the red squares are superimposed all become different colors. This is because of the final display effect of the screen. It is controlled by the shader. When we set the particle material, the RenderingMode selected is Additive (superimposed), so the final display effect will be affected by the light coming from behind the particles and change color. You can try different shader options to see the changes (Figure 3.1.1-5) shows the effect of RenderingMode being Additive Gravity Modifier: Set the physical gravity value. A value of zero turns off gravity (Animation 6) shows the effect of using Gravity Modifier to 5 Simulation Space: Controls whether particles follow the movement of the particle emitter Local: After the particles are generated, they move following the movement of the particle emitter coordinates. In this mode, the movement of the particle emitter will be reflected on each particle. World: After the particles are generated, they do not follow the particle emitter and move directly in the world coordinate system. Simulation Speed: Adjust the speed at which the entire particle system updates Scale Mode: Controls the scaling mode of particles Hierarchy: Affected by the scaling of both itself and the parent node Local: only affected by yourself World: not affected Max Particles: The maximum number of particles in a system. If the limit is reached, some particles are removed. If set to 1, the particle system will emit particles one by one. Auto Random Seed: Automatic particle random seed, which will be different every time it is played after it is enabled. After removing the check box, you can fill in the value of the random seed. Different values ​​will cause the emitted particles to behave slightly differently. 3.1.2 Emission module Emission This module is part of the particle system component and is used to specify the properties of emitted particles. When creating a new particle system, the Emission module is enabled by default. (Figure 3.1.2) Enable: whether to enable Rate over Time: Number of particles emitted per second Rate over Distance The number of particles emitted per unit of distance moved. This mode is useful for simulating particles that are actually produced by the motion of an object (for example, dust left by wheels on a dirt road) Bursts: Bursts are events that produce particles. These settings allow particles to be emitted at specified times. You can set multiple groups of burst points and modify the time, minimum number of particles, and maximum number of particles respectively. (Animation 7) shows using a Rate Over Time of 5 to emit 5 particles per second, and using a set of Bursts to suddenly emit 30 particles at the 3rd second. 3.1.3 Shape module Shape This module defines the volume or surface from which particles are emitted, and the direction of the starting velocity. (Figure 3.1.3-1) Shape Type: The choice of shape affects the area where particles can be emitted, and also affects the initial direction of the particles. For example, a Sphere emits particles outward in all directions, and a Cone emits a divergent stream of particles. Sphere: a ball that can emit particles in all directions Radius: Radius Emit from shell: Emit according to the shell Randomize Direction: Randomize direction (Animation 8) shows the use of a sphere with a radius of 3, emitted from the edge of the sphere Hemisphere: hemispheric shape Radius: Radius Emit from shell: Emit according to the shell Randomize Direction: Randomize direction (Figure 3.1.3-2) cone: cone shape, allowing particles to fan out from one point to a circle like the light of a flashlight Angle DEG: the angle of the circular aspect of the shape Radius: Radius Length: length Emit from: Emission method `Base`: Based on the tapered bottom `Base Shell`: Based on the tapered bottom shell `Volume`: based on the interior of the cone `Volume Shell`: based on conical inner shell Randomize Direction: Randomize direction (Animation 9) shows the use of a cone with a radius of 2 and a cone length of 6, emitting from inside the cone Box: Box-shaped, which allows all particles to be emitted in a single direction, and can well simulate rain and snow particle effects. Length: length in each direction of XYZ Randomize Direction: Randomize direction (Figure 3.1.3-3) circle: ring Radius: Radius Angle DEG: the angle of the ring Emit From Edge: Emit based on edge Randomize Direction: Randomize direction (Figure 3.1.3-4) 3.1.4 Lifetime Lifetime This module defines the properties of the emitted particles during their lifetime. (Figure 3.1.4) Velocity over Lifetime: Velocity in the life cycle Constant: constant mode, the speed is constant Curve: Curve mode Random from two Constant: Random speed mode Random between two Curve: Take random values ​​​​in two curves Space: space `Local`: model space `World`: world space Color over Lifetime: Color in the life cycle Constant: constant mode, the color is constant Gradient: Gradient mode Random from two Constant: Random two color modes Random between two Gradient: Randomly take values ​​in two gradients Size over Lifetime: Size in the life cycle `Separate Axes`: Separate by axis `Curve`: Curve mode `Random Between Two Contants`: Randomly select values ​​from two constants `Random between two Curve`: Take random values ​​​​in two curves Rotation over Lifetime: Rotation in the life cycle Separate Axes: Separate by axis `Constant`: constant `Curve`: Curve mode `Random Between Two Contants`: Randomly select values ​​from two constants `Random between two Curve`: Take random values ​​​​in two curves 3.1.5 Texture animation Texture Sheet A module used to play particle animation. The raw material of particle animation is a texture, which contains a set of frame animation and can render particles in an animated manner. Frame animation: Use multiple pictures, each picture is a frame, to form a complete animation called frame animation. Or a large picture that contains all the frames of an animation (Figure 3.1.5-1) (Figure 3.1.5-2) LayaAir currently uses grid mode (Grid) Tiles: The number of tiles the texture is divided into in the X (horizontal) and Y (vertical) directions Animation: Animation mode can be set to whole sheet or single line (i.e. each line represents a separate animation sequence) Frame: Set frame Type: frame type `Constant`: Fixed number of frames `Curve`: A curve that specifies how animation frames increase over time. `Random Between two constant`: Random between two fixed frame numbers `Random Between two curve`: Random between two curves Start Frame: Start frame, allows you to specify which frame the particle animation should start from Cycles: The number of times the animation sequence repeats during the particle's lifetime (Figure 3.1.5-3) The usage process will be introduced in Section 4 Flame Example 3.2 Particle rendering module ShurikenParticleRenderer Renderer module settings determine how a particle's image, model, is transformed, shaded, and overdrawn by other particles. (Figure 3.2) Receive Shadows: Determines whether particles in this system can receive shadows from other sources. Only opaque materials can receive shadows. Cast Shadows: If this property is enabled, the particle system will create shadows when struck by a shadow-casting light. Scale In Lightmap: Adjust the pixel density of specific objects in the final LightMap. Materials: Materials used to render particles Render Mode: How to generate a rendered image from a graphics image (or mesh). Billboard: Render particles as billboards, always facing the camera Stretched Billboard: allows the use of particle scaling while facing the camera. Speed ​​Scale: Set the length according to the particle speed Length Scale: Determine the length of the particle by comparing its width Horizontal Billboard: The particle plane is parallel to the XZ bottom plane Vertical Billboard: The particles are upright on the Y-axis, but facing the camera Mesh: Particles are rendered from a 3D mesh instead of a texture (GIF) Sorting Fudge: Sorting correction, using this will affect the painting order. Particle systems with lower Sorting Fudge values ​​are more likely to be drawn last, thus appearing in front of transparent objects and other particle systems 3.3 Particle shader PARTICLESHURIKEN Select Laya's particle in the material, and you can add Laya's built-in particle shader (PARTICLESHURIKEN), which can render various particle systems. Effect. All particles use this material. (Figure 3.3) Color: Specifies the color of the particles. Texture: Specifies the texture map used by particles Alpha Test Value: When the transparency test is turned on, the current pixel determines whether to output color according to the set conditions. Tiling Offset: Get texture tiling and offset Material Render Mode: Set rendering mode Opaque: Default setting, suitable for ordinary solid objects without transparent areas. ​ Cutout: Allows the creation of transparency effects with hard edges between opaque and transparent areas. In this mode, there are no translucent areas and the texture is either 100% opaque or invisible. This is useful when using transparency to create the shape of a material, such as leaves or holed and tattered cloth. ​ Transparent: Suitable for rendering realistic transparent materials, such as clear plastic or glass. In this mode, the material itself will take on a transparency value (based on the texture's alpha channel and the tint color's alpha), but reflections and lighting highlights will remain visible at full clarity, just like a truly transparent material. Additive: superposition method ​ AlphaBlended: Transparent blending method Cull: Culling method 4. Flame effect production example 4.1 Create flame prefab (Figure 4.1) In the Scene3D scene, right-click the mouse and select Create Effects->Particle3D. By default, a 3D particle system is created, named FireEffect, and dragged to the Assets->Particle3D directory to create the prefab. 4.2 Flame sequence frame animation (Figure 4.2) Prepare the flame sequence frame animation texture file, place it in the Assets directory, click on the texture, check sRGB and Alpha Channel, the TextureType is still Default, click the Apply button to ensure that the modification is successful. 4.3 Set flame material (Figure 4.3) Create a material under Assets and name it FlameRoundYellowParticle. The Shader uses Laya.Particle. Basically all particle effects use this Shader. Color is set to 191,191,191,255, texture selects the map added above, and Material Render Mode selects ADDITIVE. 4.4 Set up particle system rendering module (Figure 4.4-1) After creating the particle system, the ShurikenParticleRenderer component will be added by default in the Inspector panel, and the FlameRoundYellowParticle material will be selected. (Figure 4.4-2) In the Scene window, you can see that the particle effect has been replaced by a texture, and you need to further set the texture animation. 4.5 Using texture animation (Figure 4.5-1) In the TextureSheet of the particle system, create an Instance. Since the composition of the flame map is 10x5, modify the Tiles to X: 10, Y: 5. After modification, the particle system map becomes a flame effect, but it is still a static image. Next, modify the Frame animation. Modify Frame->Type to Curve, click Curve to open the panel, the horizontal axis is the timeline, and the vertical axis is the number of frames of the frame animation. , the effect we want is to play the flame frame animation in a loop in 1 second, that is, from 0 to 50 frames, then we modify the Curve as shown below (Figure 4.5-2) After completing the Curve, look at the flame effect and you can now play the frame animation. (Animation 10) 4.6 Set basic properties (Figure 4.6) The Constant of Start Speed ​​is 0, the initial speed when the flame is emitted is 0, the Constant of Start Size is 2, which enlarges the size of the flame by 2 times, and the Simulation Speed ​​is 2, which can speed up the speed of flame playback. 4.7 Set up the transmitter (Figure 4.7) Modify the number of particles emitted per unit time to 5, which is equivalent to burning 5 flames per second. 4.8 Set up the shape module (Figure 4.8) We hope that the particles will be emitted in a circle to achieve the effect of flame gathering and burning. 4.9 Set particle life cycle (Figure 4.9-1) The most important step is to set the particle life cycle. First, set the color process within the flame life cycle, create a Color Over Lifetime instance, set the Type to Gradient gradient curve, open the Gradient panel, and the three downward arrows above indicate the color. The transparency ranges from 0% opaque -> 80% opaque -> 100% fully transparent. The two upward arrows below indicate the color range from c99451 to ff4500. (Figure 4.9-2) Since the flame is a particle that moves upward until it disappears, create a Velocity Over Lifetime instance, select the Curve curve, and only need to modify the displacement of the Y-axis to 1 second from 0 to 1, moving up 1 unit. (Figure 4.9-3) Since the flame will shrink in size, create a Size Over Lifetime instance, select the Curve curve, and only need to modify the size from 1 to 0.5 in 0.5 seconds, doubling the size. (Animation 11) At this time, you can see in the Scene window that the flame effect has been completed. 5. Application scenarios and code examples Often during the battle process of the game, a large number of particles need to be created, so the object pool needs to be used. Object pool optimization is a very important optimization method in game development and is also one of the important factors affecting game performance. There are many objects in the game that are constantly being created and removed, such as the creation and removal of character attack bullets, special effects, the destruction and refreshing of NPCs, etc. The creation process consumes a lot of performance, especially when the number is large. . Object pool technology can solve the above problems very well. When objects are removed and disappear, they are recycled to the object pool. When new objects are needed, they are directly taken out of the object pool and used. The advantage is that it reduces the overhead when instantiating the object, allows the object to be used repeatedly, and reduces the chance of new memory allocation and garbage collector running. Note: When the object is removed, it is not immediately erased from the memory. Only when the memory is deemed to be insufficient, the garbage collection mechanism will be used to clear it. Clearing is very memory intensive and may cause lag. Using the object pool will reduce the garbage objects of the program and effectively improve the running speed and stability of the program. 5.1 Custom Particle3D class import Node = Laya.Node; import Sprite3D = Laya.Sprite3D; import ShuriKenParticle3D = Laya.ShuriKenParticle3D; import ShurikenParticleSystem = Laya.ShurikenParticleSystem; import { Pool } from \"./Pool\"; //The base class of particle effects, including creation, playback, pause, destruction, and cleaning up the object pool export class Particle3D extends Sprite3D { private _isInited: boolean = false; private _filePath: string = null; private _particle: Laya.Sprite = null; private _shuriKenParticle3D: Array= []; private _shurikenParticleSystem: Array= []; constructor() { super(); } //Create a particle effect by passing in the path of the particle effect, and take one from the object pool static Create(path: string): Particle3D { var ret:Particle3D = Pool.getInstance().getItemByClass(\"Particle3D@\" + path, Particle3D); ret.Init(path); return right; } //Particle effects initialization private Init(file_path:string): void { if (this._isInited) { return; } this._filePath = file_path; console.log(\"Particle3D\"); //Clone one from the obtained particle system var res = Laya.loader.getRes(file_path); var particle = res.clone(); this._particle = particle; //Get all particle systems of this particle effect for later overall playback for (var i = 0, len = this._particle.numChildren; i 5.2 Custom object pool class export class Pool { private _poolDic:{[key: string]: any;} = {}; private InPoolSign: string = \"__InPool\"; constructor() { } private static _instance: Pool = new Pool(); public static getInstance() { return this._instance; } //Find the corresponding object pool by name getPoolBySign(sign:string): any { return this._poolDic[sign] || (this._poolDic[sign] = []); }; //Recycle recover(sign:string, item:any): void { item[\"__InPool\"] = true; }; //Get an object by name. If there is no object in the object pool, create one getItemByClass(sign:string, cls:any): any { var right = null; var pool = this.getPoolBySign(sign); for (var i = 0, len = pool.length; i 5.3 Code call const { regClass, property } = Laya; import { Particle3D } from \"./Particle3D\"; @regClass() export class Main extends Laya.Script { //The path of particle effects private filePath = \"FireEffect\"; onStart() { console.log(\"Game start\"); //Load particle effects resources Laya.loader.load(this.filePath, Handler.create(this, () => { })); } //Every time the mouse clicks on the screen, a special effect will be created mouseDown(e: Event): void { var particle = Particle3D.Create(this.filePath); this.owner.addChild(particle); } //After the mouse is raised, the object pool will be released mouseUp(e: Event): void { Particle3D.ClearPool(this.filePath); } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:44:32 "},"IDE/materialEditor/readme.html":{"url":"IDE/materialEditor/readme.html","title":"Material Editor","keywords":"","body":"IDE material properties1. Creation of materials2. Material panel2.1 Basic properties of materials2.1.1 BlinnPhong Shader2.1.2 Unlit Shader2.1.3 PBR Shader2.1.4 Particle Shader2.1.5 Trail Shader2.1.6 SkyBox Shader2.1.7 SkyPanoamic Shader2.1.8 SkyProcedural Shader2.2 Material effect display2.2.1 Switch the materials of different meshes2.2.2 Turn off lighting effects3. Use of materialsIDE material properties In order to draw objects in the scene, we need to describe the shape and appearance of the object. We use mesh to represent the shape of the object and materials to represent the appearance of the object. Materials and shaders are closely linked, and the materials we use must have corresponding shader forms. 1. Creation of materials We can create materials in the project panel of the IDE. The material creation operation is as shown in the animation 1-1: Animation 1-1 We create a material and name it \"myMaterial\". 2. Material panel After creating the material, we see that new attribute descriptions will appear on the Inspector panel on the right. When we select the created material, the attribute panel will display the attribute content of the current material. The attribute panel mainly displays the basic properties of the material and the material effect. It consists of two parts, as shown in Figure 2-1. Let us explain in detail the composition of the material properties panel. Figure 2-1 2.1 Basic properties of materials Materials describe different surfaces based on different shader models. The IDE has eight built-in shader types. We explain the basic properties of each shader corresponding to the material according to the shader type. Switching the shader of the material is by selecting is implemented using the Shader of the material. The specific operation diagram is shown in Figure 2-1-1 to switch to other types of shaders. Animation 2-1-1 2.1.1 BlinnPhong Shader The Blinn-Phong illumination model can simply describe the absorption and reflection of light on the surface of an object, making the surface of the object present different degrees of brightness. It mainly describes the highlight, diffuse light and ambient light parts of the surface of the object. (1) VertexColor vertex color Whether to support the macro definition switch of vertex color. When turned on, the vertex color content of the mesh can be superimposed. (2) AlbedoTexture diffuse reflection map You can set the content of the diffuse reflection map of the material. The example uses the map of a brick, and the effect is as shown in the animation 2-1-1-2-1: Animation 2-1-1-2-1 (3) AlbedoColor diffuse color You can set the overall diffuse reflection color of the material, as shown in the animation 2-1-1-3: Animation 2-1-1-3 （4） AlbedoIntensity Sets the intensity of the diffuse color. (5) SpecularTexture highlight map Used to set the specular reflection of the object's surface, and reflect the smooth reflection degree of the object's current vertex according to the rgb value of the UV of the object's current vertex on the highlight map, as shown in Figure 2-1-1-5-1 and Figure 2-1- As shown in 1-5-2: Figure 2-1-1-5-1 Figure 2-1-1-5-2 Before and after setting the highlight map, you can clearly see that due to the influence of the highlight map, only part of the wall has a highlight effect. This can be used to simulate the highlight phenomenon of different materials and different locations. (6) SpecularColor highlight color You can set the color of the highlight part, as shown in Figure 2-1-1-6, set the highlight color to green: Figure 2-1-1-6 (7) Shininess glossiness Used to set the highlight range. The effect is as shown in the comparison between 2-1-1-7-1 and 2-1-1-7-2 at different gloss levels: Figure 2-1-1-7-1 Figure 2-1-1-7-2 When the shininess value is small, the overall highlight range is larger; when the shininess value is larger, the overall highlight range is smaller. (8)NormalTexture normal map Used to set the normal of the object model in tangent space for lighting calculation. The model needs to have tangent data. As shown in Figure 2-1-1-8-1 and Figure 2-1-1-8-2, the lighting and coloring with the participation of normal maps are more realistic. Figure 2-1-1-8-1 Figure 2-1-1-8-2 It can be seen that after adding the normal map, the lighting has been recalculated, and the surface of the object has become more realistic. (9) AlphaTestValue alpha test value This needs to be used in conjunction with the material's rendering mode of CUTOUT. In CUTOUT mode, when the alpha of the fragment color value of the current vertex is less than AlphaTestValue, the value of this fragment will be directly discarded without rendering. We use a spider web The picture is used as a diffuse reflection map. You can check the effect of this value by adjusting the value of AlphaTestValue. The spider diagram is shown in 2-1-1-9-1, and the value of AlphaTestValue is shown in the animated picture 2-1-1-9-2: Figure 2-1-1-9-1 The alpha channel value of the hollow part is 0 Animation 2-1-1-9-2 It can be seen that as the value becomes larger, more fragments are discarded until all fragments are discarded and not rendered. (10) TilingOffset scaling offset You can set the scaling and offset of the object model UV to achieve different effects of sampling AlbedoTexture, as shown in the animation 2-1-1-10: Animation 2-1-1-10 (11) MaterialRenderMode material rendering mode OPAQUE: In opaque mode, models obscured behind objects will not be rendered. CUTOUT: Culling mode, which will discard some fragments based on the alpha value of the albedo map and the value of AlphaTestValue. TRANSPARENT: Transparent mode, which will be mixed with the objects behind to create a transparent effect. ADDITIVE: Overlay mode, which will superimpose the pixels behind the object ALPHABLENDED: The same blending method as transparent mode. The difference from transparent mode is that the fog in the scene will not be mixed. (12) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQueue, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; (13) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.2 Unlit Shader The Unlit shader is a material that is not exposed to light and is not affected by lighting. It only relies on the texture and color of the material to express the surface effect of the object. (1)VertexColor vertex color Whether to apply vertex color. When this macro definition is turned on, the model vertex color will be superimposed. (2) Texture map Set the map used to describe the stroke color of the object, as shown in Figure 2-1-2-2-1 and Figure 2-1-2-2-2. After setting the map, the surface of the object displays the corresponding map part based on UV Color, and you can see that when there is light in the scene, it will not be affected by the light. Figure 2-1-2-2-1 Figure 2-1-2-2-2 (3)AlbedoColor diffuse color Similarly, AlbedoColor can superimpose colors onto the object surface. As shown in Figure 2-1-2-3-1, we superimpose a red color onto the object surface: Figure 2-1-2-3-1 (4) AlphaTestValue alpha test value This also needs to take effect when the rendering mode is CUTOUT and is used in conjunction with it. It is the same as the Blinn-Phong shader. It is also determined by judging whether the alpha value of the current vertex fragment and the value of the set AlphaTestValue are smaller than the value of AlphaTestValue. Will be discarded and not rendered. We still use the spider web map used by the Blinn-Phong shader above to see how different alphaTestValue values ​​are processed, as shown in the animation 2-1-2-4-1: Animation 2-1-2-4-1 You can see that the difference from Blinn-Phong is that the alpha value of Unlit will superimpose the value of AlbedoColor.a. The alpha of our AlbedoColor is 1.0. At this time, all the fragments will not be discarded. (5) TilingOffset scaling offset Used to set the scaling and offset of the UV of the object model, which has the same effect as the Blinn-Phong shader, as shown in the animation 2-1-2-5-1: Animation 2-1-2-5-1 (6) MaterialRenderMode material rendering mode OPAQUE: In opaque mode, models obscured behind objects will not be rendered. CUTOUT: Culling mode, which will discard some fragments based on the alpha value of the albedo map and the value of AlphaTestValue. TRANSPARENT: Transparent mode, which will be mixed with the objects behind to create a transparent effect. ADDITIVE: Overlay mode, which will superimpose the pixels behind the object. ALPHABLENDED: The same blending method as transparent mode. The difference from transparent mode is that the fog in the scene will not be mixed. (7) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; (8) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front How to use unlit to achieve the material effect of the original 2.0 engine by changing settings Change the MaterialRenderMode material rendering mode to addtive or blend mode. The effect is the same if the color space is not excluded. The color space of 3.0 has become linear. 2.1.3 PBR Shader PBR material is a physically based rendering material that can provide an accurate representation of the interaction between light and surfaces, and can more realistically describe the surface properties of objects. We use the image-based lighting (IBL) lighting mode to better display the properties of PBR. We need to convert the ambient light source of the scene from SolidColor to spherical harmonics, and click GenerateLighing below to generate an IBL cube map CubeMap, as shown in the figure As shown in 2-1-3-1: Figure 2-1-3-1 (1) AlbedoTexture diffuse reflection map In order to set the overall texture of the surface material of the object, the wall above is also used as the texture, as shown in Figure 2-1-3-1-1 and Figure 2-1-3-1-2. The effect of setting AlbedoTexture: Figure 2-1-3-1-1 Figure 2-1-3-1-2 (2)AlbedoColor diffuse color You can superimpose a whole color on the surface of the object. As shown in Figure 2-1-3-2-1, we superimpose a yellow color on the material: Figure 2-1-3-2-1 (3) Metallic metal degree It is used to set the effect of metallic glossiness on the surface of an object. Generally, we use 0 and 1 to set the metallicity of the object. It is completely absent or completely present. When the metallicity is 1, it can reflect the content of the surrounding environment. Imagine that when we look into a smooth metal ball, it reflects our face. In this way, we have set up the IBL-based spherical harmonic cube map as the ambient light in the IDE. When we bring the metallicity of the material closer and closer to 1, the surface of the object will reflect the content of the surrounding environment. At the same time, we set the smoothness to 1. This way you can see the effect more clearly, as shown in the animation 2-1-3-3-1: Animation 2-1-3-3-1 When we adjust the metallicity of the material and slide it toward 1, we can see that the surface of the object gradually reflects the content of the surrounding environment. When the metallicity is 1, it can completely reflect the surrounding environment. (4) Smoothness Used to set the smoothness of the object surface. When the smoothness is 0, the diffuse reflection of the object surface is obvious and the highlights are insufficient. When the smoothness is 1, the highlights are more obvious. As shown in the animation 2-1-3-4-1: Animation 2-1-3-4-1 (5) SmoothnessSource smoothness source Two smoothness sources can be set, one is obtained from the alpha channel of AlbedoTexture and the other is obtained from the alpha channel of MetallicGloassTexture. In fact, the smoothness of the object's surface material is mapped to the alpha channel of the AlbedoTexture map, or to the alpha channel of the MetallicGloass map, so that lighting calculations can be performed based on the smoothness of each vertex of the object. AlbedoTextureAlpha: Get the surface smoothness of the object from the alpha channel of the Albedo map. MetallicGloassTextureAlpha: Get the surface smoothness of the object from the alpha channel of the MetallicGloass map. (6) SmoothnessTextureScale smoothness map scaling value When it is set to obtain the smoothness value from the alpha channel of the texture, you can control the overall smoothness value under the alpha channel of the texture by setting this scaling value. We set the smoothness source to the alpha value of albedoTexture, and use the above spider web map as the albedo map, as shown in the animation 2-1-3-6-1: Animation 2-1-3-6-1 (7)NormalTexture normal map Setting the normal map of the object will calculate the lighting based on the normal map of the object, as shown in Figure 2-1-3-7-1 and Figure 2-1-3-7-2. After setting the normal map, the lighting will The highlight and diffuse parts have been recalculated: Figure 2-1-3-7-1 Figure 2-1-3-7-2 (8) OcclusionTexture occlusion map By sampling the g channel of the Occlusion map, you can set the AO ambient light occlusion value of the model vertex, so that when performing PBR lighting calculations, the lighting values ​​at small seams and other locations can be more realistically simulated. (9) OcclusionTextureStrength occlusion map strength Used to adjust the intensity of the occlusion map. When the intensity is 0, the overall occlusion value is 1; when the intensity is 1, the occlusion value of the occlusion map is used. (10) Emission self-illumination Used to set whether the self-illumination of the model is turned on. After turning it on, two new self-illumination parameters will be added, namely EmissionColor and EmissionTexture; EmissionColor self-illuminating color The superimposed overall self-illuminating color will be more obvious in the diffuse reflection part. As shown in Figure 2-1-3-10-1, a red self-illuminating color is superimposed: Figure 2-1-3-10-1 EmissionTexture self-illuminating map Setting the self-illumination map can superimpose the self-illumination color set above on different vertex positions according to the model, as shown in Figure 2-1-3-10-2: Figure 2-1-3-10-2 (11) EmissionIntensity self-luminous intensity Set the intensity of the self-illuminating color. When the intensity is 0, there is no self-illuminating effect; when the intensity is 1, the set self-illuminating color is superimposed. (12) MetallicGlossTexture metal smooth map You can set up a map to store the metallicity and smoothness of the surface material of the object. The r channel of the map stores the metallicity information of the model material, and the a channel of the map stores the smoothness information of the model material. Below we use a pure black and pure white map. To show the influence of metal smoothness map on PBR material, as shown in Figure 2-1-3-12-1 and Figure 2-1-3-12-2: Figure 2-1-3-12-1 Figure 2-1-3-12-2 The metallicity and smoothness of the pure black image in Figure 2-1-3-12-1 are 0, basically only the diffuse reflection effect of the cube map. The metallicity and smoothness of the pure white image in Figure 2-1-3-12-2 are The smoothness is 1, which can reflect the surrounding three-dimensional ambient light content very well. (13) AlphaTestValue alpha test value It also needs to be used with the rendering mode set to CUTOUT mode. It will be tested based on the alpha superposition value of AlbedoTexture and AlbedoColor. Fragments less than the AlphaTestValue value will be discarded and not rendered. （14）TilingOffset The effect is the same as Blinn-Phong and Unlit. It can be used to set the model UV scaling and offset values ​​to achieve sampling of different positions of the Albedo map. (15) MaterialRenderMode material rendering mode OPAQUE: In opaque mode, models obscured behind objects will not be rendered. CUTOUT: Culling mode, which will discard some fragments based on the alpha value of the albedo map and the value of AlphaTestValue. TRANSPARENT: Transparent mode, which will be mixed with the objects behind to create a transparent effect. ADDITIVE: Overlay mode, which will superimpose the pixels behind the object ALPHABLENDED: The same blending method as transparent mode. The difference from transparent mode is that the fog in the scene will not be mixed. (16) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; (17) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.4 Particle Shader Particle shaders are used to set the surface display of particles, and are mainly used in particle special effects. We need to create a particle system in the scene, as shown in animation 2-1-4-1: Animation 2-1-4-1 At the same time, the material needs to be assigned to the particle system, as shown in the animation 2-1-4-2: Animation 2-1-4-2 In this way, the material is assigned to the particle system for use. Let’s briefly talk about the role of each parameter. (1) Color particle color Used to set the color of the particle material, as shown in Figure 2-1-4-1-1, we set the particle color to red, and the particles emitted by the particle system at this time turn red: Figure 2-1-4-1-1 (2) Texture map Used to set the texture style of particles, as shown in Figure 2-1-4-2-1: Figure 2-1-4-2-1 (3) AlphaTestValue alpha test value The CUTOUT mode on the particle shader is invalid, and the alpha test value does not need to be set. （4）TilingOffset It has the same effect as Blinn-Phong and Unlit. It can be used to set the UV scaling and offset values ​​of the model to achieve sampling of different effects of the Albedo map. (5) MaterialRenderMode material rendering mode OPAQUE: In opaque mode, models obscured behind objects will not be rendered. CUTOUT: Invalid under particle shader. TRANSPARENT: Transparent mode, which will be mixed with the objects behind to create a transparent effect. ADDITIVE: Overlay mode, which will superimpose the pixels behind the object ALPHABLENDED: The same blending method as transparent mode. The difference from transparent mode is that the fog in the scene will not be mixed. (6) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; (7) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.5 Trail Shader The Trail shader is used to achieve the trailing effect. We need a trailing effect object to implement it. Create a trailing effect object in the scene as shown in Figure 2-1-5-1: Animation 2-1-5-1 We add the corresponding material to the trailing special effects object as shown in the animation 2-1-5-2. Add the myMaterial material to the trailing special effects object: Animation 2-1-5-2 In order to see the effect of the trailing, we need to move the trailing special effects object. To do this, we add a Move script so that the special effects object can move along the x-axis. (1) Color color Used to set the color of the trailing, as shown in the animation 2-1-5-1-1, we set a red as the trailing color: Animation 2-1-5-1-1 (2) Texture map Used to set the shape of the trailing, as in the animated picture 2-1-5-2-2, we add a picture 2-1-5-2-1 as a texture, the trailing shader uses ADDITIVE mode to achieve transparent overlay Effect: Figure 2-1-5-2-1 Animation 2-1-5-2-2 （3）AlphaTestValue alphaTest值 Trailing shaders only use ADDITIVE and ALPHABLENDED modes, this value has no effect here. (4) TilingOffset scaling offset It can be used to set the UV scaling and offset during texture sampling to achieve the effect of texture scaling and offset. (5) MaterialRenderMode material rendering mode Trailing shaders only use ADDITIVE and ALPHABLENDED modes: ADDITIVE: Transparent overlay mode, superimposes all the alpha values ​​of the following pixels to achieve a transparent effect. ALPHABLENDED: The same mixing method as the transparent mode. The difference from the transparent mode is that it will not mix the fog in the scene. This mode will not produce the ADDITIVE transparency effect. (6) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; The trailing shader only uses ADDITIVE and ALPHABLENDED modes, here set to 3000. (7) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.6 SkyBox Shader The skybox shader is used to set the skybox style of the scene. The skybox requires a cubemap for sampling. We first need to create a new cubemap and set the texture according to the top, bottom, left, right, front and back of the skybox, as shown in the animation 2-1- As shown in 6-1: Animation 2-1-6-1 Setting up the sky box requires modifying the sky box material of Scene3D, as shown in the animation 2-1-6-2: Animation 2-1-6-2 (1)TintColor Overlay the color onto the sky box, as shown in Figure 2-1-6-1-1, and set a light red color to make the entire sky red: Figure 2-1-6-1-1 (2) Exposure Used to set the exposure of the sky box. When the exposure is 0, the sky box is black; as the exposure value increases, the normal cube map color will gradually be displayed, and then the sky box will turn completely white due to overexposure. As shown in the animation 2-1-6-2-1: Animation 2-1-6-2-1 (3)Rotation You can rotate the cubemap around the y-axis from 0 to 360 degrees. (4)CubeTexture spherical map To set the sampling map of the sky box, you need to use a CubeMap type cube map. (5) AlphaTestValue alpha test value This value does not take effect when switching to CUTOUT mode on the skybox shader. （6）TilingOffset Since cubemaps are used, this value has no effect on the skybox shader. (7) MaterialRenderMode material rendering mode On the skybox shader, setting it to CUTOUT, TRANSPARENT, ADDITIVE, or ALPHABLENED modes does not take effect. (8) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; Since the rendering mode of the skybox material only takes effect in OPAQUE mode, just set it to 2000. (9) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.7 SkyPanoamic Shader Skybox panoramic map shader, here a 2D panoramic map is used to wrap the scene in the form of a cube map to achieve ambient light effects. The use of this material is the same as that of the skybox, and it is directly assigned to the skybox renderer of the 3D scene. Can. (1)TintColor color The function is the same as the skybox shader, which superimposes a color on the panorama skybox. (2)Rotation rotation You can set the rotation angle of the sky box around the Y axis, between 0 and 360. (3) PanoramicTexture panoramic map The panorama map requires a cylindrical 2D map using latitude and longitude. (4) AlphaTestValue alpha test value Since only OPAQUE mode is effective on the panoramic skybox shader, this value is invalid in CUTOUT mode. （5）TilingOffset Due to the way cubemaps are implemented using 2D textures, this value is invalid. (6) MaterialRenderMode material rendering mode In panorama skybox mode, only OPAQUE mode takes effect. (7) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; Since only OPAQUE mode is in effect, it is set to 2000; (8) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.1.8 SkyProcedural Shader A procedural skybox that simulates the sky by setting the parameters of the sun. (1) U_SunSize sun size Set the disk size of the sun, as shown in Figure 2-1-8-1-1. Set the sun size to 0.1: Figure 2-1-8-1-1 (2) Sun type There are three types of sun used to set the procedural skybox: SUN_NONE No Sun, no sun is displayed on the skybox when this mode is selected. SUN_HIGH_QUALITY High-quality solar simulation. In this mode, the divergence and convergence of sunlight can be adjusted. SUN_SIMPLE A simple sun simulation can only adjust the overall size of the sun. (3) U_SunSizeConvergence sun size convergence The size of the sun converges. The smaller the value, the larger the overall solar disk. It only takes effect in the SUN_HIGH_QUALITY mode. As shown in the animation 2-1-8-3-1: Animation 2-1-8-3-1 (4) U_AtmosphereThickness Atmosphere thickness The density of the atmosphere. A higher-density atmosphere will absorb more colors, as shown in Figure 2-1-8-4-1 when the density is 1, and Figure 2-1-8-4-2 when the density is 2. Show: Figure 2-1-8-4-1 Figure 2-1-8-4-2 (5)U_SkyTint sky color Sets the color of the sky above the horizon. (6)U_GroundTint ground color Sets the color of the ground below the horizon. (7)U_Exposure exposure Set the light and dark of the sky box through the exposure value, as shown in the animation 2-1-8-7-1: Animation 2-1-8-7-1 (8) AlphaTestValue alpha test value Since procedural skyboxes only use OPAQUE, this value has no effect. （9）TilingOffset Since procedural skies do not have textures, this value has no effect. (10) MaterialRenderMode material rendering mode Only takes effect in OPAQUE mode. (11) RenderQueue rendering queue It can be used to set the rendering queue of the material shader. The larger the RenderQuere is, the later the rendering will be. Generally, after setting the rendering mode of the material, the rendering queue will be set according to the rendering mode. The queue corresponding to OPAQUE mode is 2000; The queue corresponding to CUTOUT mode is 2450; The queue corresponding to TRANSPARENT mode is 3000; The queue corresponding to ADDITIVE mode is 3000; The queue corresponding to ALPHABLENDED mode is 3000; Since the procedural skybox only takes effect in OPAQUE mode, set it to 2000. (12) Cull elimination mode Culling is performed based on the different connection orders of the face vertices (clockwise or counterclockwise). Off: Turn off culling Back: Remove the back side Front: remove the front 2.2 Material effect display The material effect display is mainly used to display the material effect after setting the attributes. You can use the mouse to interact here to operate the effects of the material ball in different directions. 2.2.1 Switch the materials of different meshes You can switch the effects of materials under different meshes by clicking the square button on the right, as shown in the animation 2-2-1: Animation 2-2-1 2.2.2 Turn off lighting effects You can switch the material's effect of receiving light or not by clicking the light bulb button on the right, as shown in the animation 2-2-2: Animation 2-2-2 3. Use of materials After we adjust the properties of the material to the effect we want, we can assign the material to the object in the scene. There are two methods for setting the material of the object, namely the following animation 3-1 and animation 3-2. Shown: Animation 3-1 As shown in the animation 3-1 above, you can directly drag the material onto the object in the Scene window, or you can select the corresponding material on the renderer of the corresponding object as shown in the animation 3-2. Animation 3-2 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:42:32 "},"IDE/ShaderBlueprint/readme.html":{"url":"IDE/ShaderBlueprint/readme.html","title":"Shader Blueprint","keywords":"","body":"ShaderBlueprint1. Blueprint Overview1.1 Create a blueprint1.2 Blueprint interface preview2. Similarities and differences with Shader2.1 Three fixed basic material types2.2 Material mixing method2.3 ShaderName //Pending items2.4 ShadowCaster2.5 DepthNormal2.6 AlphaTest2.7 SceneFog3. Simple example3.1 Display a simple model3.2 Display a simple Blinnphong shader4. Node data transmission method5. Common node types5.1 Coordinate class5.2 Camera class5.3 Mathematics5.4 Texture class5.5 Color Class6. Common Params types6.1 Float6.2 Texture2D6.3 Vector2/3/46.4 Color6.5 Define7. Custom function8. Advanced examples8.1 Vertex Shader Fragment8.2 Fragment Shader FragmentsExpansion: Quick operationsShaderBlueprint 1. Blueprint Overview 1.1 Create a blueprint Right-click the Create menu in the Assert window and select Shader BluePrint to create a blueprint file. When the blueprint file is not opened, the Shader file corresponding to the blueprint file is not created; the Shader file is created only when the blueprint file is opened, completing the mapping between the blueprint and Shader. Picture 1-1 1.2 Blueprint interface preview Figure 1-2 Blueprint file Inspector window Blueprint Params window Blueprint file Pass window Blueprint preview window 2. Similarities and differences with Shader 2.1 Three fixed basic material types 2.1.1 PBR Common Shader properties: NormalWS The world normal calculates the lighting results of each vertex in world coordinates. alphaTest After the AlphaTest switch is enabled, Shader uses the value of alphatest to determine whether to discard the pixel. AlbedoColor Surface color (excluding lighting) Metallica Metallicity, a value that describes the metallic properties of an object, actually controls the extent to which a surface is like \"metal\". For a pure surface, the value of metallicity may be 0 or 1. Most objects in reality are actually somewhere between this. between intervals Smoothness Smoothness describes the smoothness of an object. It can usually be determined based on the blur or clarity of reflection or the breadth or density of specular reflection highlights. Occlusion Ambient Occlusion Parameters, Ambient Occlusion is an effect that approximates the attenuation of light due to occlusion, a subtle representation that makes corners, crevices darker to create a more natural, realistic look Emission Self-illuminating color Anisotropy Anisotropic parameters, increase the number of samples to supplement the details displayed on the model Alpha Transparency, if the TRANSPARENT rendering mode is selected, different transparency levels will be selected based on the Alpha value. Figure 2-1 shows the fragment shader content where the PBR material type is a Shader Blueprint. Figure 2-1 2.1.2 UnLit NormalWS The world normal calculates the lighting results of each vertex in world coordinates. AlphaTest After the AlphaTest switch is enabled, Shader uses the value of alphatest to determine whether to discard the pixel. Color base color Alpha Transparency, if TRANSPARENT rendering mode is selected, different transparency levels will be selected based on the Alpha value. Figure 2-2 shows the fragment shader content where the UnLit material type is a Shader Blueprint. Figure 2-2 2.1.3 Blinnphong NormalWS The world normal calculates the lighting results of each vertex in world coordinates. AlphaTest After the AlphaTest switch is enabled, Shader uses the value of alphatest to determine whether to discard the pixel. DiffuseColor Diffuse color (the color of places where no light is produced) SpecularColor Specular color (the color of where the light is generated) Shininess surface smoothness Gloss Surface roughness Aplha Transparency, if TRANSPARENT rendering mode is selected, different transparency levels will be selected based on the Alpha value. Figure 2-3 shows the fragment shader content where the Blinnphong material type is a Shader Blueprint. Figure 2-3 2.2 Material mixing method OPAQUE (opaque) final color = source color. This means that the material will be drawn in front of the background. CUTOUT (cutout) If the Alpha value sampled in the map > AlphaTestValue, the final color is the source color, otherwise the pixel is discarded. TRANSPARENT (translucent) Final color = source color opacity + destination color (1 - opacity). ADDTIVE (additive color mixing) Final color = source color + target color ALPHABLENDED (transparent blending) This means that the object is in semi-transparent mode, but the final pixel is shaded in a different blending mode. The AlphaBlended blending mode is SrcAlpha SrcColor + (1 - SRCAlpha) DstColor. Generally speaking, SrcAlpha comes from the alpha value of the texture. 2.3 ShaderName //Pending items ShaderName is entered in the ShaderName text box. 2.4 ShadowCaster Shadow calculation switch. When this switch is turned on, 2.5 DepthNormal DepthNormal switch, when this switch is turned on, DepthNormal Pass will be added to calculate the normal information of the scene (this function may be used in some post-processing) 2.6 AlphaTest Alpha test switch. When this switch is turned on, the Value function of the AlphaTest variable of the fragment shader is enabled, transparent clipping is enabled, and pixels that trigger the alphatest Value condition are directly discarded without filling color. 2.7 SceneFog Scene fog effect switch. When this switch is turned on, sceneFog is enabled to calculate the scope of the fog effect through the w value of the screen space. 3. Simple example 3.1 Display a simple model Figure 3-1 Pass in a texture through Params Sampling the incoming texture via UV Use the color sampled from the texture as the Color passed to Unlit Pass the world normal into Unlit’s world normal input The results of the blueprint are shown below Figure 3-2 3.2 Display a simple Blinnphong shader Figure 3-3 Pass in world normals Pass in the surface color through Params The results of the blueprint are displayed as shown in the figure Figure 3-4 4. Node data transmission method In a node in the blueprint, the left side is the input data and the right side is the output data. Input data can come from a source data, Params variable or the output of other nodes Pic 4-1 5. Common node types 5.1 Coordinate class Coordinate type Coordinate interpretation PositionWS Vertex world coordinates in world space normalWS Vertex normal world coordinates in world space tangentWS Vertex tangent world standard in world space biNormalWS Vertex bitangent world coordinates in world space worldMat World space matrix 5.2 Camera class Property type Attribute explanation viewDirection Sight vector (mathematical expression of sight in 3D world space) cameraPosition Camera position world space coordinates cameraDirection Camera forward direction cameraUp Camera Up direction cameraNear Camera near plane size cameraFar Camera far plane size 5.3 Mathematics Property type Attribute explanation add / minus / multiply / divide Four arithmetic operations without / cos / so Trigonometric functions clamp Clamp the value within the range of min and max mix / max Minimum value, maximum value step / smoothstep x > value : 0.0 : 1.0 pow Next dot / cross Dot product vector, cross product vector 5.4 Texture class Property type Attribute explanation sampler2D Normal sampling 2D texture map samplerCube Sampling 3D CubeMap sampler2DNormal (OpenGL) Sampling normal map (GL in the lower left corner) sampler2DNormal(Directx) Sampling normal map (DX in the upper left corner) 5.5 Color Class Attribute explanation Property type GammaToLinear Convert gamma space to linear space LinearToGamma Convert linear space to gamma space 6. Common Params types Add a Params variable. Select \"+\" in the Params window and select the corresponding Parmas variable type. Figure 6-1 6.1 Float Define a float value and try a float type object in the inspection panel first. Figure 6-2 6.2 Texture2D Define the value of a 2D texture and display a 2D texture type object in the inspection panel Figure 6-3 6.3 Vector2/3/4 Define a vector type, which is divided into Vector2, Vector3, and Vector4 according to the number of components. Figure 6-4 6.4 Color Define a color value, usually there are four components of RGBA data Figure 6-5 6.5 Define Macro definition is used to execute different result content for different trigger results of macro conditions, and is more efficient than if-else Figure 6-6 7. Custom function 7.1 Create blueprint function Right-click the Create menu in the Project window and select Shader BluePrint Function to create a blueprint function. Figure 7-1 7.2 Add parameters In the blueprint editing window, right-click on the blank space, select the ShaderFunction option, and select the Input In tab. Figure 7-2 7.3 Automatic return value In the final Default Output Result node, the input data type determines the output type of the Shader function. The function blueprint will automatically determine the output type, as shown in the figure below Figure 7-3 7.4 Calling functions within functions In the blueprint function interface, right-click where you want to place the blueprint function node, and select the function defined when creating the blueprint function (blueprint function file name) in the CustomFun-BlueMap item. Figure 7-4 8. Advanced examples simple grass Figure 8-1 8.1 Vertex Shader Fragment Use Perlin noise to simulate a Vec4 vector Figure 8-2 Perform some special transformations on noise values Reduce the generated noise value by 0.016, multiply it by the g channel and a channel of the external Color, sum the multiplied results, add the obtained sum to an interference value, and finally multiply it with the world matrix Figure 8-3 Take the xz component from the result of multiplying the world matrix and add it to the xz component of positionOS to get the new xz component of positionOS. Figure 8-4 8.2 Fragment Shader Fragments Determine whether the SNOW macro is enabled. When the macro is enabled, calculate 1- the result of the square of the vertex color g value in (0,1). When the macro is turned off, the value is 0. Figure 8-5 Multiply the UV coordinate offset with a 2x2 matrix composed of a trigonometric function and then offset it back to the original position. Figure 8-6 Sample the grass texture map, extract the A channel and convert it into a gamma value as the Alpha value of the grass and pass it into the PBR function. The Albedo value is the incoming color value * texture sampling value + macro judgment value. Figure 8-7 The results of the blueprint are shown below Figure 8-7 Expansion: Quick operations Node type Generation method Quickly generate float nodes Press and hold the numeric key 1 and left-click where you want to place it Quickly generate Vector2 nodes Press and hold the numeric key 2 and left-click where you want to place it Quickly generate Vector3 nodes Press and hold the numeric key 3 and left-click where you want to place it Quickly generate Vector4 nodes Press and hold the numeric key 4 and left-click where you want to place it Quickly generate If nodes Press and hold the letter key i, and left-click where you want to place it Quickly generate bool nodes Press and hold the letter key b and left-click where you want to place it Quickly generate sampler2D nodes Long press the t key and left-click the location you want to place Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 19:03:07 "},"IDE/Component/readme.html":{"url":"IDE/Component/readme.html","title":"Component","keywords":"","body":"Built-in componentsMeshTrailPixel LineReflection ProbeVolume Global IlluminationStatic BatchLOD GroupBuilt-in components The engine has a large number of commonly used components built in, making it easy for developers to use. Since some components are closely related to other functions, they are reflected in other chapters, such as physical components, animation components, etc. Components of this chapter include: Mesh Trail Pixel Line Reflection Probe Volume Global Illumination Static Batch LOD Group Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:30:48 "},"IDE/Component/Mesh/readme.html":{"url":"IDE/Component/Mesh/readme.html","title":"Mesh","keywords":"","body":"Mesh of component system1.Mesh1.1 Mesh Overview2.Mesh component--MeshRenderer2.1 Mesh Renderer Inspector2.2 Material of MeshRenderer3.Mesh component--MeshFilter3.1 MeshFilter Inspector Quote4. Create a simple Mesh through PrimitiveMeshMesh of component system 1.Mesh 1.1 Mesh Overview Mesh refers to the mesh data of the model. The 3D model is made up of polygons, and a complex polygon is actually made up of multiple triangles. So the surface of a 3D model is composed of multiple triangular faces connected to each other. In three-dimensional space, the collection of data that constitute the vertices of these triangles and the index data of the triangles is a Mesh. Figure 1.1 1.2 Mesh data A mesh data contains a lot of data information. Common vertices, normals and other data in Shader are obtained from Mesh data. A standard grid data consists of the following attributes: Vertex: a collection of positions in three-dimensional space Topology: the basic fragment type of Mesh Index: Index data, a collection of integers describing vertex combination fragments Vertex: vertex data Each vertex can have the following attribute contents: position vertex The vertex position indicates the specific position of the vertex in the model space. This value is used in the engine to determine the surface of the Mesh. All meshes require this vertex attribute and is a must. normal normal Vertex normals represent the direction pointing directly \"out\" from the surface at the vertex location. tangent A vertex tangent represents the direction along which the \"u\" (horizontal texture) axis of the surface at the vertex location points. color color Vertex color represents the base color of the vertex (if any). uv coordinates A mesh can contain up to eight sets of texture coordinates. Texture coordinates are often called UVs, and these collections are called channels. Bones (optional) In a skinned mesh, the blend index represents which bones affect the vertices, and the bone weight describes how much those bones affect the vertices. Topology: fragment topology The topology of the mesh defines the structure of the index buffer, which in turn describes how vertex positions are combined into faces. Each topology type uses a different number of elements in the index array to define a single face LayaAir supports the following mesh topologies: Triangle Quad Lines Points Index Data: Index data The index array contains integers that reference elements in the vertex position array. These integers are called indices For example, for a grid containing an indexed array of the following values: 0,1,2,3,4,5 If the mesh has a triangle topology, then the first three elements (0,1,2) identify one triangle and the last three elements (3,4,5) identify another triangle. There is no limit to the number of faces a vertex can contribute. This means that the same vertex can appear multiple times in the index array. 2.Mesh component--MeshRenderer The Mesh Renderer component is used to render meshes. This component is used in conjunction with the Mesh Filter component on the same game object; the Mesh Renderer component renders the mesh referenced by the Mesh Filter component. In the engine code, the MeshRenderer class inherits from the BaseRender component class. 2.1 Mesh Renderer Inspector Figure 2-1 A: Specify whether the Render displays cast shadows B: Specify whether and how the renderer casts shadows when a suitable light shines on the Render. C: LightMap zoom size D: LightMap index number E: Render material list 2.2 Material of MeshRenderer The difference between Material and Share Material‘ Material When we reference and modify this property, LayaAir will return the first instantiated material under the Render and assign it to the current MeshRederer component. So, what is the first instantiated material? Each MeshRenderer component has a Materials property. This array determines how many material components can be placed under the object. The default is 1. When there are many materials on the same object, we can manually change the upper and lower position relationship of the material components. The first instantiated material here refers to the first material component from top to bottom on the object, not MeshRenderer.materials[0], which means that every time we reference it, a new material will be generated. into memory. However, the original property settings of the shader in our project will not be changed after the reference. Share Material When we change Renderer.sharedMaterial, all objects using this material ball will be changed, and the changed settings will be saved in the project Assume that cube01 and cube02 share a material redMat. When we want to modify the properties of the material on cube01 through sharedMaterial, the corresponding properties on cube02 will also be modified. Summary When using MeshRenderer.material, each call will generate a new material into memory. When using Renderer.sharedMaterial, a new material will not be generated, but the original material will be modified directly, and the modified settings will be saved to the project. It is generally not recommended to use this to modify. When a certain material ball is only used by one game object, you can use this to modify it. It is also best to save the original attribute settings before modifying, and restore the original settings immediately after use to prevent the next time. The previous setting information will remain on the loaded gameobject. If it is a game object like the protagonist that needs to modify many material properties or shader properties, you can use material for the first time, which can dynamically generate a material instance, and then use shared material to dynamically modify the newly generated material. , and no new material will be created 3.Mesh component--MeshFilter The Mesh Filter component contains a reference to the mesh. This component works with a Mesh Renderer component on the same GameObject; the Mesh Renderer component renders the mesh referenced by the Mesh Filter component. 3.1 MeshFilter Inspector Quote Figure 3-1 Mesh Properties Reference to a mesh resource To change the mesh resource referenced by the MeshFilter component, select the arrow identifier next to the mesh name to invoke the picklist to select the desired Mesh mesh. Note: When you change the mesh referenced by a Mesh Filter component, the settings of other components on this game object do not change. For example, the MeshRenderer component does not update its settings, which may cause the engine to render the mesh with unexpected properties. If this happens, adjust the settings of other components as needed 4. Create a simple Mesh through PrimitiveMesh In the course to quickly start the 3D journey, we have used the createBox method of PrimitiveMesh to create a box model. In this lesson, we introduce this class to create other basic models and use transform to adjust it. Location. More detailed usage can be found in View API. What should be noted when creating is that the engine loaded into the scene comes with a model, and the pivot point is at the center of the model, so we use the center point of the model as a reference to move, rotate, and scale. When loaded into a scene, the model will be placed at the world coordinate origin of the scene by default. //Create an empty node to place each model sprite3D = scene.addChild(new Laya.Sprite3D()); //cube var box = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createBox(0.5, 0.5, 0.5))); box.transform.position = new Laya.Vector3(2.0, 0.25, 0.6); box.transform.rotate(new Laya.Vector3(0, 45, 0), false, false); //sphere var sphere = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createSphere(0.25, 20, 20))); sphere.transform.position = new Laya.Vector3(1.0, 0.25, 0.6); //Cylinder var cylinder = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCylinder(0.25, 1, 20))); cylinder.transform.position = new Laya.Vector3(0, 0.5, 0.6); //capsule body var capsule = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCapsule(0.25, 1, 10, 20))); capsule.transform.position = new Laya.Vector3(-1.0, 0.5, 0.6); //Cone var cone = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createCone(0.25, 0.75))); cone.transform.position = new Laya.Vector3(-2.0, 0.375, 0.6); //flat var plane = sprite3D.addChild(new Laya.MeshSprite3D(Laya.PrimitiveMesh.createPlane(6, 6, 10, 10))); The effect is as shown in Figure 2-2: Figure 2-2 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:24:12 "},"IDE/Component/Trail/readme.html":{"url":"IDE/Component/Trail/readme.html","title":"Trail","keywords":"","body":"Trailing1. Overview2. Creation and use in IDE2.1 Create a trailing object2.2 Property settings2.3 Trailing material2.4 Trailing filterTrailing 1. Overview The Trail Renderer is used to create a trailing effect behind objects in the scene to represent them moving around. The afterimage that appears at the position of the moving path of the object is a trailing effect. (Animation 1-1) As shown in the animation 1-1, this is a cube that rotates on its own, with a trailing effect around it. Let's take a look at how to create and use trailing in the IDE 2. Creation and use in IDE 2.1 Create a trailing object In the Hierarchy window of a 3D scene, you can create a trailing object under any node or in a blank position by right-clicking the mouse, as shown in animation 2-1. (Animation 2-1) You can’t see any effect on the trailing object created at this time. In fact, it creates an empty node and adds the Trail Renderer component. Let’s learn about the component information. 2.2 Property settings As shown in Figure 2-2, the trailing renderer has the following properties (Figure 2-2) Since the Trail Renderer component inherits from the Base Renderer component, the trailing renderer itself has some basic properties, as shown in Figure 2-3 (Figure 2-3) Basic properties such as Receive Shadow Receive Shadow, shadow generation settings Case Shadow and the scaling and offset of the light map will not be introduced here. 2.3 Trailing material The material used for trailing requires the Shader Laya.Trail 2.3.1 Create Material First, we create a new Material under Asset. By default, the Shader of Material is BlinnPhone. Next, we modify the Shader, as shown in the animation 2-4. (Animation 2-4) 2.3.2 Material map As shown in Figure 2-5, the material with Laya.Trail Shader has the following attributes: (Figure 2-5) Here we mainly focus on the texture map of the trailing effect, such as the effect in the example of animation 1-1. If you need to create a trailing effect, you need a texture map of the trailing effect, as shown in Figure 2-6. (Figure 2-6) We next drag the texture map into the material, as shown in Figure 2-7, so that the trailing map is configured (Animation 2-7) 2.3.3 Texture color We want the trailing effect to be a gray smoke-like effect, then we need to set the color of the material, as shown in Figure 2-8, select the gray color and change the transparency to 55 (Figure 2-8) In this way, the color is configured. At the same time, we need to change the Material Render Mode to Additive mode to make the black color in the texture pure transparent, and change Cull to Off, as shown in Figure 2-9 shown (Figure 2-9) After this modification, the effect will be as shown in the animation 2-10. (Animation 2-10) 2.4 Trailing filter The trailing material can specify the trailing texture effect, transparency method, etc., but the trailing filter can only set the trailing time, trajectory, length, etc., just like the 3D particle system, as shown in Figure 2-11 (Figure 2-11) 2.4.1 Fade out time Time: fade-out time, the longer the time, the longer the trailing fade-out time The default is 5 seconds, and it will disappear after 5 seconds, as shown in the animation 2-12. (Animation 2-12) But we can adjust the time to 1 second, as shown in animation 2-13 (Animation 2-13) 2.4.2 Track alignment Alignment: Set the direction the trajectory is facing VIEW: The trajectory faces the camera TransformZ: The trajectory is oriented towards the Z axis of its transform component 2.4.3 Minimum distance Min Vertex Distance: Gets the minimum distance between old and new vertices, which is actually the minimum trailing segment distance, equivalent to the length of the trailing You can determine the distance (in world units) that the game object to which the trajectory is applied must travel before a new segment is added to the path. A smaller value like 0.1 will create track segments more frequently, resulting in a smoother track. Larger values ​​like 1.5 create track segments that are more jagged in appearance. Additionally, wider trajectories can suffer from visual artifacts when vertices are very close together and trajectories change direction significantly over short distances. NOTE: For performance reasons it is best to use the largest possible value to achieve the effect you are trying to create 2.4.4 Width setting Width : Width value and curve value to control the width of the track along its length. The curve is sampled at each vertex, so its accuracy is limited by the number of vertices in the trajectory. The total width of the track is controlled by the width value. As shown in the animation 2-9, we can add curve nodes by double-clicking the red line with the mouse, adjust the curve angle through the white rotation axis, and delete the red nodes by double-clicking the mouse. (Animation 2-14) 2.4.5 Color settings Color: set in colorGradient mode, with two optional modes Fixed fixed mode Blend blending mode As shown in Figure 2-15, the color settings are from translucent to white, and finally to translucent. (Figure 2-15) 2.4.6 Texture mode texture Mode: Texture mode, the same as normal texture mode Stretch: Texture maps can be applied along the entire length of the track Tile: Tile the texture along the length of the track Usually we use Stretch mainly to apply the effect of a map change. As shown in the animation 2-16, the effect of using Tile tiling is (Animation 2-16) Finally, we chose Stretch as the trailing effect, as shown in animation 2-17 (Animation 2-17) At this point, the trailing renderer has been introduced. Combined with the use of the animation editor, the object can move in the scene, so that the trailing effect can be seen. Developers can make good use of the trailing renderer to create Effects like smoke, afterimages, etc.! Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:29:34 "},"IDE/Component/PixelLine/readme.html":{"url":"IDE/Component/PixelLine/readme.html","title":"Pixel Line","keywords":"","body":"Pixel lines1. Overview2. Creation and use in IDE2.1 Create pixel line 3D sprite2.2 Property settings2.3 Pixel line material2.4 Pixel line data3. Creation and use in code3.1 Construction method3.2 AddLine()3.3 Tool.linearModel()3.4 Code usagePixel lines 1. Overview Pixel Line (Pixel Line) can also be called pixel line 3D sprite. It is a way to draw 3D sprite by rendering a set of colored lines, as shown in Figure 1-1 (Picture 1-1) As shown in Figure 1-1, these are the six grid modes of 3D basic display objects provided by IDE. It is a drawing method that uses lines to display the grid. 2. Creation and use in IDE 2.1 Create pixel line 3D sprite In the Hierarchy window of a 3D scene, under any node or in a blank position, you can create a pixel line 3D sprite by right-clicking the mouse, as shown in animation 2-1. (Animation 2-1) The pixel line 3D sprite created at this time does not have any effect. In fact, an empty 3D sprite node is created and the Pixel Line Renderer component is added. Let’s learn about pixel line rendering. Device component information 2.2 Property settings As shown in Figure 2-2, the pixel line renderer has the following properties (Figure 2-2) Since the Pixel Line Renderer component inherits from the Base Renderer component, the pixel line renderer itself has some basic properties, as shown in Figure 2-3 (Figure 2-3) Basic properties such as Receive Shadow Receive Shadow, shadow generation settings Case Shadow and the scaling and offset of the light map will not be introduced here. 2.3 Pixel line material First, we create a new Material under Asset. By default, the Shader of Material is BlinnPhone. Next, we drag this Material into the material properties of the pixel line renderer, as shown in animation 2-4. (Animation 2-4) The second step is to modify the shader of BlinnPhone to Laya.Unlit shader and check Vertex Color (Animation 2-5) With the material in place, all that remains is to add pixel line data. 2.4 Pixel line data There are two points in pixel line data, the maximum number of pixel lines and pixel line data, as shown in Figure 2-6 (Figure 2-6) Max Line Count: Maximum number of lines Pixel Lines Datas: Pixel line data Note: The number of pixel line data cannot exceed the maximum number of lines. By default, a pixel line data has been added. The white line from the (0, 0, 0) point to the (0, 0, 0) point is just a point, and we cannot see the effect. We can modify the End Position and color, as shown in Figure 2-7 (Figure 2-7) After modification, we can see a most basic pixel line, as shown in Figure 2-8 (Figure 2-8) At this point, the pixel line renderer has been introduced. Usually it is impossible for us to add each pixel line to draw a grid through the IDE. Often we will do it through code. Here we introduce how to use the code. 3. Creation and use in code PixelLineSprite3D is a pixel line 3D sprite class provided by the LayaAir engine. Let’s take a look at the most important methods of this class. 3.1 Construction method As you can see from the code below, when initializing a PixelLineSprite3D constructor, the code has helped us add the PixelLineRenderer component and set the UnlitMaterial material and check the use of VertexColor, as shown in section 2.3 above. The process of manually adding materials is automatically done in the code. /** * Create an instance of PixelLineSprite3D. * @param maxCount The maximum number of line segments. * @param name name. */ constructor(maxCount: number = 2, name: string = null) { super(name); this._render = this.addComponent(PixelLineRenderer); this._geometryFilter = (this._render as PixelLineRenderer)._pixelLineFilter; (this._render as PixelLineRenderer).maxLineCount = maxCount; let material = this._render.material = new UnlitMaterial(); material.enableVertexColor = true; } 3.2 AddLine() PixelLineSprite3D has directly called addLine() of the PixelLineRenderer component. It seems that you can directly set the point position and color. /* * Add a line. * @param startPosition initial point position * @param endPosition end point position * @param startColor Initial point color * @param endColor End point color */ addLine(startPosition: Vector3, endPosition: Vector3, startColor: Color, endColor: Color): void { (this._render as PixelLineRenderer).addLine(startPosition, endPosition, startColor, endColor); } 3.3 Tool.linearModel() Usually we can use the addLine() method to convert complex grid data into pixel line data. We can write a Tool tool class to facilitate conversion: //Tool tool class export class Tool { private static transVertex0: Vector3 = new Vector3(); private static transVertex1: Vector3 = new Vector3(); private static transVertex2: Vector3 = new Vector3(); private static corners: Vector3[] = []; //Linear model conversion method static linearModel(sprite3D: Sprite3D, lineSprite3D: PixelLineSprite3D, color: Color): void { if (sprite3D instanceof MeshSprite3D) { var meshSprite3D: MeshSprite3D = sprite3D; //Get the grid data of the Sprite3D object var mesh: Mesh = meshSprite3D.meshFilter.sharedMesh; var positions: Array = []; //Copy and fill position data into array mesh.getPositions(positions); //Copy and get a copy of the grid index var indices = mesh.getSubMesh(0).getIndices(); for (var i: number = 0; i 3.4 Code usage By using the tool class Tool.linearModel with the following code, the grid data of a PixelLineSprite3D object can be set to pixel line data: //Create a sphere var sphere: MeshSprite3D = (this.sprite3D.addChild(new MeshSprite3D(PrimitiveMesh.createSphere(0.25, 20, 20)))); sphere.transform.position = new Vector3(0.0, 0.75, 2); //Create a pixel line 3D sprite var sphereLineSprite3D: PixelLineSprite3D = (this.lineSprite3D.addChild(new PixelLineSprite3D(3500))); //Convert the mesh data of the sphere to pixel line data Tool.linearModel(sphere, sphereLineSprite3D, Color.GREEN); At this point, the pixel line code part has been introduced. Often we can also convert an external model into pixel line data for use, which can enrich the display effect in actual projects. As shown in animation 3-1, the pixel line effect of the external model is displayed. (Animation 3-1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:26:00 "},"IDE/Component/ReflectionProbe/readme.html":{"url":"IDE/Component/ReflectionProbe/readme.html","title":"Reflection Probe","keywords":"","body":"Reflection Probe: reflection probe1. Reflection probe overview1.1 Baking probe2. Properties of reflection probe2.1 Ambient Mode2.2 Importance2.3 Intensity2.4 Box Projection2.5 Bounds2.6 Ambient light intensity and reflection intensity2.7 Sampling size and sampling quality2.8 Clear information2.9 IBL optionsReflection Probe: reflection probe 1. Reflection probe overview The traditional form of reflection is to simulate the reflection from the object in the form of reflection map. For static open scenes, the effect obtained by the traditional reflection map is acceptable, but when the object is in a complex environment, the effect of the reflection map is LayaAir uses reflection probes to sample the surrounding environment of all scenes of the object. Reflection probes can be used to ensure that the reflection effect of the object is realistic enough in complex environments. When there are multiple probes, the engine will automatically interpolate the reflection results sampled by each probe to obtain a smooth reflection transition effect. The reflection probe uses the texture form of CubeMap to collect and save it in CubeMap from six directions. The reflection results in six directions are shown in the figure below. Picture 1-1 1.1 Baking probe The probe type in the LayaAir engine is Bake. The reflection captured by the baking probe can only contain objects marked as Static. The specific operation is to select the object that needs to be baked for reflection, select the object, and check the object Static in the upper right corner of the Inspector panel. options. Figure 1-2 After setting the object that needs to bake reflection information to Static, add the Reflection Probe component to the Sprite3D object. Figure 1-3 Select the appropriate sampling level and sampling size in the Reflection Probe component, and click the Bake button to start baking the reflection probe. Figure 1-4 2. Properties of reflection probe 2.1 Ambient Mode There are two ambient light modes, one is spherical harmonic mode and the other is solid color mode. Figure 2-1 Spherical Harmonic Mode The ambient light information provided by the sky box is calculated through spherical harmonics, and the values ​​collected by the reflection probe are calculated by spherical harmonics. Solid color mode The reflection probe collects reflection information at non-specified locations and is filled with a solid color. 2.2 Importance Judgment of importance. The current engine only supports single probe mode. If the newly created probe's Important value is greater than the main probe's Important value, the current probe will be used as the main probe. 2.3 Intensity The intensity size adjustment applied to the texture that this reflection probe applies to its shader 2.4 Box Projection Normally, a reflection cubemap is assumed to be at an infinite distance from any given object. As the object is rotated, different angles of the cubemap become visible, but the object cannot move further toward or away from the reflective environment. This state usually performs well for outdoor scenes, but its limitations show up in indoor scenes; the internal walls of the room are obviously not infinitely far away, and the closer the object is to the wall, the greater the reflection from the wall should be. Figure 2-2 2.5 Bounds The scope of the reflection probe is in the form of a bounding box. The reflection probe only receives reflection information from objects located within the bounding box. Bounds Min: the minimum coordinate of the bounding box Bounds Max: the maximum coordinate of the bounding box Bounding box Size = Max — Min Figure 2-3 2.6 Ambient light intensity and reflection intensity Ambient light intensity: The attribute is the received ambient light intensity. The effect applied to the mapped reflective object is that the ambient light in the reflection effect is stronger and brighter. Reflection intensity: The attribute is the intensity of the received reflection content. The effect applied to the mapped reflection object is that the reflection effect is stronger and brighter. 2.7 Sampling size and sampling quality Baked reflection probe sampling size: determines the size (resolution) of the single RT of the baked CubeMap Baked reflection probe sampling quality: determines the writing quality of a single RT of the baked CubeMap (three levels: high, middle and low) Figure 2-4 2.8 Clear information Clear information: In addition to the reflection content part, the baked probe content is optional when filling the content. Clear color: When the fill content is selected as SolidColor, select the fill color in the ClearColor option Figure 2-5 2.9 IBL options IBL Tex: Baked Reflection Probe IBL Texture IBL Tex RGBD: baked texture format (color channel + depth channel) Figure 2-6 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:26:40 "},"IDE/Component/VolumetricGI/readme.html":{"url":"IDE/Component/VolumetricGI/readme.html","title":"Volumetric GI","keywords":"","body":"Volumetric GI1. Volumetric GI Overview2.Volumetric GI component2.1 Create a Volumetric GI component2.2 Volume Bound2.3 Volumetric GI specific parametersVolumetric GI 1. Volumetric GI Overview Volumetric Global Illumination (Volumetric GI) refers to a technique used in computer graphics to simulate the interaction of light with participating media such as fog, smoke, or volumetric clouds. It is designed to capture the scattering and indirect lighting effects caused by media in a realistic way. Volumetric GI can enhance the visual quality and realism of a scene by taking into account the spread of light in participating media. It takes into account the scattering properties of the medium and calculates how light bounces and interacts with surrounding objects and surfaces. This technique is particularly useful for creating atmospheric effects, dynamic lighting scenes, and photorealistic renderings of translucent or volumetric materials. There are various algorithms and methods used to implement volumetric GI, including: Voxel-based methods: These techniques discretize three-dimensional space into a grid of voxels and simulate the propagation of light within the voxels. The voxel-based representation captures the density and scattering properties of the medium, allowing for realistic results. Light Marching: This technique involves projecting light through participating media and accumulating light contributions along the path of the light. Indirect illumination can be calculated by repeatedly sampling the medium and evaluating its scattering properties. Screen space methods: These methods utilize screen space information, such as depth and normal buffers, to approximate volumetric GI effects. They often employ various filtering and blending techniques to simulate diffuse and indirect lighting within the participating media. Precomputed volumetric technology: In some cases, precomputed light transmission data can be used to accelerate the rendering of volumetric GI. This involves precomputing light interactions in participating media and storing them in data structures for efficient lookup during rendering. Volumetric GI is a computationally intensive process that can require significant resources, especially for real-time applications. Therefore, it is often used selectively or combined with other lighting techniques to achieve the desired visual effect. Overall, volumetric GI plays a vital role in creating realistic and immersive environments by accurately simulating the interaction of light with participating media. It adds depth, atmosphere and natural lighting effects to virtual scenes, enhancing the overall visual quality and realism. 2.Volumetric GI component 2.1 Create a Volumetric GI component Volumetric GI components can be added to Sprite3D objects in the scene, and the engine's Volumetric GI components can provide real-time GI effects within the scope of the Volume. In the property settings panel, the way to create a Volumetric GI component is as shown in Figure 2-1: Add component -> Rendering -> Volumetric GI. (Figure 2-1) (Figure 2-2) 2.2 Volume Bound Only objects within the Volume Bound range will be affected by Volumetric GI. A certain number of probes are evenly distributed in the Volume Bound to collect surrounding spherical harmonic information. (Figure 2-3) 2.3 Volumetric GI specific parameters Bound Min: Controls the Bound surface in the negative direction of the X, Y, and Z axes. Bound Max: Controls the Bound surface in the positive direction of the X, Y, and Z axes. Importance Weight: Control the weight ratio between different Volumetrics. Probe Counts: The number of Porbe arrangements in Bound. Figure 2-4 shows the Probe arrangement of different orders of magnitude: (Figure 2-4) Normal Bias: The inward offset of the surface along the normal line to reduce errors caused by encountering the same pixel sampling. View Bias: The offset of the surface along the direction of the field of view to reduce errors caused by encountering the same pixel sampling. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:30:04 "},"IDE/Component/StaticBatchVolume/readme.html":{"url":"IDE/Component/StaticBatchVolume/readme.html","title":"StaticBatchVolume","keywords":"","body":"Static Batch Volume componentStatic Batch Volume component In the Object's inspect panel, add a component, select the Rendering option, and find the Static Batch Volume component. figure 1 Drag the small white dot in the Scene window to select the appropriate Volume size. figure 2 Use of Static Batch Volume component: After selecting the appropriate size for the Volume box above in the Scene, in the component's details panel, check Static Instance Batch, and then click reBatch. The selected objects in the Volume will perform Batch operations, optimize Draw Call, and improve operation. For efficiency, check the CheckLOD option and enable LOD Cull Rate Array to take over the object LOD group in the Volume. At this time, the LOD judgment of all objects in the Volume is no longer based on a single rendering object, but based on the LOD judgment of the Volume. The system will calculate Volume and Rate calculated in the field of view to select different LOD levels. Rebatch will be automatically called in Game, and all objects in the Volume will automatically determine and perform Static Batch Instance operations. image 3 Figure 4 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:28:22 "},"IDE/Component/LOD/readme.html":{"url":"IDE/Component/LOD/readme.html","title":"LOD Group","keywords":"","body":"LOD1. LOD Overview2.LOD component2.1 Create LOD components2.2 LOD level slider2.3 Renders3. Import LOD mesh (experimental)4.LOD Cull Rate ArrayLOD 1. LOD Overview Level of Detail (LOD) is a technique that reduces the number of GPU operations required by the LayaAir engine to render distant meshes. When a game object in the scene is far away from the camera, less detail will be visible compared to a game object that is very close to the camera. But by default, the engine will use the same number of triangles to render two game objects at different distances. This can waste GPU computing resources, affecting performance in the scene. LOD technology allows the engine to reduce the number of triangles rendered for a game object based on its distance from the camera. To use this technique, the game object must have a large number of meshes whose geometry has progressively lower levels of detail. These meshes are called LOD levels. The further a game object is from the camera, the lower the LOD level of detail rendered by the engine. This technique reduces the burden placed on the hardware by these distant game objects, thus improving rendering performance. 2.LOD component 2.1 Create LOD components You can add LOD groups to objects in the scene by creating a LOD component. Multiple LOD groups can be added to the engine's LOD to achieve different rendering results at different distances. Steps to create LODGroup component: Add component -> Select Rendering component type -> Select LOD Group component Figure 2-1 Figure 2-2 2.2 LOD level slider Adjust the switching range of different LODs by adjusting the proportions of different LOD levels on the LOD level slider. Figure 2-3 The LOD level slider is divided into an interval ranging from left to right [100%, 0%]. The displayed percentage of each level is the left interval value of the current block. The black line indicates the LOD level of the current camera. The black indicator line is refreshed in real time and will change to different LOD intervals as the camera moves. Expand Mincull Rate Figure 2-4 The Mincull Rate for each LOD level represents the threshold for activating that level. The threshold is based on the ratio of the game object's screen space height to the total screen height. For example, if LOD0's threshold is set to 0.4, LOD0 will activate when the camera pulls back far enough so that the game object's height takes up 40% of the view. In the picture above, the ratio of Mincull Rate is represented in the image as the ratio of the length of the green line to the length of the yellow line. It is usually a floating point decimal from 0.0 to 1.0. 2.3 Renders Figure 2-5 Renders are actually Sprite3D objects that hold meshes at that LOD level. Typically this is a child of the Sprite3D object that has the LOD component The Renders renderer can add multiple rendering objects and render multiple objects at the same LOD level. 3. Import LOD mesh (experimental) Create a grid resource with LOD levels in the art software. After importing it into the engine IDE, select the grid model file and check the Add Lod Group function in the import settings. Figure 3-1 4.LOD Cull Rate Array In fact, LOD Cull Rate Array is one of the functions of Static Batch Volume. LOD Cull Rate Array is actually a rendering of N levels of Rate calculated for the objects in this Volume. For example, the actual Rate of the current field of view and Volume is 0.2, and the level of LOD2 in the LOD Cull Rate Array is 0.1, so the object in the current field of view is the rendered LOD2 object. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:23:14 "},"IDE/prefab/readme.html":{"url":"IDE/prefab/readme.html","title":"prefab","keywords":"","body":"Prefab module1. Overview2. Create in IDE2.1 Create prefab (2D)2.2 Create prefab (3D)2.3 Modify the prefab editing scene3. Use prefabs3.1 2D Prefab3.2 3D Prefab4. Preload prefabsPrefab module 1. Overview In project development, situations like this often occur: (1) When the project was established, the art defined a series of standard font colors and font sizes, which were applied in each UI. One day, the art suddenly said that it wanted to change the default font color and font size, and the UI producer needed to modify all interfaces. This would be very troublesome. For this situation, you can easily deal with it by using prefabs. Only modifying one place can affect the whole situation. (2) Different 2D interfaces have partially the same layout. I hope that if I modify it once, the same layout of multiple interfaces will change together. This situation can be easily solved by using prefabs. (3) In 3D project development, once certain objects that are reused in the same scene or in different scenes, such as models, textures, animations and other settings have been made, heroes, monsters, special effects, etc. can be created directly in the scene. We hope that when using it, we only need to load it with code. For this situation, it can only be achieved by using prefabs. For needs similar to the above, LayaAirIDE provides 2D prefabs and 3D prefabs. This article will introduce how to use these two prefabs. 2. Create in IDE The process of creating prefabs can only be completed in the IDE. Usually, prefabs are created as files with the suffix \".lh\". This section introduces how to create prefabs (2D) and prefabs (3D) in the IDE 2.1 Create prefab (2D) Prefabs (2D) are prefabs used in the development process of 2D interfaces, usually for repetitively used 2D components, partial interfaces, etc. As shown in the animation 2-1, under the assets of the project resources in the IDE, developers can select the directory where they want the prefab to be stored. In this directory, create a prefab (2D) in the menu of the right mouse button. (Animation 2-1) Developers usually need to rename the created prefab so that the function of the prefab can be identified by name, as shown in animation 2-2. (Animation 2-2) Click on the Title prefab and you can see that there is a root node \"Box\", as shown in Figure 2-3 (Figure 2-3) Developers can create 2D components under Box, or convert Box nodes into other 2D components for use. We will introduce them in detail later. 2.2 Create prefab (3D) The process of creating a 3D prefab is the same as that of a 2D prefab, as shown in animation 2-4. (Animation 2-4) The difference is that when you double-click to open the prefab 3D, the root node is \"Sprite3D\", which is the 3D sprite object we need to create. At the same time, the right side of Figure 2-5 is the default IDE scene, using the sky box that comes with the IDE. (Figure 2-5) 2.3 Modify the prefab editing scene Developers can change the editing scene of the 3D prefab in the following ways, as shown in animation 2-6 (Animation 2-6) For example, we have a 3D city scene. In the project settings of the IDE, click the Edit option, and in the prefab editing scene, drag in the 3D city scene file. At this time, view the scene window of the prefab again and you can see the scene change. It’s time for a 3D city. In this case, it is more convenient for developers to create 3D prefabs in the scene more flexibly. 3. Use prefabs 3.1 2D Prefab As mentioned in the first section, during the development process, many interfaces will use fonts similar to titles. It is best for developers to implement this through prefabs. When there is a need to change the fonts of all interface titles, they only need to modify One prefab is enough. 3.1.1 Convert node type Since the created prefab defaults to the Box root node, if you create a title under the Box, then this Box node is redundant. If a large number of titles are created in the interface, a lot of Boxes will be created, which is a strong consideration for performance. It is not recommended, so we hope to use the conversion node to change the Box to a Label component. As shown in animation 3-1 (Animation 3-1) 3.1.2 Set font Next, we won’t introduce the title production process here. As shown in Figure 3-2, we temporarily create a yellow 30-point bold font as the title and rename it Title (Figure 3-2) 3.1.3 Using prefabs in IDE After the prefab is created, it can be dragged into the IDE into the interface we want to use, as shown in animation 3-3. (Animation 3-3) There is a List in the scene, and we hope that the item will have a title. We drag the Title prefab into the Box of the List as the Label title of the List item. You can see that the color of the Label name in the node is green, which means that this node is a prefabricated node. Of course, all nodes under this node will be green. 3.1.4 Modify prefab properties When the requirement says that you want to change all titles to red, that is to say, you modify it once, and multiple interfaces change together. Then you only need to modify the color of the text in the Title prefab, as shown in animation 3-4 (Animation 3-4) After modifying the prefab, you can see the effect of the modification in the scene interface where the prefab is used. Of course, you can also run it directly on the prefab interface to see the effect. After editing, developers need to remember to save the prefab file when closing the prefab interface, otherwise the previous changes will be lost when the prefab is opened next time. You can also continue to add new UI components to the prefab. Similarly, the newly added UI components in the scene are synchronized. It is not shown here, developers can try it themselves. Note: Any script added to the UI component can also be synchronized to the scene, but the runtime class under the prefab cannot be synchronized. 3.1.5 Overriding Prefab Properties If we operate the prefab node in the scene, for example, add a new UI component, modify the properties of the UI component, and hang a script on the UI component, as shown in Figure 3-3 (Figure 3-3) For example, there is an item node under the List in the scene that is a prefabricated body. We have made several changes under the List, which will be marked in Figure 3-3. Added LabelScript script to Label component (identified by \"+\" sign) Modified the width attribute of the item node (the attribute setting panel has a yellow line prompt) Added Button component (identified by \"+\" sign) These modifications can also be overridden into prefabs, let’s see how. As shown in Figure 3-4 (Figure 3-4) Click the item node, and in the properties panel on the right, click the Override Properties button to open the Override Properties to Item operation panel. Since there were three operations before, we click item, LabelScript, Button, and you can see it, as shown in Figure 3-8 (Figure 3-8) The IDE records these three modification operations. We can undo or apply each item separately, or we can directly undo all or apply all. When you click Apply or Apply All for each operation and return to the item prefab window, the three modifications will be updated and saved to the prefab, as shown in Figure 3-9. (Figure 3-9) Through the above operation, the effect of modifying the prefab can also be achieved by overriding the properties of the prefab. Note: If a relative layout is set in the prefab, then when using the prefab object on the scene, the relative layout on the scene cannot be set to null (the IDE does not check it or forces the code to set it to null. This is also not allowed. Useless), the relative layout within the prefab will prevail. However, if the relative layout value is modified in the scene, the settings on the scene will prevail. For example, if the top of the prefab is set to 10, and when the scene uses this prefab, the top is changed to 20. When running, the scene will use 20 as the benchmark. 3.1.6 Using prefabs in code Adding a prefab through code is as simple as using a component. As shown in Figure 3-5, we want to put the Title prefab under the Box. (Animation 3-5) The sample code is as follows: const { regClass, property } = Laya; @regClass() export class ScriptA extends Laya.Script { //declare owner : Laya.Sprite3D; @property( { type: Laya.Box } ) private box: Laya.Box; constructor() { super(); } onStart(): void { //Load prefab file Laya.loader.load(\"resources/Title.lh\").then( (res)=>{ //Create prefab let label: Laya.Label = res.create(); //Add the prefabricated Label font to the box node this.box.addChild( label ); } ); } } The running effect is shown in Figure 3-6 (Figure 3-6) 3.2 3D Prefab The process of using 3D prefabs is the same as that of 2D prefabs. We will not introduce how to make prefabs here. Let’s take a look at the effect of using 3D prefabs through the following example. 3.2.1 Use in IDE Assume that we have created a 3D prefab and made LayaMonkey by adding components such as models, materials, animation state machines, etc., as shown in Figure 3-7 (Figure 3-7) At this point, the created LayaMonkey can be dragged into any scene, as shown in animation 3-8 (Animation 3-8) 3.2.2 Used in code Using 3D prefabs through code is the most common way. Often enemies in game battles are continuously created through code. Like the above situation where the IDE is dragged into LayaMonkey, we use code to implement it as follows: const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { @property( { type : Laya.Camera } ) private camera: Laya.Camera; @property( { type : Laya.Scene3D } ) private scene: Laya.Scene3D; onStart() { console.log(\"Game start\"); //Load prefab file Laya.loader.load(\"resources/Prefab.lh\").then( (res)=>{ //Create prefab let monkey: Laya.Sprite3D = res.create(); //Add prefab to the scene this.scene.addChild( monkey ); monkey.transform.position = new Laya.Vector3(-28.9354,0.3,-63.20264); } ); } } The running effect is as shown in Figure 3-9 (Animation 3-9) 4. Preload prefabs During the development process, we will implement various functions by creating a large number of prefabs. Therefore, a prefab can also be understood as a collection of resources. When loading a prefab file through code, the associated resources can be loaded together. Therefore, during the project startup loading process, you can directly load all prefabs first, just like the preloading scene, and the engine will load the associated resources together. In LayaAir's 2D entry sample code, you can see the implementation code by preloading a set of prefabs: import { LoadingRTBase } from \"./LoadingRT.generated\"; const { regClass, property } = Laya; @regClass() export default class LoadingRT extends LoadingRTBase { onAwake(): void { Laya.loader.load( //First load what is needed for this scene [\"resources/UI/image.png\", \"resources/UI/progress.png\", \"resources/UI/progress$bar.png\"] ).then(() => { let resArr: Array = [ { url: \"resources/prefab/uiDemo/useUI/ChangeTexture.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/useUI/MouseThrough.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/useUI/PhysicalCollision.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/useUI/Progress.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/useUI/TextShow.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/page/IframeElement.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/page/UsePanel.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/BagList.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/ComboBox.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/LoopList.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/MailList.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/Refresh.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/TreeBox.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/list/TreeList.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/animation/AtlasAni.lh\", type: Layer.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/animation/FrameAni.lh\", type: Type.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/animation/SkeletonAni.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/animation/TimelineAni.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/animation/TweenAni.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/interactive/Astar.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/interactive/Joystick.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/interactive/ShapeDetection.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/uiDemo/interactive/tiledMap.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/Bullet.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/closeBtn.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/ComboList.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/defaultButton.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/defaultLabel.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/DropBox.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/LoopImg.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/role.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/ani/cd.lh\", type: Laya.Loader.HIERARCHY }, { url: \"resources/prefab/ani/refresh.lh\", type: Laya.Loader.HIERARCHY }, ]; //3.0 load can load 2D and 3D resources at the same time Laya.loader.load(resArr, null, Laya.Handler.create(this, this.onLoading, null, false)).then(() => { //After loading is completed, process the logic this.progress.value = 0.98; console.log(\"Loading completed\", this.progress.value); //There are too few preloaded things. It is delayed for one second to see the effect locally. Real projects do not need to be delayed. Laya.timer.once(1000, this, () => { //Jump to the entrance scene Laya.Scene.open(\"Scenes/Index.ls\"); //Do not use Laya.Scene.open(\"./Scenes/Index.ls\"); }); }); // Listener loading failed Laya.loader.on(Laya.Event.ERROR, this, this.onError); }); } /** * Print errors when reporting errors * @param err error message */ onError(err: string): void { console.log(\"Loading failed: \" + err); } /** * Listen when loading */ onLoading(progress: number): void { //When the loading is almost completed, let the displayed progress be a little slower than the actual progress. This is reserved for automatic loading when opening the scene, especially if there are many scene resources to be opened and they are not completely put into preloading, and they need to be automatically loaded again. When loading a section. if (progress > 0.92) this.progress.value = 0.95; else this.progress.value = progress; console.log(\"Loading progress: \" + progress, this.progress.value); } } Through the above code, you can see in the debugging tool in the browser that the engine will load all prefab resources. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:56:47 "},"IDE/layapackage/readme.html":{"url":"IDE/layapackage/readme.html","title":"layapackage","keywords":"","body":"IDE plug-in systemPlug-in Development InstructionsInstructions for plug-in importOfficial plug-inIDE plug-in system Starting from LayaAir3.1.x, developers can customize plug-ins and upload them to the asset store. Plug-in Development Instructions Instructions for plug-in import Official plug-in Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:38:26 "},"IDE/layapackage/plug-in/readme.html":{"url":"IDE/layapackage/plug-in/readme.html","title":"plug-in","keywords":"","body":"Plug-in development instructions1. Plug-in capabilities2. Plug-in operating environment2.1 Using native capabilities in Laya.Script2.2 How to communicate between UI process script and Scene process script2.3 Script isolation mechanism3. Make editor UI4. Programmatic generation interface4.1 Common methods4.2 Example5. Customize Inspector field editing interface6. Customized panel7. Use dialog boxes8. Expand the built-in menu9. Create menu10. Draw shapes and interactive handles in the scene view11. Custom configuration12. Extended editor configuration interface13. Expand the build process14. Customize publishing target platform15. Resource import pre-processing and post-processing16. International support17. Command line supportPlug-in development instructions 1. Plug-in capabilities The editor is developed using the Electron framework, which is essentially an encapsulation of the Chrome browser. The editor is actually a single-page application made with HTML+JS+CSS. But we encapsulate most of the functions, so game developers and plug-in developers do not need to learn HTML/CSS or related front-end frameworks. When we develop plug-ins, we need to use the UI framework provided by the editor. Generally, we are not allowed to directly modify the DOM structure of the editor. Considering user experience and compatibility, resource stores generally do not allow such plug-ins to be put on the shelves. In the engine/types directory of the project, there are three declaration files related to editor plug-in development, editor.d.ts, editor-ui.d.ts, editor-env.d.ts. They contain a large number of editor extensions. API. editor.d.ts is the API of the editor UI process. Commonly used are the classes and interfaces under the global object Editor and IEditor namespaces. editor-env.d.ts is the API of the scene scene process. Commonly used are the classes and interfaces under the global object EditorEnv and IEditorEnv namespace. editor-ui.d.ts editor UI library. Use classes and interfaces under the IEditorUI namespace. Among them, IEditor.utils/IEditorEnv.utils exposes a large number of practical tool functions, including UUID generation, encryption and decryption, ZIP compression/decompression, file/directory copy/move, HTTP request, upload/download, etc. Developers can directly use the node module. In addition, the IDE also has built-in some commonly used npm libraries, such as sharp, glob, pinyin, @svgdotjs/svg.js, etc. //How to use nodejs module import fs from \"fs\"; import path from \"path\"; const sharp = window.require(\"sharp\"); const glob = window.require(\"glob\"); 2. Plug-in operating environment The editor is a multi-process system, with three main processes: Main process/UI process/Scene process. Plug-ins can only run in the UI process and Scene process. The UI process does not load the engine library, that is, there is no LayaAir engine environment; the Scene process has a LayaAir engine environment, and communication with the UI can only be through the asynchronous communication API provided by the editor. In addition, plug-in scripts may also run in previews (including in-editor previews and external browser previews). The difference from the Scene process is that there is no node environment in the preview process. To sum up, there are three environments in which plug-in scripts may run: (1) UI process: local modules such as node can be used directly, but the Laya engine cannot be used; (2) Scene process: You can directly use local modules such as node, and you can use the Laya engine; (3) Preview process: Local modules such as node cannot be used, but the Laya engine can be used; If a plugin script mistakenly uses a feature that does not exist in the current environment, the script may not run. For example, using node's fs module to access the file system in a Laya custom component script will cause the script to report an error when previewing or final publishing. In order for the script to run correctly in various environments, developers need to isolate these three types of code at the file level when writing scripts. For example, a TS file of a custom panel cannot reference the Laya engine because it runs in the UI process. For another example, a Laya.Script cannot use fs, path and other modules because it may run in the preview process. But these two needs are also common, what should we do? 2.1 Using native capabilities in Laya.Script Here is a recommended approach: //Script.ts @Laya.regClass() class Script extends Laya.Script { wantToUseNode() { EditorEnv.scene.runScript(\"TestSceneScript.visitNode\"); } } //TestSceneScript.ts import fs from \"fs\"; //Note that it is IEditorEnv.regClass, not Laya.regClass!! @IEditorEnv.regClass() class TestSceneScript { static visitNode() { fs.readFileSync(....) } } The TestSceneScript.ts file will be trimmed in publishing because it is not directly referenced by Laya.Script. 2.2 How to communicate between UI process script and Scene process script After setting the node/component properties, the nodes/components in the scene will automatically refresh without coding. For example: //The following is the UI process code //Get the selected node let node = Editor.scene.getSelection()[0]; //Modify node attributes, objects in the scene will be automatically synchronized, no manual work is required node.props.x = 100; //Modify the component properties, and the objects in the scene will be automatically synchronized, no need to do it manually. node.getComponent(\"MeshRenderer\").props.enabled = false; Call a method of the node/component and return a value. For example: //The following is the UI process code //Get the selected node let node = Editor.scene.getSelection()[0]; //Call the test method in the MyScript component and pass in the parameter abc let ret = await Editor.scene.runNodeScript(node.id, node.getComponent(\"MyScript\").id, \"test\", \"abc\"); console.log(ret); Customize a function and execute it. For example: //The following is the code for the scene process //Note: IEditorEnv.regClass is required @IEditorEnv.regClass() export class TestSceneScript { //Note: this is the current IEditorEnv.IGameScene object. If not needed, you can also omit this statement. static test(this: IEditorEnv.IGameScene, msg: string) { console.log(msg); //hello return \"ok\"; } } //The following is the code of the UI process let ret = await Editor.scene.runScript(\"TestSceneScript.test\", \"hello\"); console.log(ret); //ok If the scene process needs to send a message to the UI process, use the following method: //Select a resource in the project resource panel EditorEnv.postMessageToPanel(\"ProjectPanel\", \"select\", assetId); //Call a method of the custom Panel and return the result let ret = await EditorEnv.sendMessageToPanel(\"MyPanel\", \"getResult\"); 2.3 Script isolation mechanism The editor implements script isolation by compiling scripts into three js. Bundle.js contains the version that can be run in the preview environment, that is, in the browser; bundle.editor.js is a script that runs in the UI process; bundle.js. scene.js is a script in the Scene process. This mechanism is automatic, but developers need to understand how this mechanism works: All scripts containing the @Laya.regClass decorator will be compiled into bundle.js and bundle.scene.js. Note that the \"all\" referred to here is limited to the Debug version. In the release version of bundle.js, only scripts referenced by the scene will be included. bundle.scene.js will not appear in release builds. All scripts containing the @IEditorEnv.regClass decorator will be compiled into bundle.scene.js. This js only runs inside the editor, so you can use node capabilities with confidence. All scripts containing @IEditor.xxx decorators will be compiled into bundle.editor.js. This js only runs in the UI process, so you can use node capabilities with confidence, but if you reference Laya classes, an error will be reported. Although this identification mechanism can solve the problem of marking the usage of different scripts, it is still recommended that developers use directory isolation for their own purposes. For example, put the scripts run by the UI process into the directory named editor, and put the scripts that only run in the editor into the directory named scene, so that maintenance will be clearer. 3. Make editor UI LayaAirIDE provides a visual editor for developing editor UI. In the menu of the Project Resources panel, create a new Editor Interface Prefab, such as MyWidget.widget. It is recommended to place such prefabs in the editorResources directory or its subdirectories. The editorResources directory is a special directory with an agreed name in LayaAirIDE. It has similar characteristics to resources, that is, no matter how deep it is placed in the subdirectory, the resource path can start from editorResources. For example, if a resource is located at \"/MaDaHa/v1/editoResources/a/b.png\", you can directly fill in \"editorResources/a/b.png\" when referencing the resource, regardless of the previous \"MaDaHa/v1/\". This is very important in the plug-in system, because when developing plug-ins, plug-in developers cannot determine in which directory the plug-in resources will be placed when users use them. They can only be sure that users will not destroy the internal directory structure of the plug-in. The resources directory has the same characteristics, the difference is that the resources directory will be copied to the release directory when publishing, but editorResources will never be copied. Double-click to open MyWidget.widget, and use the built-in UI editor to create the UI interface required by the plug-in. Taking the panel as an example, the method of loading the prefab in the code is: @IEditor.panel(\"Test\") export class MyPanel extends IEditor.EditorPanel { async create() { this._panel = await gui.UIPackage.createWidget(\"editorResources/UI/MyWidget.widget\"); let input: gui.TextInput = this._panel.getChild(\"TextInput\").getChild(\"title\"); input.on(\"changed\", () => { console.log(\"Changed!\"); }) } } 4. Programmatic generation interface 4.1 Common methods In addition to using the UI editor to create the interface, you can also use code to create some commonly used UI components, which are in IEditor.GUIUtils. export interface IGUIUtils { /** * Editor default background color */ bgColor: gui.Color; /** * Editor's default dividing line color */ lineColor: gui.Color; /** * Editor default text color */ textColor: gui.Color; createButton(autoSize?: boolean): gui.Button; createIconButton(flat?: boolean): gui.Button; createCheckbox(autoSize?: boolean): gui.Button; createIconCheckbox(flat?: boolean): gui.Button; createRadio(): gui.Button; createComboBox(): gui.ComboBox; createTextInput(): TextInput; createTextArea(): TextArea; createSearchInput(): SearchInput; createNumericInput(): NumericInput; createColorInput(): ColorInput; createGradientInput(): GradientInput; createCurveInput(): CurveInput; createResourceInput(): ResourceInput; createNodeRefInput(): NodeRefInput; createProgressBar(): gui.ProgressBar; createSlider(): gui.Slider; createListItem(): ListItem; createIconListItem(): ListItem; createCheckboxListItem(): ListItem; createCheckboxIconListItem(): ListItem; createInspectorPanel(): InspectorPanel; } 4.2 Example For example, to dynamically create a button, you can use the following code. let button = IEditor.GUIUtils.createButton(); //The function it implements is actually the same as the following code, but more concise //let button = gui.UIPackage.createWidgetSync(\"~/ui/basics/Button/Button.widget\"); IEditor.InspectorPanel is a general interface class that generates interfaces through configuration. Here is an example of generating a panel entirely through configuration. @IEditor.panel(\"Test\") export class MyPanel extends IEditor.EditorPanel { private _data : any; declare _panel : IEditor.InspectorPanel; async create() { this._panel = IEditor.GUIUtils.createInspectorPanel(); Editor.typeRegistry.addTypes([ { name: \"MyPanelType\", //Please note that the name is globally unique and must be long properties : [ { name : \"text\", type : \"string\" }, { name : \"count\" , type: \"number\" }, { name : \"actions\", inspector: \"Buttons\", options : { buttons : [ { caption : \"Click me\", event: \"my_click\" } ] } } ] } ]); this._panel.allowUndo = true; //Set as needed //If you don't need the undo function, you can also directly this._data = {}; this._data = IEditor.DataWatcher.watch({}); //inspect can be called multiple times to combine multiple data in one panel for editing this._panel.inspect(this._data, \"MyPanelType\"); this._panel.on(\"my_click\", ()=> { alert(\"hello\"); }); } } The execution effect is as follows: If you don't need the 'My Panel Type' column at the top to be displayed, you can slightly modify the code and add the following red text: { name : \"MyPanelType\", catalogBarStyle: \"hidden\", properties : [ .... ] } The effect is as follows: The configuration method can generate very complex interfaces. It can not only be used to make a single panel, but can also be embedded into other UIs. For example, when making an interface in the UI editor, drag in the InspectorPanel prefab (it is placed in \"editor-widgets/baisc/Inspector/InspectorPanel.widget), and then the Widget object type obtained through getChild in the code is automatically IEditor.InspectorPanel , which can then be filled through the above-mentioned API (inspect, etc.). Please refer to Documentation for type and attribute definition syntax. 5. Customize Inspector field editing interface When we write a component and expose certain fields to the IDE for editing, sometimes we want to be able to customize the editing interface of a certain field. We can do the following steps: Write an InspectorField @IEditor.inspectorField(\"MyTestField\") export class TestField extends IEditor.PropertyField { @IEditor.onLoad static async onLoad() { await gui.UIPackage.resourceMgr.load(\"MyField.widget\"); } create() { let input = gui.UIPackage.createWidgetSync(\"MyField.widget\"); return { ui: input }; } refresh() { //Here is responsible for setting the data to the interface } } MyTestField is a registered name. In actual application, it is necessary to ensure that it does not conflict with the name given by others, so it is recommended to use a name like \"com.layabox.test\". The create method of InspectorField is synchronous, so createWidget cannot be used here, but createWidgetSync needs to be used. This requires ensuring that the prefab is loaded before creation. So an IEditor.onLoad callback is used here to load resources in advance. Set the inspector attribute of the field to the name you just took, here it is MyTestField @Laya.regClass() export class Script extends Laya.Script { @property({ type : Laya.Node, inspector: \"MyTestField\" }) public node: Laya.Node; } Actual effect: 6. Customized panel You can add a panel to the editor in the following ways @IEditor.panel(\"test\", { title: \"Test\", icon : \"editorResources/20230710-161955.png\" }) export class TestPanel extends IEditor.EditorPanel { async create() { this._panel = await gui.UIPackage.createWidget(\"MyPanel.widget\"); } } The effect is as follows: 7. Use dialog boxes A popup dialog can be created in the following ways: //MyDialog.ts export class MyDialog extends IEditor.Dialog { async create() { this.contentPane = await gui.UIPackage.createWidget(\"MyDialog.widget\"); } onShown() { } onHide() { } } Within the editor, all dialog boxes are singletons. The way to display this dialog box is: import { MyDialog } from \"./MyDialog\"; Editor.showDialog(MyDialog, null); 8. Expand the built-in menu Supports extensions to the editor's existing menus. As shown in the following code, a test menu is added under the Tools menu of the application menu bar, and clicking the menu will call the test function. class AnyName { @IEditor.menu(\"App/tool/test\") static test() { console.log(\"click menu\"); } } The first parameter of menu represents the path of the menu. The path is separated by \"/\". \"App/tool/test\" represents the test sub-item of the tool submenu under the App menu. Note that the path here uses ID, not the text displayed in the menu. All menu names and their submenus supported by extensions within the editor can be printed for reference by the following method: The second parameter of the menu method is an optional parameter, through which some additional configuration can be performed. For example: class AnyName { @IEditor.menu(\"App/tool/test\", { position: \"before openDevTools\" } ) static test() { console.log(\"click menu\"); } } Through the position option, you can set this newly added test menu to be displayed in front of the original menu \"Open Developer Tools - Editor\" instead of being added to the end by default. Commonly used options are: position: Set the position of the menu, supported syntax: \"first\" / \"last\" / \"before ids\" / \"after ids\" / \"beforeGroup ids\" / \"afterGroup ids\". The difference between \"before\" and \"beforeGroup\" is that \"before\" is inserted in front of the reference menu, while \"beforeGroup\" is inserted before the nearest dividing line in front of the reference menu. The difference between \"after\" and \"afterGroup\" is that \"after\" is inserted after the reference menu, while \"afterGroup\" is inserted after the nearest dividing line behind the reference menu. In the extension definition of the same class, it is added after the menu of the previous extension by default. If it is not in the same class and position is not specified, it will be added to the end of the menu by default. ID values ​​for multiple reference menus are separated by commas. checkbox: Set the menu to a checkbox effect. sepBefore : Display a dividing line before this menu. sepAfter: Display a dividing line after this menu. enableTest : Given a function that returns a Boolean value, this function is executed before the menu is displayed and is used to determine the activation (grayed out) state of the menu. App menu is not supported. visibleTest: Given a function that returns a Boolean value, this function will be executed before the menu is displayed to determine the visible or hidden state of the menu. Only the menu popped up by calling the show method is valid. App menu is not supported. checkedTest: Given a function that returns a Boolean value, this function will be executed before the menu is displayed to determine the visible or hidden state of the menu. App menu is not supported. The following example demonstrates the use of enableTest. In this newly added menu, if there is no selected object in the scene, it will be grayed out and the click callback cannot be triggered. class AnyName { static testEnable() { return Editor.secene.getSelection().length > 0; } @IEditor.menu(\"Hierarchy/test\", { enableTest: ()=> AnyName.testEnable() } ) static test() { console.log(\"click menu\"); } } 9. Create menu New menus can be created and their popups controlled with code. The method is: let menu = IEditor.Menu.create([ { label: \"test\" , click : function() { console.log(\"clicked\"); } } ]); //When you need to pop up menu.show(); The menu also supports cascading, and there is no limit to the number of levels. For example: IEditor.Menu.create([ { label: \"test\" , submenu: [ { label : \"a\" }, { label : \"b\", submenu : [ { label : \"c\" } ] } ] } ]); You can assign an ID to the menu and reference the menu through the ID. But be careful that the ID value does not conflict with the ID of the editor's built-in menu or other people's menus. IEditor.Menu.create(\"MyTestMenu\", [ { label: \"test\" , click : function() { console.log(\"clicked\"); } } ]); //When you need to pop up IEditor.Menu.getById(\"MyTestMenu\").show(); 10. Draw shapes and interactive handles in the scene view Use the interface provided by IEditorEnv.Gizmos/IEditorEnv.Handles/IEditorEnv.Gizmos2D to draw shapes and interactive handles in the scene view. Assume that we already have a custom component Script1, and bind a CustomEditor script to Script1 through the IEditorEnv.customEditor decorator to achieve custom editing in the editor. //Script1.ts @regClass() export class Script1 extends Laya.Script { declare owner : Laya.Sprite3D; } //TestCustomEditor.ts @IEditorEnv.customEditor(Script1) export class TestCustomEditor extends IEditorEnv.CustomEditor { declare owner: Laya.Sprite3D; onSceneGUI(): void { IEditorEnv.Handles.drawHemiSphere(this.owner.transform.position, 2); } onDrawGizmos(): void { IEditorEnv.Gizmos.drawIcon(this.owner.transform.position, \"editorResources/UI/ready1.png\"); } } The effect is as follows: The implementation of 2D is different, it must pass the IEditorEnv.Gizmos2D interface, and currently only supports onDrawGizmosSelected events, onDrawGizmos and onSceneGUI events are not supported. Here's an example in 2D: @IEditorEnv.customEditor(Script2) export class TestCustomEditor extends IEditorEnv.CustomEditor { private _c: IEditorEnv.IGizmoCircle; onDrawGizmosSelected(): void { if (!this._c) { let manager = IEditorEnv.Gizmos2D.getManager(this.owner); this._c = manager.createCircle(10); this._c.fill(\"#ff0\"); } this._c.setLocalPos(10, 10); } } The effect is as follows: 11. Custom configuration Plug-in developers can customize some configuration data, which can be saved to files or only saved in memory. For example: @IEditor.onLoad static onLoad() { //Please note that the attributes here do not use types in the Laya engine, such as Vector3, which are not allowed. Editor.typeRegistry.addTypes([ { name: \"MyTestSettingsType\", properties: [ { name: \"option1\", type: \"boolean\", default: true }, { name: \"option2\", type: \"string\", default: \"\", } ] } ]); Editor.extensionManager.createSettings(\"MyTestSettings\", \"project\", \"MyTestSettingsType\"); } The first parameter of createSettings is the name of this configuration. It is global. Please choose a name that will not conflict with others. The second parameter is where the configuration data is placed. The optional values ​​are: project: Save to the path \"project/settings\". This is a shared location for configuration files shared by all members of the project. The saved file name is \"plugin-configuration name.json\". The plugin prefix allows users to clearly identify that this is a configuration file created by a third-party plug-in. ocal: Save to the path \"project/local\". This is the IDE user's personalized setting for the project. The files here are generally not recommended for sharing among project members. application: Save to the user data directory of the system. This is the IDE user's personalized setting for the IDE, and it should not be related to the specific project. memory: only exists in memory and will not be saved to a file. The third parameter is the type name, corresponding to the addTypes operation above. The third parameter can also be omitted if the type name and configuration name are consistent. After the configuration is created, the UI process can access the configuration data through Editor.getSettings and then read and write, for example: let data = Editor.getSettings(\"MyTestSettings\").data; data.option2 = \"hello\"; Configurations are loaded and saved automatically, no manual operation is required. The scene process can access the configuration data through EditorEnv.getSettings, but it is read-only and cannot be modified. And because it is cross-process, to get the latest data, sync must be called first, for example: let settings = EditorEnv.getSettings(\"MyTestSettings\"); await settings.sync(); console.log(settings.data.option2); //hello 12. Extended editor configuration interface If we created some customized configuration data through the previous section, we can display it in the project configuration interface or the preference interface for users to modify. For example: @IEditor.panel(\"TestSettings\", { usage: \"project-settings\", title: \"测试\" }) export class TestSettings extends IEditor.EditorPanel { async create() { let panel = IEditor.GUIUtils.createInspectorPanel(); panel.inspect(Editor.getSettings(\"MyTestSettings\").data, \"MyTestSettings\"); this._panel = panel; } } The @IEditor.panel decorator has been introduced in \"6. Using the Panel\" and will not be repeated here. The only difference is the setting of the usage option. Possible values ​​for usage are: project-settings: displayed in the project configuration interface build-settings: displayed in the build release interface preference: displayed in the preference interface The display effect of the above code is: 13. Expand the build process In addition to starting in the interface, the build process can also be called through API. The following example demonstrates starting a build task through a custom menu: class Abc { IEditor.menu(\"App/my/build\") static build() { IEditor.BuildTask.start(\"web\"); } } You can also manually start the build task in the scene process: IEditorEnv.BuildTask.start(\"web\"); Customize the plug-in process by building plug-ins. The interface for building plug-ins is IBuildTask. IBuildTask is defined as: export interface IBuildPlugin { /** * When the build task is initialized. Configurations such as config and platformConfig can be modified in this event. * @param task */ onSetup?(task: IBuildTask): Promise; /** * The build task starts. You can initialize the structure of the target directory in this event, or perform necessary checks and installations, etc. * @param task */ onStart?(task: IBuildTask): Promise; /** * Collecting resources that need to be released. The assets collection is all resource objects that need to be published that the system collects based on all valid rules such as dependencies and resources directory rules. You can add additional resource objects to the collection. * @param task * @param assets */ onCollectAssets?(task: IBuildTask, assets: Set): Promise; /** * Exporting resources. exportInfoMap contains information about exported resources, including saving location and other information. The output location of the outPath custom resource can be modified. * @param task * @param exportInfoMap */ onBeforeExportAssets?(task: IBuildTask, exportInfoMap: Map): Promise; /** * Exporting resources is completed. If developers need to add their own files, or perform operations such as compression, they can be handled in this event. * @param task * @param exportInfoMap */ onAfterExportAssets?(task: IBuildTask): Promise; /** * The build has been completed, some manifest files, configuration files, etc. can be generated in this event. */ onCreateManifest?(task: IBuildTask): Promise; /** * If there is a native build process, handle it here. * @param task */ onCreatePackage?(task: IBuildTask): Promise; /** * Build task completion event. * @param task */ onEnd?(task: IBuildTask): Promise; } All hook functions are optional and the required logic can be implemented as needed. Plugins need to be registered through the IEditorEnv.regBuildPlugin decorator. The following example demonstrates how to manually add a resource to participate in the build when the web platform is built. @IEditorEnv.regBuildPlugin(\"web\") class MyBuildPlugin implements IEditorEnv.IBuildPlugin { async onCollectAssets(task : IEditorEnv.IBuildTask, assets: Set) { let myAsset = ... assets.add(myAsset); //In the publishing plug-in, you need to use task.logger to output logs task.logger.debug(\"add my asset\"); } } If you need to build the plug-in to take effect on all platforms, you can pass \"*\" as the first parameter of regBuildPlugin. The second parameter of regBuildPlugin can pass a priority value. The greater the priority, the earlier the plug-in will be called during build. Some tools and methods often used in plug-ins include: (1) Use the task.logger interface to record logs; (2) Use IEditorEnv.utils.renderTemplateFile to render the template file, using the mustache library; (3) Use task.mergeConfigFile to merge configuration files. That is, if there are json format configuration files with the same path and name in the built-in template directory and the project template directory (build-templates), they can be merged through this method; (4) Use IEditorEnv.utils.intallCli to install some public cli packages, which will be installed under library/cli-package. For example: await IEditorEnv.utils.installCli(\"@oppo-minigame/cli\", options); (6) Use IEditorEnv.utils.exec to execute any local command. (7) Use IEditorEnv.utils.downloadFile to download files. (8) Use IEditorEnv.utils.ZipFileR to decompress the file. You can extend the build options panel and add some custom parameters. As described in the \"Customize Panel\" section, we can set the usage of the panel to \"build-settings\". @IEditor.panel(\"TestBuildSettings\", { usage: \"build-settings\", title: \"测试\" }) export class TestBuildSettings extends IEditor.EditorPanel { @IEditor.onLoad static start() { Editor.typeRegistry.addTypes([ { name: \"MyBuildSettings\", catalogBarStyle : \"hidden\", properties: [ { name: \"option1\", type: \"boolean\", default: true }, { name: \"option2\", type: \"string\", default: \"2332\", } ] } ]); Editor.extensionManager.createSettings(\"MyBuildSettings\", \"project\"); } async create() { let panel = IEditor.GUIUtils.createInspectorPanel(); panel.allowUndo = true; panel.inspect(Editor.getSettings(\"MyBuildSettings\").data, \"MyBuildSettings\"); this._panel = panel; } } The effect is as follows: These parameters can be accessed through the Settings mechanism in the build plug-in, for example: @IEditorEnv.regBuildPlugin(\"web\") class MyBuildPlugin implements IEditorEnv.IBuildPlugin { async onSetup(task : IEditorEnv.IBuildTask) { let mySettings = EditorEnv.getSettings(\"MyBuildSettings\"); await mySettings.sync(); task.logger.debug(mySettings.data.option1); } } 14. Customize publishing target platform You can add a release target platform to the IDE through a plug-in. For example: Editor.extensionManager.createBuildTarget(\"test\", //The unique id of the platform, no conflict { caption: \"Customized platform\", //Target name settingsName:\"MyBuildPlatformtSettings\", //You need to register with Edition.extensionManager.createSettings first inspector: \"TestBuildSettings\" //A panel with usage build-settings templatePath: \"editorResources/testTemplate\" //An optional parameter. Place the build template file in the specified directory. It will be automatically copied to the output directory during the build. }); Here is a complete example: @IEditor.panel(\"TestBuildSettings\", { usage: \"build-settings\", title: \"test\" }) export class TestBuildSettings extends IEditor.EditorPanel { @IEditor.onLoad static start() { Editor.typeRegistry.addTypes([ { name: \"MyTestSettings2\", catalogBarStyle : \"hidden\", properties: [ { name: \"option1\", type: \"boolean\", default: true }, { name: \"option2\", type: \"string\", default: \"2332\", } ] } ]); Editor.extensionManager.createSettings(\"MyBuildPlatformtSettings\", \"project\"); Editor.extensionManager.createBuildTarget(\"test\", { caption: \"Customized platform\", settingsName:\"MyTestSettings2\", inspector: \"TestBuildSettings\" }); } async create() { let panel = IEditor.GUIUtils.createInspectorPanel(); panel.allowUndo = true; panel.inspect(Editor.getSettings(\"MyBuildPlatformtSettings\").data, \"MyBuildPlatformtSettings\"); this._panel = panel; } } The effect is as follows: During the scenario process, you need to add one or more build plugins for this new custom platform. @IEditorEnv.regBuildPlugin(\"test\") export class TestBuildPlugin implements IEditorEnv.IBuildPlugin { async onCreatePackage(task: IEditorEnv.IBuildTask) { //The platformConfig here corresponds to MyBuildPlatformtSettings. There is no need to getSettings by yourself. task.logger.info(task.platformConfig.option2); } } After the build is completed, if you need to support \"run\", the build plug-in needs to define a runHandler. The following example demonstrates accessing the built content through the Web. The root directory of the Web site is the target directory of the build, so an empty string is passed in. If it is a subdirectory, the path to the subdirectory can be passed in. @IEditorEnv.regBuildPlugin(\"test\") export class TestBuildPlugin implements IEditorEnv.IBuildPlugin { async onCreatePackage(task: IEditorEnv.IBuildTask) { task.config.runHandler = { serveRootPath : \"\" }; } } 15. Resource import pre-processing and post-processing Sometimes we need to do some automated processing when importing resources, such as automatically setting it to an elf texture when importing a picture, setting a compression format, etc. In this case, we can use the IAssetProcessor interface. The interface is defined as follows: export interface IAssetProcessor { //Called before image resources are imported onPreprocessImage?(assetImporter: IImageAssetImporter): void | Promise; //Called before any type of resource is imported onPreprocessAsset?(assetImporter: IAssetImporter): void | Promise; //Called after the image resource is imported onPostprocessImage?(assetImporter: IImageAssetImporter): void | Promise; //Called after any type of resource is imported onPostprocessAsset?(assetImporter: IAssetImporter): void | Promise; } Classes that implement the IAssetProcessor interface need to be registered through the decorator IEditorEnv.regAssetProcessor. The following is a simple example of AssetProcessor, which sets all images that are not sprite textures to compressed format. @IEditorEnv.regAssetProcessor() export class TestAssetProcessor implements IEditorEnv.IAssetProcessor { onPreprocessImage(assetImporter: IEditorEnv.IImageAssetImporter): void | promise { if (assetImporter.config.textureType != 2) { assetImporter.config.platformDefault = { format: 10 }; } } } (1) You can use assetImporter.isNew to distinguish whether it is a newly added resource; (2) After adding or modifying IAssetProcessor, the resource library does not automatically re-execute the script for existing resources. The user needs to use the right-click menu \"Reimport\" of the resource library. Of course, you can also re-import through the plug-in code: EditorEnv.assetMgr.importAsset(asset). 16. International support Using the interface provided by LayaAirIDE, you can realize the internationalization of the plug-in interface and the internationalization of the information output in the plug-in code. First we need to create a new configuration file. If this configuration is used for interface internationalization, please create it in the directory where all your interface files are located or the upper-level directory. Identification: The unique identification of the international configuration file, automatically generated, cannot be modified (if you really want to modify it, you can open the configuration file in text mode and modify it directly, but you need to ensure it is unique. However, it has been bound on the interface after modification will be all lost). Scope of use: Runtime or editor extension. Runtime means it is used for games (not supported yet). Currently we choose the editor extension, which is used in the plug-in interface. Default Language ID: The text language used in interface design when making editor prefabs visually. For example, if you make the interface in Chinese, then here is zh-CN, if you make the interface in English, then here is en, and so on. If the language set here is consistent with the runtime language, the text on the interface will be used directly and the translation file will not be used for replacement. Fallback Language ID: If a translation file matching the runtime language cannot be found, the fallback language ID will be used to continue matching. For example, if the runtime language is German and there is no German (de) translation file in the translation file, the translation file with the fallback language ID (en) will be used. Translation Reference: Generally used to automatically collect text on the interface to form a reference file. Then use this reference file to translate into various languages, and then add it to the translation file list. The reference file does not need to be added to the translation file list because the text in the reference file is existing on the interface. Collect text: After clicking, all prefab files in the directory and subdirectories where the configuration file is located will be analyzed, all text that needs to be translated will be collected into reference files, and these texts will be converted into international formats. If the reference file is not set, one will be automatically generated. Synchronize: After re-collecting the text, click Synchronize to match the entries of all translation files with the reference files. For example, if a new text \"abc\" is created on the interface, after clicking to collect the text, an entry \"abc\" will be added to the reference file. After clicking sync, an entry \"abc\" will be added to all translation files. In addition to automatically collecting text on the interface, we can also manually set it, such as the title of a button: Click the button in the upper right corner, and the interface will pop up: Here you can select or create a new entry in the language file. After selecting an item, the input box updates to display: The green horizontal bar shows the key value of the translation file, indicating that the text has been internationalized. After the interface is internationalized, language adaptation is fully automatic without code intervention. In addition to interface internationalization, the information output by the code also needs to be internationalized. Usually we recommend using another configuration file, not to be confused with the configuration file used by the interface. Let’s create a new internationalization configuration: Here you only need to manually create multiple translation files and drag them into the translation file list. The key values ​​of these files need to be synchronized themselves. The translation reference feature can be ignored as there is no need to collect it from the interface. The method used in the code is: myI18n: gui.Translations; @IEditor.onLoad async onLoad() { myI18n = await gui.UIPackage.resourceMgr.load(\"editorResources/i18nSettings.i18ns\"); } test() { console.log(myI18n.t(\"a\")); } In many cases, if you only need a small amount of internationalization support in the code and don't want to create multiple json files, there is also a full-code method. //The first parameter needs to be globally unique let myI18n = gui.Translations.create(\"LodSimplify\"); myI18n.setContent(\"zh-CN\", { meshRate: \"Model compression ratio\", meshRateTips: \"Compress the model mesh 2x according to the set ratio\" }); Editor.typeRegistry.addTypes([ { name: \"LodSimplifyData\", properties: [ { name: \"meshRate\", type : \"number\", caption: myI18n.t(\"meshRate\", \"Mesh Rate\"), tips: myI18n.t(\"meshRateTips\", \"Compress the model mesh based on the set ratio.\"), } ] } SetContent can be called multiple times to add translations in different languages. The following example adds translations for language en, so the default value can be omitted when applying the t function. //The second parameter is the backup language ID. The default is en, so it can be omitted here. let myI18n = gui.Translations.create(\"LodSimplify\", \"en\"); myI18n.setContent(\"zh-CN\", { meshRate: \"Model compression ratio\", meshRateTips: \"Compress the model mesh 2x according to the set ratio\" }).setContent(\"en\", { meshRate: \"Mesh Rate2\", meshRateTips: \"Compress the model mesh based on the set ratio.\" }); Editor.typeRegistry.addTypes([ { name: \"LodSimplifyData\", properties: [ { name: \"meshRate\", type : \"number\", caption: myI18n.t(\"meshRate\"), tips: myI18n.t(\"meshRateTips\"), } ] } 17. Command line support You can start the editor in the terminal and execute the script in the background. The parameters are: > LayaAirIDE --project=/path/to/project --script=MyScript.buildWeb --project: project path --script: Specify the script to be executed For example, using the following script, you can build a web platform using the command line. After the script is executed, the background process will automatically exit. @IEditorEnv.regClass() class MyScript { static async buildWeb() { return IEditorEnv.BuildTask.start(\"web\").waitForCompletion(); } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:36:42 "},"IDE/layapackage/pluginImport/readme.html":{"url":"IDE/layapackage/pluginImport/readme.html","title":"Plugin Import","keywords":"","body":"Plug-in import instructions1. Purchase plug-ins1.1 Entrance1.2 Plug-in classification1.3 Purchase2. Import and use2.1 Resource store import2.2 Local import plug-in3. Video tutorialPlug-in import instructions LayaAir version 3.1 has a new resource store. Users’ minimum version of LayaAir IDE must be updated to 3.1 to use the resources in the resource store. 1. Purchase plug-ins 1.1 Entrance Users can enter the resource store from the following entrances: 1, 3.1 and above versions of IDE (Picture 1-1) Enter the URL directly into the browser (https://store.layaair.com/) (Figure 1-2) Top navigation of official website (Figure 1-3) 1.2 Plug-in classification The resource store plug-ins are divided into the following categories: Project source code category: used for complete project packages. (Figure 1-4) Resource category: pure resources such as art or sound effects, no code. (Figure 1-5) IDE-based plug-in system: Call the plug-in API to expand the development capabilities of the IDE. (Figure 1-6) Tool category: Connect external tools and import them into the IDE for use, which is helpful for the integrated development of the IDE. (Figure 1-7) Other project-related library resources or project codes: such as third-party physics engine libraries, Shader codes, etc. (Figure 1-8) Note: The first type of project source code plug-in has a import method that is different from the others, which will be explained in detail in the second section. 1.3 Purchase Users first need to register an account on the resource store homepage. There are two login methods: mobile phone number and WeChat. (Figure 1-9) After registering, you can make a purchase. It should be noted that paid resources in the resource store will not be refunded at the time of purchase unless they are seriously inconsistent with the description. Therefore, it is recommended that you communicate with the plug-in author for confirmation before purchasing paid resources. When purchasing resources, first click Add to My Resources, (Figure 1-10) After purchasing, click View my resources, (Figure 1-11) You can jump to the purchased resources page, and all the purchased resources are here. (Figure 1-12) 2. Import and use 2.1 Resource store import 2.1.1 Source code plug-in import If you are importing a project source code plug-in like \"Plane War Game Source Code\", (Figure 2-1) Click to open in LayaAirIDE and click to open in the pop-up box. (Animation 2-2) If version 3.1 and above of LayaAirIDE is installed locally, clicking on it will open the IDE. In the purchased source code menu on the sidebar, there is the source code of the Aircraft Battle game that has been purchased. (Figure 2-3) After selecting, click Download Template. (Figure 2-4) After the download is complete, click Create Project to create an engineering project for this game. (Figure 2-5) 2.1.2 Common plug-in import If it is other types of ordinary plug-ins, such as \"level of detail reduction plug-in\", (Figure 2-6) It is a common plug-in. After clicking to open it in LayaAir IDE, you must first create a project in the IDE. (Animation 2-7) Then you will be prompted to import resources. (Figure 2-8) If there is already an open LayaAir project before clicking on the resource store, you can directly import the resources, and the plug-in panel will be opened directly after importing. (Animation 2-9) 2.1.3 Update plug-in Another point to note is that if the merchant updates the resources in the resource store, the user needs to manually update the resources on the purchased resources page. Taking the \"LayaAIGC plug-in\" as an example, you first need to check the update log, and then before clicking update, developers are recommended to back up the old plug-in package themselves, and finally click the update button and re-import the plug-in into the IDE to complete the update. (Animation 2-10) 2.2 Local import plug-in If the user wants to import a resource package that he has saved before, he can click Import Resource Package under the Tools menu bar in the IDE. Note that the suffix of the resource package file name is .layapkg. (Figure 2-11) If the user stores the resource package remotely, he can choose to import the resource package from the network and fill in the remote address. 3. Video tutorial Users can also watch the official video tutorial to complete the plug-in import: LayaAir3.1 Resource Store Tutorial Collection. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:37:58 "},"IDE/layapackage/Layabox/readme.html":{"url":"IDE/layapackage/Layabox/readme.html","title":"Official Plugins","keywords":"","body":"Official plug-inLOD surface reduction plug-inOfficial plug-in LayaAir officially provides some plug-ins for developers to use: LOD surface reduction plug-in Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:32:59 "},"IDE/layapackage/Layabox/LOD/readme.html":{"url":"IDE/layapackage/Layabox/LOD/readme.html","title":"LOD Reduction Plugin","keywords":"","body":"Level of detail (LOD) surface reduction tool plug-in1. Plug-in overview1.1 Introduction to plug-ins1.2 Main functions2. Instructions for use3.1 Import plug-in3.2 Parameter descriptionLevel of detail (LOD) surface reduction tool plug-in Author: Charley Welcome to the Level of Detail (LOD) surface reduction tool plug-in. This plug-in has powerful model optimization functions, which can help developers reduce the performance pressure of game engines when displaying 3D models. 1. Plug-in overview 1.1 Introduction to plug-ins LOD is the abbreviation of \"Level of Detail\", usually translated as \"level of detail\", and some documents will also be translated as \"level of detail\". It is the same thing. It is a method used in computer graphics to handle large-scale scenes. A general technical solution. In this plan, it is believed that the complexity of the model should be dynamically adjusted based on factors such as the distance between the viewpoint and the model, the size of the model's projection on the screen, and other factors. In this way, close, large, and important models are represented with high-resolution details, while distant, small, and unimportant models are represented with low-resolution details. With the help of the LOD technology solution, the computer only needs to display the scene details currently visible from the camera angle, which reduces the computational burden and the performance requirements of the hardware equipment. While ensuring the image quality and animation smoothness, it allows for a larger Scenes and more complex scenery settings, which to a certain extent improve the expressiveness and user experience of games or other visualization products. LOD is commonly used in video games, virtual reality, city simulation and other fields. In a game, for example, the farther the character is from you, the fewer polygons the model will have and the blurr the texture will be. The closer the character is to you, the more polygons the model will have and the clearer the texture will be. This can make full use of hardware performance and provide Better gaming experience. The LOD face reduction plug-in officially produced by Layabox is used to create and manage the level of detail (LOD) of 3D models and reduce the number of model Mesh faces. LOD technology can greatly improve the performance of 3D games and applications by adjusting the number of polygons displayed based on an object's distance in the 3D scene. This plug-in effectively reduces the number of renderings and reduces the computing pressure on GPU hardware when complex models exist. It is especially suitable for devices running with limited hardware resources. 1.2 Main functions (figure 1) Level generation and deletion: Users can set multiple LOD levels and delete new levels. Model surface reduction and compression: Level of detail surface reduction tool, which can automatically calculate the number of triangles in the model and generate reduced models at each level based on the compression ratio. Specified level culling rate: For each level of model, you can customize the ratio conditions for optimizing culling in the scene. 2. Instructions for use 3.1 Import plug-in After we add the resources from the IDE resource store to My Resources, in the list of purchased resources, click Open in LayaAirIDE, and the browser control for calling the IDE will pop up. Click Open LayaAirIDE again. , the operation process is shown in Figure 2-1. (Figure 2-1) After the above operation, the control will launch LayaAir3-IDE and a window for importing resources will pop up. We click Import in the window. When the import is completed, a prompt panel indicating that the import is completed will pop up. Click OK to complete the import of the plug-in. The operation is shown in Figure 2-2. (Figure 2-2) The interface after the import is completed is shown in Figure 2-3: (Figure 2-3) Plug-in update After the plug-in developer launches a new version, it will not actively update the version for plug-in users (some users may not want to upgrade), so plug-in developers need to manually click update in the resource store. After updating, click \"\" in LayaAir IDE Open\" will re-import and open the new version of the plug-in. The operation is shown in Figure 2-4. 3.2 Parameter description 3.2.1 Target types and area reduction targets The target object of LOD subtraction is specified by two parameters, The first is the target type. The three types supported by this item are: node (Node), prefab (prefab), and model mesh (Mesh). The second is the area reduction target. The area reduction target is the specific resource to be reduced. The target resource for area reduction will be controlled according to the target type. For example, for node types, you can only drag 3D node objects from the Hierarchy Panel to the subtraction target, while for prefabs and model meshes, you can only drag the corresponding types of resources from the Project Resource Panel. As shown in Figure 3-1: (Figure 3-1) 3.2.2 Preserve boundaries The concept of `preserving boundaries' means that during the process of simplifying the model, the vertices located at the topological boundaries are not moved. Topological boundary vertices are those that are on the edge of a triangle but have no paired triangle. The vertices of the boundary are important feature points, and moving these vertices may seriously change the shape of the model and even cause visual errors. Through the preserve boundary function, the model can be simplified while maintaining the overall shape and relative accuracy of the model. This feature can be useful when simplifying part of a large mesh. When using, if this function is checked, the tool will keep the vertices located on the boundary unchanged when generating the LOD model, and only move and simplify other vertices and elements, without oversimplifying the edges of the model. This ensures that after the model is simplified, its boundaries remain intact and prevents the visual impact of changes in the shape of the boundaries. 3.2.3 Specify storage path Clicking the Reduction surface button will generate the model resources after surface reduction. By default, they are generated to the root directory under assets (named with the mesh name as the directory). When Specify storage path is checked, the input box for the storage path will appear, as shown in Figure 3-2, which is used to customize a directory as the model directory generated after surface reduction. (Figure 3-2) 3.2.4 Level of detail configuration The configuration of level of detail (LOD) is mainly divided into three modules: increase or decrease of level of detail, model compression ratio configuration, and minimum culling rate. Adding and deleting levels of detail The default setting of the tool is 3 levels of detail. Layer 0 represents the original level with values ​​​​100%, 1 represents the level setting of 50% ratio, and 2 represents the level setting of 10% ratio. If you want to add levels, click the plus sign, as shown in Figure 3-3. (Figure 3-3) If you want to delete a level, click the delete icon in front of the level ID, as shown in Figure 3-4. (Figure 3-4) Model compression ratio configuration For each level, you can set a different compression ratio, 100% is the original size, no compression. If it is lower than 100%, the mesh of the model will be compressed according to the proportion. Minimum rejection rate The minimum culling rate means that at the corresponding level of detail, if its size on the screen is lower than the set minimum viewing angle ratio, the object will be completely culled, that is, it will no longer be rendered. This helps optimize rendering performance and reduce resource consumption. The proportion of the culling rate is related to the relative size of the model displayed in the 3D scene, and is generally described in the form of a percentage. Generally, the closer an object is to the camera, the larger it will appear on the screen, and vice versa. For example, if the LOD minimum culling is set to 50%, this means that the model height is half of the scene's display height. When the proportion of a model is less than 50%, those models with a proportion greater than or equal to this proportion in the LOD group will not be rendered, and the next level model in the LOD group will be rendered instead. In short, the minimum culling rate is used to determine which level of detail model is rendered, typically using a more detailed high-resolution model when the object is close to the camera, using a lower-resolution model at a distance, or keeping only the outline of the model to reduce rendering overhead. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 18:32:14 "},"2D/advanced/readme.html":{"url":"2D/advanced/readme.html","title":"Advanced 2D","keywords":"","body":"2D AdvancedAdvanced use of textTiledMap map2D Performance Optimization2D Advanced The 2D advanced part includes some documents related to engine expansion functions, comprehensive use of engine functions, advanced use, etc. Advanced use of text TiledMap map 2D Performance Optimization Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 17:56:57 "},"2D/advanced/useText/readme.html":{"url":"2D/advanced/useText/readme.html","title":"use Text","keywords":"","body":"Advanced Use of Text1. Display text component2. Bitmap display text component3. HTML, UBB, template4. Input text component5. Performance optimization of text5.1 Use corresponding text components as much as possible5.2 Avoid using text strokes whenever possible5.3 Optimization of DrawCall interrupted by textAdvanced Use of Text LayaAir engine and IDE provide rich text components, suitable for various text application scenarios. This article introduces the display text components, bitmap text components, and input text components in the IDE respectively, so that everyone can have a comprehensive understanding of each text component of the LayaAir engine. 1. Display text component The displayed text is the basic text that can only be viewed and cannot be edited or modified. LayaAirIDE provides two basic display text components, Text and Label. 1.1. The underlying rendering mechanism of text The LayaAir engine has two methods for underlying rendering of text. They are the unified text submission method of the Text class, and the fillText single character drawing submission method of the Graphics class. If Text text is used, the text characters in each Text text object will form a small picture collection and submit it to the large picture collection. For example, a text object in the game has 300 words, and if one of the characters changes, the corresponding The 300-word text atlas of the text object is re-introduced in the large image collection. Or suppose, in a plot game, two people are having a conversation. One of the text objects needs to be continuously re-valued and assigned, causing the display content of the text object to change frequently. At this time, the Text object will continuously submit the text atlas to the large image collection. After the large atlas is filled, a new atlas needs to be created to continue submitting, instead of using the old atlas. If it does not reach the GC conditions will always exist, so if you check the memory usage statistics this time, you can see that the memory will continue to increase until the GC conditions are reached, and then it will be destroyed. And when the GC clears the garbage memory, it may cause instant lag. When using fillText text drawing of the Graphics class, single characters are submitted to the large image collection, and characters that already exist in the large image collection will not be submitted repeatedly. Therefore, the utilization rate of the atlas is relatively good. Even when the text changes, it will not create a lot of junk atlases like Text text. From this point of view, is fillText the best to use? If the text does not need to be changed, then submitting the atlas by word is not as efficient as submitting it directly at once. Therefore, we still have to look at the type of text, corresponding to the type of text used, and select the corresponding engine API, which will be better. 1.2. Static text and dynamic text Based on the mechanism of text rendering and submission in the previous section, and the difference between text used only for display or for interaction, we divide it into two concepts. Text that is only used for display and the text content does not need to be changed is called static text. Text that needs to change its content is called dynamic text. Text and Label both belong to classes that handle static text. They are rendering mechanisms that uniformly submit every change to the text to a large atlas. fillText, fillBorderText, strokeText, etc. are all text drawing methods used for single-character submission in the Graphics class. In LayaAir IDE, Text and Label are static text components. However, text drawing methods such as fillText, fillBorderText, and strokeText of the Graphics class in the LayaAir engine are not encapsulated as components in the IDE, and the engine API needs to be used directly in the project code. 1.3. Differences and choices in using different text APIs If we have understood what static text and dynamic text are, then the choice of use is relatively simple. For example, there is no need to change some navigation and label buttons on the UI, and static text can be used. Text plots and tasks require dynamic text. There are two types of static text components: Text and Label. How to choose? Among them, Text is the most basic text component. It inherits directly from Sprite, while Label inherits from UIComponent and then Sprite. In principle, the shorter the path, the better the performance. Therefore, for relatively simple text, when Text can satisfy the requirements, Text should be used first in principle. Label, because of its rich attributes, is suitable for relative layout and other application scenarios that cannot be satisfied by Text. For fillText, we not only need to understand its advantages, but also its shortcomings. Since the fillText text is drawn by the engine itself, it is currently only applicable to mainstream national languages ​​such as Chinese and English. For complex languages ​​such as Thai and Arabic, the display may be abnormal. Therefore, for these international language games with complex typesetting, the only way is to use system characters or bitmap characters of static text components to minimize the need for dynamic text modifications. 1.4. Things to note when using For static text, the Text component is preferred, because the performance is best when only static text is displayed. For dynamic text, fillText is preferred, unless requirements such as internationalization cannot be met. For static text, when there are complex requirements such as relative layout, the Label component is more powerful. The code usage of fillText is explained as follows: /** * Draw text on the canvas. * @param text The text output on the canvas. * @param x The x coordinate position (relative to the canvas) at which to start drawing text. * @param y The y coordinate position (relative to the canvas) at which to start drawing text. * @param font defines the font size and font, such as \"20px Arial\". * @param color defines the text color, such as \"#ff0000\". * @param textAlign text alignment, optional values: \"left\", \"center\", \"right\". */ fillText(text: string | WordText, x: number, y: number, font: string, color: string, textAlign: string): FillTextCmd { return this.addCmd(FillTextCmd.create(text, x, y, font, color, textAlign, 0, \"\")); } Here we focus on the difference between the font attribute in fillText and several other text font attributes. The sample code for fillText is as follows: /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { let sprite = new Laya.Sprite(); Laya.stage.addChild(sprite); sprite.graphics.fillText(\"fillText: text drawn by the engine, suitable for simple single-line text\", 100, 300, \" 60px simHei \", \"#ff0000\", \"left\"); } In Text and Label, font only refers to the system font. For example, whether the text is Microsoft YaHei or Arial, just select or enter the corresponding font. In fillText, font is the setting value of font and font size. All related text styles (size, font, italics, bold) can also be specified here. For example, when the value is 60px simHei, the text size is set to 60 pixels, using the simHei font. As shown in Figure 1-1 below: (Picture 1-1) A value of 60px simHei italic adds an italic effect. As shown in Figure 1-2 below: (Figure 1-2) The value bold 60px simHei italic adds text bolding effect. As shown in Figure 1-3 below: (Figure 1-3) Tips: Size and font must be set, and the font must be placed behind the px size of the text. bold needs to be placed in front of the text px size. 2. Bitmap display text component Bitmap display text is a kind of text based on bitmap. Although it displays the content of the text, its essence is still a bitmap. Usually used for fonts that are not common on the system or personalized fonts for art design. The compatibility and beauty of the fonts can be ensured through bitmaps. For games with strict text effect and position requirements, it is recommended to use bitmap text. Ordinary text may have pixel-level position offsets under different operating environments. For example, there are also positional offsets between low and high versions of Chrome. Therefore, for static UI texts with high requirements, bitmaps can be used to display text. Bitmap text is suitable for text that does not require a large number of words. It is often used for title text such as level X and combo X. It is not suitable for games with text plots. 1. FontClip font clipping component The FontClip component is used by LayaAir to divide the complete bitmap into independent text units based on the principle of equal cutting, and then arbitrarily clip and splice them together. The effect is shown in Figure 2-1. (Figure 2-1) The numbers 0-9 in Figure 2-1 are the display of the original art image effect, and the number 999 is the effect of the FontClip component. In the property panel on the right side of Figure 2-1, the sheet value corresponds to the 9 numbers of the bitmap. At this time, the numbers must be completely corresponding, because this value is not only the reference basis for the engine to cut the number of copies, but also the text mapping relationship. Only by matching, whatever value is entered in the attribute value will be displayed, such as 999 in Figure 2-1. And the FontClip component can also control effects such as the bitmap text spacing after cutting. If the bitmap text is not numbers, but letters or Chinese, etc., and the content is relatively large, the text can also be arranged in multiple lines when the art is drawn, but each text must be arranged with equal height, equal width and equal spacing. At this time, the sheet value used for mapping needs to add a space at the end of each line to let the engine know that the bitmap text is arranged in multiple lines. Results as shown below: (Figure 2-2) From Figure 2-2, we can see that the sheet attribute value Rat, Ox, Tiger, Rabbit, Dragon, Snake, Horse, Sheep, Monkey, Rooster, Dog and Pig Year corresponds to the text on the bitmap, and a space is added after the sheep. At this time, you can The value input text characters on the bitmap, and we also show the effect of vertical typesetting, indicating that the cut text can also be controlled by typesetting. Careful developers will find that the bitmap characters are in traditional Chinese and the sheet values ​​are in simplified Chinese, but the display effect is not affected. This is because the sheet value only serves as a mapping relationship. Even if the text of the twelve zodiac signs corresponds to the zodiac picture, the corresponding zodiac picture will be displayed. However, the number on the mapped text and bitmap must be complete, otherwise the wrong number of slices will lead to display errors after the bitmap is clipped. Finally, let’s talk about spaces. If the current FontClip component is oriented to a single line of text as shown in Figure 2-1, the sheet value does not support spaces. For the multi-line text in Figure 2-2, the space in the sheet value represents a line break, not a blank space. If you add a space to the Value value, you can see from Figure 2-2 that a complete text position will be vacant. In fact, it is not just spaces. All text that does not exist in the sheet value will be filled with empty complete characters when entered in the value. 2. BitmapFont bitmap font Usually FontClip can already meet the needs of single-line bitmap text such as levels and special effects. If there are special circumstances where you want spaces or artistic fonts that are not available in some systems, you can also use BitmapFont bitmap fonts to achieve this. In LayaAir IDE, you can directly create and produce bitmap fonts. This function will be introduced below. As shown in Figure 2-3, in the project resource panel, right-click to create a bitmap font. (Figure 2-3) After creation, as shown in Figure 2-4, a BitmapFont.fnt font file will be generated. (Figure 2-4) After clicking to select, you can create a bitmap font in the property settings panel as shown in Figure 2-5. (Figure 2-5) Click the + of \"Edit Character Set\" to create a character, as shown in Figure 2-6: (Figure 2-6) Parameters Meaning Allow scaling When checked, the text can be scaled and displayed according to the font size setting in the text. If this is not checked, the font size setting will be ignored and only the actual size of the bitmap text will be displayed Font size After checking Allow scaling, the font size here is used for scaling adjustment of the actual text font size. For example, if the font size of the actual text is set to 24 and the font size of the bitmap font is set to 12, then the bitmap font will eventually be enlarged by 1 times for display. It is recommended here to be consistent with the \"font size\" attribute of the text component, so that the obtained The zoom effect is the most accurate. If scaling is not allowed, the font size setting here and the actual text will have no effect, and the source image size of the bitmap font will always be maintained Custom row height After checking, you can set the row height. If unchecked, the default row height is used. Line height determines the height of each line when text is displayed in multiple lines, and is mainly used for typesetting text in the vertical direction. If it is 0, the font size is used as the line height. If greater than 0, this is the actual text line spacing (the distance between the upper boundaries of two bitmap fonts). After creation, you can set the line height in the \"leading\" attribute of the text component character The character corresponding to the picture only supports single characters, which can be numbers or strings. Pictures A picture in the resource library Placeholder If the value is 0, it represents the horizontal occupancy width of a character after creation, which is determined by the width of the character image. If the value is greater than 0, use that value as the kerning between characters (the distance between the left borders of two bitmap fonts) As shown in Figure 2-7, there are twelve pictures in the resources folder, which are bitmaps of the twelve characters \"rat, cow, tiger, rabbit, dragon, snake, horse, sheep, monkey, chicken, dog, pig\". These twelve pictures are used as bitmaps. Figure font. The height of the image is 151 px, so the line height is set to 151. The placeholder defaults to 0, and after creation it will become 144, which is the width of the image. After editing, click \"Apply\". After clicking, another BitmapFont.png image will be created for previewing the bitmap font. (Figure 2-7) Bitmap fonts can be selected in the Font property of text components such as Text, Label, TextInput, and TextArea, and the font size and line spacing can be adjusted. The following takes Text as an example to demonstrate the use of bitmap fonts. As shown in the animation 2-8, select the bitmap font you just created in Text, and then enter the \"character\" corresponding to the bitmap font in the text to use the bitmap font. (Animation 2-8) Tips： Developers can also use external tools to complete the production and then import it for use. Here is an open source tool recommended: https://snowb.org/, which can be produced online. 3. HTML, UBB, template HTML tags are used on all text-related UI components, and can be mixed with other UBB tags, text templates, and ordinary text. Developers only need to set the corresponding syntax attributes. Please refer to the documentation for supported syntax and usage methods. \"Basic Text\". 4. Input text component The input text components are the single-line input component TextInput and the multi-line text area component TextArea. You can actually tell the difference from the component names. One is that it cannot wrap lines and is used for single-line input. For example, those single-line input boxes on registration information use TextInput. The other is a multi-line text component TextArea that can wrap lines, such as personal introduction, notes, etc. And the TextArea text component supports a vertical scroll bar on the right side and a horizontal scroll bar on the bottom. Because the usage of the input text component is relatively simple, the component is also relatively easy to understand. I won’t introduce it in detail here. During use, you can try it by following the prompts or directly read the corresponding component attribute description document. 5. Performance optimization of text 5.1 Use corresponding text components as much as possible Each different component has its own unique function, so you must fully understand the function of the component and use it according to its characteristics. As mentioned above, the performance of the Text component for static display of text is the best. Therefore, during project development, Text components should be used as much as possible. Use Label when the Text component is not satisfied. For static text that does not need to change the content, when the text component has many nodes, we can turn on cacheAs, set normal to optimize the number of nodes, and set bitmap to optimize the number of DrawCalls. When the text content needs to be changed, even if only one character is changed, if FillText can meet the needs, then the FillText text component should be used first as much as possible. When FillText cannot satisfy the requirement, secondly consider whether the bitmap text component can satisfy the requirement, and finally consider the static text component. 5.2 Avoid using text strokes whenever possible At runtime, text with a stroke calls the drawing command one more time than text without a stroke. At this time, the CPU usage of text is proportional to the number of texts. Therefore, try to use alternatives to accomplish the same needs. For example, when the amount of characters is small, bitmap text can be used. 5.3 Optimization of DrawCall interrupted by text In 2D UI layout, if developers mix and arrange text with other UI nodes, it will inevitably interrupt the merged rendering of the atlas, increase the number of DrawCalls, and generate unnecessary performance overhead. So, there are two options to optimize. First, when editing the layout in LayaAir IDE, arrange all text components sequentially in the nodes and do not intersperse them with other UI components. Second, there is a drawCallOptimize attribute in the component in LayaAir IDE. We set the true value for the drawCallOptimize attribute of the parent node of all texts. When this is set, the engine will automatically enable text merging optimization and extract all text to the top layer. Developers no longer need to deliberately adjust the sorting of atlas resources and texts to achieve the goal of automatic optimization of drawCall, and the optimization will be more Just be thorough. It should be reminded that the drawCallOptimize optimization solution will automatically raise the text to a display level, so it is not suitable for special needs where the text must be semi-occluded. Of course, in most cases the text should be displayed in full. If it is fully hidden, you can directly set the hidden attribute. Therefore, it is recommended that developers enable this optimization plan. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:12:06 "},"2D/TiledMap/readme.html":{"url":"2D/TiledMap/readme.html","title":"TiledMap","keywords":"","body":"Use TiledMap map1. Overview2. Export the Tiled Map supported by the engine2.1 Download and install Tiled Map Editor2.2 Tiled Map format supported by the export engine3. LayaAir engine uses Tiled Map map3.1 IDE selects laya.tiledmap component3.2 Create TiledMap map3.3 Control map3.4 Drag the map4. Tiled Map usage optimization4.1 Destroy the map4.2 Cache related4.3 Merge layers4.4 Remove covered gridsUse TiledMap map 1. Overview Tiled Map Editor is a free map editor that can be used to edit 2D game maps. The LayaAir engine supports parsing maps exported by Tiled Map. This article will introduce how to use maps exported by Tiled Map Editor in LayaAir engine development. Note: This article is only for developers who are familiar with and use the Tiled Map map tool. This article introduces how to use the map exported by Tiled Map Editor in LayaAir engine projects. Please find third-party tutorial documents for the content of the Tiled Map Editor tool itself. 2. Export the Tiled Map supported by the engine 2.1 Download and install Tiled Map Editor After opening the official homepage (http://www.mapeditor.org/), click the DownLoad at itch.io button directly to enter the download link (https://thorbjorn.itch.io/tiled). (Figure 2-1) If the official website is revised, you can also find the download link directly from the download page http://www.mapeditor.org/download.html. Find the corresponding system version link, download and install it (The version used in this document is Tiled 1.9.2). Tips： When you open the download, a payment page for sponsoring the software will pop up. If you don’t want to pay, you can directly click No thanks, just take me to the downloads, which will take you to a free download link. 2.2 Tiled Map format supported by the export engine The specific usage of the Tiled Map tool will not be discussed in this article. You can search for relevant tutorial documents on Baidu or Google. What has a lot to do with the engine is the format. Developers need to pay special attention. Generally, problems arise because they did not pay attention here. 2.2.1 Requirements for tile layer format when creating a map Click to create a new map. After setting the initial parameters such as map size and block size, click Save As to save it in the location you specified to complete the creation. However, the tile layer format requires special attention, because the LayaAir engine does not support the Base64 tile layer format of the Tiled Map map. So when creating a new map must be in CSV format, as shown in Figure 2-2. (Figure 2-2) If you made the wrong choice when creating, you can also change the tile layer format to CSV or XML in the properties panel, as shown in Figure 2-3. Base64-related formats are not supported. (Figure 2-3) 2.2.2 Export to json format In this example, we directly open the Tiled Map example map orthogonal-outside.tmx (located in the examples directory of the Tiled Map map installation directory), as shown in Figure 2-4 (Figure 2-4) When exporting, we need to choose the json format. In the file menu of the Tiled tool, click Save As to save the completed Tiled map as a json file type. In this example, it is named orthogonal.json (the file name is whatever the developer wants, just keep it consistent later), and click Save , and save it in the project directory (in this case, the project root directory \\assets\\resources\\TiledMap), as shown in Figure 2-5. (Figure 2-5) 2.2.3 Modify the album path and copy Tiled resources Just saving it as a json file is not enough, we also need to change the absolute path of the image to a relative path. We use the IDE to open the orthogonal.json we just saved and search for the keyword image. We will find that the default atlas path is located in the Tiled installation directory. As shown in Figure 2-6. (Figure 2-6) The path must not be in the Tiled installation directory. Therefore, we need to copy this image to the project directory first, at the same level as the previously saved orthogonal.json. As shown in Figure 2-7. (Figure 2-7) At the same time, we need to modify the format of the image file in the IDE to support transparent channels. (Figure 2-8) Then change the atlas path in orthogonal.json to a relative path, as shown in Figure 2-9 (Figure 2-9) The preparation phase is over and the coding phase begins... 3. LayaAir engine uses Tiled Map map 3.1 IDE selects laya.tiledmap component (Figure 3-1) As shown in Figure 3-1, the engine class library only supports tiledmap after checking the laya.tiledmap component. 3.2 Create TiledMap map 3.2.1 createMap API Description The createMap method in the laya.TiledMap class can create a TiledMap map. The basic parameter description is shown in Figure 3-2. (Figure 3-2) 3.2.2 Create map example const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { private tMap:Laya.TiledMap; onEnable() { //Create map object this.tMap = new Laya.TiledMap(); //Create Rectangle instance, viewport area var viewRect:Laya.Rectangle = new Laya.Rectangle(0, 0, Laya.stage.designWidth, Laya.stage.designHeight); //Create TiledMap map this.tMap.createMap(\"resources/TiledMap/orthogonal.json\", viewRect, new Laya.Handler(this, this.completeHandler)); } //Add the map to Scene2D private onLoaded(): void { this.tMap.mapSprite().removeSelf(); this.owner.addChild(this.tMap.mapSprite()); } //Callback when map loading is complete private completeHandler(e: any = null): void { this.onLoaded(); } } Compile and run the code, and the effect is as shown in Figure 3-3, indicating that the map has been created successfully. (Figure 3-3) 3.3 Control map To control the map, you must first load the json of the map, and then control it in the callback method. Below we will learn how to use it with examples. 3.3.1 Map zoom The scale attribute in the laya.map.TiledMap class can control the zoom ratio of the map. We follow the previous example, add a callback in the createMap method, and then use the scale attribute to zoom the map. The sample code is as follows: private onLoaded():void { this.tMap.mapSprite().removeSelf(); this.owner.addChild(this.tMap.mapSprite()); //Enlarge the original map 2 times this.tMap.scale = 2; } The running effect is shown in Figure 3-4. (Figure 3-4) 3.3.2 Set the center point of map zoom Obviously, the effect in Figure 3-4 is not what we want. After zooming in. Some parts are not shown. This is caused by the default zoom center point being in the center area of ​​the viewport. Viewport area and default zoom center point position The viewport area is set in the second parameter of the create map method (createMap), //Create map object this.tMap = new Laya.TiledMap(); //Create Rectangle instance, viewport area var viewRect:Laya.Rectangle = new Laya.Rectangle(0, 0, Laya.stage.designWidth, Laya.stage.designHeight); //Create TiledMap map this.tMap.createMap(\"resources/TiledMap/orthogonal.json\", viewRect, new Laya.Handler(this, this.completeHandler)); By looking at the code, we find that the viewport is set to (Laya.stage.designWidth, Laya.stage.designHeight). The default value of the method setViewPortPivotByScale that controls scaling is 0.5. Then the center point position is shown in Figure 3-5. (Figure 3-5) When the map is zoomed in twice (this.tMap.scale = 2;), since the zoom is performed based on the center points of the x and y axes of the viewport area, the effect shown in Figure 3-6 will be produced after zooming in. (Figure 3-6) Next, we will further understand the center point of the scale attribute through the animation 3-7, which shows the scaling effect from 0.1 to 2 times the original image ratio. (Animation 3-7) Use the setViewPortPivotByScale method to set the zoom center point What was introduced in the previous article is the default zoom center point effect. So how to set and change the zoom center point. The setViewPortPivotByScale() method in the laya.map.TiledMap class can set the center point of the viewport. The basic API description is shown in Figure 3-8. (Figure 3-8) The first parameter of the setViewPortPivotByScale() method scaleX is the scaling coordinate ratio in the X-axis direction, and scaleY is the scaling coordinate ratio in the Y-axis direction. For example: this.tMap.setViewPortPivotByScale(0.1,0.5); Code Description: Assume the viewport size is 1136*640 scaleX value 0.1 means that the coordinate of the x-axis scaling center point is 113.6 (1136*0.1) scaleY value 0.5 means that the coordinate of the y-axis scaling center point is 320 (640*0.5) When the code is running, the x-axis 113.6 and the y-axis 320 are used as the center point coordinates of the viewport for scaling. Set the zoom center point to the upper left corner of the viewport When the zoom center point of setViewPortPivotByScale is set to 0,0, it is the upper left corner of the viewport. Continuing to use the previous example, the coding is as follows: //Add the map to Scene2D private onLoaded(): void { this.tMap.mapSprite().removeSelf(); this.owner.addChild(this.tMap.mapSprite()); //Set the zoom center point to the upper left corner of the viewport this.tMap.setViewPortPivotByScale(0,0); //Enlarge the original map 2 times this.tMap.scale = 2; } Set the zoom center point to the upper left corner of the viewport, and then zoom in 2 times, the effect is as shown in Figure 3-9. (Figure 3-9) 3.4 Drag the map When the map is enlarged, it cannot be fully displayed. At this time, you need to drag the map to view all. In addition to the methods introduced in the previous article, dragging the map also requires the moveViewPort() (moving the viewport) method and the changeViewPort() (changing the viewport size) method. The basic descriptions of these two APIs are shown in Figures 3-10 and 3-11. (Figure 3-10) (Figure 3-11) Check the code directly below to understand the use of these two methods. const { regClass, property } = Laya; @regClass() export class Main extends Laya.Script { private tMap:Laya.TiledMap; private MapX:number = 0; private MapY:number = 0; private mLastMouseX:number; private mLastMouseY:number; onEnable() { //Create map object this.tMap = new Laya.TiledMap(); //Create Rectangle instance, viewport area var viewRect:Laya.Rectangle = new Laya.Rectangle(0, 0, Laya.stage.designWidth, Laya.stage.designHeight); //Create TiledMap map this.tMap.createMap(\"resources/TiledMap/orthogonal.json\", viewRect, new Laya.Handler(this, this.completeHandler)); } //Add the map to Scene2D private onLoaded(): void { this.tMap.mapSprite().removeSelf(); this.owner.addChild(this.tMap.mapSprite()); //Set the zoom center point to the upper left corner of the viewport this.tMap.setViewPortPivotByScale(0,0); //Enlarge the original map 3 times this.tMap.scale = 3; Laya.stage.on(Laya.Event.RESIZE,this,this.resize); Laya.stage.on(Laya.Event.MOUSE_DOWN, this, this.mouseDown); Laya.stage.on(Laya.Event.MOUSE_UP, this, this.mouseUp); this.resize(); } //Callback when map loading is complete private completeHandler(e: any = null): void { this.onLoaded(); } /** * Move map viewport */ private mouseMove():void{ var moveX:number = this.MapX - (Laya.stage.mouseX - this.mLastMouseX); var moveY:number = this.MapY - (Laya.stage.mouseY - this.mLastMouseY) //Move map viewport this.tMap.moveViewPort(moveX, moveY); } private mouseUp():void { this.MapX = this.MapX - (Laya.stage.mouseX - this.mLastMouseX); this.MapY = this.MapY - (Laya.stage.mouseY - this.mLastMouseY); Laya.stage.off(Laya.Event.MOUSE_MOVE, this, this.mouseMove); } private mouseDown():void { this.mLastMouseX = Laya.stage.mouseX; this.mLastMouseY = Laya.stage.mouseY; Laya.stage.on(Laya.Event.MOUSE_MOVE, this, this.mouseMove); } /** * Change viewport size * Reset the map viewport area */ private resize():void { //Change the viewport size this.tMap.changeViewPort(this.MapX, this.MapY, Laya.stage.designWidth, Laya.stage.designHeight); } } The code running effect is shown in Figure 3-12. (Animation 3-12) 4. Tiled Map usage optimization 4.1 Destroy the map When the Tiled Map is no longer used, it needs to be destroyed using the destroy() method to recycle the occupied memory. For example: this.tMap.destroy(); 4.2 Cache related 4.2.1 Turn on and off automatic caching When the LayaAir engine uses TiledMap, plots without animation will be automatically cached by default, and the cache type defaults to normal. //Automatically cache plots without animation this.tMap.autoCache = true; //The type of automatic caching. It is recommended to use normal when the map is large. this.tMap.autoCacheType = \"normal\"; //Eliminate the gaps caused by scaling, that is, remove the black edges this.tMap.antiCrack = true; The above code attributes are the default values ​​of the engine. In most cases, you can keep the default values ​​without additional settings. So why introduce it again? Because sometimes, black edges (gaps) will appear in the cached Tiled map. Despite the antiCrack attribute, most black edges caused by normal caching can be eliminated. But if the occasional black border problem remains unresolved. The problem of black edges (gaps) can be solved by turning off automatic caching. 4.2.2 Set cache block size Recommended settings for cache blocks TiledMap maps are composed of unit blocks. If the original size is maintained during caching, performance will be affected when there are many small image blocks. Therefore, it is recommended to turn on the cache block setting and set the size of the cache block to about 512 pixels, which must be an integer multiple of the original small image block. For example, the single image block size in the example in this article is 16*16, then the cache block can be set to 32 times 16, which is 512*512. If the single image is 15*15, the cacheable block can be set to 510*510 (34 times), and so on. Try to set it around 512 under the premise of an integer multiple of the original block. Recommended is 512*512. Specific setting method of cache block The settings of the cache block need to be set when createMap (creating the map). Set the fourth parameter gridSize, the example is as follows: //Create a Rectangle instance for the second parameter, the viewport area var viewRect:Laya.Rectangle = new Laya.Rectangle(0, 0, Laya.Browser.width, Laya.Browser.height); //Create a Point object instance with a size of 512*512 for the fourth parameter gridSize var gridSize:Laya.Point = new Laya.Point(512, 512); //Create TiledMap map this.tMap.createMap(\"res/TiledMap/orthogonal.json\",viewRect, Laya.Handler.create(this,this.onMapLoaded), null, gridSize); 4.3 Merge layers 4.3.1 Turn on merged layers When there are multiple layers in TiledMap, turn on the attribute enableMergeLayer of the merged layer to merge the layers, which will improve performance. The way to turn it on is: //Enable layer merging this.tMap.enableMergeLayer = true; Tips: It should be noted that if you need to operate on the layers before merging, you cannot merge them directly. Because after merging, the layers before merging cannot be operated. 4.3.2 Layer merging and grouping If the layers are not grouped in TiledMap, then when the layers are merged, all the layers will be merged together. Therefore, it is necessary to divide it into multiple layers and operate them separately. Layers can be grouped in a TiledMap. TiledMap layer grouping method Open the TiledMap map editor, select the layer to be grouped, and add a string type attribute named layer in the layer's custom property bar. The operation is shown in Figure 4-1. (Pic 4-1) Click OK. After the addition is completed, all layers with custom attribute layers added will be added. Set the group name. For example, if we set the group name of block layer 2 and block layer 3 to layaAir, then the layer named layaAir will be merged into the same layer after enableMergeLayer is turned on. The operation is shown in Figure 4-2. (Figure 4-2) When merging layers is turned on, the layer attribute can be added to the layer attributes. At runtime, adjacent layers with the same layer attributes will be merged to improve performance. 4.4 Remove covered grids If the underlying grid is occluded, and the occluded plot is not transparent, then the occluded part is directly removed without being rendered, which can improve performance. The method to enable removal of overwriting is: //Remove the parts covered by non-transparent blocks this.tMap.removeCoveredTile = true; Tips： If it is opened, it is impossible to operate the removed part. Therefore, you must confirm before turning on this function and no longer operate on the removed part. Prerequisites for removeCoveredTile to be enabled If the type attribute is not set for the tile in the Tiled Map, then even if removeCoveredTile is turned on, it will be invalid. Therefore, before turning it on, you need to add a custom attribute type for the tile in the TiledMap editor and set it to 1. How to set the tile type in Tiled Map In the tile panel, click tile editing to open the tile terrain editing panel. The operation is shown in Figure 4-3. (Figure 4-3) In the tile terrain editing panel, select the terrain, click the + icon in the custom attribute bar, and add the type attribute of the int type. Then click OK to complete the addition. The operation is shown in Figure 4-4. (Figure 4-4) After completing the addition, set the type attribute value to 1. The operation is shown in Figure 4-5. (Figure 4-5) As long as the custom attribute type is set to 1, when removeCoveredTile is turned on. When blocked and invisible, they can be removed to improve performance. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:51:36 "},"2D/performanceOptimization/readme.html":{"url":"2D/performanceOptimization/readme.html","title":"performance Optimization","keywords":"","body":"Performance optimization1. Memory optimization method1.1 Optimize memory through object pool1.2 Release memory1.3 Resource uninstallation1.4 About filters and masks2. Rendering optimization method2.1 Optimize Sprite2.2 Optimize DrawCall2.3 Optimizing Canvas2.4 CacheAs2.5 Text Stroke2.6 Skip text formatting and render directly3. Reduce CPU usage3.1 Reduce dynamic attribute lookup3.2 Recovery of performance consumption3.3 How to obtain the boundary of the displayed object3.4 Change frame rate based on activity status3.5 Using callLater3.6 Picture/Atlas Loading4. Other optimization strategies4.1 Reduce the number of particles used4.2 Minimize the use of rotation, scaling, alpha and other attributes4.3 Do not create objects and complex calculations in Timer loops4.4 Use autoSize and getBounds as little as possible4.5 The execution of functions caught by try catch will become very slow5. Use chrome’s performance analyzer5.1 CPU usage analysis5.2 Memory usage analysis6. Use of texture compressionPerformance optimization 1. Memory optimization method 1.1 Optimize memory through object pool Object pool optimization is a very important optimization method in game development and is also one of the important factors affecting game performance. There are many objects in the game that are constantly being created and removed, such as the creation and removal of character attack bullets, special effects, the destruction and refreshing of NPCs, etc. The creation process consumes a lot of performance, especially when the number is large. . Object pool technology can solve the above problems very well. When objects are removed and disappear, they are recycled to the object pool. When new objects are needed, they are directly taken out of the object pool and used. The advantage is that it reduces the overhead when instantiating the object, allows the object to be used repeatedly, and reduces the chance of new memory allocation and garbage collector running. Note: When the object is removed, it is not immediately erased from the memory. Only when the memory is deemed to be insufficient, the garbage collection mechanism will be used to clear it. Clearing is very memory intensive and may cause lag. Using the object pool will reduce the garbage objects of the program and effectively improve the running speed and stability of the program. For specific usage, please refer to the \"Object Pool\" document 1.2 Release memory The JavaScript runtime cannot start the garbage collector. To ensure that an object can be recycled, all references to the object need to be deleted. The destroy() method provided by Sprite will help set the internal reference to null. For example, the following code ensures that the object can be garbage collected: //Create a Sprite instance var sp:Laya.Sprite = new Laya.Sprite(); //Set the sp internal reference to null sp.destroy(); When an object is set to null, it is not immediately removed from memory. The garbage collector will only run when the system thinks memory is low enough. Memory allocation (not object deletion) triggers garbage collection. Garbage collection can consume a lot of CPU during garbage collection and affect performance. Try to limit the use of garbage collection by reusing objects. Also, set references to null whenever possible so that the garbage collector spends less time looking for the object. Sometimes (for example, two objects refer to each other), it is impossible to set both references to null at the same time. The garbage collector will scan the unreachable objects and clear them, which will consume more performance than reference counting. 1.3 Resource uninstallation There are always many resources loaded when the game is running. These resources should be unloaded in time after use, otherwise they will remain in the memory. The following example shows how to compare the resource status before and after loading the resource: var assets: Array = [] assets.push(\"resources/apes/monkey0.png\"); assets.push(\"resources/apes/monkey1.png\"); assets.push(\"resources/apes/monkey2.png\"); assets.push(\"resources/apes/monkey3.png\"); Laya.loader.load(assets).then(()=>{ for(var i:number = 0, len: number = assets.length; i 1.4 About filters and masks Try to minimize the use of filter effects. When filters (BlurFilter and GlowFilter) are applied to a display object, two bitmaps are created in memory at runtime. Each bitmap is the same size as the display object. The first bitmap is created as a rasterized version of the display object and then used to generate another bitmap with the filter applied: (Picture 1-1) Two bitmaps in memory when applying filter When one of the properties of the filter or display object is modified, both bitmaps in memory are updated to create the resulting bitmap, which can take up a lot of memory. In addition, this process involves CPU calculations, which will reduce performance when updated dynamically. ColorFiter's GPU consumption under WebGL is negligible. As a best practice, whenever possible, use bitmaps created with image authoring tools to simulate filters. Avoiding creating dynamic bitmaps at runtime can help reduce CPU or GPU load. Especially an image that has a filter applied and is not being modified. 2. Rendering optimization method 2.1 Optimize Sprite Try to reduce unnecessary levels of nesting and reduce the number of Sprites. Try to remove objects in non-visible areas from the display list or set visible=false. For containers with a large amount of static content or content that changes infrequently (such as buttons), you can set the cacheAs attribute for the entire container, which can greatly reduce the number of Sprites and significantly improve performance. If there is dynamic content, it is best to separate it from the static content so that only the static content is cached. In the Panel, direct sub-objects outside the panel area (the sub-objects of the sub-objects cannot be judged) will not be rendered. Sub-objects beyond the panel area will not be consumed. 2.2 Optimize DrawCall Setting cacheAs for complex static content can greatly reduce DrawCall. Making good use of cacheAs is the key to game optimization. Try to ensure that the rendering order of pictures in the same atlas is next to each other. If different atlases are cross-rendered, the number of DrawCalls will increase. Try to ensure that all resources in the same panel use one atlas, which can reduce submission batches. 2.3 Optimizing Canvas When optimizing Canvas, we need to pay attention not to use cacheAs in the following situations: The object is very simple, such as a word or a picture. Setting cacheAs=\"bitmap\" will not only not improve performance, but will also cause performance loss. There are frequently changing contents in the container, such as an animation or countdown in the container. If cacheAs=\"bitmap\" is set to this container, performance will be lost. You can determine whether the Canvas cache is being refreshed by looking at the first value of the Canvas statistics. 2.4 CacheAs Setting cacheAs can cache the display object as a static image. When cacheAs is used, if the sub-object changes, it will be automatically re-cached. At the same time, the reCache method can also be manually called to update the cache. It is recommended to cache complex content that does not change frequently as static images, which can greatly improve rendering performance. cacheAs has three optional values: \"none\", \"normal\" and \"bitmap\". The default is \"none\", no caching is done. When the value is \"normal\", command caching is performed. When the value is \"bitmap\", use renderTarget cache. It should be noted here that the renderTarget cache mode under webGL has a size limit of 2048. Exceeding 2048 will increase additional memory overhead. In addition, the overhead of continuous redrawing is relatively high, but drawcalls will be reduced and rendering performance will be the highest. The command cache mode under webGL will only reduce node traversal and command organization, but will not reduce drawcalls, and the performance is medium. After setting cacheAs, you can also set staticCache=true to prevent automatic updating of the cache, and you can manually call the reCache method to update the cache. cacheAs mainly improves performance in two ways. One is to reduce node traversal and vertex calculation; the other is to reduce drawCall. Making good use of cacheAs will be a powerful tool for engine optimization performance. The following example draws 10,000 texts (depending on computer performance, this example is 10,000): class Test { private text:Laya.Text; constructor() { Laya.init(550,400,Laya.WebGL); Laya.Stat.show(); var textBox=new Laya.Sprite(); for(var i=0;i The following is a screenshot of the runtime on the author's computer. The FPS is stable at around 52. (Figure 2-1) When we set the container where the text is located to cacheAs, as shown in the example below, the performance is greatly improved, and the FPS reaches 60 frames. //...Omit other code var textBox=new Laya.Sprite(); textBox.cacheAs=\"bitmap\"; //...Omit other code (Figure 2-2) 2.5 Text Stroke At runtime, text with a stroke calls the drawing command one more time than text without a stroke. At this time, the CPU usage of text is proportional to the number of texts. Therefore, try to use alternatives to accomplish the same needs. · For text content that rarely changes, cacheAs can be used to reduce performance consumption. · For text fields whose content changes frequently but uses a small number of characters, you can choose to use bitmap fonts. 2.6 Skip text formatting and render directly In most cases, a lot of text does not require complex typesetting and simply displays a line of text. In order to cater to this demand, Text provides a method called changeText that can directly skip typesetting. this.text.text=\"text\"; Laya.stage.addChild(this.text); //The text content is only updated later. Using changeText can improve performance. this.text.changeText(\"text changed.\"); Text.changeText will directly modify the last instruction for drawing the text in the drawing instruction. This behavior of the previous drawing instruction still existing will cause changeText to be used only in the following situations: · The text is always one line. · The style of the text is always the same (color, weight, italics, alignment, etc.). Even so, such needs are still often used in actual programming. 3. Reduce CPU usage 3.1 Reduce dynamic attribute lookup Any object in JavaScript is dynamic and you can add attributes at will. However, searching for an attribute among a large number of attributes can be time-consuming. If you need to use a certain attribute value frequently, you can use a local variable to save it: foo() { var prop=this.target.prop; //use prop this.process1(prop); this.process2(prop); this.process3(prop); } 3.2 Recovery of performance consumption When using functions that consume performance every day, especially loop processing, when not in use, be sure to recycle them in time or stop the loop. LayaAir provides two timer loops to execute code blocks. The execution frequency of Laya.timer.frameLoop depends on the frame frequency. The current frame rate can be viewed through Stat.FPS. The execution frequency of Laya.timer.loop depends on the time specified by the parameter. Laya.timer.frameLoop(1, this, this.animateFrameRateBased); Laya.stage.on(\"click\", this, this.dispose); dispose() { Laya.timer.clear(this, this.animateFrameRateBased); } When the life cycle of an object ends, remember to clear its internal Timer 3.3 How to obtain the boundary of the displayed object In relative layout, it is often necessary to correctly obtain the bounds of the displayed object. There are many ways to get the boundaries of the displayed object, and it is necessary to know the differences. Use getBounds/getGraphicBounds. var sp=new Laya.Sprite(); sp.graphics.drawRect(0,0,100,100,\"#FF0000\"); var bounds:Laya.Rectangle=sp.getGraphicBounds(); Laya.stage.addChild(sp); getBounds can meet most needs, but because it needs to calculate the boundary, it is not suitable for frequent calls. Set the container's autoSize to true. var sp=new Laya.Sprite(); sp.autoSize=true; sp.graphics.drawRect(0,0,100,100,\"#FF0000\"); Laya.stage.addChild(sp); The above code can correctly obtain the width and height at runtime. autoSize will be recalculated when the width and height are obtained and the state of the display list changes (autoSize calculates the width and height through getBoudns). So it is not advisable to apply autoSize to a container with a large number of sub-objects. If size is set, autoSize will not take effect. Get the width and height after using loadImage: var sp=new Laya.Sprite(); sp.loadImage(\"res/apes/monkey2.png\",0,0,0,0,Laya.Handler.create(this,function() { console.log(sp.width,sp.height); })); Laya.stage.addChild(sp); loadImage can correctly obtain the width and height only after the callback function after loading is triggered. Directly call the size setting: Laya.loader.load(\"res/apes/monkey2.png\",Laya.Handler.create(this,function() { var texture=Laya.loader.getRes(\"res/apes/monkey2.png\"); var sp=new Laya.Sprite(); sp.graphics.drawTexture(texture,0,0); sp.size(texture.width,texture.height); Laya.stage.addChild(sp); })); Using Graphics.drawTexture does not automatically set the width and height of the container, but you can use the width and height of the Texture to assign it to the container. Needless to say, this is the most efficient way. Note: getGraphicsBounds is used to obtain the width and height of vector drawing. 3.4 Change frame rate based on activity status There are three modes of frame rate, Stage.FRAME_FAST In fast mode, the maximum FPS is the maximum frame rate of the monitor. If the maximum frame rate of the monitor is 60, then the maximum FPS is 60. If the maximum frame rate of the monitor is 120, then the maximum FPS is 120. Stage.FRAME_SLOW In slow mode, the maximum FPS is half of the monitor's maximum frame rate. During the game running, the engine will discard every other frame. If it can actually reach 40 frames, then the final frame rate of the game is only 20. If the frame rate can reach 100, then the final frame rate can only be 50. Stage.FRAME_MOUSE Mouse mode selectively switches between fast mode and slow mode. Sometimes the game does not need to be executed at full frame rate. For example, at 60 frames full frame, 30FPS can already meet the response of human vision in most cases, but mouse interaction At this time, 30FPS may cause incoherence in the picture, so Stage.FRAME_MOUSE came into being. The following example shows moving the mouse on the canvas at the frame rate of Stage.FRAME_SLOW so that the ball follows the movement of the mouse: Laya.init(this.Browser.width,this.Browser.height); Laya.Stat.show(); Laya.stage.frameRate=Laya.Stage.FRAME_SLOW; var sp=new Laya.Sprite(); sp.graphics.drawCircle(0,0,20,\"#990000\"); Laya.stage.addChild(sp); Laya.stage.on(Laya.Event.MOUSE_MOVE,this,function() { sp.pos(Laya.stage.mouseX,Laya.stage.mouseY); }); (Figure 3-1) At this time, the FPS displays 30, and when the mouse moves, you can feel that the update of the ball position is inconsistent. Set Stage.frameRate to Stage.FRAME_MOUSE: Laya.stage.frameRate = Laya.Stage.FRAME_MOUSE; (Figure 3-2) At this time, after moving the mouse, the FPS will display 60, and the screen smoothness will be improved. After the mouse remains motionless for 2 seconds, FPS will return to 30 frames. 3.5 Using callLater callLater delays the execution of the code block until before rendering of this frame. If the current operation frequently changes the state of an object, you may consider using callLater to reduce repeated calculations. Consider a figure for which setting any appearance-changing properties will cause the figure to be redrawn: var rotation=0, scale=1, position=0; private function setRotation(value):void { this.rotation=value; update(); } private function setScale(value):void { this.scale = value; update(); } private function setPosition(value):void { this.position = value; update(); } public function update() { console.log('rotation: ' + this.rotation + '\\tscale: ' + this.scale + '\\tposition: ' + this.position); } Call the following code to change the status: setRotation(90); setScale(2); setPosition(30); The printed result of the console is: rotation: 90scale: 1position: 0 rotation: 90scale: 2position: 0 rotation: 90scale: 2position: 30 update was called three times, and the final result was correct, but the first two calls were unnecessary. Try changing the three updates to: Laya.timer.callLater(this, update); At this time, update will only be called once, and it is the result we want. 3.6 Picture/Atlas Loading After completing the loading of images/atlases, the engine will start processing image resources. If an image gallery is loaded, each sub-image will be processed. If a large number of images are processed at one time, this process may cause lengthy delays. In the resource loading of the game, resources can be loaded according to levels, scenes, etc. The fewer images you have to process at the same time, the more responsive the game will be at that time. After the resource is used, it can also be unloaded to release memory. 4. Other optimization strategies 4.1 Reduce the number of particles used Since particles are vector drawing, using a large number of particles will put a lot of pressure on the CPU. However, GPU computing can be used in WebGL mode, which can reduce the pressure on the CPU. However, it should be controlled as much as possible, especially on mobile platforms, to reduce usage. 4.2 Minimize the use of rotation, scaling, alpha and other attributes Attributes such as rotation, scaling, alpha, etc., these attributes will consume performance, but the engine uses WebGL rendering mode, which greatly optimizes performance. 4.3 Do not create objects and complex calculations in Timer loops Since the loop() and frameLoop() methods of Timer will be continuously executed in a loop, when creating objects and complex calculations, it will cause a lot of performance consumption in the loop. Therefore, try not to create objects in the loop as much as possible. Objects and complex calculations. 4.4 Use autoSize and getBounds as little as possible autoSize() and getBounds() require a lot of calculations and have a great impact on performance, so use them as little as possible. 4.5 The execution of functions caught by try catch will become very slow Try to reduce the use of try catch in the project. The execution of functions caught by try catch will become very slow. 5. Use chrome’s performance analyzer Performance Analyzer (Profiles) is part of the chrome developer tools. You can open the chrome developer tools by right-clicking on the page and selecting Inspect Element or pressing F12 on the Google Chrome page. Then click Profiles to switch to the Performance Analyzer (Profiles) panel. 5.1 CPU usage analysis Start CPU Performance Analyzer Select Record JavaScript CPU Profile and click the Start button or the solid dot in the upper left corner. At this time, Chrome will start to record the execution of the method of the current web page. As shown in Figure 5-1. (Figure 5-1) End the monitoring of CPU performance analyzer To end the monitoring recording of this performance analyzer, click the Stop button (or the solid red circle on the left). As shown in Figure 5-2. (Figure 5-2) View CPU Performance Analyzer records After monitoring ends, a monitoring result file will be listed under Profiles on the left. Click to open this monitoring result file. As shown in Figure 5-3 (Figure 5-3) Monitoring results are displayed in the form of data tables. We can find the function names provided in Function based on the consumption ranking, and optimize the places where performance consumption is large. 5.2 Memory usage analysis Start memory analysis Select Take Heap Snapshot and click the Take Snapshot button (you can also click the black solid circle on the left), as shown in Figure 5-4. (Figure 5-4) The generated memory snapshot file records the number of current web page objects, the memory size occupied, etc. in the form of a data table. Memory snapshot record After starting memory analysis, a memory snapshot record file of the current web page will be generated soon under the Profiles column on the left. Click to view relevant data, as shown in Figure 5-5. (Figure 5-5) Memory snapshot analysis After taking the first memory snapshot, click the dot in the upper left corner to record a new memory snapshot. Click to select the second memory snapshot to select the Comparison mode that changes between this second snapshot and the first snapshot. Optimize web pages through analysis. (Figure 5-6) (Figure 5-7) 6. Use of texture compression Benefits of using texture compression: Reduce memory, especially for mobile applications. The memory usage should not be too large, otherwise low-end machines will easily crash. Reduce bandwidth. For mobile game applications, a large number of textures will be transferred to the GPU during rendering. If there is no limit, it will not only seriously affect the rendering performance, but also cause serious heat generation. For specific usage, please refer to the \"Texture Compression\" document Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:47:40 "},"2D/dom/readme.html":{"url":"2D/dom/readme.html","title":"DOM","keywords":"","body":"LayaAir and native DomSVG of LayaAirDom element Image of LayaAirDom element video of LayaAirLayaAir's dom element FileLayaAir's dom element script tagLayaAir's dom element iframeLayaAir and native Dom In development projects, developers will inevitably encounter DOM element support, but it is not supported or the support is incomplete in LayaAir. So in this section we will take a look at some techniques encountered in development. SVG of LayaAir What is svg? Probably most developers have heard of this term, or know that it is a vector image description format specified by w3c. We will not describe some definitions and history of svg here. Interested developers can refer to here. But it is rarely used in projects. However, the power of svg cannot be ignored. Some simple graphics can be described in a few lines of text without the need for network loading. For example, rich artistic characters, strange-shaped graphics, text perspective effects, etc. may be difficult to implement using programs, such as the following: What to do if there is this kind of text in your project? Maybe what we think of is art producing pictures. Is there an easier way? Here we choose to use svg for processing. We know that using div+css styles in dom elements to display this effect is the simplest and fastest way. So let's use css styles to show this effect. Let's see how a simple script can achieve this effect. var data = '' + '' + '' + 'I like ' + '' + 'cheese' + '' + '' + ''; var DOMURL = window.URL || window.webkitURL || window; var img = new Image(); var svg = new Blob([data], {type: 'image/svg+xml'}); var url = DOMURL.createObjectURL(svg); img.src = url; img.style.position =\"absolute\"; img.style.zIndex = 99999 document.body.appendChild(img); How to run the above code? Open Google Chrome, open a blank web page, F12, paste the above code into the console, and then press Enter, you can see the effect of the screenshot above. Or create a new html, paste the code in it, and open it with a browser. Isn't it very simple? Then we can modify the displayed text arbitrarily. Developers can modify it and try it out to see the effect. Let’s briefly introduce this code. Among them, data is the data format of svg. For this, please refer to the definition and description of svg. //Here is the key point. We set the text effect through the css style supported by svg. Text-shadow sets the css style effect of the text. If the developer wants to change the text style, he can modify the style. The above is in JavaScript, using the native dom element img for display, so what should we do if we want to use it in the game? This is actually very simple. Now that we have used img to display it on the page, the next thing we have to do is how to apply and display this img in the project. Let's create a new project. The code looks like this: var data: string = \"data:image/svg+xml,\" + '' + '' + '' + 'I like ' + '' + 'cheese' + '' + '' + ''; var sp: Laya.Sprite = new Laya.Sprite(); sp.loadImage(data, 0, 0, 200, 200); Laya.stage.addChild(sp); Pass the data as the URL to the loadImage method, and the engine will help us load, decode and display it. The parameters in the loadImage method not only receive the URL of the address, but also receive the base64 and svg formats. Compile and run the above code and we see the effect in the picture below. Summary: The above code gives us a good inspiration. In the project, our special artistic words can be simpler and more convenient using this method. Developers can find some more gorgeous effects on their own, such as 3D perspective effects, mixed graphics and text, shadows, reflections, etc. This method not only reduces the bandwidth of the network, but more importantly, makes it easier for us to modify it from time to time. Once a style is set, it can be applied when exporting in the project. Would it be more efficient and faster if the above method was used instead of bitmap fonts? Dom element Image of LayaAir In HTML5, the image tag is powerful. We don’t want to introduce too much about its features here. Here we introduce simple common forms. QR code One of the more common functions is to display the current QR code address in the project. The user can recognize it by long pressing. To generate a QR code here, we use a third-party js library to generate a QR code. The class library code can be downloaded from GitHub. This [address] is used here (https://github.com/davidshimjs/qrcodejs). Create a new project and add the downloaded qrcode.js to index.html. For the API of qrcode, please refer to address. The specific logic code is as follows: var div:any = Laya.Browser.document.createElement(\"div\"); this.qrcode = new Laya.Browser.window.QRCode(div,{ width:100, height:100 }); var url:string = \"http://layabox.com/\"; this.qrcode.makeCode(url); Laya.stage.once(\"click\",this,this.clickHandler); this.qrcodeSp = new Laya.Sprite(); Laya.stage.addChild(this.qrcodeSp); Compile and run the above code, then click on the stage to see that the QR code has been displayed on the stage. You can scan it with your mobile phone and find that your mobile phone has jumped to the official website. Note: The QR code generated at this time has no response when long pressed in WeChat or the browser, because the QR code generates a canvas tag instead of an image tag. So if you want to long press to pop up the recognition option, you can only use the image tag. This can be extended by developers themselves. Dom element video of LayaAir Live video In the HTML5 era, video playback basically uses the video tag. If you don’t have rich experience in video playback, the best choice is to use a mature playback plug-in. The currently popular ones are video.js, hls.js, plyr .js. It is excellent in terms of compatibility, experience and performance. Official demos of these plug-ins are provided. For example, https://plyr.io/, http://video-dev.github.io/hls.js/demo/, http://codepen.io/sampotts/pen/JKEMqB. Let's take Plyr + hls.js as an example to see how we should write it in LayaAir. Add the following code to the index.html file: Player style file, Add video tag. Name the id \"player\", which we will use in the program later. This is the class library used by the player. Developers remember to download it to their own projects or servers in the production environment. The following is the logic of the main class: class LayaUISample { constructor() { //Initialize the engine Free.heat(0,0); var Hls:any = Laya.Browser.window.Hls;//Get a reference to Hls. var plyr:any = Laya.Browser.window.plyr;//Get a reference to plyr //Get the video object, which is the tag named \"player\" on the page var video:any = Laya.Browser.document.querySelector('#player'); if(Hls.isSupported()){ var hls:any = new Hls(); //Load m3u8 source hls.loadSource('http://content.jwplatform.com/manifests/vM7nH0Kl.m3u8'); hls.attachMedia(video); hls.on(Hls.Events.MANIFEST_PARSED,function():void{ video.play(); }); } plyr.setup(video); } } new LayaUISample; Compile and run the code and find that the webpage can already play videos. Developers may notice that when we initialize the engine here, it looks like this: Laya.init(0,0);//Initialize the engine;Set the size to 0 because we have no interaction with the stage here. So we set it to 0 here, we don't even need to initialize it. If the developer's project contains logic that interacts with the stage, you can set the size that suits you. During the playback process, developers can open Google's console with F12, switch to the Network tab and see that our video is a ts file. As the playback progresses, more and more files are found. In fact, this is playback based on the hls protocol. The basic principle of this technology is to cut video files or video streams into small pieces (ts) and create index files (m3u8). For deeper principles, such as video decoding and video frame data, developers can refer to the following: https://developer.apple.com/streaming/ https://developer.mozilla.org/zh_CN/docs/Web/API/MediaSource https://github.com/nickdesaulniers/netfix https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement In the above example, we use hls+plyr to play. For other methods, developers please refer to this tutorial for expansion. Camera The support of HTML5 video as a camera browser is limited, and it requires https protocol. The support of Google and the new version of WeChat is still good. If your compatibility requirements are not that high, you can try adding the camera function. Let's first look at the example given on mdn. https://mdn.github.io/webaudio-examples/stream-source-buffer/ The developer uses a mobile phone or WeChat to open this address to test the support of your mobile phone. This is a test connection, and the protocol is https. Developers should pay attention to this when calling the camera. Your remote address must be https. For more information, please refer here: https://github.com/mdn/webaudio-examples The link here is the sound and video examples given by mdn. LayaAir also has corresponding packages for cameras. Let’s take a look at how to use them. class Main { private video:Laya.Video; constructor() { //Initialize the engine Laya.init(Laya.Browser.width,Laya.Browser.height); if(Laya.Media.supported() === false){ alert(\"The current browser does not support\"); } else{ this.showMessage(); var options:any = { audio:true, video:{ facingMode: { exact: \"environment\" }, // Rear camera, the default value is, you can also not set it to. width: Laya.stage.width, height:Laya.stage.height } }; Laya.Media.getMedia(options,Laya.Handler.create(this,this.onSuccess),Laya.Handler.create(this,this.onError)); } } private showMessage():void{ var eg:Laya.Text = new Laya.Text(); Laya.stage.addChild(tex); tex.text = \"Click the stage to play and pause\"; tex.color = \"#ffffff\"; tex.fontSize = 100; tex.valign = \"middle\"; tex.align = \"center\"; tex.size(Laya.stage.width,Laya.stage.height); } private onSuccess(url:string):void{ this.video = new Laya.Video(Laya.stage.width,Laya.stage.height); this.video.load(url); Laya.stage.addChild(this.video); Laya.stage.on(\"click\",this,this.onStageClick); } private onerror(error:Error):void{ alert(error.message); } private onStageClick():void{ //Switch play and pause if(!this.video.paused){ this.video.pause(); } else{ this.video.play(); } } } new Main; Compile and run the above example and find that it cannot be opened. This is normal. To run this example, you need to build an https server yourself. Then use your mobile phone to open the index.html corresponding to this address. It is also very simple to build a simple https server. Here we can use Laya's command line tool. Download address https://nodejs.org/en/ for installation. After the installation is complete, open the cmd command line, enter npm install -g layacmd and wait for the installation to complete. Find the index.html we just compiled. Hold down shift+right click to open the cmd window here and enter layacmd open, and then a static server of http and htpps will be started. According to the address output from the command line, we then use the mobile Google Chrome or WeChat to access this address. For example, here is https://10.10.20.34:8001/index.html. LayaAir's dom element File In project development, we may need to allow users to upload pictures. We need to use the file tag of html5 for this (WeChat needs to use the interface provided by WeChat. We will talk about the following tutorials specifically in the WeChat tutorial. Other browsers may also have compatibility issues). Below we write a simple example. class Main { private video:Laya.Video; constructor() { //Initialize the engine Laya.init(100,100); var file:any = Laya.Browser.document.createElement(\"input\"); file.type = \"file\"; file.style.position = \"absolute\"; file.style.zIndex = 999; Laya.Browser.document.body.appendChild(file);//Add to the stage var fileReader:any = new Laya.Browser.window.FileReader(); file.onchange = function(e:any):void { if(file.files.length){ fileReader.readAsDataURL(file.files[0]); } }; fileReader.onload = function(evt):void { if(Laya.Browser.window.FileReader.DONE == fileReader.readyState) { var sp:Laya.Sprite = new Laya.Sprite(); sp.loadImage(fileReader.result,0,0,300,300); Laya.stage.addChild(sp); } } } } new Main; Compile the above code and click the button. Select a picture file or camera to take a photo, and find that the picture has been displayed on the stage. Then a simple program to call the photo album or camera is completed. But we found this \"button\" to be very ugly. So how to change the button style? This needs to be handled with the help of css style. The traditional approach is to set the transparency value of this button to 0, and then place a button that overlaps it instead. By changing his style through this illusion, he is actually the one who clicked. It’s just that users can’t feel it. So let's modify it and see how to change the style. //Create a hidden file and align it with the button. The position is consistent. Here we default to the 0 o'clock position. var file:any = Laya.Browser.document.createElement(\"input\"); //Set file style file.style=\"filter:alpha(opacity=0);opacity:0;width: 150px;height:60px;\"; file.type = \"file\"; //The setting type is file type. file.accept=\"image/png\";//Set the file format to png; file.style.position =\"absolute\"; file.style.zIndex = 999; Take a look at the complete code below: class Main { private video:Laya.Video; constructor() { //Initialize the engine Laya.init(100,100); var skins:any = [\"res/a.png\"]; Laya.loader.load(skins,Laya.Handler.create(this,this.onUIAssetsLoaded)); } private onUIAssetsLoaded():void{ var btn:Laya.Button = new Laya.Button(\"res/a.png\"); Laya.stage.addChild(btn); //Create a hidden file and align it with the button. The position is consistent. Here we default to the 0 o'clock position. var file:any = Laya.Browser.document.createElement(\"input\"); //Set file style file.style=\"filter:alpha(opacity=0);opacity:0;width: 150px;height:60px;\"; file.type = \"file\"; //The setting type is file type. file.accept=\"image/png\";//Set the file format to png; file.style.position =\"absolute\"; file.style.zIndex = 999; Laya.Browser.document.body.appendChild(file);//Add to page; var fileReader:any = new Laya.Browser.window.FileReader(); file.onchange = function(e:any):void { if(file.files.length>0) { fileReader.readAsDataURL(file.files[0]); } }; fileReader.onload = function(evt):void { if(Laya.Browser.window.FileReader.DONE == fileReader.readyState) { var sp:Laya.Sprite = new Laya.Sprite(); sp.loadImage(fileReader.result,0,0,100,100); Laya.stage.addChild(sp); } }; } } new Main; Compile and run the code, and you can see that the ugly dom button is gone. When we click our customized button, we can also select pictures and display them on the stage. In the above example, we overlapped it at the origin, set the transparency to 0, and disguised it as invisible. Developers can try to put it in other locations for testing. This tutorial does not cover the specific implementation. For other file APIs, please refer to the relevant instructions of mdn and w3c. In addition to displaying on the stage, there may also be uploading operations to the server. In this case, FormData can be used. This developer can try it. LayaAir's dom element script tag Sometimes our projects have a lot of large js files. Loading them all at once is not only a waste of traffic, but also causes page lags, resulting in an extremely poor user experience. Although compression and obfuscation can be used to reduce the size, the amount of code will be very large for a slightly larger project. Or the local js file is unnecessary when the first screen is loaded. At this time, we need to load it at the appropriate time, so splitting the files and modules is very necessary. Splitting the file involves out-of-the-box loading. Then the script tag will come in handy at this time. This function can be achieved by loading the remote script through the script's src. It can also be achieved by setting the innerHTML of the script. Of course, there is also the third type of eval. Below we explain the usage in each of these situations. Achieved by setting src Script creation can be added to the page manually or dynamically created through code. Here we take code creation as an example to illustrate. Let’s get into the code first. The code logic is as follows: class Main { private video:Laya.Video; constructor() { //Initialize the engine Laya.init(500,500); var script:any = Laya.Browser.document.createElement(\"script\"); script.src = \"demo1.js\"; script.onload = function():void{ //Load the completion function and start calling the module's functions. //new an object in js var client:any = new Laya.Browser.window.Demo1(); client.start(); } script.onerror = function():void{ //Load error function } Laya.Browser.document.body.appendChild(script); } } new Main; Then create a new js file, the simple code is as follows: var Demo1 = (function () { function Client() { } Client.prototype.start = function () { // body... console.log(\"Calling method\"); }; return Client; })(); console.log(\"I was loaded in\"); Below we briefly explain these two pieces of code. var script:any = Laya.Browser.document.createElement(\"script\");Create a script tag. script.src = \"demo1.js\";Set the path of js to be loaded. script.onload = ... and script.onerror =.... are callback functions for loading completion and loading failure respectively. Laya.Browser.document.body.appendChild(script);Adds the created script tag to the page. var client:any = new Laya.Browser.window.Demo1();Instantiate the class declared by js. client.start();Calls the function of the instance. Compile and run the above code. Open Google's console and you can see the output: \"I'm loaded in\" \"Call method\" Setting via innerHTML of script Setting innerHTML is actually assigning the text format of js to innerHTML. We can use the format of the loaded file to convert the remotely loaded file into text content and assign it to the tag. Take a look at an example below. class Main { private video:Laya.Video; constructor() { //Initialize the engine Laya.init(500,500); var httpreq:Laya.HttpRequest = new Laya.HttpRequest(); httpreq.on(Laya.Event.COMPLETE,this,this.completeHandler); httpreq.on(Laya.Event.ERROR,this,this.errorHandler); httpreq.send(\"demo1.js\"); } private completeHandler(e:any):void{ var script:any = Laya.Browser.document.createElement(\"script\"); Laya.Browser.document.body.appendChild(script); script.innerHTML = e; var client:any = new Laya.Browser.window.Demo1(); client.start(); } private errorHandler(e:any):void{ } } new Main; Compile and run the above code, and you can see that the effect is the same as loading with src. This example uses HttpRequest to load a file and then assigns the loaded content to script.innerHTML. The tag parses and executes js by itself. Of course, this example uses HttpRequest to load, and developers can also use the Laya.loader.load method to load. eval method to load private completeHandler(e:any):void { Laya.Browser.window.eval(e); var client:any = new Laya.Browser.window.Demo1(); client.start(); } We changed the previous loading completion function to `Laya.Browser.window.eval(e);` and then compiled and opened the console and found that the effect was the same. This has nothing to do with the script tag. Summary: The above three common methods can all realize dynamic loading of js files. What are the differences between the three methods? - The script tag src loads a js file. This js file can be from a different source than the current page, which means it can be loaded across domains. - The script.innerHTML method receives the text format of a js file and uses the XMLHttpRequest method to load it, so the file cannot cross domains, or it can only be loaded. The advantage is that the js file can be customized in format, such as encryption. , interspersed with other formats, then loaded in binary format, and decoded into real js in the program. - The eval method is basically the same as the script.innerHTML method. The content loaded is also very random. However, eval is not recommended. It is an almost abandoned method and is not recommended in terms of performance or security. For specific reasons, please see mdn’s explanation. [https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/eval。](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/eval) **In fact, we can also put the loading method into the worker, which further reduces the rendering pressure and lag of the page. Developers can read the worker's tutorials for divergence. ** ### LayaAir’s dom element sound Speaking of the sound of HTML5, developers may first think of the audio tag, but the audio tag is extremely useless for development projects. Today we are talking about another interface. The Audio API provided by HTML5 for JavaScript programming allows us to have Ability to directly operate the original audio stream data in the code and process and recreate it arbitrarily. For audio api, w3c provides me with enough [interface](https://www.w3.org/TR/webaudio/), in [mdn](https://developer.mozilla.org/zh-CN/ docs/Web/API/AudioContext) The above introduction is also more detailed. On browsers with relatively complete support, the sound API can produce extremely rich visual effects. Since the sound API is extremely rich, we will introduce it here and briefly introduce its usage. As for audio synthesis, mixing, sound effects, spectrum analysis of audio data, adding filters to audio, such as improving the timbre, etc. Developers can check mdn or related information. . Let’s first look at an example on mdn. In this example, create a 2-second buffer and fill it with white noise, then pass it to Play it. Its function is explained in the comments. ```javascript var audioCtx = new (window.AudioContext || window.webkitAudioContext)(); // Stereo var channels = 2; // Create an empty two-second stereo buffer at the // sample rate of the AudioContext var frameCount = audioCtx.sampleRate * 2.0; var myArrayBuffer = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate); window.onclick = function() { // Fill the buffer with white noise; //just random values between -1.0 and 1.0 for (var channel = 0; channel Run the above js code, click the page and you will hear the sound played. So how to write it using LayaAir? var audioCtx: any = new (Laya.Browser.window.AudioContext || Laya.Browser.window.webkitAudioContext)(); //Stereo var channels: number = 2; // Create an empty two-second stereo buffer at the // sample rate of the AudioContext var frameCount: number = audioCtx.sampleRate * 2.0; var myArrayBuffer: any = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate); Laya.stage.on(Laya.Event.CLICK, this, function (): void { // Fill the buffer with white noise; //just random values between -1.0 and 1.0 for (var channel: number = 0; channel Compile and run the above example, click the stage, and you will hear the sound played. This example is very simple, just build a sound in memory. So what should I do if it is loaded externally? In the following example, we load a sound file externally. By the way, let's draw the frequency spectrum of the sound. class Main { private AudioContext:any; private audioContext:any; private analyser:any; private audioBufferSourceNode:any; constructor() { //Initialize the engine Release.heat(500, 500); AudioContext = Laya.Browser.window.AudioContext || Laya.Browser.window.webkitAudioContext; this.audioContext = new AudioContext(); this.analyser = this.audioContext.createAnalyser(); this.analyser.fftSize = 256; Laya.stage.once(Laya.Event.CLICK,this,this.clickHandler); } private clickHandler(e:any):void { var http:Laya.HttpRequest = new Laya.HttpRequest(); http.on(Laya.Event.COMPLETE,this,this.completeHandler); http.send(\"res/3.mp3\",\"\",\"get\",Laya.Loader.BUFFER); } private completeHandler(e:any):void { this.audioContext.decodeAudioData(e,this.decodeAudioData.bind(this)); } private decodeAudioData(buffer:any):void { this.audioBufferSourceNode = this.audioContext.createBufferSource(); this.audioBufferSourceNode.connect(this.analyser); this.analyser.connect(this.audioContext.destination); this.audioBufferSourceNode.buffer = buffer; this.audioBufferSourceNode.start(0); Laya.timer.loop(1,this,this.drawHandler); } private drawHandler():void { Laya.stage.graphics.clear(); var dataArray:Uint8Array = new Uint8Array(this.analyser.frequencyBinCount); this.analyser.getByteFrequencyData(dataArray); var step:number = Math.round(dataArray.length / 60); for (var i:number = 0; i Compile and run the above project, click on the stage to see that the spectrum of the sound is displayed. As shown below: Summary: It can be seen that the sound function of the web is getting more and more powerful. If the compatibility of some low-end machines is not considered, it is completely possible to make a web player. This is just a spectrum effect. Developers can try mixing, adding filters to the sound, and other functions. The relevant API can be found in mdn. LayaAir's dom element iframe When inserting some third-party websites, we generally use iframes, and even third-party channels basically use iframes to embed an application. We will also encounter the use of iframes in our projects. The following example demonstrates the application of iframe in the project. The code looks like this: var iframe:any = Laya.Browser.document.createElement(\"iframe\"); iframe.style.position=\"absolute\";//Set layout positioning. This cannot be missing. iframe.style.zIndex = 100;//Set level iframe.style.left =\"100px\"; iframe.style.top =\"100px\"; iframe.src = \"http://ask.layaair.com/\"; Laya.Browser.document.body.appendChild(iframe); What developers need to remind here is to remember to set the positioning and level. Many developers are not careful, causing the iframe to run under the game layer and not be visible. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-21 18:44:03 "},"3D/advanced/readme.html":{"url":"3D/advanced/readme.html","title":"Advanced 3D","keywords":"","body":"3DAdvancedCustom ShaderPost-processingCommandBuffer3D Performance OptimizationWebXRUnity resource export plug-in3DAdvanced The 3D advanced part includes comprehensive use of engine functions, advanced use and other related documents. Custom Shader Post-processing CommandBuffer 3D Performance Optimization WebXR Unity resource export plug-in Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:08:00 "},"3D/advanced/customShader/readme.html":{"url":"3D/advanced/customShader/readme.html","title":"Custom Shader","keywords":"","body":"An article to learn to customize Shader1. Basic knowledge of Shader1.1 What is Shader?1.2 Shader of LayaAir engine2. How to customize Shader2.1 Common attributes in Mesh2.2 Rule Description3.uniformMap4. Child colorer SubShader4.1 What is SubShader4.2 What is Pass5.Shader file structure details5.1 Instancing5.2 ReflectionProbe5.3 attributeMap5.4 defines5.5 styles6. Brief description of GLSL syntax6.1 Common variable types6.2 Common vector types6.3 Common matrix types6.4 varying7.ShaderPass8.GLSL Block9. Start writing a LayaAir Shader9.1 Create a Shader9.2 Write a Shaderinclude in LayaAir Shader is similar to include in C language. xxx.glsl has built-in shader algorithms that have been packaged by the engine. The above code shows the usage of some of these algorithms.10. Vertex shader fragment11. Fragment Shader Fragment12.GLSL data transfer12.1 Application processing stage12.2 Vertex Shader Stage12.3 Fragment Shader Fragments13. Material rendering mode and Shader rendering modeAn article to learn to customize Shader This document is an advanced document for 3D use of the LayaAir engine. Before reading, you need to have general 3D basic knowledge such as 3D vertices, normals, UVs, etc. If there are nouns you do not understand, please read the relevant basic concept documents first. 1. Basic knowledge of Shader 1.1 What is Shader? Shader is called shader in Chinese. Shader is essentially a program written in the GLSL shading language to run on the GPU. It is used to tell the graphics software how to calculate and output images. From every pixel to the entire screen. There are several shading languages. The LayaAir engine is based on webGL and can only use GLSL language. Shaders are mainly divided into two categories: vertex shader Vertex Shader and fragment shader Fragment Shader (also called fragment shader). 1.1.1 Vertex Shader A vertex shader is a program used to process vertex data, such as vertex coordinates, normals, colors, and texture coordinates. It is called on each vertex and can transform a geometry (for example: a triangle) from one position to another, for example, for vertex transformation, texture coordinate generation, texture coordinate transformation, etc. Since 3D graphics are composed of triangular patches, the vertex Shader must calculate the vertices on each triangular patch and prepare for the final pixel rendering. 1.1.2 Fragment Shader Fragment Shader Fragment shaders are used to calculate and fill the color of each pixel, so they are also called pixel shaders. It can be used for interpolation operations, texture access, texture application, fog, color calculation, etc. For each sample of pixels covered by a primitive, a \"fragment\" is generated. Each fragment has a \"window space\" position along with some other values, and it contains the per-vertex output values ​​from all interpolations of the previous \"vertex processing\" stage. The output of the fragment shader is a depth value, possibly a stencil value (unmodified by the fragment shader), and zero or more color values ​​that may be written to a buffer in the current framebuffer. The fragment shader takes a single fragment as input and produces a single fragment as output. 1.2 Shader of LayaAir engine 1.2.1 Structure and composition The Shader in the LayaAir engine mainly revolves around the .shader file as the core. In the core of the engine, the .shader file is the result of the Shader3D class object abstracted into a textual representation. When selecting different Shader effects, different .shader files will be generated. These. The shader file becomes the core factor for different model materials. How to create .shader file? Right-click the menu bar in the project resource window -> Select Create -> Select Shader (as shown in Figure 1-1). There are five built-in Shader options. (Picture 1-1) 1.2.2 Application scope The application of Shader in the LayaAir engine is mainly reflected in the expression of material effects on different objects. By selecting different Shaders, the material of the object changes accordingly to form different effects. The default Shaders built into the LayaAir engine are: BlinnPhong (Blinn Fong), Unlit (unlit), PBR (physically based rendering), Particle (particle), PostProcess (post-processing). 2. How to customize Shader 2.1 Common attributes in Mesh The word polygon comes from Greek and consists of poly (many) and gnow (angle). According to the definition, polygon refers to a closed plane figure bounded by line segments. We can find the most basic common 3D objects in different 3D software or game engines: spheres, cylinders, capsules, and blocks. These basic 3D objects are composed of several polygons. The shapes of these 3D objects are different. But their properties are similar. They all have attributes such as vertices, normals, UV coordinates, and vertex colors, which are all stored in a data structure defined as Mesh. We can access all of these properties independently in a Shader and save them in some common data structure, such as Vector, which is great because we can modify their values ​​to produce exciting effects. Figure 2-1 below shows the three visualization forms of vertices, polygons, and edges. (Figure 2-1) Next, we will introduce the common attributes in the Mesh data structure separately: Vertex What is the apex? A vertex is the point where two sides of a triangle intersect, so each triangle is composed of three vertices, so a most basic triangle fragment has three vertices, Figure 2-2 below shows the transformation of the object object and the visual form of the object's vertex coordinates. (Figure 2-2) normal Suppose we have a blank piece of paper and we ask a friend to draw on the front of the paper. If both sides are equal, how do we determine which one is the front side of the blank page? This is why normals exist. Normals correspond to vertical vectors on a polygonal surface and are used to determine the direction or direction of a face or vertex. In 3D software, we can choose to visualize the normals of vertices, which allows us to see the position of the vertices in space. Figure 2-3 below shows the result of normal visualization of the object. (Figure 2-3) UV coordinates Texture coordinates, also called UV coordinates, map the width and height of the texture; the process of locating vertices on UV coordinates is called \"UV mapping\". It is a process of creating, editing, and organizing UVs that appear as flat, two-dimensional representations of object meshes. In our shader, we can access this property to position the texture on the 3D model or save information in it. Figure 2-4 shows the morphological relationship of Mesh and UV coordinates. (Figure 2-4) The area of ​​UV coordinates is equal to the range from 0.0f to 1.0f, where 0.0f represents the starting point and 1.0 represents the end point. Figure 2-5 below shows the visual expression of UV coordinates. (Figure 2-5) VertexColor When we export objects from a 3D software, the software assigns a color to the object to be affected, either by lighting or copying another color. This color is called the vertex color and corresponds to white by default, with the value \"1.0\" in the RGBA channel. 2.2 Rule Description Shader3D Start/End Shader file head/end Used to declare rendering pass, rendering status, material parameters and other parameters Shader3D Start { //Fill in Shader rendering pass, rendering status, material parameters and other attributes here } Shader3D End name Shader name Used to explain the name of the Shader and distinguish the functions and effects of different Shaders. Shader3D Start { //Here ShaderName is the name of the Shader, not the name of the .shader file, but actually the name of the Shader3D object. name: ShaderName } Shader3D End type Shader type Currently, LayaAir only supports the Shader3D type. We are considering supporting advanced Shader types such as Compute Shader in the future. Shader3D Start { type:Shader3D } Shader3D End 3.uniformMap Uniforms are a way to send data from an application in the CPU to a shader in the GPU, but uniforms and vertex attributes are a little different. First of all, uniform is global. Global means that the uniform variable must be unique within each shader program object, and it can be accessed by any shader at any stage of the shader program. Second, no matter what you set the uniform values ​​to, uniforms will keep their data until they are reset or updated. UniformMap is a data structure that stores a bunch of Uniform variables. Through combination, developers can more intuitively understand the Uniform variables used in Shader. 3.1 Uniform common variable types Common types of Uniform variables: Texture2D, Color, Vector2, Vector3, Vector4, Bool, Float, Matrix4x4, TextureCube Texture2D is the image type used for 2D texture sampling. The image locally supports formats: JPG, PNG Color color type, which is a vector value composed of four Float types, and the unit is an RGB value variable in the range of 0-1 Vector2 Vector 2 type, mostly used for 2D coordinate position representation, often used for UV coordinates and screen coordinates Vector3 Vector 3 type, the most commonly used 3D coordinate position representation, the three components xyz express the specific position in 3D space Vector4 Vector 4 type, mostly used to represent coordinate positions in homogeneous 3D space Bool Boolean type Float floating point type Matrix4X4 4X4 homogeneous matrix TextureCube Image type used for 3D texture sampling. Locally supported image formats: PNG, JPG, HDR Shader3D Start { //Link the attributes (name, type) mentioned in Section 2.2 above type: Shader3D name: ExampleShader uniformMap : { u_Color : {type: Color, default:[1,1,1,1]}, u_MainTex : {type: Texture, default: \"white\"}, u_SampleTexcoord : {type: Vector2, default:[1,1]}, u_LightDir : {type: Vector3, default:[1,1,1]}, u_vecPos : {type:Vector4, default:[1,1,1,1]}, u_isWebGL2 : {type: bool, default: true}, u_spend : {type:float, default:1.0}, u_SkyMap : {type:TextureCube, defalue: \"black\"} u_defaultMat : {type:Matrix4x4, default:[ 1,0,0,0 0,1,0,0, 0,0,1,0, 0.0,0, ]} } } Shader3D End 3.2 Common built-in uniforms in engines Note: The Uniform variables listed below are only Uniform variables commonly used by engines. The Uniform variables involved in other engines are high-level usage methods and will not be introduced in detail in this article. Interested developers can go to xx in the engine. The corresponding Uniform variables can be found in the .glsl file. In this article, we only introduce some high-frequency Uniform variables used in commonly used Shader writing. variable name Description The GLSL file it belongs to (direct use is not recommended for high-level operations) and_WorldMat World Matrix Sprite3DCommon.glsl u_ProjectionParams(near, far, invert, 1 / far) Projection parameters Camera.glsl u_Viewport(x, y, width, height) Viewport Camera.glsl u_CameraDirection Camera direction Camera.glsl u_CameraUp Camera up orientation Camera.glsl u_CameraPos camera position Camera.glsl u_ZBufferParams：1.0 - far / near, far / near, (near - far) / (near * far), 1 / near Zbuffer参数 Camera.glsl u_CameraDepthTexture depth texture Camera.glsl u_Time time Scene.glsl u_FogParams(Start, range, Density, default) Fog effect parameters Scene.glsl u_FogColor Fog color Scene.glsl 4. Child colorer SubShader 4.1 What is SubShader SubShader sub-shader can be understood as Shader's rendering scheme. Each Shader has at least one SubShader, and there can be multiple SubShaders. Sub-shaders divide the Shader object into multiple parts, which are compatible with different hardware, rendering pipelines and run setting information. Contained in a subShader: Information about the hardware, pipeline, and runtime settings of this subshader. One or more passes. 4.2 What is Pass Pass is the basic element of the Shader object. A series of Passes are defined in SubShader, which includes setting the quality of the GPU state and the Shader program running on the GPU. However, the presence of too many Passes in a SubShader will cause a decrease in rendering efficiency and create a performance bottleneck. Shader3D Start { ..... shaderPass:[ { //Shader VS/FS Info here } ] } Shader3D End 5.Shader file structure details 5.1 Instancing 5.1.1 What is Instancing When rendering, if there is a type of object with the same vertex data, but the world space position is different, such an object is suitable for Instancing rendering. Imagine a scene full of grass: each blade of grass is a small model containing several triangles. You may need to draw many grass roots, and ultimately you may need to render thousands or tens of thousands of grass roots per frame. Because each blade of grass is only composed of a few triangles, rendering is almost instantaneous, but thousands of rendering function calls will greatly affect performance. If you start Instancing, send this kind of data to the GPU at once, and then call a drawing function to let OpenGL use this data to draw multiple objects. This is very convenient. This is Instancing. Instancing allows us to use one DrawCall to draw multiple objects, saving CPU->GPU communication for each drawing. 5.1.2 enableInstancing switch enableInstancing: Whether to enable Instancing. When enableInstancing is true, the Shader enables the Instancing function. When enableInstancing is false, the Shader does not enable the Instancing function. Shader3D Start { .... enableInstancing:true, .... .... } Shader3D End 5.2 ReflectionProbe 5.2.1 What is ReflectionProbe Reflection probes can capture the surrounding environment from all directions and then store the captured content as a CubeMap (cube map), which can be used by objects with reflective materials. Multiple reflection probes can be used in a scene, and the probes sample the visual environment at key points in the scene. When a reflective object is close to the probe, the reflections sampled by the probe can be used in the object's reflection map. Additionally, when several probes are located near each other, the engine can interpolate between them, allowing for gradual changes in reflection. Therefore, using reflection probes can produce very realistic reflections while keeping the processing overhead to an acceptable level. 5.2.2 Working principle of reflection probe The capture environment of the probe can be represented by a CubeMap. The CubeMap is conceptually very similar to a box with six-sided images of a cube drawn on the internal surface. The Shader must be able to sample the CubeMap's image. Each point on the object's surface \"sees\" a small area of ​​the cubemap in the direction the surface is facing (that is, the direction of the surface normal vector). Here the shader uses the color of the cube map to calculate what color the object's surface should be. Figure 5-1 below shows the comparison results between CubeMap and skybox. (Figure 5-1) 5.2.3 supportReflectionProbe switch supportReflectionProbe ：ReflectionProbe开关。 Enable the switch to True when the probe exists in the scene, and enable the switch to False when the probe does not exist in the scene. Shader3D Start { .... .... supportReflectionProbe:false, .... .... } Shader3D End 5.3 attributeMap attribute is usually the data from Mesh vertices. The variable value of this attribute is read-only and usually does not need to be set. There is a set of attributeMap in the engine by default to meet common mesh vertex types. Only special mesh data is needed. Only when you need to set special variables in attributeMap The vertex data in LayaAir3D is elf-by-elf. Here we only introduce the vertex data related to commonly used model sprites. (That is, it does not include trailing sprites and particle sprites) This table will list the variable names and corresponding vertex channels of all vertex data currently passed in by the engine. Description channel The position of the vertex in model space VertexMesh.MESH_POSITION0 Normal vector of vertex in model space VertexMesh.MESH_NORMAL0 Tangent vector of model space VertexMesh.MESH_TANGENT0 The first uv coordinate VertexMesh.MESH_TEXTURECOORDINATE0 The second uv coordinate VertexMesh.MESH_TEXTURECOORDINATE1 Bone weight VertexMesh.MESH_BLENDWEIGHT0 Bone index VertexMesh.MESH_BLENDINDICES0 MVP Matrix VertexMesh.MESH_MVPMATRIX_ROW0 World Matrix VertexMesh.MESH_WORLDMATRIX_ROW0 vertex color VertexMesh.MESH_COLOR0 User-defined reserved space VertexMesh.MESH_CUSTOME0 5.4 defines 5.4.1 Basic usage Use macro switches to control the Shader instructions that generate different branch conditions in the vertex shader and fragment shader. The basic composition of the macro switch in defines is: defineName: The name of the macro switch. type: Generally bool, true or false triggers two different branches. private: When the private value is false, in the material property setting panel, the macro switch will be displayed as a check switch in the Shader window, allowing developers to control the opening and closing of macros in the panel as needed; when the private value is true, The check switch is not displayed. (Figure 5-2 below shows the display of the check switch in the Shader window, and Figure 5-3 shows the specific use of defines in the Shader file) (Figure 5-2) (Figure 5-3) 5.4.2 Linkage with uniformMap The macro switches in defines can be set in conjunction with the global properties in uniformMap, for example, the following sample code: uniformMap:{ //define A at the same time when modifying u_AlbedoTexture1 u_AlbedoTexture1: { type: Texture2D, define: A }, //define A and B at the same time when modifying u_AlbedoTexture2 u_AlbedoTexture2: { type: Texture2D, define: [A,B] } }, defines: { A : { type: Bool }, B : { type: Bool }, C : { type: Bool } }, In the material property setting panel, adding texture to u_AlbedoTexture1 will cause A to be checked; adding texture to u_AlbedoTexture2 will cause A and B to be checked, and the effect is as shown in the animation 5-4. (Animation 5-4) 5.5 styles It used to be that in uniformMap or define, you could directly adjust the display details of uniform or define on the UI. Now you can move these details to the styles section to make uniformMap and define more concise. 5.5.1 For uniformMap It turns out that in uniformMap, more details need to be defined, for example (original writing): uniformMap:{ u_Number: { type: Float, default:0, alias:\"数字\", range:[0,100], fractionDigits: 2 } }, If there are many details, these details can be moved to styles for the simplicity of uniformMap: uniformMap:{ u_Number: { type: Float, default:0 } }, styles: { u_Number: { caption:\"Number\", range:[0,100], fractionDigits: 2 } }, 5.5.2 For defines The more important function of styles is that you can define attributes that are only used in the UI and do not belong to uniform and define. For example: defines: { RAIN : { type: Bool, default: true }, SNOWY : { type: Bool, default: false } }, styles: { RAIN: { caption: \"Rain\", inspector : null }, //inspector is null and is not displayed in the properties panel SNOWY : { caption: \"SNOWY\"}, // Define attributes that do not belong to uniform and define weather : { caption:\"天气\", inspector: RadioGroup, options: { members: [RAIN, SNOWY] }} }, RAIN and SNOWY are in defines, but the inspector of RAIN in styles is null, so they are not displayed. SNOWY is displayed normally. Weather is an attribute that is only used in the UI and does not belong to uniform and define. The effect is shown in Figure 5-5. (Figure 5-5) 6. Brief description of GLSL syntax The variable types of GLSL partially overlap with uniformMap. The Shader file of the LayaAir engine is encapsulated based on the GLSL language, with the purpose of improving the ease of use of developers writing shaders. GLSL is a shader language based on the graphics API of the GL series. It includes some common variable types and operations on vectors and matrices, making the rendering pipeline programmable. 6.1 Common variable types Variable type Description Default value in LayaAir bool boolean scalar data type false float/vec2/vec3/vec4 Contains 1, 2, 3, 4 floating point vectors 0/[0, 0]/[0, 0, 0]/[0, 0, 0, 0] sampler2D represents a 2D texture “white” samplerCube represents the cube texture mat4 represents a 4x4 matrix 6.2 Common vector types Vectors can be constructed in the following three forms: thing2 v1 = thing2(1.0, 0.0); vec3 v2 = vec3(1.0); // v2 = [1.0, 1.0, 1.0] vec4 v3 = vec4(1.0, 0.0, vec2Value); //v3 = [1.0, 1.0, vec2Value.x, vec2Value.y] Vectors can be accessed through x, y, z, w and r, g, b, a. glsl supports simultaneous access to multiple subscripts eg: vec.xyz 6.3 Common matrix types mat4 marixt4x4 = mat4(1.0); // marixt4x4 = { 1.0, 0.0, 0.0, 0.0, // 0.0, 1.0, 0.0, 0.0 // 0.0, 0.0, 1.0, 0.0 // 0.0, 0.0, 0.0, 1.0 } mat2 matrix2x2 = mat2(coll1, col2); mat3 matrix3x3 = mat3(0.0, 0.0, 0.0, // first column 0.0, 0.0, 0.0, // second column 0.0, 0.0, 0.0); // third column 6.4 varying varying is a variable output by the vertex shader and passed to the fragment shader. Under the influence of the pipeline, the variable value will not be consistent with the output of the vertex shader, but will be interpolated by the pipeline. This may cause the normal of the vertex output to be unnormalized. At this time, manual normalization is required. The code example is as follows: //Normalized normal vec3 normal = normalize(v_normal); 7.ShaderPass Earlier we briefly introduced the function of Pass in SubShader. In this section we will combine the detailed Shader content to show the specific functions of ShaderPass. Shader3D Start { type:Shader3D name:exampleShader enableInstancing:true, supportReflectionProbe:false, uniformMap: { u_MVPMatrix : {type: Matrix4x4}, u_OutLineWidth : {type: float, default:0.0} } shaderPass:[ { pipeline:Forward, VS:OutLineVS, FS:OutLineFS } { pipeline:Forward, VS:OutLine1VS, FS:OutLine1FS } ] } Shader3D End Shader3D Block sets the type and name of the Shader as well as the support for instancing and probes. It declares the uniform variables required in the shader. The shaderpass defines the rendering method as forward rendering and relative to glsl's vs and fs. GLSL Block content. 8.GLSL Block The content of this part is mainly to define the content of glsl statements in vs and fs in different rendering fragments in the above ShaderPass. Start and end flags: GLSL Start / GLSL End Pass corresponding VS and FS fragment tags: #defineGLSL \"name\" / #endGLSL Among them, the contents contained in #defineGLSL and #endGLSL are glsl statements relative to the shader function. GLSL Start #defineGLSL OutlineVS void main() { vec4 position = vec4(a_Position.xyz + a_Normal * u_OutlineWidth, 1.0); gl_Position = u_MvpMatrix * position; } #endGLSL #defineGLSL OutlineFS varying vec3 v_Normal; varying vec2 v_Texcoord0; void main() { gl_Position = u_MvpMatrix * a_Position; mat3 worldMat=mat3(u_WorldMat); v_Normal=worldMat*a_Normal; v_Texcoord0 = a_Texcoord0; gl_Position=remapGLPositionZ(gl_Position); } #endGLSL GLSL End 9. Start writing a LayaAir Shader 9.1 Create a Shader In the LayaAir IDE interface, find the project resource window -> right-click to open the menu interface -> select create options -> select shader options (as shown in Figure 9-1 below). You can create a \"non-light\" type .shader file, then open it with an editor and write a custom Shader. (Figure 9-1) When developers study this section, they should focus on experiencing the functions implemented by FS fragments and VS fragments. The specific principles will be explained in Sections 10 and 11. 9.2 Write a Shader 9.2.1 Basic attribute information The Shader file just created, the Shader created by default contains some common functions that may be encountered in actual development: Shader3D Start Shader file start header. Shader3D End Shader file end header. The content in Shader3D Start/End is some attribute information of Shader and does not involve glsl statements. Figure 9-2 below shows the basic information contained in a basic Shader3D Start/Shader3D End structure: (Figure 9-2) type: Set type to Shader3D. name: Set the Shader name to NewShader (the original name is UnlitShader). enableInstancing: Whether to enable Instancing. supportReflectionProbe: Whether to enable light probe support. UniformMap: Four Uniform variables are created. Figure 9-3 below shows the result displayed on the IDE panel after the material is bound to the Shader. When the material is bound to the Shader, the variables in the UniformMap will become a panel interface on the IDE material editor, and the uniform value can be modified on the panel interface. (Figure 9-3) shaderPass: The current Shader has only one pass, the vs content is unlitVS, the fs content is unlitPS, and the rendering mode is forward rendering. 9.2.2 FS fragment and VS fragment GLSL Start / GLSL End: The start and end of the VS and FS pair of each Pass, #defineGLSL defines the glsl statement fragment of VS or FS. FS fragment Delete the contents in the original UnlitShader.shader and FS fragment main(). Here are a few simple effects: (1) Fill the object with a solid color and set gl_FragColor to a vec4 variable with a transparent channel. The actual result is as shown in Figure 9-4 below. (Figure 9-4) (2) Fill the object with the color of the texture, and set gl_FragColor to the color value of the sampled texture. The specific effect is shown in Figure 9-5 below. The upper left corner of the figure is a schematic diagram of the original texture. (Figure 9-5) (3) Fill the color of the object with the color of the uniform variable, and adjust the color in the IDE. The specific effect is shown in Figure 9-6 below. (Figure 9-6) (4) Use TilingOffset to offset the UV texture sampling. The specific effect is shown in Figure 9-7 below. (Figure 9-7) Note: The v_Texcord0 at this time is scaled and offset transformed in VS, not in FS. Click here to avoid the table. It will be explained in detail in the VS section. When offsetting the UV texture sampling, you need to use a power-of-two texture map to display the effect shown in Figure 9-7. If it is a non-power-of-two image, you need to set it as shown in Figure 9-8. After scaling the image to power-of-two, click Apply. (Figure 9-8) VS fragment The sample code is as follows: #defineGLSL unlitVS #define SHADER_NAME UnlitShader #include \"Math.glsl\"; #include \"Scene.glsl\"; #include \"SceneFogInput.glsl\"; #include \"Camera.glsl\"; #include \"Sprite3DVertex.glsl\"; #include \"VertexCommon.glsl\"; #ifdef UV varying vec2 v_Texcoord0; #endif // UV #ifdef COLOR varying vec4 v_VertexColor; #endif // COLOR void main() { Vertex vertex; getVertexParams(vertex); #ifdef UV v_Texcoord0 = transformUV(vertex.texCoord0, u_TilingOffset); #endif // UV #ifdef COLOR v_VertexColor = vertex.vertexColor; #endif // COLOR mat4 worldMat = getWorldMatrix(); vec4 pos = (worldMat * vec4(vertex.positionOS, 1.0)); vec3 positionWS = pos.xyz / pos.w; gl_Position = getPositionCS(positionWS); gl_Position = remapPositionZ(gl_Position); } #endGLSL include in LayaAir Shader is similar to include in C language. xxx.glsl has built-in shader algorithms that have been packaged by the engine. The above code shows the usage of some of these algorithms. In graphics, there are often some usages surrounding transformations: such as world matrix, projection matrix, clipping space, UV transformation, etc. There are some such usages in LayaAir's .glsl header file, as follows: getWorldMatrix() returns a mat4 type world matrix (), model space coordinates world matrix = world space coordinates. *[Sprite3DVertex.glsl] getVertexParams() returns a Vertex structure, which contains the original data of the Mesh: vertex coordinates, normals, UV (UV macro), tangent (NEEDTBN macro), paratangent (NEEDTBN macro), vertex color (COLOR macro) . [VertexCommon.glsl] transfromUV() returns a new UV coordinate of vec2, and performs scaling and offset operations according to the second parameter of the function. The actual algorithm is: newUV = (oldUV.x x + tilloffset.z, oldUV.y y + tilloffset.w) xy of tilloffset corresponds to the scaling value of xy, and zw corresponds to the offset value of xy. [Sprite3DCommon.glsl] The structure PixelParams defines some vertex attributes in world space: vertex coordinates, normals, UV (UV macro), tangent (NEEDTBN macro), and paratangent (NEEDTBN macro). The structure PixelParams only defines the vertex attributes of these worlds and is not initialized. InitPixelParams() returns the initialized PixelPaams variable. [BlinnPhongCommon.glsl] getPositionCS() passes in world coordinates and returns the coordinates of the clipping space. [Camera.glsl] remapPositionZ() remaps the coordinate Z of the clipping space. [Camera.glsl] 9.2.3 Shader references glsl file In the .shader file of LayaAir IDE, if the glsl built into the engine is referenced (usually registered in ShaderInit3D.ts through the addInclude method of Shader3D.ts), then it can be referenced directly. For example: #include \"Color.glsl\"; If it is a custom .glsl file, it can be placed anywhere under the assets folder. Then the .shader file refers to the .glsl file through a relative path. Even if it is a directory of the same level, it must start with ./, for example: #include \"./abc.glsl\"; #include \"./path/to/abc.glsl\"; #include \"../path/abc.glsl\"; 10. Vertex shader fragment The main function of the vertex shader is to transform the input vertices, transform them from model space to clipping space, and output them to the fragment shader. Figure 10-1 shows the simple input and output of a vertex shader. (Figure 10-1) Readers do not need to understand the running details of WebGL in depth. They only need to focus on the content of GLSL statements to easily complete the creation of Shader content. The previous chapters briefly describe some of the contents of GLSL. Figure 10-2 below shows the vertex shader in Illustration of the run stages in the graphics rendering pipeline. (Figure 10-2) At the stage shown in the figure above, the vertices in the model go through a series of transformations in Figure 10-3. (Figure 10-3) Local Space local coordinates, which can also be called model coordinates. It can be understood as the coordinates relative to the parent node. World Space world coordinates. World coordinates are a large spatial extent, relative to the world origin. It is obtained by multiplying the model coordinates and the world matrix. View Space observation coordinates. It can be understood as converting world coordinates to camera space coordinates, and the converted values ​​are relative to the camera origin. It is obtained by multiplying the world coordinates and the observation matrix. Clip Space clipping coordinates. That is to say, the observation coordinates are processed to the range of -1.0 ~ 1.0, which is the standard equipment coordinates we provide in WebGL, and finally the coordinates beyond -1 ~ 1 are eliminated. It is obtained by combining the observation coordinates with the projection matrix. Screen Space screen coordinates. This process is actually to convert the coordinates in the range of -1.0 ~ 1.0 to the coordinate range defined by gl.viewport. The final transformed coordinates are sent to the rasterizer and converted into fragments. 11. Fragment Shader Fragment The main function of the fragment shader is to calculate the color of each pixel fragment, obtain the color difference from the vertex shader, and sample the color data from the texture. Figure 11-1 shows the shading results of the model sampled texture. (Figure 11-1) 12.GLSL data transfer 12.1 Application processing stage In the application processing stage, the model is integrated into basic fragments (triangles), and different attribute coordinate information is obtained from the model. The red framed part in Figure 12-1 is the application processing stage. (Figure 12-1) 12.2 Vertex Shader Stage Some values ​​after calculation in the application phase are passed to the vertex shader as uniforms to participate in the calculation, and then passed to the rasterization and subsequent fragment shader parts in the form of varing types. The red framed part in Figure 12-2 is the vertex shader. stage. (Figure 12-2) 12.3 Fragment Shader Fragments The varing type result after color interpolation is completed in the rasterization stage is passed to the fragment shader. The fragment shader processes the color value and outputs the result to the corresponding buffer (divided into a color buffer and a depth buffer). This step is the red box selection in Figure 12-3. (Figure 12-3) 13. Material rendering mode and Shader rendering mode Different materials in LayaAir have different rendering modes, and the rendering results in different modes are different. Common rendering modes are shown in the red box in Figure 13-1 below: (Figure 13-1) For material-related content, please refer to \"Material Editing Module\". OPAQUE (opaque) There is no transparency effect. Even if there is translucency in the texture, the model will not be translucent. The Alpha value does not affect the final rendering effect and is always 1. CUTOUT (cutout) (Figure 13-2) Transparent cropping can be performed based on the Alpha value sampled from the texture containing Alpha information. You can also crop based on the comparison of the AlphaTest value in Figure 13-2 with the Alpha value sampled in the texture. This will cause holes in the cropped result. Parts and normal parts will produce severe aliasing, but the efficiency is high. If the aliasing effect is serious, it is recommended to sample the TRANSPARENT mode, and the transparent result will be more linear. TRANSPARENT (translucent) Translucent rendering is performed based on the Alpha value in the texture or rendering is given a fixed Alpha value. ADDTIVE (additive color mixing) It is mainly used for some materials that are transparent and have high color brightness. It will perform additive color mixing according to the brightness of the texture pixels. The texture colors of the front and back of the model and the texture colors of overlapping models will superimpose on each other to form a highlight translucent effect. (Figure 13-3) ALPHABLENDED (transparent blending) This means that the object is in semi-transparent mode, but the final pixel is shaded in a different blending mode. The AlphaBlended blending mode is SrcAlpha SrcColor + (1 - SRCAlpha) DstColor. Generally speaking, SrcAlpha comes from the alpha value of the texture. (Figure 13-4) The RenderMode of the Shader inside the engine will be compared with the RenderMode of the material. Generally, the RenderMode of the material is the main one. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:19:20 "},"3D/advanced/PostProcessing/readme.html":{"url":"3D/advanced/PostProcessing/readme.html","title":"Post Processing","keywords":"","body":"Post-processing1. Post-processing overview2. Add a built-in post-processing effect3. Engine built-in post-processing type: ScalableAO4. Engine built-in post-processing type: Bloom5. Engine built-in post-processing type: GaussianDoF6. Engine custom post-processing typePost-processing 1. Post-processing overview Post-processing is one of the essential technologies in modern games. PostProcessing usually processes the results after the ordinary scene rendering is completed, processing one or several Textures to obtain a new Texture. PostProcessing's rendering Pipeline is the same as ordinary model rendering. The difference is that it is usually just a simple copy in the vertex shader, and the main logic is written in the fragment shader. The images below show the scene with and without post-processing applied. Scenes without post-processing applied Apply post-processed scenes 2. Add a built-in post-processing effect Select the camera object in the Scene that needs to be added with post-processing effects. Figure 2-1 PostProcess component in the component panel of the camera object Figure 2-2 Select the instantiated PostProcess component Figure 2-3 Add appropriate post-processing effects in Effects Figure 2-4 3. Engine built-in post-processing type: ScalableAO The ambient occlusion effect is used to calculate the points in the scene that are exposed to ambient lighting. It then darkens areas that are hidden from ambient light, such as creases, holes, and spaces between close objects. You can achieve the ambient occlusion effect in two ways: In real time as a full-screen post-processing effect. Real-time ambient occlusion effects can be resource-intensive. Its impact on processing time depends on screen resolution and effect properties. Figure 3-1 Expandable ambient occlusion parameter types: Parameter type Parameter explanation AO Color Set the color of ambient occlusion Intensity Ambient occlusion produces intensity Radius Set the radius of the sampling point to control the scope of the ambient occlusion area AO Quality Ambient occlusion effect quality (high-medium-low three levels) 4. Engine built-in post-processing type: Bloom The Bloom effect causes bright areas in an image to glow. To do this, it creates rim lights that extend from bright areas to your image. This simulates the effect a real-world camera would have when light floods the lens. The Bloom effect also has a Grunge feature, which you can use to apply a full-screen layer of dirt or dust to diffract the Bloom effect. Pic 4-1 Bloom parameter types: Parameter Type Parameter explanation Clamp Set the clamp pixel value to control the Bloom amount Color Choose a Bloom color Fast Mode Quick mode Dirt Texture Choose a dirty texture to add smudges or dust to your footage Intensity Set lens dirty intensity Threshold Set the brightness level to filter out pixels below this level Soft Knee Sets a progressive threshold for transitions between below/above threshold (0 = hard threshold, 1 = soft threshold). Diffusion Sets the range of the veil effect in a screen resolution-independent manner. Anamorphic Ratio Set the ratio to scale Bloom vertically (range [-1,0]) or horizontally (range [0,1]). This simulates the effect of an anamorphic lens. 5. Engine built-in post-processing type: GaussianDoF Depth of field is a common post-processing effect that simulates the focal length characteristics of a camera lens. In real life, cameras can only focus sharply on objects within a certain distance; objects closer or further from the camera will be somewhat out of focus. Not only does this blur provide a visual clue as to the distance of an object, but it also introduces Bokeh, a term used to describe the pleasant visual artifacts that appear when bright areas of an image are out of focus. Figure 5-1 GaussianDoF parameter type: Parameter type Parameter explanation Far Start Depth of field start value Far End Depth of field end value Max Radius Maximum blur depth of field radius 6. Engine custom post-processing type After writing your own post-processing effect in the 3.0 engine, add the keyword @regClass() before the class definition to explicitly display the customized post-processing effect in the Camera's post-processing component. in the effects list Figure 6-1 Figure 6-2 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:22:27 "},"3D/advanced/CommandBuffer/readme.html":{"url":"3D/advanced/CommandBuffer/readme.html","title":"Command Buffer","keywords":"","body":"CommandBuffer document1. Introduction2. Usage steps3.Usage examplesCommandBuffer document 1. Introduction CommandBuffer is the rendering command buffer, which saves the rendering command list. When we add some rendering instructions to the CommandBuffer, we can control the rendering process and execute these instructions at the time we want. The command buffer sets the render target or draws a given mesh, which can be set to be executed at different points during camera rendering. CommandBuffer is a high-end 3D rendering function used to expand the rendering effects of the LayaAir engine rendering pipeline. It is very useful when realizing effects such as frosted glass (transparent glass blur), outline perspective strokes or edge light effects, beach footprints, depth of field, etc. Everyone who knows it knows that CommandBuffer is very powerful and is also a rendering often used in 3A-level masterpieces. function, and there will be no additional loss of functions, and some effects are even more performance-efficient than other solutions. It is a rendering extension function that can also be used to enhance 3D rendering effects in small game platforms. 2. Usage steps 1. After creating the CommandBuffer, add rendering instructions to the CommandBuffer Add the code interface as follows: var buf:CommandBuffer = new CommandBuffer();buf.setRenderTarget(renderTexture);buf.drawRender(renders[i],materials[i],0); 2. CBuffer needs to be bound to the rendering event of the Camera. The Camera events currently supported by laya are as follows: BeforeForwardOpaque = 0, //Before rendering non-transparent objects, BeforeSkyBox = 2, //Before rendering sky boxes, BeforeTransparent = 4, //Before rendering transparent objects, BeforeImageEffect = 6, //Before post-processing, AfterEveryThing = 8, // After all rendering The interface for adding CommandBuffer to camera events is as follows: this.camera.addCommandBuffer(this.cameraEventFlag,this.commandBuffer); The interface to delete CommandBuffer is as follows: this.camera.removeCommandBuffer(this.cameraEventFlag,this.commandBuffer); CommandBuffer is a rendering instruction set. This rendering instruction set is composed of independent rendering instructions one by one. setShaderData//Set shader data, you can set the texture vector number in the shader, etc. setGlobalShaderData//Set global data, which can be used for all shaderblitScreenQuad//Render the source texture to the target rendering texture instruction through the full-screen quadrilateral. blitScreenQuadByMaterial//Render the source texture to the target rendering texture through the full-screen quadrilateral instruction setRenderTarget//Set the instruction rendering target. After calling, all rendering will be rendered to the picture bound by the method clearRenderTarget//Clean up the bound rendering texture drawMesh// Render a MeshdrawRender//Render a Render You can combine different rendering instructions and put them into different rendering processes. Let’s analyze the official examples to better understand the usage of CommandBuffer. 3.Usage examples 3.1.BlurryGlass example (frosted glass example) Renderings Example principle Frosted glass is a transparent material, and the three capsules behind it are all opaque materials, so we need to take out all the rendering objects behind the frosted glass model every frame, blur them, and then sample the picture according to the screen UV to the frosted glass, and it can be achieved Such effect Sample code createCommandBuffer(camera:Camera){ //When you need to get the camera rendering result before rendering a transparent object, so call the following attribute true camera.enableBuiltInRenderTexture = true; //Create CommandBuffer var buf:CommandBuffer = new CommandBuffer(); //Create a screen RenderTexture that needs to be blurred var viewPort:Viewport = camera.viewport; //Create a new RenderTexture var renderTexture = RenderTexture.createFromPool(viewPort.width,viewPort.height,RenderTextureFormat.R8G8B8,RenderTextureDepthFormat.DEPTHSTENCIL_NONE); this.texture = renderTexture; //Copy the current rendering result to the created RenderTexture buf.blitScreenTriangle(null,renderTexture); //Get the blur shader var shader:Shader3D = Shader3D.find(\"blurEffect\"); //Set fuzzy parameters var shaderValue:ShaderData = new ShaderData(); //down Sample level sets the downsampling level var downSampleFactor:number = 4; var downSampleWidth:number = viewPort.width/downSampleFactor; var downSampleheigh:number = viewPort.height/downSampleFactor; //Set blur material parameters var texSize:Vector4 = new Vector4(1.0/viewPort.width,1.0/viewPort.height,viewPort.width,downSampleheigh); shaderValue.setNumber(BlurEffect.SHADERVALUE_DOWNSAMPLEVALUE,1); shaderValue.setVector(BlurEffect.SHADERVALUE_TEXELSIZE,texSize); //Create downsampling RenderTexture1 var downRenderTexture = RenderTexture.createFromPool(downSampleWidth,downSampleheigh,RenderTextureFormat.R8G8B8,RenderTextureDepthFormat.DEPTHSTENCIL_NONE); //Downsampling command stream buf.blitScreenTriangle(renderTexture,downRenderTexture,null,shader,shaderValue,0); //Create downsampling RenderTexture2 var blurTexture:RenderTexture = RenderTexture.createFromPool(downSampleWidth,downSampleheigh,RenderTextureFormat.R8G8B8,RenderTextureDepthFormat.DEPTHSTENCIL_NONE); blurTexture.filterMode = FilterMode.Bilinear; //Horizontal blur buf.blitScreenTriangle(downRenderTexture,blurTexture,null,shader,shaderValue,1); //vertical blur buf.blitScreenTriangle(blurTexture,downRenderTexture,null,shader,shaderValue,2); //Horizontal blur buf.blitScreenTriangle(downRenderTexture,blurTexture,null,shader,shaderValue,1); //vertical blur buf.blitScreenTriangle(blurTexture,downRenderTexture,null,shader,shaderValue,2); //At this point, the blurred image has been generated in downRenderTexture //Set global uniform variables var globalUniformNameID:number = Shader3D.propertyNameToID(\"u_screenTexture\"); //Assign the global variable u_screenTexture to the blurred image buf.setGlobalTexture(globalUniformNameID,downRenderTexture); //Add commandBuffer to the rendering process camera.addCommandBuffer(CameraEventFlags.BeforeTransparent,buf); //Recycle used RenderTexture RenderTexture.recoverToPool(downRenderTexture); RenderTexture.recoverToPool(blurTexture); return; } 3.2.OutLine example (outline stroke) Rendering: Example principle: After the rendering is completed, bind another black Rendertexture, redraw the particles, Box, and monkey as pure red, and then blur the image. Subtract the unblurred image from the blurred image color to get the rendering border. Finally, the rendering border Add it back to the rendered canvas to achieve the outline effect. code show as below createDrawMeshCommandBuffer(camera:Camera,renders:BaseRender[],materials:Material[]):CommandBuffer{ var buf:CommandBuffer = new CommandBuffer(); //Set true when you need to get the camera rendering effect in the process camera.enableBuiltInRenderTexture = true; //Create a Rendertexture as large as the screen var viewPort:Viewport = camera.viewport; var renderTexture = RenderTexture.createFromPool(viewPort.width,viewPort.height,RenderTextureFormat.R8G8B8A8,RenderTextureDepthFormat.DEPTHSTENCIL_NONE); //Set RenderTexture as render target buf.setRenderTarget(renderTexture); //Clear the color of the render target to black and do not clean up the depth buf.clearRenderTarget(true,false,new Vector4(0,0,0,0)); //Render the incoming Render to the texture for(var i = 0,n = renders.length;i Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:15:06 "},"3D/advanced/performanceOptimization/readme.html":{"url":"3D/advanced/performanceOptimization/readme.html","title":"performance Optimization","keywords":"","body":"3D performance optimization1. Basic understanding of graphics performance1.1 Reduce the CPU cost of rendering1.2 Reduce GPU cost of rendering2. Optimize Draw Call3.GPU instance4.Dynamic Batch5.Static Batch6.Custom Static Batch(Static Batch Volume component)3D performance optimization 1. Basic understanding of graphics performance 1.1 Reduce the CPU cost of rendering During the rendering process, the factor that has the greatest impact on CPU rendering time is the cost of sending rendering instructions to the GPU. Rendering instructions include Draw Calls and commands that change settings on the GPU before drawing 3D objects. The following methods can reduce the CPU cost of rendering: Reduce the number of rendered objects in the scene Consider reducing the total number of objects in the scene, e.g. using skyboxes instead of rendering distant 3D objects Perform more efficient culling of objects in the scene to reduce rendering pressure on the engine. Reduce the number of times the object is rendered Where appropriate, use LightMap to bake lights and shadows. This operation will increase video memory usage and build time, but can improve running efficiency. Reduce the number of light sources Use real-time shadows with caution Use reflection probes with caution 1.2 Reduce GPU cost of rendering Limited by memory bandwidth, the texture size is too high and the number of textures is too large, which will cause a GPU rendering bottleneck. Enable mipmaps for textures whose distance from the camera changes at runtime. (For example, most textures used in 3D scenes). This increases the memory usage and storage space of these textures, but improves runtime GPU performance. Use a suitable compression format to reduce the size of textures in memory. This reduces load times, reduces memory footprint, and improves GPU rendering performance. Compressed textures use only a fraction of the memory bandwidth required by uncompressed textures. If the application is vertex processing bound, it means that the GPU can process more vertices during the vertex processing stage Reduce vertex shader execution cost. Optimize geometry: don't use unnecessary triangles and try to keep the number of UV mapped seams and hard edges (double vertices) as low as possible. Use LOD to optimize different Mesh types and optimize the number of vertices. 2. Optimize Draw Call Because rendering state changes can be resource-intensive, it's important to optimize them. The main way to optimize render state changes is to reduce their number. There are two ways to do this: Reduce the total number of draw calls. When you reduce the number of draw calls, you also reduce the number of render state changes between them. Organize draw calls in a way that reduces the number of changes to rendering state. If the graphics API can perform multiple draw calls using the same rendering state, the draw calls can be grouped together without performing as many render state changes. The following methods are provided in LayaAir: GPU instance Dynamic Batch Static Batch Custom Static Batch 3.GPU instance GPU instancing is a draw call optimization method that renders multiple copies of a mesh with the same material in a single draw call. Each copy of the grid is called an instance. This is useful for drawing things that appear multiple times in a scene, such as trees or grass. GPU instances render the same mesh in the same draw call. To add variety and reduce a repetitive look, each instance can have a different property, such as Color or Scale. Draw calls that render multiple instances appear in the framework debugger draw grid(instances). GPU Instance requires hardware support. Make sure the hardware you are currently using can support GPU Instance rendering. The above picture shows a GPU Instance test scene and the detailed drawing information corresponding to the test scene. In the picture, red-green-blue-yellow are four different materials. There are currently only three Instance DrawCalls, and the engine automatically executes the Instance rendering process for objects that meet the Instance conditions. Engine Instance rendering conditions: Same Mesh same material enableInstance (customize the switch on the Shader, the engine's default shader turns on Instance) Whether the shadow status is the same (whether to receive shadow) Whether the reflection probe status is the same Red-green-blue objects have different Mesh and different materials, but every red, green or blue object has the same material, the same Mesh, the same Instance state, the same shadow state, Same reflection probe status. Therefore, these three types of objects comply with the engine Instance rendering judgment process. The engine automatically instantiates these three types of objects and instantiates all objects of each color into one InstanceDraw Call to complete the rendering process. Yellow objects meet almost all the requirements for Instance rendering judgment. However, because of different Mesh grid data, the engine will not perform Instance rendering on all yellow objects. In summary, a basic Instance rendering condition can be summarized into three points: enableInstance is turned on, the same Mesh, and the same material. If you need to customize your own personalized Instance rendering judgment, developers need to organize the rendered data themselves in the form of CommandBuffer 4.Dynamic Batch Dynamic merging is divided into two types: instance merging and vertex merging. Both optimizations require no settings from the developer, and objects can move dynamically without restrictions. However, the merger principle is relatively strict. The following are the most basic conditions for the two mergers. Instance merge: Both conditions of the same Mesh and the same material need to be met. In a three-dimensional scene, there may still be a large number of models with the same material as Mesh, and there is a lot of room for instance merging at this time. Vertex merge: The same material is required and the model vertices are less than 10. Vertex merging currently has room for use on some fake shadow and special effects models. Note: Translucent objects require continuous rendering to be dynamically merged, so the probability of dynamic merging of translucent objects is low. Turn off dynamic batching option In the engine's Config3D.ts file, enableDynamicBatch value option, true means turning on dynamic batching, false means turning off dynamic batching. Pic 4-1 5.Static Batch Static batching is a draw call batching method that combines non-moving meshes to reduce draw calls. It converts the combined meshes to world space and builds a shared vertex and index buffer for them. Then, for the visible mesh, the engine performs a series of simple draw calls with almost no state changes between each call. Static batching does not reduce the number of draw calls, but rather the number of render state changes between them. Static batching is more efficient than dynamic batching because static batching does not transform vertices on the CPU. Turn off static batching option In the engine's Config3D.ts file, enableStaticBatch value option, true means turning on dynamic batching, false means turning off dynamic batching. Figure 5-1 Conditions for static batching: The object is Static (including sub-objects) Unified model using the same material Figure 5-2 6.Custom Static Batch(Static Batch Volume component) In the Object's inspect panel, add a component, select the Rendering option, and find the Static Batch Volume component. Figure 6-1 Drag the small white dot in the Scene window to select the appropriate Volume size. Figure 6-2 Use of the Static Batch Volume component: After the Volume box above is selected to the appropriate size, in the component's details panel, check Static Instance Batch, and then click reBatch. The selected object in the Volume will perform the Batch operation, optimizing Draw. Call to improve operational efficiency. The Batch component with the CheckLOD option checked will automatically check the object LOD attribute information in the Volume, and then divide all objects in the Volume into different LOD rendering objects according to the object LOD level of the LOD Cull Rate Array. Figure 6-3 Figure 6-4 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:21:06 "},"3D/WebXR/readme.html":{"url":"3D/WebXR/readme.html","title":"WebXR","keywords":"","body":"WebXR usage instructions1. Introduction to WebXR2. Current status and prospects of WebXR3. LayaAir engine WebXR applicationWebXR usage instructions 1. Introduction to WebXR WebXR is a set of standards that support rendering 3D scenes to present a virtual world (virtual reality, also known as VR) or to add graphics images to the real world (augmented reality, also known as AR). The WebXR Device API implements the core of the WebXR feature set, managing the selection of an output device, rendering a 3D scene to the selected device at the appropriate frame rate, and managing motion vectors created using input controllers. At the engine level, the scene is rendered in 3D by calculating the perspective applied to the scene to render the scene from each user's perspective, taking into account the conventional distance between eyes, and then rendering the scene twice, once for each eye . The resulting image (the scene is rendered twice on one frame, half for each eye) is then displayed to the user. As shown in Figure 1. (figure 1) 2. Current status and prospects of WebXR We can understand XR as the collective name for VR and AR. Whether it is VR equipment for pure virtual world immersion experience or AR equipment for enhanced display experience in the real world, they have begun to enter people's lives, and the number of people buying equipment continues to increase. This is just like the early state of smartphones. As the devices become lighter and lighter, the wearing experience becomes more and more friendly, and I believe their popularity will become wider and wider. Of course, we must also recognize the current XR devices. If the popularity is to reach the scale of smartphones, there are still many hard targets to be achieved. For example, in order to restore the visual experience of the real world, the field of view (FOV) of the VR device must be considered. The horizontal angle that a person's single eye can see without obstruction is about 150°, and the vertical angle is about 120°. If we want to achieve a retina-level high-definition display with a FOV experience close to this, then we need 8K for one eye and a visual display size of 16K for both eyes. This pressure on the transmission bandwidth and hardware performance of the web side cannot be solved in the short term. Even if millisecond-level eye tracking technology is used, it still needs to reach a physical resolution of 4K for one eye and 8K for both eyes. Taking into account the popularity of 5G and the improvement of hardware performance, the carrying and wearing experience of the product, etc. It will take at least a few years before you can barely reach the basic threshold of the national level. Although it cannot reach the level of universal application at present and in the near future, VR's hardware configuration, wearing experience, platform content quality and other ecology are obviously getting better, so the number of users is also growing. Coupled with the waves of popularity of the concept of the Metaverse in 2021, the capital market is more optimistic about the future prospects of this immersive experience. Therefore, the era of 2D display (without a sense of real space) will sooner or later transition to the era of immersive 3D display. Understanding and deploying XR in advance and taking the lead in entering the blue ocean field is an opportunity that cannot be missed. The LayaAir engine started to support the WebXR standard in version 2.13 and can run directly in the browsers of mainstream VR devices or in the mobile Chrome browser that supports the WebXR standard. 3. LayaAir engine WebXR application 3.1 Display on mobile phone 3.1.1 Mobile browser supporting webXR When running on a mobile phone, a VR box that can clamp the mobile phone can meet the needs of VR display. As shown in animation 2. (Animation 2) Since the current browsers on mobile phones are not friendly to webXR support, the currently known WebXR browser environments are only Chrome Android 79 or above and Samsung Internet 11.2 or above. And you also need to go over the wall to download the services necessary for webXR to run. In terms of interactive operation, there is currently no very mature supporting equipment. Therefore, in addition to watching movies, VR on mobile phones is not suitable for the application scenarios of our current ordinary mobile phones for interactive games. Unless it is for demonstration needs such as 3D exhibition halls without interaction, we do not VR development based on mobile phones is not recommended. 3.1.2 Prepare webXR running environment The hardware device when this document was written was the OPPO iQOO model, and the browser environment used was Chrome 96. You also need to download and install the Google Play app store through the VPN of Hong Kong, China. Then search and install Google Play Services For AR and Google VR services in the app store. The running environment does not need to be exactly the same as this article. It is enough to install the Google Play app store and the latest version of the Chrome browser (Android). After completing the above preparations, links based on the webXR standard can be displayed normally. 3.1.3 How to use LayaAir to develop webXR standard products Regarding the display of webXR, the official webXR website already has all the sample codes. The main processes are described here. You can also go to the official website examples to view the complete sample source code. First of all, scene loading, camera control, script addition, UI, etc. are no different from writing ordinary 3D games (so I won’t introduce this part). Before starting VR mode, Usually developers need to determine whether the current environment supports the VR mode of webXR, and then decide whether to activate the VR mode or activate the UI button to activate the VR mode. The API to support VR is: WebXRExperienceHelper.supportXR(\"immersive-vr\") //Determine whether the browser supports VR mode. There are three modes: immersive-vr\\immersive-ar\\inline this.changeActionButton.visible = await WebXRExperienceHelper.supportXR(\"immersive-vr\"); immersive-vr is the parameter of VR mode. If it is AR mode, the parameter can be changed to immersive-ar. This document only introduces VR mode. If it is detected that the VR environment is supported, you can enter VR mode directly, or activate the UI button to enter VR mode and enter VR mode by listening for clicks on the button. /** Initialize XR */ async initXR(){ //Create a webXR camera let caInfo : WebXRCameraInfo = new WebXRCameraInfo(); //Set the far cutting plane caInfo.depthFar = this.camera.farPlane; //Set the near cutting plane caInfo.depthNear = this.camera.nearPlane; //Apply for XR interaction and pass in the information needed for VR let webXRSessionManager = await WebXRExperienceHelper.enterXRAsync(\"imersive-vr\",\"local\",caInfo); //Set up WebXR camera WebXRExperienceHelper.setWebXRCamera(this.camera, webXRSessionManager); } Through the above code, the VR display can be completed. 3.2 Display and interaction in Oculus 3.2.1 Code part Whether it is a mobile browser or an Oculus VR device, since they are all based on the WebXR standard, the developer's code process is the same no matter where it is displayed. However, compared to mobile browsers, dedicated VR headsets such as Oculus are not only a natural webXR environment (no need to install additional XR services), but are also very user-friendly in terms of interactive operations. This is also our recommended VR development and experience. environment. Therefore, in this section, we will no longer introduce the VR display part, but directly introduce the interactive part. /** Initialize XR */ async initXR(){ //Create a webXR camera let caInfo : WebXRCameraInfo = new WebXRCameraInfo(); //Set the far cutting plane caInfo.depthFar = this.camera.farPlane; //Set the near cutting plane caInfo.depthNear = this.camera.nearPlane; //Apply for XR interaction and pass in the information needed for VR let webXRSessionManager = await WebXRExperienceHelper.enterXRAsync(\"imersive-vr\",\"local\",caInfo); //Set up WebXR camera let webXRCameraManager = WebXRExperienceHelper.setWebXRCamera(this.camera, webXRSessionManager); //Note, here begins the control interaction for VR entry handle input let webXRInput = WebXEExperienceHelper.setWebXRInput(webXRSessionManager, webXRCameraManager); this.bindMeshRender(webXRInput); } bindMeshRender(webXRInput:WebXRInputManager){ let rightControl = Laya.loader.getRes(\"res/OculusController/controller.gltf\") as Sprite3D; let leftControl = Laya.loader.getRes(\"res/OculusController/controller-left.gltf\") as Sprite3D; let pixelright = new PixelLineSprite3D(20,\"right\"); let pixelleft = new PixelLineSprite3D(20,\"left\"); this.scene.addChild(rightControl); this.scene.addChild(leftControl); this.scene.addChild(pixelright); this.scene.addChild(pixelleft); webXRInput.bindMeshNode(leftControl,WebXRInput.HANDNESS_LEFT); webXRInput.bindMeshNode(rightControl,WebXRInput.HANDNESS_RIGHT); webXRInput.bindRayNode(pixelleft,WebXRInput.HANDNESS_LEFT); webXRInput.bindRayNode(pixelright,WebXRInput.HANDNESS_RIGHT); //Get the frame loop scheme of xrInput webXRInput.getController(WebXRInput.HANDNESS_RIGHT).on(WebXRInput.EVENT_FRAMEUPDATA_WEBXRINPUT,this,this.getRightInput); webXRInput.getController(WebXRInput.HANDNESS_LEFT).on(WebXRInput.EVENT_FRAMEUPDATA_WEBXRINPUT,this,this.getLeftInput); /** * 0 trigger * 1 side trigger * 3 Joystick pressed * 4 X, A key * 5 Y, B key */ //Left controller listening let leftXRInput = webXRInput.getController(WebXRInput.HANDNESS_LEFT); //Button event listening of the left controller leftXRInput.addButtonEvent(0,ButtonGamepad.EVENT_TOUCH_OUT,this,this.LeftbuttonEvent0); // Pay attention to different triggers of the same button leftXRInput.addButtonEvent(1,ButtonGamepad.EVENT_TOUCH_STAY,this,this.LeftbuttonEvent1); leftXRInput.addButtonEvent(1,ButtonGamepad.EVENT_TOUCH_OUT,this,this.LeftbuttonEvent1_1); leftXRInput.addButtonEvent(3,ButtonGamepad.EVENT_TOUCH_OUT,this,this.LeftbuttonEvent3); leftXRInput.addButtonEvent(4,ButtonGamepad.EVENT_TOUCH_ENTER,this,this.LeftbuttonEvent4); leftXRInput.addButtonEvent(5,ButtonGamepad.EVENT_TOUCH_OUT,this,this.LeftbuttonEvent5); // Monitor the joystick event of the left controller leftXRInput.addAxisEvent(1,AxiGamepad.EVENT_OUTPUT,this,this.LeftAxisEvent); //Right controller listens let rightXRInput = webXRInput.getController(WebXRInput.HANDNESS_RIGHT); //Button event listening of the right controller rightXRInput.addButtonEvent(0,ButtonGamepad.EVENT_PRESS_ENTER,this,this.RightbuttonEvent0); rightXRInput.addButtonEvent(0,ButtonGamepad.EVENT_PRESS_VALUE, this, this.rightTriggerOn); // Pay attention to different triggers of the same button rightXRInput.addButtonEvent(1,ButtonGamepad.EVENT_PRESS_STAY,this,this.RightbuttonEvent1); rightXRInput.addButtonEvent(1,ButtonGamepad.EVENT_PRESS_OUT,this,this.RightbuttonEvent1_1); rightXRInput.addButtonEvent(3,ButtonGamepad.EVENT_PRESS_OUT,this,this.RightbuttonEvent3); rightXRInput.addButtonEvent(4,ButtonGamepad.EVENT_PRESS_ENTER,this,this.RightbuttonEvent4); rightXRInput.addButtonEvent(5,ButtonGamepad.EVENT_PRESS_OUT,this,this.RightbuttonEvent5); // Monitor the joystick event of the right controller rightXRInput.addAxisEvent(1,AxiGamepad.EVENT_OUTPUT,this,this.RightAxisEvent); } /** For omitted codes, please go to the official website for examples **/ The above code is not all the code. For all the codes for oculus display and interaction, please go to the official website examples to view. 3.2.2 demo test tips After the code is compiled, go directly to the browser that comes with Oculus Quest and enter the test address to run the test effect. Reminder: Account activation for Oculus Quest devices also requires VPN circumvention. The default state in the example is normal mode. You need to click the button to switch to WebXR mode. At this time, you can view the VR example and interact with the controller. After setting the game area of ​​the VR device, open the browser of the VR device and jump to the address of the WebXRController example. Wait for the example to load and run. The default state in the example is normal mode. You also need to click the button to switch to WebXR mode. This You can view VR examples and interact with controllers. Controller interaction description for example: Ray detection and picking up objects The left and right controllers and rays are visible in the VR scene. Objects can be detected and picked up through rays. The specific operation is to point the end or direction of the ray to the object to be picked up, and continuously press the side triggers of the left and right controllers. Lock object. Adjust the distance from the picked object After picking up the object, you can adjust the distance to the object through the buttons on the controller; on the right controller, the \"B\" key increases the distance to the object, and the \"A\" key decreases the distance to the object; on the left controller On the top, the \"Y\" key increases the distance to the object, and the \"X\" key decreases the distance to the object. It should be noted that the X and Y buttons of the left controller are TOUCH type events, which are sensitive to triggering and can be triggered by touching the buttons. Adjust the rotation speed of picked objects After picking up the object, you can control the rotation speed of the object through the trigger button on the controller; the trigger range of the right controller is a linear range, and the rotation speed can be controlled by the force applied to the trigger in the range of 0~1; the left controller The trigger event of the controller can also be in a linear range. In order to distinguish the event trigger, the left controller trigger is set to a fixed value and cannot be adjusted by the left trigger. Adjust the rotation angle of the picked object on the x and y axes After picking up the object, you can use the joystick on the controller to adjust the rotation angle of the object on the x-axis and y-axis. The logic of the two controller joysticks is consistent. The forward and backward movement of the joystick adjusts the angle of the object on the x-axis; Moving the rod left and right adjusts the angle of the object on the y-axis. Controller event monitoring Controller event monitoring is mainly divided into two categories: TOUCH and PRESS. The event monitoring and implementation logic are as follows: EVENT_TOUCH_ENTER and EVENT_PRESS_ENTER: The corresponding monitoring is the X and A keys of the left and right controllers. The logical difference is that the X key can be triggered by lightly touching it, and the A key needs to be pressed to trigger. EVENT_TOUCH_STAY and EVENT_PRESS_STAY: The corresponding monitoring is the side trigger button of the left and right controller, which needs to be continuously touched or pressed. EVENT_TOUCH_OUT and EVENT_PRESS_OUT: The corresponding monitoring is the Y and B keys of the left and right controllers. The logical difference is that the Y key is lightly pressed to leave and the B key is pressed to leave. EVENT_PRESS_VALUE: There is a range of events corresponding to the right trigger output type. The logic is implemented to return a floating value based on the pressing force of the trigger. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 15:04:34 "},"3D/advanced/Unity/readme.html":{"url":"3D/advanced/Unity/readme.html","title":"Unity Resource Plugin","keywords":"","body":"Unity resource export plug-in1. About plug-ins2. Import LayaAir’s Unity plug-in2.1 Installing the plug-in for the first time in the project2.2 Plug-ins have been updated2.3 Reminder for plug-in import and installation3. Functions of resource export plug-in3.1 Scene export3.2 Preset export3.3 Help4. Scene object export support list4.1 Basic properties of the Inspector panel4.2 Camera properties4.3 Lighting-related attributes4.4 Model-related attributes4.5 Texture properties4.6 Animation properties4.7 Prefab5. Model export file and loading display5.1 Description of export file types5.2 Loading display6. Frequently Asked QuestionsUnity resource export plug-in 1. About plug-ins The main reason for adopting the Unity plug-in solution is to support developers to seamlessly migrate the resources purchased in the Unity Resource Mall to LayaAir IDE for related development work. The Unity Resource Mall has a certain amount of exquisite and high-quality art. Resources, using the Untiy resource export plug-in can migrate these exquisite art resources to the IDE of the LayaAir engine for development. It is undoubtedly an invisible help for some small and beautiful projects, and can also allow high-quality developers with Unity experience You can enter the HTML5 and mini-game industries at a lower learning cost. Plug-in project address: https://github.com/layabox/LayaAir3.0UnityPlugin.git 2. Import LayaAir’s Unity plug-in There is a function in Unity to import custom packages. Through this function, you can import the exclusive function package provided by the LayaAir engine into Unity to export the scenes and resources edited in Unity, and then use them for 3D development of the LayaAir engine. The process of importing this customized LayaAir function package into Unity can be regarded as installing a Unity plug-in that exports LayaAir engine resources. This section will introduce this process in detail. 2.1 Installing the plug-in for the first time in the project After opening a Unity project, if the plug-in has not been installed, you need to open the Window->Package Manager window under the Unity menu bar, as shown in Figure 2-1. (Figure 2-1) Then, as shown in Figure 2-2, in the opened window, click the + button in the upper left corner and select Add package from git URL. (Figure 2-2) Fill in the Git address of the plug-in (https://github.com/layabox/LayaAir3.0UnityPlugin.git) and click Add, as shown in Figure 2-3. (Figure 2-3) After clicking, the plug-in will be installed automatically. The effect after the installation is completed is shown in Figure 2-4. (Figure 2-4) After the plug-in is installed, you can see an additional LayaAir3D in the menu bar, as shown in Figure 2-5. This shows that the import has been successful. (Figure 2-5) 2.2 Plug-ins have been updated If LayaAir officially updates the plug-in, and the resource export plug-in is already installed in the developer's Unity project, the developer only needs to update it. As shown in Figure 2-6, find the LayaAir 3.0 Export Tool plug-in in the Package Manager window and click Update to update it. (Figure 2-6) If you want to remove the plugin, just click Remove. 2.3 Reminder for plug-in import and installation For developers who are not familiar with Unity, please be reminded that the LayaAir engine Unity resource export plug-in is not universal for all projects imported at one time. After each new project is created, the above process of importing the LayaAir plug-in package must be repeated. Also note: 1. Reminder about color space: LayaAir is a linear color space. For developers whose Unity color space is set to Gamma, the export effect may be inconsistent with LayaAir. Developers need to confirm whether Unity is set to Linear color space. You can use the following steps to view the settings of Unity color space: Editor -> Project Setting -> Player -> Other Setting -> Color Space, the operation is shown in Figure 2-7. (Figure 2-7) 2. Reminder about normal map Unity's normal map has been compressed. When exporting, the LayaAir IDE preview may be inconsistent with Unity. Users who customize Shader need to pay attention to the normal transformation. 3. Functions of resource export plug-in 3.1 Scene export (Figure 3-1) Scene export panel 3.1.1 Node settings Ignore inactive nodes: If this option is checked, inactive nodes such as Camera in Figure 3-2 will not be exported. (Figure 3-2) 3.1.2 Model settings Ignore vertex UV: If this option is checked, there will be no UV information in the exported Mesh data. Ignore vertex color: If this option is checked, the exported Mesh data will have no vertex color information. Ignore vertex normals: If this option is checked, the exported Mesh data will have no vertex normal information. Ignore vertex tangents: If this option is checked, the exported Mesh data will have no vertex tangent information. Automatically generate UV1: If this option is checked, the exported Mesh data UV Set is set to UV1. 3.1.3 Other settings Customized export root directory: If you check this option, as shown in Figure 3-3, you can set the resource path exported by the plug-in (fill in the absolute path in the text box). (Figure 3-3) 3.2 Preset export (Figure 3-4) Preset export panel 3.2.1 Node settings Ignore inactive nodes: If this option is checked, inactive nodes such as Camera in Figure 3-5 will not be exported. (Figure 3-5) Export first-level nodes in batches: If this option is checked, nodes similar to those in Figure 3-6 will eventually be exported as the LayaMonkey root node. (Figure 3-6) 3.2.2 Model settings Ignore vertex UV: If this option is checked, there will be no UV information in the exported Mesh data. Ignore vertex color: If this option is checked, the exported Mesh data will have no vertex color information. Ignore vertex normals: If this option is checked, the exported Mesh data will have no vertex normal information. Ignore vertex tangents: If this option is checked, the exported Mesh data will have no vertex tangent information. Automatically generate UV1: If this option is checked, the exported Mesh data UV Set is set to UV1. 3.2.3 Other settings Customized export root directory: If you check this option, as shown in Figure 3-7, you can set the resource path exported by the plug-in (fill in the absolute path in the text box). (Figure 3-7) 3.3 Help In the help menu item, the lower-level menus include Study Document Study and Q&A Community Answers, which are external link menu items to facilitate developers to quickly enter the corresponding official website page. There is also a plug-in version About LayaAir, as shown in Figure 3-8. (Figure 3-8) 4. Scene object export support list In addition to the export settings on the LayaAir engine plug-in's own panel, we also need to pay attention and must understand which of Unity's function panels can be exported and which are not supported. Because the Unity plug-in of the LayaAir engine does not support export of all Unity functions. After all, the design and structure of our LayaAir engine is different from Unity's engine. Although the 3D scene is edited and exported based on the Unity editor, we need to use it according to the support rules of the LayaAir engine plug-in. In this section, we will comprehensively introduce the functions in Unity supported by the LayaAir engine and plug-ins. If it is not mentioned in the support list in this section, it is not currently supported. Therefore, if you are a developer who is new to Unity, you do not need to learn all of them when learning how to use Unity tools. You can just search and learn the support content involved in this section as keywords. The LayaAir engine plug-in will also be constantly updated. After upgrading to a new engine version, you can pay attention to the version update log and changes in this document. 4.1 Basic properties of the Inspector panel In Unity's Inspector panel, you can view and edit almost everything in the Unity editor. Next, let's first take a look at the basic common properties of the Inspector panel. (Pic 4-1) In the basic properties in Figure 4-1, LayaAir export support is as follows: Unity’s Inspector basic properties Instructions on whether LayaAir supports exporting GameObject Name (node ​​name) Supported Static Only supports checked or unchecked Layer Only supports the export of layer serial numbers. Developers can also set Layer in the LayaAir engine Position Support (including: X, Y, Z) Rotation Support (including: X, Y, Z) Scale Support (including: X, Y, Z) Comparing the above figure and table, we see that Tag is not supported. Static and Layer are partially supported. There will be no further reminders, just pay attention to the support status in the table. Here is a special mention. After static is checked, all is selected, that is, Everything, as shown in Figure 4-2. But in fact, the LayaAir engine only supports Lightmap Static and Batching Static, so if developers don’t select Everything, can they only check these two? Of course it doesn't work. We actually only recognize the status of Static checked or unchecked. If you select it here separately, the export will have no effect. (Figure 4-2) 4.2 Camera properties (Figure 4-3) In the Unity camera properties in Figure 4-3, LayaAir export support is as follows: Unity camera properties Instructions on whether LayaAir supports exporting Clear Flags Support (including: Skybox (Background color), Solid Color (Background color), Depth only, Don’t Clear) Projection Support (including: Perspective (Field of View), Orthographic (size)) Clipping Planes Support (including: Near point, Far point) Viewport Rect (standard view rectangle) Support (including: X, Y, W, H) Allow HDR (allow rendering of high dynamic color images) Support Culling Mask is invalid when set in Unity, but it is supported in layaAir engine. The default value is equivalent to Everything in Unity. The layer ID can also be set through the engine's cullingMask. 4.3 Lighting-related attributes 4.3.1 Light attribute Light (Figure 4-4) In the Unity light properties in Figure 4-4, LayaAir export support is as follows: Unity light properties Instructions on whether LayaAir supports exporting Type Partially supported (including: Spot light (Range illumination range, Spot Angle spotlight cone angle), Directional parallel light, Point point light (Range illumination range)) Color (light color) Support Mode (light mode) Support (including: Realtime real-time lighting, Baked light map, Mixed mixed light source) Intensity (light intensity) Support Shadow Type Supported (including: Soft Shadows, Hard Shadows) 4.3.2 Properties of reflection probe Reflection Probe (Figure 4-5) When the Reflection Probe component is added to Unity, in the properties in Figure 4-5, LayaAir export support is as follows: Unity’s reflection probe related configuration properties Instructions on whether LayaAir supports exporting Type Partially supported (including: Baked baking mode, Custom mode) Runtime settings Partially supported (including: Importance weight parameter, Intensity brightness, Box projection box offset reflection, Box Size reflection probe size, Box Offset reflection probe offset) Cubemap capture settings Supported 4.4 Model-related attributes Regarding the attributes of the model, ordinary models and skeletal models are supported respectively. 4.4.1 Ordinary model Ordinary models require the Mesh Filter component and the Mesh Render component, which are introduced separately below. Mesh Filter (Figure 4-6) In the Unity grid filter properties in Figure 4-6, LayaAir export support is as follows: Unity's skinned mesh rendering properties Instructions on whether LayaAir supports export Mesh support Mesh Renderer (Figure 4-7) (Figure 4-8) In the properties of Unity's Mesh Render component in Figure 4-7, LayaAir export support is as follows: Unity's mesh rendering properties Instructions on whether LayaAir supports exporting Materials Support (including: Size, Element material ball elements) Lightmap Static (static light map) Partially supported (including: Lightmaps map (Baked Lightmap baked light map (Lightmap Index, Tiling X, Tiling Y, Offset X, Offset Y))) 4.4.2 Skeleton model The Mesh and Mesh Renderer of the skeletal model are no longer separated and are merged into the component Skinned Mesh Renderer, as shown in the following figure: (Figure 4-9) In the properties of Unity's Skinned Mesh Renderer component in Figure 4-9, LayaAir export support is as follows: Unity's skinned mesh rendering properties Instructions on whether LayaAir supports export Mesh Support Root Bone (bone root node) Support Bounds Support (including: Center (X, Y, Z), Extent range (X, Y, Z)) Materials Support (including: Size, Element material ball elements) 4.4.3 Material Regarding the material of the model, here we introduce the commonly supported material types. Classification Material Build in pipeline Standard material Ulit Color/Texture/Cut Out/ Transparent material URP pipeline URP Lit material URP Ulit material skybox Procedural procedural skybox 6 Eight Panoramic panorama Old version shaders (for compatibility reasons only, not recommended) Diffuse Fast Diffuse Diffuse Detail Bumped Diffuse Bumped Specular Except for the material Shader provided above, other materials in Unity cannot be used in the LayaAir engine. 4.5 Texture properties In the Assets panel, find the 2D image resource and set the texture properties for it. (Figure 4-10) In the Unity texture properties in Figure 4-10, LayaAir export support is as follows: Unity texture properties Instructions on whether LayaAir supports exporting Generate Mip Maps (Generate Mipmap) Partially supported (only the checked state is supported) Wrap Mode Partial support (including: Repeat, Clamp forced stretching) Filter Mode Support (including: Point filtering, Bilinear filtering, Trilinear filtering) Aniso Level Support 4.6 Animation properties In terms of animation, LayaAir supports the export and use of some properties of the Animator component and the associated Animator Controller panel. 4.6.1 Aniamtor component (Figure 4-11) In the Unity animation properties in Figure 4-11, LayaAir export support is as follows: Unity animation properties Instructions on whether LayaAir supports exporting Controller (Animation Controller) Support Culling Mode (culling mode) Partially supported (including: Always Animate always plays, Cull Completely completely eliminated) 4.6.2 Animator Controller State Double-click the Controller in the Aniamtor component properties to open the animation controller panel, select State (state), and you can see the panel shown in Figure 4-12. (Figure 4-12) In the State property of the Unity animation controller in Figure 4-12, LayaAir export support is as follows: Unity's animation controller State property Instructions on whether LayaAir supports export Motion (selected animation) support Speed ​​(animation playback speed) Support 4.7 Prefab As shown in Figure 4-13, prefabs in Unity support exporting, but the properties (lights, materials, etc.) contained in the exported prefab must be properties supported by the plug-in, that is, the properties listed in this section. (Figure 4-13) 5. Model export file and loading display After understanding the functions and usage rules of the plug-in, we can edit and export it in Unity, but what do the exported file names represent and how are they loaded and used. This section begins with an introduction. 5.1 Description of export file types File suffix Export file type description .ls Scene file, select the file type generated when exporting the Scene3D category. Complete scene information will be exported, including various data, light maps, models, positions, etc. required for the scene. Therefore, when you need to export scene-related settings, you must use the Scene3D category to export, and you can see the file with the .ls suffix. .lh Preset file, select the file type generated when exporting the Preset Sprite3D category. Compared with scene files with the .ls suffix, there will be a lack of information related to scene rendering such as ambient light, environmental reflection, scene fog effects, etc. .lm Model data file, usually converted from FBX format. .lmat Material data file is the material information set for the model in Unity. When loading a .ls or .lh file, the .lmat file will be automatically loaded to generate the material. Can be loaded using the BaseMaterial class. .last year Animation data file. If there is animation on the model, the animation configuration file will be generated after exporting, which contains animation frame data. Loading can be done using the AnimationClip class. .jpg Texture image files in JPEG format. .png Texture image file in PNG format. .hdr HDR format picture files required for panoramic skybox 5.2 Loading display If the exported Unity resources are to be displayed through the LayaAir engine without considering other logic, the resources need to be loaded first. 5.2.1 Scene loading display When we want to export the entire scene, we can select the scene and set the export path. As shown in Figure 5-1, it is recommended that the export path be set to the assets folder under the project directory of the LayaAir IDE project. As for the directory under the assets directory, it is up to the developer to decide. (Figure 5-1) After exporting, just open the .ls file in the IDE to load the scene. After opening the scene, the exported scene does not have ambient light information. You need to find the baking switch under the Scene3D level. As shown in Figure 5-2, click Bake to precompute the ambient light sh data of the current scene. In this way, the effect after baking is the effect we want. (Figure 5-2) 5.2.2 Default loading display As shown in Figure 5-3, the preset export is mainly used when the entire scene does not need to be fully exported and only certain node resources are needed. Or some node resources need to be exported independently for reuse or dynamic use of code. (Figure 5-3) 6. Frequently Asked Questions If you encounter the error message below, the reason is that some packages are missing. (Figure 6-1) At this time, you need to open the package manager Package Manager in the Window menu. After opening, as shown in Figure 6-2, search for editor, then select the two packages \"Editor Coroutines\" and \"Version Control\" and add them. (Figure 6-2) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-22 14:50:03 "},"released/generalSetting/readme.html":{"url":"released/generalSetting/readme.html","title":"General Setting","keywords":"","body":"Universal release1. Overview2. Publish in IDE2.1 Build and release2.2 General options2.3 Target platform2.4 Resources used by published code2.5 Resources used in IDE2.6 Resource subcontracting2.7 Code subcontracting3. Packaging Album3.1 Why use atlas resources?3.2 Supported album packaging formats3.3 How to create an atlas using LayaAir IDE3.4 Introduction to packaged and generated atlas files3.5 How to use small pictures in the atlas in the project4. Release native resourcesUniversal release 1. Overview After completing the development of the project in LayaAir, the project needs to be published. Publishing a project is an important step in getting a developer's game or application packaged and ready for deployment to a target platform, whether it's a web browser, mobile device, or other supported platform. LayaAir3.1.x reconstructs the contract issuing process based on 3.0.x. The new version supports batch publishing, API calls, and plug-in extensions. 2. Publish in IDE 2.1 Build and release To use the IDE to publish a project, developers first open the \"Build and Release\" option in the file menu, as shown in Figure 2-1: (Figure 2-1) 2.2 General options After the build release option is turned on, you can see that there is a common option, which is consistent for each target platform: Name: The name of the project (for web publishing, it is the title name in html). Output directory: The output directory refers to the target directory to be published to. By default, it is in the release directory of the project. It is not recommended to change it here. Of course, if the developer needs to customize the output directory, it can be in the directory where the project is located, or it can be a directory unrelated to the project. Compression engine library: It is generally recommended to check it. After checking, the compressed engine class library will be used, which can reduce the package size. Compress JS file: It is generally recommended to check it. After checking, the compressed JS file will be used, which can reduce the package size. Generate source code mapping: When checked, the output directory will package the \".js.map\" file for source code mapping. Startup scene: The first scene when starting the project runtime. Include scene: In the included scene, the referenced resources will be copied to the output directory (refer to 2.5.1 for details). Always included resource directory: Resources in the selected resource directory are always copied to the output directory (refer to 2.5.2 for details). Copy files in BIN directory: When checked, the published output directory will include the files in the bin folder in the project directory (refer to Section 4 for details). Turn on version management: When checked, a key value will be added to the published file name for version management mapping, which can effectively avoid the impact of incorrect loading caused by cache or CDN. Enable subcontracting: After checking, the subcontracting function is enabled (refer to 2.6 and 2.7 for details). 2.3 Target platform Currently, there are nine publishing options in the target platform, namely: Web, Android, iOS, Douyin mini games, OPPO mini games, VIVO mini games, WeChat mini games, Xiaomi Kuai Games, and Alipay mini games. As shown in Figure 2-2, after selecting the corresponding platform, click Build. (Figure 2-2) Web means published as HTML5 version, running in the browser environment, webView, LayaNative APP environment. Android means released as an Android platform and runs in the Android APP environment. iOS refers to an APP released as an iOS platform and running in the iOS APP environment. Douyin Mini Game refers to the project published as adapted Douyin Mini Game. OPPO Mini Games refers to projects published as adapted OPPO Mini Games. `VIVO mini-games' refer to projects published as adapted VIVO mini-games. WeChat Mini Games refers to projects published as adapted WeChat Mini Games. Xiaomi Quick Game refers to projects published as adapted to Xiaomi Quick Game. Alipay Mini Game refers to a project published as an adapted Alipay Mini Game. This article mainly introduces the general publishing settings. You can click the above link to view the documentation for each publishing platform. You can also click the \"Build Other\" option in Figure 2-2 to publish directly to the corresponding platform. After publishing, you can see the publishing results in \"View Tasks\". 2.4 Resources used by published code Developers often use code references to use resources in their projects, so the IDE cannot recognize these resources. Therefore, the IDE specifies the Resources directory to meet this requirement for developers, as shown in Figure 2-3: (Figure 2-3) This is a sample project that uses code only. Note that there are two images image and c1 in the resources directory. Let’s take a look at the released directory. Taking Web publishing as an example, click the \"Build Web\" button and wait until the publishing is successful, as shown in Figure 2-4. (Figure 2-4) You will see that under the web directory (if a mini-game is released, it corresponds to the mini-game directory), there will also be a resources directory, which includes image and c1. At the same time, there will be a \"fileconfig.json\" file in the web directory. In fact, the json file contains resource attribute information. The content of the file is as follows: { \"sRGB\": true, \"wrapMode\": 0, \"filterMode\": 1, \"anisoLevel\": 0, \"readWrite\": false, \"mipmap\": false, \"pma\": true, \"hdrEncodeFormat\": 0, \"files\": [ { \"file\": \"\", \"ext\": \"png\", \"format\": 1 } ], \"platforms\": { \"0\": 0, \"1\": 0, \"2\": 0 } } Any resources in the resources directory will be published to the output directory without additional action, so developers can use the resources directory as a directory for code to use resources. 2.5 Resources used in IDE The above resources directory is mainly for using resources with code. Resources need to be stored in the resources directory. However, in our actual development process, resources are usually placed in the assets directory, including scenes and prefab files, etc., as shown in Figure 2-5. (Figure 2-5) With so many resource directories, changing them all to the resources directory would be a very huge modification work. Therefore, the IDE provides developers with two more convenient ways: 2.5.1 Including scenes: resources referenced in the scene As shown in Figure 2-6, scenes such as Game can be added to the included scene. The resources referenced by these scenes will be published to the output directory. After publishing, open the published directory. (Figure 2-6) As shown in Figure 2-7, these directories have been successfully published to the output directory. (Figure 2-7) Next run it to see the effect, as shown in the animation 2-8: (Animation 2-8) The scene can be seen running normally, but no enemies are found, and there is no music. Turn on the debugging information, as shown in Figure 2-9. You can see that enemy.lh and bgm.mp3 are not in the output directory. This is because enemy.lh and bgm.mp3 are executed through code. The resources referenced in the code must be placed in the resources directory before they are copied to the release directory. If the resources referenced by the code are not in the resources directory and are not referenced in the scene, the directory where the resource is located needs to be set to Always Contains the resource directory. (Figure 2-9) At this time, we can use the second method 2.5.2 Always include resource directories: resources referenced in the code In the \"Always Include Resource Directory\" option, click + to select the folder where the enemy.lh and bgm.mp3 resources are located, as shown in Figure 2-10: (Figure 2-10) At this time, publish again. After the publishing is successful, check the output directory, as shown in Figure 2-11. It is found that the enemy.lh and bgm.mp3 files have been published to the prefab and music directories respectively. (Figure 2-11) Run it at this time and see the effect. As shown in Figure 2-12, the enemy is running normally, indicating that the resource release has been included. (Figure 2-12) Finally, to summarize, as shown in Figure 2-13, through the resources directory, included scenes, and always included resource directories, all the resources used during the project running process can be successfully packaged into the output directory. When the project requires fewer resources, they can be placed in the resources directory numbered 1 in the figure, so that resources referenced in the scene or in the code can be published to the output directory; when the project has more resources , it is inconvenient to manage in the resources directory, so when publishing, you need to set up the resource directory outside the resources directory. The scene should be added in the \"Included Scenario\" numbered 2, and the resources referenced in the code should be added in the \"included scene\" numbered 3. \"Always included in the resource directory\". (Figure 2-13) In the initial stage of project development, developers should try to plan the directory structure of project resources in advance to avoid repeated use of resources, or continuous modification of resource directories in the later stages of the project, resulting in resource reference errors in the scene. 2.6 Resource subcontracting When building and publishing, you can turn on subcontracting. Resource subcontracting is to divide the selected resources into multiple small packages to facilitate users to load resources and avoid problems such as network instability and interruptions. The following takes web publishing as an example to demonstrate how to enable resource subcontracting. As shown in the animation 2-14, after clicking Open Subpackaging, you can add one or more subpackages below. Two subpackages (resource folders) are added in the animation. Select the paths \"sub1\" and \" sub2\", all resources under these two paths will each become a subcontract after release. \"sub1\" has a prefab (Cube.lh), material (CubeMaterial.lmat), and texture map (layaAir.png); \"sub2\" has only one prefab (Sphere.lh). (Animation 2-14) When configuring resource subcontracting, you need to set the following parameters: Parameters Description Resource folder The contents in the resource folder are the resources to be subcontracted Entrance script Refer to code subcontracting in Section 2.7 Whether the package is remote After checking, the resource folder (subpackage) will be released to the release\\xxx-remote directory after version release Automatically load at startup If checked, the resource folder (subpackage) will be automatically loaded when running the published project Remote package address If you check \"Remote package or not\" and \"Automatically load at startup\" at the same time, this parameter will be displayed and you will be asked to fill in the address of the remote package The remote package file after Web publishing is in the web-remote folder. Mini games also support remote packages. The remote package after release is located in the release directory. For example, the remote package file after the WeChat mini game is released is located in the release\\wxgame-remote folder. The same is true for other mini games. 2.6.1 Remote package Remote package means that these resources can be placed on CDN (content distribution network, readers who don't understand can first understand it as a kind of server) to provide high performance, scalability and low-cost network content to users. If the web platform does not use remote packages, there is little point in subcontracting them. Mini games use remote packages to reduce the package size. For example, as shown in Figure 2-15, if the \"sub1\" and \"sub2\" directories are set as remote packages, after publishing, these two directories will be published to the \"release\\web-remote\" directory. (Animation 2-15) Developers need to upload all the subdirectories under \"web-remote\" to the CDN by themselves (not the \"web-remote\" directory itself, but \"sub1\" and \"sub2\" under the directory). After the upload is completed, \" Delete the web-remote\" directory to prevent it from taking up space (you can also keep it). For the convenience of demonstration, local server is used to simulate instead of CDN. Create a new folder on the desktop named \"serve\", which represents the folder in the local server. A new text file \"This is a local server.txt\" is created in it to test that the local server starts successfully. You can use Node.js anywhere to start a local server. As shown in the animation 2-16, open the command line cmd in the \"serve\" folder, enter anywhere 2840, and then click the Enter key on the keyboard to start a local server, where 2840 is the specified port number . (Animation 2-16) As you can see from the animation, the address of the local server is http://192.168.56.1:2840/. This address will be used in the subsequent demonstration. It should be noted here that when running the published project, the local server needs to be turned on. The next step is to import the resources to the local server. When actually uploading to CDN, you can use tools to upload, but for the local server, directly upload the remote packages (\"sub1\" and \"sub2\") from the \"web-remote\" file Just cut or copy the folder to the \"serve\" folder. After importing the remote package to the local server, there are two situations for loading the remote package, automatic loading in the IDE, and loading with code. 2.6.2 Automatic loading in IDE As shown in Figure 2-17, after referencing resources in the IDE (adding resources in the scene), (Figure 2-17) When building and publishing, check Automatically load at startup, and then fill in the remote package address, which is the address of the local server http://192.168.56.1:2840/, as shown in the following animation: (Animation 2-18) After clicking Version Release, you need to upload \"sub1\" and \"sub2\" to the \"serve\" folder of the local server again, as shown in animation 2-19: (Animation 2-19) Now you can run the published Web project, as shown in animation 2-20. The same method is used for local debugging. Open the command window in the published folder, enter anywhere and press Enter to start. When running the Web project, it is The default port number is 8000. Be sure to keep the local server with the remote package address http://192.168.56.1:2840/ open. (Animation 2-20) You can see that the resources are loaded. Open the developer tools, as shown in Figure 2-21. You can see that the resources are loaded from the remote package http://192.168.56.1:2840/. (Figure 2-21) 2.6.3 Resources referenced by the code Sometimes, we don't want the game to load too many resources at the beginning. This will cause the load to be too large, and then manual code loading is required. As shown in Figure 2-22, the resource to be subcontracted is not referenced in the scene. Add a custom component script in the attribute settings of the Scene2D node. (Figure 2-22) Then add the following code to the script: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Scene3D }) scene3d: Laya.Scene3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Web platform uses remote package Laya.loader.loadPackage(\"sub1\",\"http://192.168.56.1:2840/\",this.printProgress).then(()=>{ Laya.loader.load(\"sub1/cube.lh\").then((res:Laya.PrefabImpl) =>{ let sp3:Laya.Sprite3D =res.create() as Laya.Sprite3D; this.scene3d.addChild(sp3); }); }) Laya.loader.loadPackage(\"sub2\",\"http://192.168.56.1:2840/\",this.printProgress).then(()=>{ Laya.loader.load(\"sub2/sphere.lh\").then((res:Laya.PrefabImpl) =>{ let sp3:Laya.Sprite3D =res.create() as Laya.Sprite3D; sp3.transform.localPositionX += 1.0; //Prevent the sphere and cube from overlapping at the initial position this.scene3d.addChild(sp3); }); }) } printProgress(res: any) { console.log(\"Loading Progress\" + JSON.stringify(res)); //Convert the res object into a string in JSON format. The value printed here is 1. This code is mainly used to print loadTask to reflect the download progress after the mini-game is released. } } Note: For resource loading, please refer to \"Resource Loading\". When loading the exploit code, uncheck Automatically load at startup, but if the subpackaged resources are not in the resources directory (\"sub1\" and \"sub2\" in this example are not there), you must add the package to Always include In the resource directory, the configuration is as shown below: (Figure 2-23) After publishing, as with the previous operation, \"sub1\" and \"sub2\" need to be uploaded to the local server \"serve\" folder. Next, you can run the Web project. Same as the previous operation, use anywhere to start. The effect is shown in Figure 2-24: (Figure 2-24) You can see that the resource is loaded. Open the developer tools, as shown in Figure 2-25. You can see that the resource is loaded from the remote package http://192.168.56.1:2840/. (Figure 2-25) 2.7 Code subcontracting 2.7.1 Method In addition to resource subcontracting, code can also be subcontracted. Generally used for sub-packaging of mini-games, it can reduce the size of the first package (because mini-games limit the size of the package) and speed up loading. Code subcontracting requires the use of script set definition, which can automatically package the scripts in the specified directory (under the src directory) into a separate js. It's also suitable for non-subcontracting purposes, such as simply wanting to split code. As shown in Figure 2-26, a script set definition can be created in the project resource panel. (Figure 2-26) Usually, the script files you write will be concentrated in the bundle.js file in the project directory \"bin\\js\\bundles\". If a certain part of the code is split, this part of the code will be transferred to the \"script set definition.js\" file in the project directory \"bin\\js\\bundles\". As shown in Figure 2-27, after creation, you can configure it in its property settings panel. (Figure 2-27) Activate: Generally needs to be checked. When checked, code subcontracting is activated. Global name: generally does not need to be set. Used for module naming, such as module1, then other modules can access the classes and functions exported by this module through \"module1.xxx\". Allow editor loading: Generally needs to be checked. When checked, the script will also be loaded in the editor environment. Allow runtime loading and Automatic loading: generally need to be checked. When checked, the script will be loaded automatically at runtime. Allow compression when publishing: When building a release, if \"Compress JS files\" is set, this script will be compressed. Entry file and Include all files: control which TS scripts must be included. The subpackage definition is for the directory. In which directory it is located, the files in this directory will be included in this subpackage. Dependencies: Like JS plug-ins, they manage the loading order. That is, you can set up multiple scripts, and these scripts will be loaded first. After configuration, when publishing the project, you only need to place the script set definition in the entry script, and then select a non-main package folder in the resource folder. Note that the sub-package cannot be a remote package, as shown in Figure 2 -28 shown, (Figure 2-28) 2.7.2 Demonstration Here we take \"2D Getting Started Example\" as an example to demonstrate the code subcontracting process. After creating a new sample project, as shown in Figure 2-29, create a new script set definition MyModule.bundledef in the src folder, and then in its property settings panel, check Include all files. Here, all the codes in the src directory are split. Developers can split the codes according to their own needs. (Figure 2-29) When MyModule is activated, the bundle.js file in the project directory \"bin\\js\\bundles\" will become smaller in size, and there will be one more MyModule.js file. This means splitting the code in the src directory, and splitting the code in bundle.js into MyModule.js. Then in the build release, as shown in Figure 2-30, place MyModule in the Entry Script and check Automatically load at startup. Among them, the script folder of the resource folder is a newly created empty folder in the assets directory, and the code subpackage after release will be located in this folder. (Figure 2-30) After publishing, you can find that in the js folder of the publishing directory, the code in the original bundle.js is split into the subpackaged script folder. 3. Packaging Album Atlas is a common art resource in game development. Multiple pictures are merged into one large picture through the IDE publishing process, and the original picture resource information is stored in the atlas format file. Figure 3-1 is a png atlas resource packaged using LayaAirIDE. (Figure 3-1) 3.1 Why use atlas resources? Using atlas resources synthesized from multiple pictures as art resources in the game has the following advantages: 1 Optimize memory When synthesizing the atlas, the blank area around each picture will be removed, and various optimization algorithms can be implemented as a whole. After the atlas is synthesized, the game package and memory usage can be greatly reduced. 2 Reduce CPU operations If multiple Sprite are rendering images from the same atlas, these Sprite can be processed using the same rendering batch, which greatly reduces the CPU calculation time and improves operating efficiency. 3.2 Supported album packaging formats LayaAirIDE supports packaging of two resource formats, PNG and JPG, into atlases. However, it is recommended to use PNG for the original resources packaged in the atlas, because the size of JPG will be larger. Tips： It should be noted that the bit depth of the original PNG resource cannot exceed 32, otherwise the packaged image will appear blurry. The Texttrue Type property of the resource entered into the atlas should be set to SpritetTextrue. In addition, PNG and JPG resources cannot be renamed from resources in other formats to PNG and JPG formats. 3.3 How to create an atlas using LayaAir IDE There are two ways to create an atlas using LayaAir IDE. The first way is more detailed, and the second way is simpler and faster. Developers can choose by themselves. 3.3.1 Automatic generation Automatically packaging image resources is only possible when LayaAir IDE is released, but you need to add and set the album packaging configuration file. Here we explain it through an example, as shown in Figure 3-2: (Figure 3-2) All image resources are placed in the assets/resources directory. As mentioned above, since images may be used in code during project development, without specifying the \"always included resource directory\", they are placed in the The resources directory will be published directly to the output directory. The atlas directory under the resources directory is used to store some scattered images and subfolders (there are also scattered images in it). The advantage of this is to classify and manage resources. There are often other resource directories under the resources directory. Try to put pictures Resources are stored separately from other resources. In the atlas directory, there are two pictures (img_bg100-0.png and img_bg100-1.png) and sub-folders ui1 and ui2, which contain many scatter images respectively. At the same time, there is also a sub-folder in the ui1 directory. If the atlas is not packaged, after publishing, the atlas directory under the output directory will be filled with scatter images. Let’s take a look at how to package an album: Step 1: Add configuration file As shown in Figure 3-3, add the configuration file in the atlas directory. (Animation 3-3) In the resources/atlas directory, right-click -> Create, select \"Automatic Atlas Settings\", and an AtlasConfig.atlascfg file will be created. The purpose of placing it under atlas is to package the pictures in the atlas directory and the pictures in sub-folders at the same time (supporting single atlas and multiple sub-folder atlases). Developers can rename this file. Step 2: Set file properties for the album Click on the AtlasConfig file, as shown in Figure 3-4: (Figure 3-4) Subfolder handling: Create one texture set per subdirectory: Pack one atlas per subfolder. Share a texture set: All images in subfolders and sibling directories are packaged into one large atlas. Include subfolders: When checked, it supports packaging subfolders into atlases. When unchecked, only pictures in the same level directory are processed into packaged atlases. Maximum width\\height of atlas: The default value is 2048×2048, which determines the maximum size of a single atlas. If there are too many original pictures and exceed the maximum width and height of a single atlas, new atlas files (multiple atlases) will be generated during packaging. Maximum width\\height of a single image: The default value is 512×512. Single images exceeding this size will not be packaged into the album. Tips: It is not recommended to package a single image exceeding 512×512 into an atlas. This image can be preloaded separately. However, loading a single image cannot exceed 1024×1024, otherwise it will affect performance. Texture set scaling: Here you can reduce the size of the atlas by scaling, for example, to 0.5. The IDE will multiply the width and height of the original image by 0.5 to generate it into the atlas. When displayed, the size of the original image will be maintained by stretching. After this processing, although the atlas The size will become smaller, but the display effect will also be affected. It can be regarded as an alternative compression scheme for the atlas. If you want to maintain image accuracy during design, try not to adjust the default values. Power of Two Limits: If checked, the width and height of the generated atlas image will be a whole power of 2. Here, it is recommended that the artist design according to the whole power of 2 when designing, and use the atlas tool to forcibly maintain the whole power of 2, which will definitely cause the size of the atlas to become larger. Therefore, unless you are faced with some runtime environment that requires optimization by the whole power of 2, under normal circumstances, there is no need to check it. Try to ask the art designer to optimize it by the whole power of 2 such as 32, 64, 128, 256, etc. Design the width and height of the image. Crop the white space around the image: If checked, the generated atlas pictures will automatically crop out the blank areas in the original pictures. The default is checked, do not remove it. Texture format: png32 is the default format, this format supports transparency and more colors; png24, no transparency; texture compression reference document [\"Texture Compression\"] (../../IDE/uiEditor/textureCompress/readme.md). Step 3: Publish the generated atlas After setting up, publish in \"Build Release\" and wait for the release to be successful. Now let's take a look at the released directory, as shown in Figure 3-5: (Figure 3-5) Three atlases (AtlasConfig, ui1 and ui2) were generated. Since the Create a texture set for each subdirectory method was selected, ui1 and ui2 each generated an atlas (the atlas file name of the subfolder is According to the folder name), the map under atlas generates an atlas (the atlas file generated in the folder where AtlasConfig.atlascfg is located is named according to the AtlasConfig file name). If there are pictures whose size exceeds 512x512, they will not be entered into the album (512×512 is the setting in Figure 3-4). There is an a directory under the ui1 directory, and Include subfolders is checked, so the scatter images under the a folder are also entered in the album ui1. If you do not check Include subfolders, the ui1/a directory will be retained, and the scatter image will still be below. 3.3.2 Tool production The second method is faster and simpler, but it cannot achieve detailed attribute settings like the first method. This method is in \"Animation Node\" is also mentioned in, and I will demonstrate it for you below. First click \"Create Album\" in the \"Tools\" menu. (Figure 3-6) Then drag the folder you want to package into the folder where the picture is located, and click Make. (Figure 3-7) You can also click the folder icon to select the path yourself, as shown in Figure 3-8. (Figure 3-8) After clicking Create, enter the file name and click Save, as shown in Figure 3-9. (Figure 3-9) The atlas is now created. When we add or delete pictures included in the atlas, we only need to repeat the above process, click on the .atlas file, and click Yes to successfully replace it, as shown in Figure 3-10. (Figure 3-10) [!Tip] If the second atlas packaging method is used, the developer must ensure that this directory will be very stable, and no subsequent additions, deletions, or modifications of image resources will be made. If a stable directory cannot be guaranteed, it is best to use the first packaging method. 3.4 Introduction to packaged and generated atlas files 3.4.1 Package the generated atlas file After packaging the atlas, special resources for the atlas will be generated (the .atlas files and .png files with the same names respectively) 3.4.2 atlas suffix file .atlas is a unique atlas format of LayaAirIDE. It is only used for atlases, so there is no need to fill in the type when loading .atlas. It is the same as loading a normal single image, which is more convenient and is the recommended way to load atlases. . The sample code for loading the atlas using atlas is: //Example of using atlas method atlas Laya.loader.load(\"resources/atlas/Atlas_ui.atlas\").then( ()=>{} ); 3.5 How to use small pictures in the atlas in the project If you use the resources in the atlas in your project, you need to preload the atlas resources first, and then set the skin (skin) attribute value of the image to \"original thumbnail directory name/original thumbnail resource name.png\". For example: Now we display the original small picture img_head2.png and image.png in the comp directory in the project through the atlas in Figure 3-5. The sample code is as follows: let resArr: Array = [ { url: \"resources/atlas/Atlas.atlas\", type: Laya.Loader.ATLAS }, { url: \"resources/atlas/Atlas_ui.atlas\", type: Laya.Loader.ATLAS }, { url: \"resources/atlas/Atlas_comp.atlas\", type: Laya.Loader.ATLAS }]; Laya.loader.load(resArr).then( ()=>{ //Create Image1 instance var img1 = new Laya.Image(); //Set the skin (the way to get the small picture in the picture collection is the original small picture directory name/original small picture resource name.png) img1.skin = \"resources/atlas/img_head2.png\"; //Add to the stage for display Laya.stage.addChild(img1); //Create Image2 instance var img2 = new Laya.Image(); //Set the skin (the way to get the small picture in the picture collection is the original small picture directory name/original small picture resource name.png) img2.skin = \"resources/atlas/comp/image.png\"; //Add to the stage for display Laya.stage.addChild(img2); } ); The running effect is shown in Figure 3-11: (Figure 3-11) At this point, the introduction to packaged atlases is complete. Developers need to plan the directory management of images in advance. They can be divided according to functions and create a sub-folder for each function. In this way, the size of the atlas can be controlled within a reasonable range as much as possible and divided according to functions. The advantage is also that it is easy to find. If developers encounter problems during use, please feel free to communicate with us at any time. 4. Release native resources Native resources refer to resources that load DOM elements through native JS. They are usually used in project development. Therefore, some developers hope to write some JS code that implements DOM in index.html to load these images or video resources. When the preview is running, since index.html is in the bin directory, these resources can only be stored in the bin directory. As shown in Figure 4-1: (Pic 4-1) Starting from LayaAir 3.0.0 beta5 version, it will support the function of publishing native resources in the bin directory. After the project Web is published, by default, all resources in the bin directory will be published to the web directory, as shown in Figure 4-2: (Figure 4-2) At the same time, LayaAir3.0 IDE also provides developers with exclusion resource rules. Adding rules here can instruct the packager to exclude some files or folders under the bin folder. For example, to exclude a folder, you can use 'abc/**', etc. , as shown in Figure 4-3 (Figure 4-3) After clicking Publish, the native resources in the above bin folder have been excluded, as shown in Figure 4-4: (Figure 4-4) It is recommended to call native objects. Let’s talk about the benefits of using LayaAir to call native objects. Let's take an example. Add an img tag to index.html in the bin directory to add some styles. The src is designated as bg2.png in the bin directory. At the same time, there is a function to hide the image by clicking on the image, as shown in Figure 4-5. Show. After publishing, this DOM code will also be published to index.html in the web directory. (Figure 4-5) There is no problem when we run index.html in the web directory, but bg2.png must be placed in the bin directory. This picture may also be used in the development of the project, which means that it will also be stored in the assets directory. Zhang bg2.png, then the developer needs to maintain the same picture in two places, causing certain trouble. Therefore, we recommend developers to use the method provided by LayaAir to call native objects. The code is as follows: //Create native img object let img:any = Laya.Browser.document.createElement(\"img\"); //Set style img.style = \"position:absolute;left:10;top:10;cursor:pointer;\"; //Specify resource address img.src = Laya.URL.postFormatURL(Laya.URL.formatURL(\"resources/bg2.png\")); //Set the attributes of the img element img.setAttribute(\"onclick\", \"this.style.display=\\'none\\'\"); //Add to page Laya.Browser.document.body.appendChild(img); We delete the DOM code in index.html in the bin directory, cut bg2.png to the resources directory of assets, and publish it again In this case, index.html in the web directory does not have any DOM code, and there is only one copy of bg2.png in the resources directory, and the running effect is the same as before! By using Laya.URL.postFormatURL(Laya.URL.formatURL(\"resources/bg2.png\")); both during preview of the IDE and when running after publishing, the LayaAir engine will use resources/bg2.png as the native The image address of img's src, developers can try it themselves. At this point, the method of calling native objects through LayaAir has been introduced. Developers can use it according to their own needs. Note: To import old projects before beta5, you need to manually delete index.html in the bin. A new template will be regenerated during preview. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:39:12 "},"released/web/readme.html":{"url":"released/web/readme.html","title":"Web","keywords":"","body":"WebPublish1. Overview2. Publish as a Web game2.1 Select target platform2.2 Directory after release3. Run the published Web project locallyWebPublish 1. Overview The web publishing function is a very core function. It usually refers to publishing as an HTML5 version and running in the browser environment, webView, and LayaNative APP environment. The project release function is usually used when the project has completed development, or has completed development in stages and is ready to be submitted to the production environment for testing. Since the structure of LayaAir 3.1.x IDE has changed greatly compared with 3.0.x, developers need to pay more attention to panel changes when it comes to IDE Web publishing. Before publishing on the Web, you need to perform [General] (../generalSetting/readme.md) settings. 2. Publish as a Web game 2.1 Select target platform In the Build and Release panel, select the target platform as Web in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build Web\" or \"Web\" in the \"Build Other\" option to publish the project as a Web project. File extension: When checked, use a safe file extension. Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. Rules for texture formats: The Web platform and the remote packages of various mini-game platforms will be released in the formats of PC/Android/iOS platforms at the same time; The WeChat platform will release both Android/iOS formats at the same time; Other mini game platforms only release Android format. Special rules follow the two options shown in the picture above. After publishing, click \"View Tasks\" to see the published tasks. As shown in Figure 2-2, (Figure 2-2) Open folder: In the resource file manager, open the file directory published by the project. View log: View the log published by the project. Build Again: Rebuild the web project. Run: Run the published web project locally. View QR code: Generate a QR code. You can connect your mobile phone and PC to the same LAN and scan the code to preview the published Web project. Delete Record: Delete the published record, but the published items will not be deleted. 2.2 Directory after release The directory structure after publishing is shown in Figure 2-3. (Figure 2-3) js directory and libs directory: Project code and engine libraries. resources directory and Scene.ls: Resource file directory and scene files. fileconfig.json： The file contains some configuration information for the Web project. 3. Run the published Web project locally To run the published Web project, you can directly click the run button in Figure 2-2 after publishing to run the published Web project in the browser. If the developer accidentally deletes the release record, he can open the file directory of the project release. In the release directory, use Node.js anywhere to start a local server to run the web project. As shown in the animation 2-4, open the command line cmd in the \"web\" folder, enter anywhere, and then click the Enter key on the keyboard to start a local server. (Animation 2-4) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 12:03:23 "},"released/miniGame/readme.html":{"url":"released/miniGame/readme.html","title":"miniGame","keywords":"","body":"Mini game release1. What is a mini game?2. Differences between mini games and HTML52.1 Differences in running underlying layers2.2 Differences in package bodies2.3 Cache and other mini-game interfaces2.4 Publishing template settings3. Which mini game platforms is LayaAir suitable for?Mini game release 1. What is a mini game? Mini games first came from WeChat, and the popularity of WeChat mini games began to drive other platforms to follow suit. So what exactly are mini-games? The official explanation of WeChat Mini Games is: [!Note] WeChat mini games are a category of WeChat mini programs. They are click-and-play, no need to download and install, and the experience is light. You can play with friends in WeChat, such as PK, watch, etc. The core of its apparent experience is: no need to download and install, just click and play. As for the friend relationship chain, not all mini-games on all platforms are suitable for promotion using relationship chains. Other features will be introduced in other chapters. What we need to know is that although most platforms continue the naming of WeChat mini games, also called XX mini games, there are also other names, such as Huawei and Xiaomi, both called XX quick games. No matter what the name is, the basic experience and features of each platform are similar, so we can generally refer to these as small games. 2. Differences between mini games and HTML5 There is no need to download and install, just click and play. Isn’t it also possible with HTML5? How is it different from mini games? 2.1 Differences in running underlying layers HTML5 links are usually run directly from the browser or webView. When released into an APP, the LayaAir engine supports the self-developed Runtime underlying engine written in C++ to run the LayaAir engine project. The principle of mini-games is similar to the mechanism of LayaAir releasing Native APP. It also uses the platform's built-in Runtime to be compatible with Canvas and WebGL interfaces, thereby achieving a click-and-play experience without downloading and installing HTML5. Therefore, strictly speaking, mini-games are not HTML5 games because mini-games do not support all HTML5 standards and graphics API interfaces. Of course, the LayaAir engine has been adapted to mainstream mini-game platforms. Developers using the LayaAir engine to develop projects can directly release them as mini-game products without modification. 2.2 Differences in package bodies HTML5 resource packages and codes need to be loaded through the network before use. The code package of the mini game must be placed on the mini game platform. By uploading and reviewing the code package of the mini game, the platform can strengthen the supervision of intellectual property rights and other benefits. From a technical point of view, the size control of the mini-game code package and resource package allows developers to control the size of the project package according to the rules of the mini-game, ensuring that the game loading experience does not take too long. 2.3 Cache and other mini-game interfaces In addition to the above introduction that is closely related to the game itself, in fact, the greater benefit of mini-games is that they provide more open interfaces than HTML5, such as more device interfaces, AI interfaces, payment interfaces, advertising interfaces, cache file management interfaces, Friend relationship link interface and so on. 2.4 Publishing template settings Developers can create build-templates/platform names in the project directory, such as build-templates/web, etc., and the contents will be copied to the output directory when publishing. If it is a json file, it will also be merged. For example, if game.json is placed in build-templates/wxgame and the content is { \"showStatusBar\": true }, then this key value will be added to the final game.json file, and other key values ​​​​of game.json in the engine template Will keep it. 3. Which mini game platforms is LayaAir suitable for? LayaAir 3.0 is currently adapted to the following platforms: WeChat Mini Game Douyin Mini Game OPPO Mini Game vivo mini-game Xiaomi Quick Game Alipay mini-game Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:11:40 "},"released/miniGame/wechat/readme.html":{"url":"released/miniGame/wechat/readme.html","title":"wechat","keywords":"","body":"WeChat mini game1. Overview2. Publish as WeChat mini-game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Use WeChat developer tools to create small game projects3.1 Log in with a developer account and select the project type3.2 Import mini-game projects3.3 Compilation of WeChat developer tools3.4 Real machine testing and debugging4. Subcontracting and dynamic resource loading4.1 Subcontracting4.2 Network dynamic loading5. Generate open data domain project template5.1 Open data domain5.2 Build template directoryWeChat mini game 1. Overview The running environment of WeChat mini games is not the browser, nor can it be run in the browser, but the Runtime in the WeChat APP. Although the interface of WeChat mini games is compatible with most Canvas and Webgl, it has the HTML5 feature of click-and-play without downloading and installation. But from a strict definition, WeChat mini games are not standard HTML5 games. It is highly recommended to take a look at the official documentation of WeChat Mini Game . The documentation of the LayaAir engine is more engine-related, and of course It will be mixed with some application introductions of small game interfaces, but it is definitely correct to take a closer look at the official WeChat documentation. Download and install WeChat developer tools WeChat Developer Tools is mainly used for preview and debugging of small game products, real machine testing, upload and submission, etc. It is an essential tool for small game development. If you are developing using the official API of WeChat mini games , there are still some things to pay attention to, such as not supporting DOM and BOM, mini games There can only be one canvas, no support for Eval, no support for XML, etc... However, for LayaAir engine developers, there is no need to deliberately understand the differences, and they can just develop according to the normal LayaAir engine development rules. Before the WeChat mini-game is released, General needs to be set. 2. Publish as WeChat mini-game 2.1 Select target platform In the build and release panel, select the target platform as WeChat Mini Game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build WeChat Mini Game\" or \"WeChat Mini Game\" in the \"Build Other\" option to publish the project as a WeChat Mini Game. Appid: Users can directly fill in the AppID of the WeChat mini game when publishing. Generate open data domain project template: Generally used to display friend rankings. After the release is completed, the openDataContext directory will be generated. (See Section 5 for details) Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release The directory structure after publishing is shown in Figure 2-2. (Figure 2-2) js directory and libs directory: Project code and engine libraries. resources directory and Scene.ls: resources resource directory and scene file Scene.ls. Due to the limitations of the initial package for small games, it is recommended to plan the contents of the initial package. It is best to put them in a unified directory to facilitate the separation of the initial package. game.js： The entry files of WeChat mini-games, the game project entry JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. game.json： The configuration file of the mini game, developer tools and clients need to read this configuration to complete related interface rendering and property settings. For example, the screen's horizontal and vertical orientation, status bar display, mini-game subcontracting, etc. are all configured here. For details on how to configure and use parameters, you can view WeChat Mini Game Development Document. fileconfig.json： The project configuration file of the mini game contains some information about the mini game project. If you want to modify the appid and other information, you can edit it directly here. The value of the project parameter libVersion must be game, and there is generally no error here. However, if the release in LayaAir IDE is normal and the adaptation library is referenced, and an error is still reported in the developer tools after publishing as a small game, you can check whether the value in libVersion is game. If not, change it to game. weapp-adapter.js： WeChat mini game adaptation library file. 3. Use WeChat developer tools to create small game projects 3.1 Log in with a developer account and select the project type Open \"WeChat Web Developer Tools\" and scan the developer's WeChat code to log in. Then select Mini Game and click to enter the project settings and select Import, as shown in Figure 3-1. (Figure 3-1) 3.2 Import mini-game projects Select the project directory, which is the target directory after LayaAirIDE is released (usually release\\wxgame in the project root directory) (Figure 3-2) After selecting the wxgame directory, as shown in Figure 3-3 (Figure 3-3) AppID test account, you can click to register, you can develop and debug without entering it, you can use the test account, but the functions will be limited. So it’s better to enter AppID 3.3 Compilation of WeChat developer tools After completing the creation of the mini-game project, you can preview the effects and debug within the tool. As shown in Figure 3-4 (Figure 3-4) 3.4 Real machine testing and debugging Since the project effects can also be debugged in LayaAirIDE, unless it is an adaptation-related issue, there will basically be no inconsistency between the effects on both sides. So the most important thing here is to click on the Preview function, scan the QR code through WeChat on your mobile phone, and conduct real machine testing and debugging in WeChat. As shown in Figure 3-5 (Figure 3-5) At this point, a complete mini-game development process is over. Mini game projects developed using LayaAir IDE are basically seamlessly used in WeChat mini game projects. 4. Subcontracting and dynamic resource loading When loading resources in WeChat mini-games, if the local path is referenced, for example: Laya.loader.load(\"resources/layaair.png\"); If the total size of the project directory does not exceed 4M, as long as local resources can be found, there is no problem in writing it. However, the local package of WeChat mini games has a 4M limit. Once this limit is exceeded, uploading and real-device preview are not allowed. So, if the project is larger than 4M, how to deal with it? 4.1 Subcontracting One option is to subcontract, WeChat mini-game subcontracting restrictions: The size of all main packages + sub-packages of the entire mini-game does not exceed 20M The main package does not exceed 4M There is no limit on the size of a single ordinary subpackage A single independent subcontract does not exceed 4M Please refer to WeChat Mini Game Official Document. Next, we will introduce how LayaAir IDE subcontracts WeChat mini-games. Developers can first look at the subcontracting settings set by General. As shown in Figure 4-1, in the build release, after turning on subcontracting, select the folder to be subcontracted to complete the subcontracting. Developers can also choose whether to use remote packages. (Pic 4-1) Different from web subcontracting, mini games subcontract resources referenced by code in different ways. In the web platform, there are three parameters for loading the package using the loadPackage method, and mini-game subpackage requires the use of two-parameter overloading. The two-parameter overloading method is not only used for WeChat mini-games, but also for other mini-games. The same goes for gaming platforms. The following is a sample code for loading subpackage: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Scene3D }) scene3d: Laya.Scene3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Mini game loading subpackage Laya.loader.loadPackage(\"sub1\", this.printProgress).then(() => { Laya.loader.load(\"sub1/Cube.lh\").then((res: Laya.PrefabImpl) => { let sp3: Laya.Sprite3D = res.create() as Laya.Sprite3D; this.scene3d.addChild(sp3); }); }) Laya.loader.loadPackage(\"sub2\", this.printProgress).then(() => { Laya.loader.load(\"sub2/Sphere.lh\").then((res: any) => { let sp3 = res.create(); this.scene3d.addChild(sp3); }); }) } printProgress(res: any) { console.log(\"Loading Progress\" + JSON.stringify(res)); } } The following focuses on the content printed by printProgress. After the WeChat developer tool opens and compiles our exported project, the following log will be printed: (Figure 4-2) wx.loadSubpackage() returns a LoadSubpackageTask, through which you can obtain the current download progress. Refer to WeChat Mini Game Official Document. The meanings of the printed parameters are: progress: Download progress; totalBytesWritten: length of downloaded data; totalBytesExpectedToWrite: The total length of data expected to be downloaded. 4.2 Network dynamic loading Another solution is dynamic loading over the network. We are in the local package, and the JS code must be put in, because JS does not allow network loading to be dynamically created. So if the JS in the local package exceeds 4M, the first thing to consider is how to optimize the JS size, such as obfuscation and compression, and separation from the UI code. If it still doesn't work, it can only be solved through the subcontracting solution of small games. If the JS does not exceed 4M, you can also put some basic resources for preloading according to the situation. So how to deal with the path of network dynamic loading. Use the URL.basePath method after the load() method of local loading. For example: onAwake(): void { //Network dynamic loading Laya.URL.basePath = \"https://XXXX\";//Please replace XXX with your real URL; //Under this, if you use load to load resources, the URL will be automatically added. Dynamically loaded from the network. Laya.loader.load(\"resources/layaair.png\").then((res: Laya.Texture) => { let sprite:Laya.Sprite = new Laya.Sprite(); sprite.texture = res; this.owner.addChild(sprite); }); } After using the URL.basePath method, and then using load to load the local path, the URL in URL.basePath will be automatically added. This achieves a combination of local and network loading. [!Tip] When assigning a value to URL.basePath, developers must read the official documentation for Network. Only if it meets the requirements. Is this the end? not at all! Here we will expand a local package whitelist mechanism. According to the way just written, if resources/layabox.png has been uploaded to the local directory of the WeChat mini game, but if res/layabox.png is loaded again after using URL.basePath, it will not be loaded from the local directory. , but dynamically loaded from the network. Therefore, the engine has implemented special directory and file processing for how to use local loading again after using URL.basePath, which is the local package whitelisting mechanism. As shown in the following example: MiniAdpter.nativefiles=[ \"layaNativeDir\", \"wxlocal\", \"resources/layaair.png\" ] The code is located in the \"laya.wxmini.js\" file under \"libs\\min\" in the release directory, and \"resources/layaair.png\" is a manually added directory. As long as the directory name or file exists in MiniAdpter.nativefiles, the engine will automatically treat the directory as a local directory. Even if URL.basePath is used, directory names or files included in the nativefiles whitelist will not be processed. Will be loaded dynamically from the network and will only be loaded locally. 5. Generate open data domain project template Open data fields are generally used to display friend rankings. 5.1 Open data domain First, as shown in Figure 5-1, in the hierarchy panel, add an OpenDataContexView component to Scene2D to activate the display of the open data domain (there is no ranking effect display at this time, and it can only be seen after publishing). The size of the component is the size of the friends ranking panel. (Figure 5-1) After adding, you can see the FPS attribute in its property settings panel, as shown in Figure 5-2, which indicates the frame rate of the sharedCanvas update to the main domain. (Figure 5-2) Then when building and publishing, check the Generate open data domain project template shown in Figure 2-1. After the release is completed, as shown in Figure 5-3, the openDataContext directory will be generated. Developers can modify the content here according to their needs. When publishing next time, if the template directory is not built according to 5.2, then this directory will not be cleared or modified. (Figure 5-3) Modify the generated project template (the file in the openDataContext directory). It is recommended to use a lightweight third-party Canvas engine to solve this requirement. Developers can use this engine to create customized friend rankings, and then replace the code in the corresponding file in the openDataContext directory. After release, debug in \"WeChat Developer Tools\". At this time, the default project template is used, and the effect is shown in Figure 5-4. (Figure 5-4) 5.2 Build template directory Developers can create build-templates/platform name in the project directory, for example: build-templates/wxgame, and the contents will be copied to the output directory when publishing. If it is a json file, it will also be merged. For example, if game.json is placed in build-templates/wxgame and the content is {\"showStatusBar\": true }, then this key value will be added to the final game.json file, and the game.json in the engine template Other key values ​​will be retained. In the development of game friend rankings, the release directory after release is generally not added to version management. The openDataContext directory here may be inconvenient in collaborative development, so you can put the customized openDataContext directory into the build template directory, that is Place wxgame under build-templates in the project root directory shown in Figure 5-5, so that the 'Generate Open Data Domain Project Template' selected each time you publish is no longer the default of the IDE shown in Figure 5-4 template, and will be copied from the template directory build-templates/wxgame. (Figure 5-5) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:07:38 "},"released/miniGame/byteDance/readme.html":{"url":"released/miniGame/byteDance/readme.html","title":"tiktok","keywords":"","body":"Douyin mini games1. Overview2. Publish as Douyin mini-game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Use Douyin developer tools to create small game projects3.1 Log in with a developer account and select the project type3.2 Import mini-game projects3.3 Compilation of Douyin developer tools3.4 Real machine testing and debugging4. Subpackage loadingDouyin mini games 1. Overview Douyin mini-games do not require users to download and are a new type of game that can be played immediately. Compared with APPs, mini-games have the characteristics of short development cycle and low development cost, which allow developers to participate in the development process more easily. Achieve rapid launch and rapid monetization. Mini games require no downloading and are simple to play. They naturally match scenes such as graphics, texts, and videos. The full product matrix takes content distribution as the core, drives the distribution of mini-games through content, and uses content to drive volume and fission of mini-games. It is recommended to take a look at the official documentation of Douyin Mini Game and the LayaAir engine The documentation is more engine-related, and of course also mixed with some mini-games interfaces application introduction, but it is definitely correct to take a closer look at the official documentation. Download and install mini game developer tools Mini game development tool is mainly used for Preview and debugging of mini game products, real machine testing, upload and submission, etc. It is an essential tool for small game development. Before the Douyin mini game is released, you need to perform General settings. 2. Publish as Douyin mini-game 2.1 Select target platform In the build and release panel, select the target platform Douyin Mini Game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build Douyin Mini Game\" or \"Douyin Mini Game\" in the \"Build Other\" option to publish the project as Douyin Mini Game. Appid: Users can directly fill in the AppID of the Douyin mini game when publishing. Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release The directory structure after publishing is shown in Figure 2-2: (Figure 2-2) js directory and libs directory: Project code and engine libraries. resources directory and Scene.ls: resources resource directory and scene file Scene.ls. Due to the limitations of the initial package for small games, it is recommended to plan the contents of the initial package. It is best to put them in a unified directory to facilitate the separation of the initial package. game.js： The entry files of Douyin mini-games, the game project entry JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. game.json： The configuration file of the mini game, developer tools and clients need to read this configuration to complete related interface rendering and property settings. For example, the horizontal and vertical screen orientation of the screen. projectconfig.json： The project configuration file of the mini game contains some information about the mini game project. If you want to modify the appid and other information, you can edit it directly here. microgame-adapter.js： Douyin mini game adaptation library file. 3. Use Douyin developer tools to create small game projects 3.1 Log in with a developer account and select the project type For account creation and login on the Douyin development platform, as well as the creation of mini-game projects, use of tools, and product release, you can view Douyin’s mini-game developer documentation. Open \"Douyin Developer Tools\" and use the \"Douyin\" APP to scan the QR code to log in. Then select Mini Game, click to enter the project settings, and select New, as shown in Figure 3-1. (Figure 3-1) 3.2 Import mini-game projects Select the import directory, which is the target directory after LayaAir IDE is released (usually release\\bytedancegame in the project root directory) (Figure 3-2) After selecting the bytedancegame directory, as shown in Figure 3-3 (Figure 3-3) AppID test account, you can click to register, you can develop and debug without entering it, you can use the test account, but the functions will be limited. So it’s better to enter AppID 3.3 Compilation of Douyin developer tools After completing the creation of the mini-game project, you can preview the effects and debug within the tool. As shown in Figure 3-4 (Figure 3-4) 3.4 Real machine testing and debugging Since the project effects can also be debugged in LayaAir IDE, unless it is an adaptation-related issue, there will basically be no inconsistency between the effects on both sides. So the most important thing here is to click on the Preview function, scan the code through Douyin, and conduct real-device testing and debugging in Douyin. As shown in Figure 3-5 (Figure 3-5) 4. Subpackage loading The following is an introduction to how LayaAir IDE subcontracts Douyin mini-games. Developers can first look at the subcontracting settings set by General. You can perform subcontracting loading through the following steps, as shown in Figure 4-1. After clicking Build and Publish, check Enable subcontracting, and then select the folder to be subcontracted. Developers can also choose whether to enable remote packages. (Pic 4-1) Douyin mini-game subcontracting restrictions: The size of the entire mini gameplay package (main package + sub-package) does not exceed 20M A single main package does not exceed 4M Unlimited size of individual packets Please refer to Douyin Mini Game Official Document. For the IDE to automatically load a subpackage, you need to check the \"Automatically load at startup\" option of the subpackage when publishing. If the resource is referenced by code, the method is slightly different from web publishing. An example of loading code is as follows: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Scene3D }) scene3d: Laya.Scene3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Mini game loading subpackage Laya.loader.loadPackage(\"sub1\", this.printProgress).then(() => { Laya.loader.load(\"sub1/Cube.lh\").then((res: Laya.PrefabImpl) => { let sp3: Laya.Sprite3D = res.create() as Laya.Sprite3D; this.scene3d.addChild(sp3); }); }) Laya.loader.loadPackage(\"sub2\", this.printProgress).then(() => { Laya.loader.load(\"sub2/Sphere.lh\").then((res: any) => { let sp3 = res.create(); this.scene3d.addChild(sp3); }); }) } printProgress(res: any) { console.log(\"Loading Progress\" + JSON.stringify(res)); } } Here we mainly introduce the content printed by printProgress. After the Douyin developer tool opens and compiles our exported project, the following log will be printed: (Figure 4-2) tt.loadSubpackage will return a LoadSubpackageTask, through which you can obtain the current download progress. Refer to Douyin Mini Game Official Document. The meanings of the printed parameters are: name: the name of the subcontract; progress: Subpackage download progress percentage; totalBytesWritten: length of downloaded data, unit Bytes; totalBytesExpectedToWrite: The total length of data expected to be downloaded, in Bytes. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:55:46 "},"released/miniGame/OPPO/readme.html":{"url":"released/miniGame/OPPO/readme.html","title":"OPPO","keywords":"","body":"OPPO Mini Game1. Overview2. Published as OPPO mini-game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Chrome jointly debugs OPPO mini-games3.1 OPPO mini game release and debugging environment preparation3.2 Complete process of OPPO mini-game release and access3.3 Real machine debugging and Chrome output3.4 Publishing unsuccessful processing experience4. OPPO developer tool debugging5. Subpackage loadingOPPO Mini Game 1. Overview It is recommended to take a look at the official documentation of OPPO Mini Game . The documentation of the LayaAir engine is more about the engine. Related, of course, there will also be some application introductions of small game interfaces mixed in, but it is definitely correct to take a closer look at OPPO's official documents. OPPO officially provides visual developer tools, click here to download, at After configuring the relevant parameters in LayaAirIDE, and then successfully publish it directly in LayaAirIDE with one click (an rpk package will also be generated), you can use OPPO developer tools to debug. Another debugging method is to install an apk debugging environment on the OPPO mobile phone, choose to open the rpk file in the apk, and then connect the mobile phone to the PC with a data cable through chrome for debugging. Before OPPO mini games are released, you need to perform General settings. 2. Published as OPPO mini-game 2.1 Select target platform In the build and release panel, select the target platform as OPPO Mini Game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build OPPO Mini Game\" or \"OPPO Mini Game\" in the \"Build Other\" option to publish the project as an OPPO Mini Game. Next we will introduce the filling in of these function parameters. 1. Game name Generally, Chinese characters are filled in, but English is also acceptable. Used for game entrances such as app stores, desktop icons, pop-up windows, etc. A good name is an important factor in whether the game can attract traffic. OPPO can be within 6 Chinese characters 2. Game package name The format of the game package name is com.company.module. The first digit is com, the second digit is the company name, and the third digit is the project name. All must be written in English, for example: com.layabox.demoGame. 3. Game icon The game icon is also an important game entrance logo. Like the game name, it is a very important element that attracts attention. If the game icon is well designed, the game name will be well chosen. The same position will get more clicks than other games. The game icon needs to provide a square size of 192*192. 4. Game version name The game version name is the actual version and is generally used to differentiate between functional versions. For example, I have a major version change. It was originally 1.0 and can be changed to 2.0. If it is just to correct the bug, then 1.0 can be changed to 1.1. By analogy, we recommend using floating point numbers for naming. For example, \"0.1\", \"1.3\", \"5.0\"... 5. Game version The game version and the version name have different purposes. Here is the channel platform used to distinguish version updates. Every interrogation must be at least recursive +1, it doesn't matter if you test it yourself. However, the value here must be at least +1 compared to the value of the last arraignment. +N is also acceptable. It must not be equal to or less than the previous version value. It is recommended that the arraignment version number be recursively +1. It should be noted here that the game version must be a positive integer. 6. Minimum platform version Minimum platform version, just fill in the platform version number displayed on the debugger. 7. Log level Seven log levels, from high to low, are OFF, ERROR, WARN, INFO, LOG, DEBUG, and TRACE. You can easily know the running status of the current program. 8. Whether to use the official version signature If you are only debugging the test version, you do not need to check it here. It must be checked before it is officially released online (submit the version to the platform). If checked, the official version signature will be enabled. About release signature: ① For companies, generally a company only uses one signature. If the company already has a signature, it is recommended to use the company’s signature. If not, publishing in the IDE integrates this function to facilitate developers to generate signatures. ②For individual developers, one official signature can be used on multiple projects. It only needs to be generated once. If the release has been signed, place the signature file in the sign/release folder of the Laya project. 9. Compressed texture Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release Click version release. Since the rpk release environment (used to generate rpk packages) will be checked before release, if there is no release environment, the download will start. The directory structure after publishing is shown in Figure 2-2. (Figure 2-2) js directory and libs directory: Project code and engine libraries. resources directory and Scene.ls: resources resource directory and scene file Scene.ls. Due to the limitations of the initial package for small games, it is recommended to plan the contents of the initial package. It is best to put them in a unified directory to facilitate the separation of the initial package. main.js： The entry files of OPPO mini games, the game project entry JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. manifest.json： The project configuration file of the mini game contains some information about the mini game project. If you want to modify it, you can edit it directly here. 3. Chrome jointly debugs OPPO mini-games 3.1 OPPO mini game release and debugging environment preparation OPPO brand mobile phones. Download and install the OPPO real machine test APP \"Quick Application\" (OPPO mini game debugger) Go to the OPPO official website Documentation and find the Install runtime.apk package to the OPPO phone Go to this column and usually choose the new version to download. It should be noted that the debugger version and the minimum platform version number are indicated in the document. When LayaAirIDE is released, it must correspond to the minimum platform version number here. PC’s chrome browser and mobile phone data connection cable. Install the node.js environment. It is recommended to install the 14.x.x stable version (10.x.x or above may have incompatibility issues), node official website: https://nodejs.org/en/. Just download and install it, it’s relatively simple and I won’t go into details. Being able to call the npm command in the command line is considered a success. Install ADB When OPPO released it, it pushed the rpk package to the games directory of the phone through ADB, so this must be installed. [ADB official website download: http://adbshell.com/downloads] As a reminder, after downloading ADB Kits, it is recommended to decompress the downloaded compressed package into a directory with a simpler path (such as: D:\\adb). Remember to add environment variables (if you don’t know how to add environment variables, you can Baidu yourself). 3.2 Complete process of OPPO mini-game release and access In order to make the launch of OPPO smoother, we have to do some inspections. First, the node environment, ADB, and Chrome must all be installed on the PC. Second, in the OPPO mobile phone, enter Settings->Other Settings->Developer Options. Developer options and USB debugging must be turned on, as shown in Figure 3-1. (Figure 3-1) In addition, make sure to install the OPPO mini game debugging environment \"Quick Application\", as shown in Figure 3-2. (Figure 3-2) Third, connect the PC and mobile phone with a USB data cable. An interface similar to Figure 3-3 will appear on the computer. For example, click on OPPO R9m in the upper left corner of Figure 3-3 to enter the phone storage. (Figure 3-3) What should be noted on the mobile phone is that the screen remains lit and open. When publishing the OPPO mini-game in the PC's IDE, if a request for authorization information appears on the mobile phone, be sure to click OK to allow it. As shown in Figure 3-4. (Figure 3-4) 3.3 Real machine debugging and Chrome output OPPO's debugging must be based on real machine debugging. PC's chrome can only output information and cannot see the screen. If the preparations are OK, under normal circumstances, after the OPPO mini-game is successfully released in LayaAir IDE, the rpk package will automatically appear in the OPPO mini-game list of the mini-game (the IDE pushes it to the specified directory by calling ADB). As shown in Figure 3-5. (Figure 3-5) The OPPO test in Figure 3-5 is the game name we filled in when we released it. If we see our corresponding game name, it means that the normal release was successful. Click Open to open the game we published. If you want to see debugging information. At this time, you need to open the chrome browser. Then enter in the input field: devtools://devtools/bundled/inspector.html?v8only=true&ws=10.10.82.111:12345/00010002-0003-4004-8005-000600070008 Just replace the IP address 10.10.82.111 in the above example with the IP on your mobile phone. 12345 is the port number. If not, replace it with 12346. I don’t know how to check the IP address, so I used Baidu. The important reminder here is that the PC must be in the same network segment as the mobile phone in a LAN environment. When debugging, make sure the mobile phone is open on the mini-game page. If there is no problem, the effect is as shown in Figure 3-6, and the debugging log will be printed. (Figure 3-6) Release and debugging, if everything goes well, it will be completed. 3.4 Publishing unsuccessful processing experience The release document only talks about the use of functions. The above document is the process under smooth conditions. However, developers may not be so smooth, so here we talk about our experience. The game is not found in the debug list, what's going on If we fail to automatically send the rpk to the mini-game directory when publishing, then there will be no way to directly see the newly released mini-game in the list in Figure 3-5. At this time, you can use adb to confirm the environment. Enter the adb devices command in cmd. 1. Abnormal connection situation: (Figure 3-7-1) At this point, the developer needs to check whether the mobile phone connection and permissions are correct. 2. When the connection is normal: (Figure 3-7-2) At this time, it means that the mobile phone has been successfully connected, and the developer mode and USB debugging have been turned on. At this time, you can try to restart OPPO's quick app apk and check the list information again. When the connection is normal, if the problem occurs again. It may be related to windows permissions. You need to make sure to start LayaAirIDE with administrator permissions. For issues related to adb or mobile phone permissions, developers can learn by themselves. Another solution allows us to use manual mode and copy the rpk package to the games directory stored on the mobile phone. If there is no games directory, create it manually. The rpk package is located in the release/OPPOgame/dist directory of the project. Copy the rpk file generated by publishing to the games directory stored on the mobile phone, as shown in Figure 3-8. (Figure 3-8) This method is more stable. In the case where the .rpk file is generated successfully, the publishing process is actually over. If there is a problem with the packaging process, you can feedback the problem to the official Layabox team, and Layabox will work with the OPPO team to handle it. 4. OPPO developer tool debugging In addition to Chrome debugging, developers can also use official developer tools. As shown in Figure 4-1, open the OPPO developer tools, click Import Game Engine Project, and then select the path. (Pic 4-1) Then select the compilation method, as shown in Figure 4-2. The default is normal compilation. If subcontracting is performed, select \"Compile Subcontracting\" and click \"Compile\" after selection. (Figure 4-2) After the compilation is successful, connect the USB to the real machine, and then click on the real machine to run: (Figure 4-3) The real machine effect is shown in Figure 4-4: (Figure 4-4) The advantage of this method compared to Chrome browser debugging is that it can display the effect of the mobile phone in real time. 5. Subpackage loading After the development is completed, developers can package other files in the project other than sub-packages into the main package; and then type the entire package into a .rpk file. Developers can first look at the subpackaging set by General. OPPO subcontracted loading package size limit The total size of all sub-packages of the entire mini-game does not exceed 16M Unlimited size of individual packets Including the main package 4M, the final rpk package size does not exceed 20M For details, please refer to the official website Documentation. To use LayaAirIDE to subcontract, just click Build and Publish, check Enable subcontracting, and then select the folder to be subcontracted. When setting, you need to pay attention. If the resource is loaded by code and is not referenced in the scene, it must be added to the always included resource directory. After release, developers only need to debug according to any of the debugging methods in Sections 3 and 4. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:59:34 "},"released/miniGame/vivo/readme.html":{"url":"released/miniGame/vivo/readme.html","title":"vivo","keywords":"","body":"VIVO minigames1. Overview2. Published as vivo mini-game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Use vivo game debugger3.1 Vivo mini game release and debugging environment preparation3.2 Complete process of vivo mini-game release and access4. Vivo mini-game subcontracting5. Frequently Asked QuestionsVIVO minigames 1. Overview It is recommended to take a look at the official documentation of vivo mini game . The documentation of LayaAir engine is more engine-related, and of course it will be mixed. There are some introductions to the application of small game interfaces, but it is definitely correct to take a closer look at vivo’s official documentation. There are no visual development and debugging tools in vivo mini-games, so you can only configure the relevant parameters in LayaAir IDE, and then publish successfully (generate an rpk package) directly in LayaAir IDE with one click. As for the debugging method, you install an apk debugging environment (vivo mini game debugger) on your vivo phone and select it in the apk Open the rpk file, and then use Chrome to connect the phone to the PC with a data cable for debugging. Before the vivo mini-game is released, General needs to be set first. 2. Published as vivo mini-game 2.1 Select target platform In the build and release panel, select the target platform as vivo mini game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build vivo mini-game\" or \"vivo mini-game\" in the \"Build other\" option to publish the project as a vivo mini-game. The following is an introduction to filling in these function parameters: 1. Game name Generally, Chinese characters are filled in, but English is also acceptable. Used for game entrances such as app stores, desktop icons, pop-up windows, etc. A good name is an important factor in whether the game can attract traffic. Vivo requires that it must be within 6 Chinese characters. 2. Game package name The format of the game package name is com.company.module. The first digit is com, the second digit is the company name, and the third digit is the project name. All must be written in English, for example: com.layabox.demoGame. 3. Game icon The game icon is also an important game entrance logo. Like the game name, it is a very important element that attracts attention. If the game icon is well designed, the game name will be well chosen. The same position will get more clicks than other games. The game icon needs to provide a square size of 192*192. 4. Game version name The game version name is the actual version and is generally used to differentiate between functional versions. For example, I have a major version change. It was originally 1.0 and can be changed to 2.0. If it is just to correct the bug, then 1.0 can be changed to 1.1. By analogy, we recommend using floating point numbers for naming. For example, \"0.1\", \"1.3\", \"5.0\"... 5. Game version The game version and the version name have different purposes. Here is the channel platform used to distinguish version updates. Every interrogation must be at least recursive +1, it doesn't matter if you test it yourself. However, the value here must be at least +1 compared to the value of the last arraignment. +N is also acceptable. It must not be equal to or less than the previous version value. It is recommended that the arraignment version number be recursively +1. It should be noted here that the game version must be a positive integer. 6. Minimum platform number The minimum platform version number currently supported by vivo on the official website can be clicked here to check. 7. Log level Seven log levels, from high to low, are OFF, ERROR, WARN, INFO, LOG, DEBUG, and TRACE. You can easily know the running status of the current program. 8. Whether to use the official version signature If you are only debugging the test version, you do not need to check it here. It must be checked before it is officially released online (submit the version to the platform). If checked, the official version signature will be enabled. About release signature: ① For companies, generally a company only uses one signature. If the company already has a signature, it is recommended to use the company’s signature. If not, publishing in the IDE integrates this function to facilitate developers to generate signatures. ②For individual developers, one official signature can be used on multiple projects. It only needs to be generated once. If the release has been signed, place the signature file in the sign/release folder of the Laya project. 9.Compress texture Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release Click version release. Since the rpk release environment (used to generate rpk packages) will be checked before release, if there is no release environment, the download will start. The directory structure after publishing is shown in Figure 2-3. Figure 2-2 is the directory under the build folder. (Figure 2-2) (Figure 2-3) engine： The js project file and libs engine library directory are the project code and class library. resources： Resource directories and resource files. Due to the limitations of the initial package for small games, it is recommended that the contents of the initial package be planned well. It is best to put them in a unified directory to facilitate the stripping of the initial package. game.js： The entrance files of vivo mini-games, the game project entrance JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. manifest.json： The project configuration file of the mini game contains some information about the mini game project. If you want to modify it, you can edit it directly here. 3. Use vivo game debugger 3.1 Vivo mini game release and debugging environment preparation Vivo brand mobile phones Download and install vivo’s debugging APP, download page: https://minigame.vivo.com.cn/documents/#/download/debugger After entering the page, click Download Now to download and install. As for how to install the vivo debugging APP, I won’t introduce it here. Download vivo mini game engine The current built-in vivo engine version of Debug APP is 1034. This version has known bugs. We must go to the vivo mini game official website to download the latest version of the mini game engine apk. The download page is: https://minigame.vivo.com.cn/documents/#/download/engine The current recommended version is 1090. After downloading and installing, we can see that the platform version number of the vivo quick app debugger is also displayed as 1090. PC’s chrome browser and mobile phone data connection cable. Install nodejs environment [node official website: https://nodejs.org/en/] Just download and install it, it’s relatively simple and I won’t go into details. Being able to call the npm command in the command line is considered a success. Install ADB ADB can be used for authorization, publishing and push, etc. You can download and install it from the ADB official website. [ADB official website download: http://adbshell.com/downloads] A brief reminder, download ADB Kits, it is recommended to decompress the downloaded compressed package into a directory with a simpler path (such as: D:\\adb). Remember to add environment variables (if you don’t know how to add environment variables, you can Baidu yourself). 3.2 Complete process of vivo mini-game release and access 3.2.1 Install and enter the quick application debugger To start the chrome debugging environment on the PC, we must first install the vivo game debugging APP (quick application debugger), as shown in Figure 3-1. Then click to enter. (Figure 3-1) 3.2.2 Scan the code in the quick application debugger interface to install the rpk package of the vivo mini game After entering the quick application debugger, we can see the APP operation interface as shown in Figure 3-2. (Figure 3-2) Transfer the rpk package in the /dist directory under the release directory to your mobile phone and install it by clicking the Local Install button. 3.2.3 Maintain physical line connection and authorization For developers with more relevant experience, make sure that the physical line of the USB mobile phone cable is connected, and there is no problem with USB debugging authorization, you can skip this step. The relevant operations are as follows: First use a mobile phone cable to physically connect the phone to the PC. In the command line that was opened before, enter adb shell, as shown in Figure 3-3. It means the USB debugging mode authorization has not been obtained. (Figure 3-3) At this time, we need to pay attention to whether the prompt shown in Figure 3-4 appears on the mobile phone. If so, click OK to allow USB debugging. (Figure 3-4) Verify authorization again. After the USB debugging mode authorization is successful, we enter adb shell again, as shown in Figure 3-5. (Figure 3-5) In short, in this link, we need to ensure that the PC has the authority to debug the mobile device. 3.2.4 Start chrome debugging environment After scanning the QR code to install, you will automatically enter the game or DEMO you just installed. To start debugging, you must exit first. Then, as shown in Figure 3-6, click Start Debugging to enter the debugging mode of the vivo mini game. (Figure 3-6) After the real machine enters debugging mode, we open the chrome browser on the PC. At this time, don’t forget to connect the USB data cable to connect the mobile device to the PC. The issue of permissions has been mentioned above and will not be repeated. We need to find the IP of the mobile phone on the mobile phone (I don’t know how to check it on Baidu) and remember it. It must be noted that the mobile phone network and the PC network must always be on the same LAN segment. In the input field of the chrome browser, enter: chrome-devtools://devtools/bundled/inspector.html?v8only=true&ws={IP}:5086/00010002-0003-4004-8005-000600070008 Just replace {IP} with the mobile phone IP address, as shown in Figure 3-7. (Figure 3-7) At this point, the complete process of vivo mini-games from publishing to starting chrome debugging has been introduced. If you want to know more about the access process and documentation of vivo mini games, remember this website: https://minigame.vivo.com.cn 4. Vivo mini-game subcontracting Developers can first look at the subpackaging set by General. Subpackaging can be loaded through the following steps, as shown in Figure 4-1. After clicking Build and Publish, check Enable subpackaging, and then select the folder to be subcontracted. The IDE automatically loads subpackaging and needs to be checked when publishing. Select the \"Automatically load on startup\" option of the subpackage. (Pic 4-1) After setting \"sub1\" and \"sub2\" as subcontracted resource folders, configuration information will be automatically generated in manifest.json. The ability to load subpackages first relies on compile-time tools, which package the project into multiple subpackages according to the subpackages rules configured by the developer in manifest.json. The size of these sub-packages is limited. Currently, the sub-package size of vivo mini-games has the following restrictions: com.application.demo.rpk overall compressed package (package name + .rpk) ------------- com.application.demo.rpk Original complete package (package name + .rpk) (original complete package compatible with older versions of the engine = subcontract main package + subcontract A + subcontract B) ------------- main.rpk sub-package main package (main+.rpk) (4M) ------------- pkgA.rpk pkgA subpackage (subpackage name+.rpk) (A+B 16M) ------------- pkgB.rpk pkgB subpackage (subpackage name + .rpk) Refer to vivo mini game Subpackage loading. If the resource is referenced by code, the loading code example is as follows: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { //declare owner : Laya.Sprite3D; @property({ type: Laya.Scene3D }) scene3d: Laya.Scene3D; constructor() { super(); } /** * Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. */ onAwake(): void { //Mini game loading subpackage Laya.loader.loadPackage(\"sub1\", this.printProgress).then(() => { Laya.loader.load(\"sub1/Cube.lh\").then((res: Laya.PrefabImpl) => { let sp3: Laya.Sprite3D = res.create() as Laya.Sprite3D; this.scene3d.addChild(sp3); }); }) Laya.loader.loadPackage(\"sub2\", this.printProgress).then(() => { Laya.loader.load(\"sub2/Sphere.lh\").then((res: any) => { let sp3 = res.create(); this.scene3d.addChild(sp3); }); }) } printProgress(res: any) { console.log(\"Loading Progress\" + JSON.stringify(res)); } } Here is an introduction to the content printed by printProgress. After opening the project we exported on the mini game debugger platform, connecting to the debugging address provided by the vivo official website will print the following log: (Figure 4-2) Vivo Mini Games officially provides the qg.loadSubpackage() API to trigger the loading of subpackages. After the loading is completed, call qg.loadSubpackage() and notify the completion of the loading through the successful callback of qg.loadSubpackage(). At the same time, qg.loadSubpackage() will return a LoadSubpackageTask, and the current download progress can be obtained through LoadSubpackageTask. 5. Frequently Asked Questions Particle rendering black screen problem Vivo mini-games sometimes encounter stuck and black screen problems when checking the box to use 3D particles. This is due to issues in vivo's support for instance extensions and vao extensions caused. It is recommended to directly configure vao to true to avoid the trouble of directly modifying the engine. You can configure vivo's release template in the project: configure vao in the manifest.json of the release template, and set the minimum platform The version is the minimum supported engine version (1102) or above. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:05:22 "},"released/miniGame/xiaomi/readme.html":{"url":"released/miniGame/xiaomi/readme.html","title":"xiaomi","keywords":"","body":"Xiaomi Quick Game1. Overview2. Published as Xiaomi Quick Game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Use Xiaomi Quick Game Debugger3.1 Xiaomi Quick Game release and debugging environment preparation3.2 Xiaomi Quick Game release and access complete process4. Xiaomi Quick Game SubcontractingXiaomi Quick Game 1. Overview It is recommended to take a look at the official documentation of Xiaomi Kuai Game . The documentation of the LayaAir engine is more engine-related. There is no visual development and debugging tool in Xiaomi Quick Game, so you can only configure the relevant parameters in LayaAir IDE, and then publish successfully (generate an rpk package) directly in LayaAir IDE with one click. As for the debugging method, you install an apk debugging environment on the Xiaomi phone, select the rpk file to open in the apk, and then connect the phone to the PC with a data cable through the Chrome browser for debugging. Before Xiaomi Quick Game is released, you need to perform General settings first. 2. Published as Xiaomi Quick Game 2.1 Select target platform In the build and release panel, select the target platform Xiaomi Quick Game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build Xiaomi Quick Game\" or \"Xiaomi Quick Game\" in the \"Build Other\" option to publish the project as Xiaomi Quick Game. Let's introduce the filling in of these function parameters: 1. Game name Generally, Chinese characters are filled in, but English is also acceptable. Used for game entrances such as app stores, desktop icons, pop-up windows, etc. A good name is an important factor in whether the game can attract traffic. Our suggestion is not to exceed 6 Chinese characters. There is no benefit if the game name is too long. 2. Game package name The format of the game package name is com.company.module. The first digit is com, the second digit is the company name, and the third digit is the project name. All must be written in English, for example: com.layabox.demoGame. 3. Game icon The game icon is also an important game entrance logo. Like the game name, it is a very important element that attracts attention. If the game icon is well designed, the game name will be well chosen. The same position will get more clicks than other games. The game icon needs to provide a square size of 192*192. 4. Game version name The game version name is the actual version and is generally used to differentiate between functional versions. For example, I have a major version change. It was originally 1.0 and can be changed to 2.0. If it is just to correct the bug, then 1.0 can be changed to 1.1. By analogy, we recommend using floating point numbers for naming. For example, \"0.1\", \"1.3\", \"5.0\"... 5. Game version The game version and the version name have different purposes. Here is the channel platform used to distinguish version updates. Every interrogation must be at least recursive +1, it doesn't matter if you test it yourself. However, the value here must be at least +1 compared to the value of the last arraignment. +N is also acceptable. It must not be equal to or less than the previous version value. It is recommended that the arraignment version number be recursively +1. It should be noted here that the game version must be a positive integer. 6. Minimum platform number Minimum platform number, just fill it in according to the platform version number displayed on the debugger. 7. Log level There are seven log levels, from high to low, they are OFF, ERROR, WARN, INFO, DEBUG, TRACE, and ALL. You can easily know the running status of the current program. 8. Whether to use the official version signature If you are only debugging the test version, you do not need to check it here. It must be checked before it is officially released online (submit the version to the platform). If checked, the official version signature will be enabled. About release signature: ① For companies, generally a company only uses one signature. If the company already has a signature, it is recommended to use the company’s signature. If not, publishing in the IDE integrates this function to facilitate developers to generate signatures. ②For individual developers, one official signature can be used on multiple projects. It only needs to be generated once. If the release has been signed, place the signature file in the sign/release folder of the Laya project. 9. Compressed texture Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release Click version release. Since the rpk release environment (used to generate rpk packages) will be checked before release, if there is no release environment, the download will start. The directory structure after publishing is shown in Figure 2-2: (Figure 2-2) js directory and libs directory: Project code and engine libraries. resources directory and Scene.ls: resources resource directory and scene file Scene.ls. Due to the limitations of the initial package for small games, it is recommended to plan the contents of the initial package. It is best to put them in a unified directory to facilitate the separation of the initial package. main.js： The entry files of Xiaomi Kuai Game, the game project entry JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. manifest.json： The project configuration file of the mini game contains some information about the mini game project. If you want to modify it, you can edit it directly here. 3. Use Xiaomi Quick Game Debugger 3.1 Xiaomi Quick Game release and debugging environment preparation Xiaomi brand mobile phone (note that it must be MIUI 8.5 or above). Download and install Xiaomi’s test APP, enter the Download Page, find the third step, and download directly according to the prompts. PC Chrome browser and mobile phone data connection cable. Install the node.js environment. The detailed steps are introduced in \"Building a Basic Development Environment\". Install ADB. It is recommended to install ADB, because sometimes, due to authorization or other inexplicable reasons. This will result in the Chrome telepresence machine debugging being unable to start normally. Therefore, installing ADB can verify the connection authorization between the mobile phone and the PC. If you make sure there are no USB debugging authorization issues, you don’t need to install it. A brief reminder, download ADB Kits, it is recommended to decompress the downloaded compressed package into a directory with a simple path (such as: D:\\adb). Remember to add environment variables (if you don’t know how to add environment variables, you can Baidu yourself). 3.2 Xiaomi Quick Game release and access complete process 3.2.1 Install and enter the quick application debugger First install the debugging APP (Quick Application Debugger) of Xiaomi Quick Game on your mobile phone, as shown in Figure 3-1. Then click to enter. (Figure 3-1) 3.2.2 Scan the QR code in the quick application debugger interface to install the rpk package of Xiaomi Quick Game After entering the quick application debugger, we can see the APP operation interface as shown in Figure 3-2. (Figure 3-2) You can scan the QR code to install, or connect a USB data cable to transfer the rpk package in the /dist directory under the release directory to your mobile phone, and install it by clicking the Local Install button. 3.2.3 Maintain physical line connection and authorization For developers with more relevant experience, make sure that the physical line of the USB mobile phone cable is connected, and there is no problem with USB debugging authorization, you can skip this step. The relevant operations are as follows: First use a mobile phone cable to physically connect the phone to the PC. Turn on the developer mode of your phone and turn on USB debugging. At this time, we need to pay attention to whether the prompt shown in Figure 3-3 appears on the mobile phone. If so, click OK to allow debugging. (Figure 3-3) Verify authorization. After the USB debugging mode authorization is successful, we open the cmd window on the PC and enter adb devices, as shown in Figure 3-4. (Figure 3-4) In short, in this link, we need to ensure that the PC has the authority to debug the mobile device. 4.4 Start the chrome debugging environment Xiaomi Quick Game has no tool development and debugging environment on the PC. It is connected to the mobile device through USB, and then in the PC command line mode, the Chrome debugger is launched through the npm run debug command (the prerequisite is to ensure that the PC has been installed Chrome browser) to jointly debug the rpk package of the real mobile phone environment, as shown in Figure 3-5. When we can see the prompt Debugger URL opened in Chrome., it means that chrome has been successfully launched. (Figure 3-5) Or enter chrome://inspect/#devices in the Chrome browser, find the connected mobile phone option after entering, and click inspect, as shown in Figure 3-6: (Figure 3-6) After the operation is completed, as shown in Figure 3-7, you can debug the Xiaomi Quick Game project according to Chrome's debugging method. (Figure 3-7) At this point, the complete process of Xiaomi Quick Game from publishing to starting Chrome debugging has been introduced. 4. Xiaomi Quick Game Subcontracting After the development is completed, the developer can subcontract the folders that need to be subcontracted, and other files in the project other than the subcontracted files are packaged into the main package. Xiaomi Quick Game Subpackage Loading Package Size Limitation The total sum of all sub-packages of the entire mini-game does not exceed 10M; The size of a single subpackage/basic package cannot exceed 5M; The overall compressed package (including the original package and all sub-packages;) does not exceed 20M. As shown in Figure 4-1, after clicking to enable subcontracting, select the folder to be subcontracted. (Pic 4-1) For subpackage loading API, etc., please refer to Xiaomi official documentation. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:10:41 "},"released/miniGame/alipaygame/readme.html":{"url":"released/miniGame/alipaygame/readme.html","title":"alipaygame","keywords":"","body":"Alipay mini game1. Overview2. Build and publish as Alipay mini-game2.1 Select target platform2.2 Introduction to the mini-game directory after release3. Use Alipay mini game development tools3.1 Apply for mini game application3.2 Install mini game development tools3.3 Log in to Alipay developer account3.4 Preview or real device debugging3.5 Upload and publish4. Subpackage loadingAlipay mini game 1. Overview Alipay mini-games do not require users to download and are a new type of game that can be played immediately. Compared with APPs, mini-games have the characteristics of short development cycle and low development cost, which allow developers to participate in the development process more easily. Achieve rapid launch and rapid monetization. It is recommended to read the documents of Alipay mini games, the first of which \"How to quickly launch a mini game\" can help developers quickly release online mini-game projects. The content of this article will also be used to install mini-game development tools. The documentation of the LayaAir engine is more engine-related, and of course also mixed with application introductions of some mini-games interface. Before releasing the Alipay mini-game, you need to perform General settings. 2. Build and publish as Alipay mini-game 2.1 Select target platform In the build and release panel, select the target platform as Alipay Mini Game in the sidebar. As shown in Figure 2-1, (Figure 2-1) Click \"Build Alipay Mini Game\" or \"Alipay Mini Game\" in the \"Build Other\" option to publish the project as an Alipay Mini Game. ES6 to ES5: If you need to use the \"real machine debugging\" function of Alipay's mini game development tools after the build is released, you need to check this option. It is generally recommended to check this box. Compressed texture: Generally, you need to check \"Allow the use of compressed texture format\". If not checked, the compression format settings of all images will be ignored. Texture source file: You can uncheck \"Always include texture source file\". If checked, the source file (png/jpg) will still be packaged even if the image uses a compressed format. The purpose is to fallback to the source file when encountering a system that does not support the compression format. 2.2 Introduction to the mini-game directory after release The directory structure after publishing is shown in Figure 2-2: (Figure 2-2) js directory and libs directory: Project code and engine libraries. resources resource directory and Scene.ls: resources resource directory and scene file Scene.ls. Due to the limitations of the initial package for small games, it is recommended to plan the contents of the initial package in advance. It is best to put them in a unified directory to facilitate the separation of the initial package. game.js： The entrance files of Alipay mini-games, the game project entrance JS files and the adaptation library JS are all introduced here. The IDE has already generated it when creating the project. Under normal circumstances, there is no need to touch it here. game.json： The configuration file of the mini game, developer tools and clients need to read this configuration to complete related interface rendering and property settings. project.config.json： The project configuration file of the mini game contains some information about the mini game project. my-adapter.js： Alipay mini game adaptation library file, used to adapt to Alipay mini games. 3. Use Alipay mini game development tools To debug the Alipay mini game project after LayaAir builds and releases it, you need to install mini game development tools. Proceed as follows: 3.1 Apply for mini game application Whether you are debugging or publishing Alipay mini games, you need an AppID. To obtain this AppID, you need to log in to the developer official website, log in to your developer account (Alipay account), and create a mini game. For specific operations, please refer to Alipay's documentation. After creating a mini-game, an AppID will be generated, which developers will use during debugging and publishing. 3.2 Install mini game development tools Alipay mini game development tools need to be used through the command line. Developers can open the command line panel (run as administrator) and enter the following command to install: npm and -g minidev@1.8.10 During the installation process, there may be delays due to network problems. It should be noted that the node.js version here cannot be too low, at least higher than 12. The 1.8.10 after the character @ indicates the version of the mini game development tool. Developers must choose the appropriate version according to their needs when installing. 3.3 Log in to Alipay developer account After downloading the mini game development tools, you need to log in. Login is also through the command line. Following the previous step, after executing the minidev login command, a QR code will appear. Developers can use Alipay to scan the code to log in to the developer account. As shown in Figure 3-1, after successful login, the words \"Authorization Completed\" will be displayed. (Figure 3-1) 3.4 Preview or real device debugging After preparing the mini game development tools, it is time to debug the mini game project built and released by LayaAir. Alipay provides two methods of preview and real-device debugging, both of which need to be executed through the command line. Generally, after the LayaAir project is built and released as an Alipay mini-game, it is debugged using a real machine. Because real machine debugging will open the debugging panel on the PC browser, while the preview can only open the debugging panel on the mobile phone. 3.4.1 Preview Preview, the required version of the mini game development tool installed is \\>= @ali/minidev@1.2.10. Execute the command in the project directory: minidev preview -a 2021xxx --ignore-http-domain-check, where \"2021xxx\" is the AppID generated in Section 3.1. The effect is shown in Figure 3-2: (Figure 3-2) The result after execution is shown in Figure 3-3. (Figure 3-3) Use Alipay to scan the code to preview the effect, as shown in Figure 3-4. You can click the three dots in the upper right corner to open the debugging panel. (Figure 3-4) In actual operation, it is not recommended to use preview. Developers who are interested can check the relevant details in Alipay Documentation. 3.4.2 Real machine debugging Real machine debugging requires the installed mini game development tool version \\>= @ali/minidev@1.3.0. Real machine debugging needs to be shown in Figure 2-1, that is, check when LayaAir is built and released as an Alipay mini game. ES6 to ES5. Execute the command in the project directory: minidev remote-debug -a 2021xxx --ignore-http-domain-check, where \"2021xxx\" is the AppID generated in Section 3.1. The effect is shown in Figure 3-5: (Figure 3-5) The result after execution is shown in Figure 3-6. An address will be generated for remote debugging, and a QR code will be generated. Developers can use Alipay to scan the code to view the effect. (Figure 3-6) At this time, open the remote address on the PC's browser, and the debugging panel will be displayed, as shown in Figure 3-7. (Figure 3-7) For individual developers, real-device debugging may encounter problems such as not being able to see the corresponding mini-games, as summarized in Alipay's Document some frequently asked questions. 3.5 Upload and publish If you want to actually publish the debugged Alipay mini game online, you still need to upload and publish it. To upload, the version of the mini game development tool required to be installed \\>=@ali/minidev@1.4.2 also needs to be executed using the command in the project directory: minidev upload -a 2021xxx -v 0.0.1 --game, Among them, \"2021xxx\" is the AppID generated in Section 3.1. After uploading, you can generate an experience code for the uploaded version on the open platform. After publishing and passing the review, it will be published and launched on the mini program official website. For the specific parameter requirements of the upload command, please refer to Alipay documentation. 4. Subpackage loading The following introduces how LayaAir IDE subcontracts Alipay mini games. Developers can first look at the subcontracting settings set by General. You can perform subcontracting loading through the following steps, as shown in Figure 4-1. Check to enable subcontracting, and then select the folder to be subcontracted. Developers can also choose whether to enable remote packages. (Pic 4-1) Alipay mini-game subcontracting restrictions: The size of all main packages + sub-packages of the entire mini-game does not exceed 20M The main package does not exceed 4M There is no limit on the size of a single ordinary subpackage Please refer to Alipay Mini Game Document. The Alipay mini-game development tool used when debugging sub-package loading needs to be upgraded to 1.8.10 and above. For the IDE to automatically load a subpackage, you need to check the \"Automatically load at startup\" option of the subpackage when publishing. If the resource is referenced by code, the method is slightly different from web publishing. An example of loading code is as follows: const { regClass, property } = Laya; @regClass() export class Script extends Laya.Script { @property({ type: Laya.Scene3D }) scene3d: Laya.Scene3D; constructor() { super(); } // Executed after the component is activated. At this time, all nodes and components have been created. This method is only executed once. onAwake(): void { //Alipay mini game Laya.loader.loadPackage(\"sub1\", this.printProgress).then(() => { Laya.loader.load(\"sub1/Cube.lh\").then((res: Laya.PrefabImpl) => { let sp3: Laya.Sprite3D = res.create() as Laya.Sprite3D; this.scene3d.addChild(sp3); }); }) Laya.loader.loadPackage(\"sub2\", this.printProgress).then(() => { Laya.loader.load(\"sub2/Sphere.lh\").then((res: any) => { let sp3 = res.create(); this.scene3d.addChild(sp3); }); }) } printProgress(res: any) { console.log(\"Loading Progress\" + JSON.stringify(res)); } } In the code, printProgress will print the loading progress log, and the effect is as follows: (Figure 4-2) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 10:42:41 "},"released/native/LayaNative_Introduction/readme.html":{"url":"released/native/LayaNative_Introduction/readme.html","title":"Native","keywords":"","body":"LayaNativeReviewLayaNative contains the following content:1. Tester:2. Build tools:3. Reflection mechanism:4. In the channel docking tool (conchMarket):5. LayaPlayer：6. The principle and development process of LayaNativeLayaNativeReview LayaNative is a complete development solution for the development, testing, and release of mobile native apps for the LayaAir engine, but it is not limited to the LayaAir engine. Based on LayaPlayer as the core runtime, LayaNative uses the reflection mechanism and channel docking solution to provide developers with secondary opening and channel docking on the native App, and provides testers and construction tools to package and publish HTML5 projects for developers. Conveniently turned into a native App. LayaNative contains the following content: 1. Tester: After downloading and installing the tester, scanning the URL QR code helps developers quickly see the running effect on the mobile terminal, saving a lot of time in repeated packaging and testing; 2. Build tools: The build tool can help developers quickly build mobile APP projects, and then use Android Studio, Eclipce, XCode and other development tools to open -> build -> run; 3. Reflection mechanism: Through the reflection mechanism, developers can realize mutual calls between JavaScript and native languages ​​​​(Android/Java or iOS/Objective-C). Through the reflection mechanism, developers can easily expand the application twice; 4. In the channel docking tool (conchMarket): The channel docking tool embeds common channel docking APIs, such as: login, sharing, recharge, friend relationship chain, etc.; 5. LayaPlayer： LayaPlayer is the core part of LayaNative. It is a cross-platform engine based on JavaScript script engine + openGLES hardware-accelerated rendering. It accelerates multimedia applications, games and other products based on HTML5 and WEBGL by extremely optimizing the memory and rendering process. Its performance is comparable to native Native-APP. LayaPlayer is written in C++ language and can be embedded in a browser or operating system to run, or it can run independently. 6. The principle and development process of LayaNative (1) Projects developed using LayaAir are ready to be released into app versions (ios or android). (2) LayaNative will use the core engine LayaPlayer for acceleration. (3) Developers can use the tester to quickly install it on mobile devices for simple testing. (4) Finally, build the ios or android project through the command line or IDE, compile and execute it. (5) If you need to publish to major channels (for example: Baidu, 360, AppStroe, Google, etc.), you need to carry out secondary development through the reflection mechanism (ie: docking the channel's SDK, logging in, recharging, sharing, etc.). (6), finally build it into an app for installation, testing, and release. The process is shown in Figure 1: ​ Figure (1) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:22:18 "},"released/native/native_index/readme.html":{"url":"released/native/native_index/readme.html","title":"native index","keywords":"","body":"LayaNative home page description1. LayaNative startup entrance2. LayaNative startup file configuration instructionsLayaNative home page description Important things need to be said three times: LayaNative is not a browser! LayaNative is not a browser! LayaNative is not a browser! 1. LayaNative startup entrance Since LayaNative is not a browser, it does not run HTML content by encapsulating controls such as browsers or webkit. Therefore, LayaNative cannot start and run html page files. The index.html in the bin directory of the engine project can be used as the entry point in the browser, but cannot be used as the startup entry point for LayaNative. LayaNative’s startup entry is by default Through the menu bar Tools--> app build of LayaAirIDE, in the opened build project window, just configure the URL. The configuration method is shown in Figure 1. In Figure 1, the entry is index.js by default. 2. LayaNative startup file configuration instructions The entry file mainly determines the screen orientation when the project is running and the information about the js files that need to be loaded. If we use the project's index.js as the startup entry file of LayaNative, after clicking the version release Examples are as follows: /** * Set the LayaNative screen orientation, you can set the following values * landscape Horizontal screen * portrait Vertical screen * sensor_landscape Landscape (both directions) * sensor_portrait Portrait screen (both orientations) */ window.screenOrientation = \"portrait\"; // Set the screen to vertical screen //-----Engine library starts----- loadLib(\"libs/laya.core.js\") loadLib(\"libs/laya.ui.js\") loadLib(\"libs/laya.d3.js\") //-----End of engine library------- loadLib(\"js/bundle.js\");//project code js Note: Please do not write any logic code in the index.js file, otherwise unknown errors may occur. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:33:47 "},"released/native/build_Tool/readme.html":{"url":"released/native/build_Tool/readme.html","title":"build Tool","keywords":"","body":"LayaBox build tool1. Operational requirements2. User-oriented3. Build the project in the IDE4. Project construction interface parameters5. Use of built project projects6. Manually switch between stand-alone version and network version7. Resource refresh8. Other issues to noteLayaBox build tool The build tool is used to generate LayaPlayer's mobile App project, which is equivalent to the App project wizard. Currently supports Android (Eclipse project, Android studio project) and iOS (XCode project). Notice: LayaNative3.0-Android, the minimum system version required is 4.3 LayaNative3.0-iOS, the minimum system version required is 10.0 1. Operational requirements 1.1 Basic development environment ​ To build the project, you must prepare a development environment. For example: to build an iOS project, you need to prepare a Mac computer and XCode, and for android, you need to prepare Android studio. 2. User-oriented Whether you are building an Android or iOS project, you must have the corresponding Android or iOS App development foundation. If you don't have it, please learn the relevant basic knowledge first. 3. Build the project in the IDE To publish a project using an IDE, developers first open the \"Build Project\" option in the file menu, as shown in animation 1 (Animation 1) Select iOS or Adroid as the target platform. Since the library files required to build the tool are relatively large, they are not directly included in LayaAirIDE. When you use this tool for the first time, you will first download the SDK package, as shown below: ​ (Figure 2) Notice This file is relatively large, so you need to be patient while downloading. 4. Project construction interface parameters Open the project construction interface in LayaAirIDE, as shown in Figure 3: (image 3) *Target platform There are two options for the type of project generated by building: Android studio project and iOS project. If you need to generate an Android project, you can choose Android-studio. If you need to generate an XCode (iOS) project, select the iOS option. Version The version of the Native project should be consistent with the LayaAir engine version, otherwise there may be version compatibility issues. Standalone If this option is checked, the App packaged by the built project is a stand-alone version, otherwise it is an online version. The stand-alone version does not require an Internet connection, there is no corresponding URL, and there is no need to provide a URL. However, game resources must be provided, otherwise it cannot be run after packaging. The address of the stand-alone version is fixed at http://stand.alone.version/index.js Package resources Resources are resources such as scripts, pictures, sounds, etc. For online games, as long as the game URL is available, it can run normally. However, if the resources are directly put into the App package, network downloading can be avoided and the resource loading speed can be accelerated. If it is a stand-alone game, since the game URL is not provided, a resource directory must be provided to package all the required resources into the App. Resources packaged into the App can still be updated through our dcc tool (resource cache management). If the resource path is not set at this time, you can still add resources manually after building the project. For the adding method, refer to LayaDcc Tool. Notice: The disadvantage of packaging resources is that it increases the size of the package body. For online games that package resources, DCC must be run on the server side, otherwise the advantage of packaging will be lost and all resources will still be downloaded. How to type dcc, refer to LayaDcc Tool. *App name The name of the App. It is also the output directory of the build project. Application ID The package name of the application is not visible under normal circumstances. Generally, anti-domain name naming rules are used (which is helpful for distinguishing and avoiding conflicts with existing APPs in the system). For example: com.layabox.runtime.demoThe package name must be in the format of xxx.yyy.zzz and must have at least two levels, namely xxx.yyy. Otherwise, packaging will fail. URL If the application to be packaged is an online project, you need to provide a startup URL that points to a js or json file, which is the entry point of the application. The project generated through LayaAir will output a startup page, usually index.js. During testing, for convenience, the local URL address is usually used for testing in the browser. When it is built into an Android App, there must be a real webserver address. For example: LAN address: http://10.10.20.19:8888/index.js Actual address: http://nativetest.layabox.com/layaplayer/index.js 5. Use of built project projects The built App project can be opened with the corresponding development tools for secondary development, packaging and other operations. Android-studio (android) projects can be imported and developed using the android-studio software. XCode (ios) projects can be imported and developed using xcode software. After opening the XCode (ios) project, you need to select the real ios device for build. (Note: The real devices are armv7, armv7s, arm64 architecture. If you use the ios Simulator, it is the X86 architecture. Currently, LayaNative does not support the X86 architecture on ios devices. If you use the simulator to compile, it will not pass. Reference resources: Usage and configuration of Android Studio Detailed process of packaging and releasing App for IOS ​ 6. Manually switch between stand-alone version and network version After the build is completed, you can switch between the stand-alone version and the network version by modifying the code directly in the project. Android project Open MainActivity.java in the built project and search for mPlugin.game_plugin_set_option(\"localize\",\"false\"); The stand-alone version needs to be set to \"true\", such as mPlugin.game_plugin_set_option(\"localize\",\"true\"); If you want to set it to the online version, you need to change it to: mPlugin.game_plugin_set_option(\"localize\",\"false\");, and set the correct address: mPlugin.game_plugin_set_option(\"gameUrl\", \"http://your address/index.js\"); iOS project After the iOS project is built, there is a function to execute loadUrl at the end of the resource/scripts/index.js script in the project directory. The home page address will be loaded here. Modifying the address here can switch between the stand-alone version and the online version. The address of the stand-alone version Fixed to http://stand.alone.version/index.js. For example, it starts with the online version, and the address is: loadUrl(conch.presetUrl||\"http://10.10.20.19:7788/index.js\");If you want to change it to a stand-alone version, modify this sentence: loadUrl(conch.presetUrl||\"http://stand.alone.version/runtime.json\");vice versa. NoticeOnce the URL address is modified, the original packaged resources will become invalid. At this time, you need to manually delete the contents in the cache directory and reuse layadcc to generate packaged resources. See LayaDCC Tool. 7. Resource refresh Build the project through the IDE, if you choose the stand-alone version and the packaged resource version. All h5 project resources (including scripts, pictures, html, sounds, etc.) will be packaged in the resource/cache directory. android directory: assets/cache/ iOS directory: resource/cache/ However, during the development process, the h5 project has been changing. In order to avoid rebuilding the project every time, it can be refreshed through the command line. Resource package version calling command: layanative3 refreshres -u http://testgame.layabox.com/index.js Stand-alone version calling command: layanative3 refreshres Tips1. The command must be executed in the directory of the built app project. The most obvious sign is that it must be in the directory of navtie.json, as shown in the figure below: For information on how to install and use the layanative command line, please refer to Using the layanative command line tool 8. Other issues to note After the android studio is built, you need to modify the version number of the android sdk according to your own environment. The current setting is 23, which needs to be modified. The file is app/build.gradle. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:16:35 "},"released/native/screen_orientation/readme.html":{"url":"released/native/screen_orientation/readme.html","title":"screen orientation","keywords":"","body":"Horizontal and vertical screen settings1. Horizontal and vertical screen settings before project construction2. Horizontal and vertical screen settings after project construction2.1 iOS2.2 Android3. Execution sequenceHorizontal and vertical screen settings This document further comprehensively introduces the horizontal and vertical screen settings of LayaNative. 1. Horizontal and vertical screen settings before project construction If you want to set up horizontal and vertical screens, go to Tools--> app build in the menu bar of LayaAirIDE. In the open build project window, just configure the screen orientation. The configuration method is as shown in the figure below. After setting the screen orientation, click Release and the screenOrientation attribute will be added to index.js: /** * Set the LayaNative screen orientation, you can set the following values * landscape Horizontal screen * portrait Vertical screen * sensor_landscape Landscape (both directions) * sensor_portrait Portrait screen (both orientations) */ window.screenOrientation = \"portrait\"; // Set the screen to vertical screen //-----Engine library starts----- loadLib(\"libs/laya.core.js\") loadLib(\"libs/laya.ui.js\") loadLib(\"libs/laya.d3.js\") //-----End of engine library------- loadLib(\"js/bundle.js\");//project code js 2. Horizontal and vertical screen settings after project construction 2.1 iOS After the iOS project is successfully built, open the resource/config.ini file and modify the value of orientation=16, as shown in the following figure: The meaning of the parameters is as follows: orientation=2 //Vertical screen: IOS home button is down orientation=4 //Vertical screen: IOS home button is on top orientation=8 //Horizontal screen: IOS home button is on the left orientation=16 //Horizontal screen: IOS home button is on the right The value of orientation can be set using bitwise OR, for example: Orientation=6 //Indicates that the vertical screen can be rotated arbitrarily orientation=24 //Indicates that the horizontal screen can be rotated arbitrarily Note: The horizontal and vertical screen settings in the iOS project are best consistent with the config.ini settings. Inconsistent settings may cause unknown situations to occur. The settings are as shown below: 2.2 Android The android project is built successfully. Open the AndroidManifest.xml file. There is a screenOrientation parameter in the activity tag. Developers can modify it according to their own needs, as shown in the following figure: The configurable parameters are Android standards and will not be explained too much here, as shown below: \"landscape\",\"portrait\",\"full_sensor\",\"sensor_landscape\",\"sensor_portrait\",\"reverse_landscape\",\"reverse_portrait\" 3. Execution sequence When the application starts, it will first read the screen orientation set in config.ini of iOS or the screen orientation set in AndroidManifest.xml of android. When index.js is parsed, the value of the horizontal and vertical screen settings is read and the screen orientation is reset. For example: Android's AndroidManifest.xml is set to portrait, and the label in index.js is set to landscape. During operation, you will find that on the Android device, the screen will rotate from portrait to landscape. Tips: It is recommended that developers set the two values ​​​​consistently to avoid screen rotation during program execution. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:43:14 "},"released/native/loading_view_new/readme.html":{"url":"released/native/loading_view_new/readme.html","title":"Loading View","keywords":"","body":"Loading interface1. Progress bar control2. Progress bar control example3. Remove all text display4. Customized interface and functions5.Special instructionsLoading interface In order to facilitate developers to customize LoadingView, LayaNative uses native functions to implement a new LoadingView. When the application starts, it needs to load the necessary html, js, and images. At this time, the progress needs to be displayed through the loading interface. When LayaNative runs the project, there is a LoadingView interface by default. After a period of time, you can enter the game, such as Figure 1 shows: ​ figure 1 1. Progress bar control Developers can control the background color, font color, Tips, etc. of LoadingView in config.js. The location of config.js: Android: assets/scripts/config.js in the project directory IOS: resources/scripts/config.js in the project directory The content in config.js is as follows, developers can modify it according to their own needs: window.loadingView = new loadingView(); if(window.loadingView) { window.loadingView.loadingAutoClose=true;//true means the engine controls the closing time. false for manual control by developers window.loadingView.bgColor(\"#FFFFFF\");//Set the background color window.loadingView.setFontColor(\"#000000\");//Set the font color window.loadingView.setTips([\"The door to the new world is about to open\", \"The enemy has 30 seconds to arrive on the battlefield\", \"Mom said, I can't eat hot tofu in a hurry\"]); //Set the tips array, which will appear randomly } 2. Progress bar control example In the actual development process, developers usually want to accurately control the hiding and display of LoadingView, then developers can set the value of loadingView.loadingAutoClose to false in config.js like this Then in the project, according to the loading completion status, set the display progress of the progress bar, and call the function as follows: window.loadingView.loading(nPercent);//The parameter is an integer value from 0 to 100. When the value is 100, LoadingView automatically closes The specific steps are as follows: Step 1: Set the value of loadingView.loadingAutoClose to false in config.js window.loadingView = new loadingView(); if(window.loadingView) { window.loadingView.loadingAutoClose=false; //Set the value to false, and the developer manually controls the closing of the loading interface. ... } Step 2: Call loadingView.loading(nPercent) to update the progress bar The pseudocode is as follows: where nPercent=0; var image1 = document.createElement('img'); image1.onload=function() { if(window.loadingView){ nPercent+=33; window.loadingView.loading(nPercent); } } image1.src = \"a.png\"; var image2 = document.createElement('img'); image2.onload=function() { if(window.loadingView){ nPercent+=33; window.loadingView.loading(nPercent); } } image2.src = \"b.png\"; var image3 = document.createElement('img'); image3.onload=function() { if(window.loadingView){ nPercent+=33; window.loadingView.loading(nPercent); } } image3.src = \"c.png\"; Tips： When the value passed in by the loadingView.loading(nPercent) function is equal to 100, the loading interface will automatically close. You can also close the loading interface by calling loadingView.hideLoadingView(). 3. Remove all text display You can remove the display of all text, including tips and loading percentage, modify config.js and set the value of showTextInfo to false. The code is as follows: window.loadingView = new loadingView(); if(window.loadingView) { ... window.loadingView.setTips([\"The door to the new world is about to open\", \"The enemy has 30 seconds to arrive on the battlefield\", \"Mom said, I can't eat hot tofu in a hurry\"]); //Set the tips array, which will appear randomly window.loadingView.showTextInfo=false; // Set value to false } 4. Customized interface and functions All code is public, so developers can modify the code as needed to implement any desired custom functionality. 5.Special instructions For the splash screen, the Android version is developed using native Java, and the iOS version is developed using Object-C. The codes are all open source. If developers need to customize the interface, they can modify it themselves. If you don’t know how to write interfaces for Android and iOS, then learn it. Bar. LayaBox will have a whitelist mechanism in the future. If the developer purchases the authorization, the LayaBox logo can be removed. If not, the LayaBox logo needs to be forcibly added. There will be a detection mechanism inside the engine. Random detection will occur. If the detection fails, it will Force Crash application. LayaNative is not an open source engine, but it is free for developers to use. If you want to remove the LayaBox logo, you need to pay. Developers can contact LayaBox Business through LayaBox official account, official website, etc. to purchase. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:28:35 "},"released/native/network/readme.html":{"url":"released/native/network/readme.html","title":"network","keywords":"","body":"About network status monitoring1. Monitoring method2. Query methodAbout network status monitoring Since the network environment of mobile devices is not stable, when the network changes, the project often needs to give users some prompts. There are two methods in LayaNative to obtain changes in the network environment. 1. Monitoring method Developers can use registered listening functions to monitor network changes. The code is as follows: The JS code is as follows if( conch ) { conch.setNetworkEvtFunction(function(type) { alert(type) }); } The AS code is as follows: if ( Render.isConchApp) { Browser.window[\"conch\"].setNetworkEvtFunction(function(type):void { alert(type) }); } The return value class is int type NET_NO = 0; NET_WIFI = 1; NET_2G = 2; NET_3G = 3; NET_4G = 4; NET_YES = 5; Tips1. Conch can only be called in the LayaNative environment. There is no definition of conch in the web version, so you need to check whether it exists. 2. Or you can use if(Render.isConchApp) to judge. 2. Query method Developers can also query the network status through active query. The code is as follows: if( conch ) { var nType = conch.config.getNetworkType(); } The return value class is int type NET_NO = 0; NET_WIFI = 1; NET_2G = 2; NET_3G = 3; NET_4G = 4; NET_YES = 5; Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:34:52 "},"released/native/LocalStrorage/readme.html":{"url":"released/native/LocalStrorage/readme.html","title":"Local Storage","keywords":"","body":"About LocalStorageUsage under ASUsage under JS and TSIncorrect usage:About LocalStorage LayaNative supports the use of LocalStorage, but there are format requirements. GetItem() and setItem() must be used to store and obtain values. Usage under AS //Storage the specified key name and key value, string type. LocalStorage.setItem(\"LayaBox\",\"H5 engine!\"); //Get the value of the specified key name. LocalStorage.getItem(\"LayaBox\"); Usage under JS and TS //Storage the specified key name and key value, string type. Laya.LocalStorage.setItem(\"LayaBox\",\"H5 engine!\"); //Get the value of the specified key name. Laya.LocalStorage.getItem(\"LayaBox\"); Incorrect usage: The usage of the following js syntax is supported by PC browsers or mobile terminals (browser naked running), but is not supported by LayaNative. //Storage, not supported under LayaNative localStorage.test = 100; //Value, not supported under LayaNative alert(localStorage.test); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:31:55 "},"released/native/Android_BackPress/readme.html":{"url":"released/native/Android_BackPress/readme.html","title":"Android BackPress","keywords":"","body":"Take over android back buttonTake over android back button These two functions can be used in LayaNative, conch.setOnBackPressedFunction(onBack) and conch.exit(), to take over the processing of pressing the \"back key\". After taking over setOnBackPressedFunction, this function will be executed when the user presses the back key. Once this function is called, the default function of pressing twice to exit in the engine is blocked. At this time, if you want to exit the application, you can do so by calling the exit() function. Tips1. Conch can only be called in the LayaNative environment. There is no definition of conch in the web version, so you need to check whether it exists. 2. Only the Android version of LayaNative has these two functions. js example is as follows: var n=3; if(window.conch){ window.conch.setOnBackPressedFunction(()=>{ console.log('press back '+n); if(n-- Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:13:49 "},"released/native/real_device_debugging/readme.html":{"url":"released/native/real_device_debugging/readme.html","title":"Debugging JS on Android","keywords":"","body":"Debug JavaScript code on real Android device1. Principle of debugging2. Debugging the Android project built by layaAirIDEStep 1:Step 2: Modify debug modeStep 3: Compile and run the projectStep 4: Use Chrome to connect to the projectStep 5: Debugging4. Problems in the current versionDebug JavaScript code on real Android device 1. Principle of debugging Debugging of JavaScript code is performed using the Chrome browser on the debugging machine. When LayaNative on the Android test machine is started, a WebSocket server will be started at the same time. The Chrome browser communicates with LayaNative through WebSocket, thereby enabling the debugging of the project's JavaScript using Chrome. When debugging JavaScript code in a project, there are two debugging modes to choose from: Debug/Normal mode In this mode, the project on the Android test machine can be started and run directly, and the Chrome browser can be connected for debugging after the project is run. Debug/Wait mode In this mode, after the project on the Android test machine is started, it will wait for the connection of the Chrome browser. When Chrome connects successfully, the JavaScript script will continue to be executed. When you need to debug JavaScript scripts loaded at startup, please choose this mode first. Note: In the debugging project, please ensure that the debugging machine and the Android test machine are on the same network. 2. Debugging the Android project built by layaAirIDE Step 1: Use LayaAirIDE to build the project and generate the Android project. Step 2: Modify debug mode Use Android Studio to open the built project. Open android_studio/app/src/main/assets/config.ini, modify the value of JSDebugMode, and set the required debugging mode. Figure 1: figure 1 The values ​​and meanings of JSDebugMode are as follows: Value Meaning 0 Turn off debugging 1 Debug/Normal mode 2 Debug/Wait mode Tips： When the project is officially released, please set the value of JSDebugMode to 0, otherwise it will affect the performance of the project during runtime. Step 3: Compile and run the project Use Android Studio to compile the project. If you select Debug/Normal mode, wait for the Android test machine to successfully start and run the project. Figure 2 Android test machine successfully starts and runs the project If Debug/Wait mode is selected, wait for the Android test machine to successfully start the project. Figure 3 Android test machine started successfully Step 4: Use Chrome to connect to the project Open the Chrome browser on the debugging machine and enter the following URL: devtools://devtools/bundled/js_app.html?v8only=true&ws=10.10.82.142:5959/177987ab-1d16-4ea6-afcc-c11c0a1bb9e9 Note: 10.10.82.142 in ws=10.10.82.142:5959 is the IP address of the Android test machine, 5959 is the port number value set by JSDebugPort in the config.ini file in step 2. Please base it on the actual situation of your device and changes to requirements. Step 5: Debugging After the connection is successful, you can use Chrome to debug the JavaScript in the project. as shown in picture 2: Figure 4 4. Problems in the current version The following problems will be solved in future versions, please understand. During the debugging process, using breakpoints manually added by the debugger (non-debugger breakpoints) may cause debugging confusion. If you encounter this situation, please follow these steps: Step 1: Set breakpoints as follows Figure 11 Step 2: Cancel all breakpoints Figure 12 Step 3: Restart the project, and then use Chrome to connect to the project. Figure 13 Step 4: Restore required breakpoints Figure 14 Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:42:42 "},"released/native/LayaDcc_Tool/readme.html":{"url":"released/native/LayaDcc_Tool/readme.html","title":"LayaDcc Tool","keywords":"","body":"LayaDCCToolsIntroduceType of LayaPlayer resource packageInstall and use layadcc1. Install Node.js2. Install layadcc3. How to use4. Practical operationcommon problemAppendixLayaDCCTools Introduce LayaDCC: Laya-Dynamic Content Check is a hot update solution provided by LayaPlayer. The advantage is that runtime differential updates can effectively reduce network traffic. His main data is the DCC file, which is used to describe the check values ​​of all files in the project. DCC files are generated using the tool layadcc. layadcc will traverse all project files and generate a binary file filetable.bin containing the check values ​​of all files. When LayaPlayer starts, it will obtain this file from the server (if necessary) to determine what files need to be updated. layadcc can also be used to generate resource packages and package resources into the App. Type of LayaPlayer resource package There are currently three resource packaging solutions. App networking package: The App itself does not carry any resources and is the smallest in size. When LayaPlayer is run for the first time, all resources used will be downloaded from the server and cached locally. When running for the second time and later, the dcc file will be obtained from the server first, and then when a certain file needs to be downloaded, it will check whether the local resources need to be updated. Only when they need to be updated will they be actually downloaded. Unupdated resources will be downloaded directly from Local cache reads. The local cache will gradually grow. App networking package with resources: The App package itself contains some or all game resources, and the package size is large. The data can still be updated, that is, the dcc file will still be fetched from the server for verification every time it is run. If a file in the package is found to be old, a new file will be downloaded and cached locally. When running again in the future, as long as If the cached file has not been changed, the cached file will still be used. After multiple updates, most of the files in the App package may be invalid, and the local cache is taken every time. At this time, it is recommended to update the App package again and use new resources to package it. App offline package (stand-alone package): All resources are packaged directly into the App, no network download is required, or even an Internet connection is required. The largest size. Because it is a stand-alone version and does not have a URL, it cannot dynamically update resources. If you want to update resources, you can only update the App. Install and use layadcc layadcc is based on Node.js, so it requires Node.js environment. 1. Install Node.js Go to nodejsofficial website to download. node.js cannot be too old and does not support version 0.xx. You can use the command to check the node version. For example: $ node -v v4.2.0 This version will do. 2. Install layadcc npm install -g layadcc If the installation is completed successfully, you can execute layadcc directly in the command line. 3. How to use layadcc resource directory [options] options: -cache generates resource bundles. -lwr Convert all file paths to lowercase. (Generally not required) -url url If you want to package resources, the corresponding url. -cout outpath The output directory of packaged resources. If not set, it will be in the resource directory. For example: layadcc d:/game/wow -cache -url www.game.com 4. Practical operation 4.1 Operating environment Make sure Node.js, npm, layadcc are installed correctly Authentication method:figure 1As long as no error is reported when executing layadcc, it will be fine. 4.2 html5 project environment Suppose there is a game project placed in the F:/work/test/bestgame/ directory (the startup page index.html is in this directory). Its directory structure is: figure 2The corresponding url address after this project is released is: http://www.layabox.com/bestgame/index.html (If the stand-alone version does not require a url address) 4.3 Packaging resources Now we need to package this html5 project and put it into the App project. layadcc F:/work/test/bestgame -cache -url http://www.layabox.com/bestgame/index.html If it is a stand-alone package, enter: layadcc F:/work/test/bestgame -cache -url http://stand.alone.version/index.html As shown below:image 3 After adding the -cache parameter, all resource files will be traversed and output to the directory specified by -cout. If there is no -cout parameter, a layadccout directory will be created in the working directory (as shown above). The cache directory under the output directory is the resource that needs to be used when packaging the App. Then copy this directory to the corresponding directory of the built project, and you can compile and package it to generate the App. In different development environments, they need to be placed in different directories (if you use LayaAirIDE or layabox command line tools, this step can be completed automatically). Android Eclipse: (Figure 4) The resource directory of android is the assets directory under the project Android Studio:(Figure 5) iOS XCode: (Figure 6) IOS is the resource directory 4.4 Update server This is the most common operation after the App is released. Whenever the content of the HTML5 project is updated and needs to be submitted to the server or local testing, a new DCC must be generated so that the client can be updated to the latest resources. The operation process is as follows: Figure 7 You can see that after executing layadcc, an update directory will be generated under the specified directory (now the current path . ). Then copy the update directory to the same directory on the local or remote server. Tips:For convenience and no errors, it is recommended to execute layadcc directly in the directory where the server is located. update directory introduction: Figure 8 allfiles.txt The relative paths of all resource files. assetsid.txt The verification code of the entire resource package counted by this DCC. filetable.bin dcc main file, which contains the check value of each file. Filetable.txt text format dcc file, except for the first three lines, each line represents a file and the corresponding check value, which exactly corresponds to allfiles.txt, that is, the file corresponding to line 4 is the first line of allfiles.txt. filetable1.txt This file is no longer used. Notice: If there is no update directory in the directory on the web server, or there is no content in the update directory, the client's dcc update mechanism will be turned off, so that all resources will be downloaded again every time. This approach is recommended during development. The above example is in the current directory. You can also specify other paths, either relative or absolute, for example: layadcc d:/game/bin/h5 or layadcc ../bin/h5 4.5 Test Test of successful resource packaging Let’s talk about the situation where there are no resources in the package. In this case, all resources will be downloaded from the Internet. The log is as follows: Figure 9 You can see that there are many Downloads Print information instructions: The @127.0.0.1 followed by the url here is for debugging, indicating the server address corresponding to this file. s=0 means that this file has no dcc information, l=xxx means the length of the downloaded file. If a resource package is installed, that is, the contents in the cache directory are copied to the directory specified above. The most intuitive change at this time is that the package becomes larger. Then run the app, and there will be a printout of resources read from the resource package, as follows: Figure 10 Print information instructions Printing found the file in the package: means that the corresponding resources were obtained from the package and were not downloaded from the Internet. Seeing this log means that the resources were packaged successfully. If you are playing the stand-alone version, all resources should have this printout and there should not be any downloads. Whether the service has DCC testing: Open the address in the browser: http://www.layabox.com/bestgame/update/filetable.txt Be careful to change it to your own address. If the file exists, it means that dcc has been typed. As shown below:Figure 11 Test that the update mechanism works The intuitive test is that after the resources are updated, the App will produce corresponding changes, such as modified pictures, which can be seen on the App. Judging from the log, when retrieving resources, anything that has not changed is printed as found the file in the package:, and anything that has changed is printed as download [ ] xxxurl. Notice 1 Download is only executed once, and the second time you enter the app, if the resource has not been changed, it will be fetched directly from the cache. 2 The mechanism of DCC is runtime update, so it will only be downloaded when the resource is needed during execution, instead of downloading all updates as soon as it is started. Summarize Whenever there is download [ ] url, it means downloading, which means there is no dcc or the resource has been updated. Whenever there is found the file in the package:, it means that the resource packaging is successful and dcc has worked. Notice: When layadcc is executed, the modification time of all files will be modified. The purpose is to prevent CDN from thinking that the files have not been modified when returning to the source. The above address is fictitious, there is no such address as http://www.layabox.com/bestgame/index.html. common problem After packaging the resources, I don’t feel that the speed has become faster. I suspect that all the resources are still being downloaded. Determine whether it is really all downloading and see if the log contains the Download and find mentioned above. If there is both read cache and downloading, there is no problem, but the downloading is really slow. If everything is Download, there is no read cache1. Did you forget to type dcc? Check the server through the browser to see if there is dcc information. Check whether the packaged resource path is correct. After the App was released, some resources were modified, but they were not updated by the App. Did you forget to get DCC? I applied DCC, but forgot to submit it to the server (it is recommended to apply DCC on the server)? I have run DCC and submitted it to the server, but due to CDN, this change has not yet been distributed to your node. I confirmed that the DCC process is correct, but a certain resource will be re-downloaded every time without going through the cache. Confirm whether this resource is in the packaged resources, that is, in the dcc list. You can search for this file in update/allfiles.txt. If in. Confirm whether the URL requesting this resource has a search part, that is? xxx. If it is added, the DCC process will not work. If there is no search, it is possible that the actual content of the file does not match the check value. DCC will think it is a wrong file and will not cache it. possible reason:1. After typing dcc, someone changed the content of this file, causing the dcc check value to not match the actual file content. Solution: Re-enter DCC No one changed the content of the file, but the dcc was typed on the client. After the file was uploaded to the server, the content was modified by the uploading software. This situation usually occurs with text files. For example, some version management tools and ftp tools will change the carriage return and line feed under Windows into the carriage return on Unix. Solution: Use zip to transfer files, or type dcc on the server. There is no problem above, and the error is in the picture. The possible reason is that some systems intercept HTTP requests globally and cache a compressed image through their own server when requesting an image to achieve the so-called traffic saving. The check value of this compressed image is definitely different from that recorded by dcc. Solution: Turn off the data saving function. If traffic saving is not enabled. But if CDN is used, it may also be a CDN problem. For example, the dcc file is refreshed, but the corresponding resource file is not refreshed. Confirmation method: Download the resource file on this node through the curl command (see the appendix for the method), compare it with the resource file on the source site, and confirm if it is different. Solution: Force refresh the CDN node, or contact CDN customer service. During development, it is too troublesome to type dcc for every update. Don't use layadcc to hit dcc. If you have already hit it, Delete the update directory and reinstall the app to remove the internal cache. In this way, the DCC mechanism will be turned off and each file will be re-downloaded with each request. If you hit dcc again and an update directory is generated on the server side, the cache will work again. If you want to turn it off, do the above operation again. In order to reduce the size of the package, I hope to only package some resources. What is the correct posture? Whether it is the first installation or an app upgrade in the future, if you only use some resources, make sure that the DCC information in the resources is generated based on complete data. For example, there are 100 resources in total, and you only want to package 50 into the app. You need to run dcc in the complete resource state, save the generated dcc information (mainly filetable.txt), then delete 50 resources, and use layadcc to generate cache files. , at this time, the dcc information generated in the cache directory is incomplete, so it must be overwritten with the file generated in the previous step. Problems that will occur if incomplete dcc is used: When updating the app, native will give priority to using the dcc file cached in the app, resulting in the loss of part of the cache information. In this way, files not in filetable.txt will be considered to not need to be cached, thus Keep downloading until the next server dcc update. Appendix LayaDCC process Figure 12 The corresponding code is in index.js. Download the file on a certain cdn node. curl -H \"Host:www.layabox.com\" http://182.110.238.110/bestgame/index.html >a.html It means downloading the file http://www.layabox.com/bestgame/index.html on the 182.110.238.110 node and saving it to a.html. Among them, Host: the following content is changed to your own domain name, and the ip address after http:// is changed to the address of the node server. How to obtain the node server address? In LayaPlayer, the node server usually does not change, so the address can be obtained by printing any Download, for example: Downloaded http://www.layabox.com/bestgame/bestgame.min.js@182.110.238.110 s=44216b56 l=422 We know that the node address is 182.110.238.110. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:21:02 "},"released/native/Secondary_Development/readme.html":{"url":"released/native/Secondary_Development/readme.html","title":"Secondary Development","keywords":"","body":"Use reflection mechanism to implement secondary development1. Call static function3. Platform code (android/ios) actively executes js scripts3.1 IOS/OC executes JS script3.2 Android/Java executes JS scriptUse reflection mechanism to implement secondary development LayaNative helps developers facilitate secondary development by providing a reflection mechanism. Let’s use an example to learn how to carry out secondary development. 1. Call static function Using LayaNative, you can call static functions written in the mobile terminal's native development language (Java under Android, Objective-C under iOS) in the JavaScript layer. 1.1 JavaScript layer: How to call the JavaScript layer: var os = conchConfig.getOS(); was bridge; var obj = {}; if (os == \"Conch-ios\") { bridge = PlatformClass.createClass(\"JSBridge\");//Create a script proxy } else if (os == \"Conch-android\") { //Requires complete class path, note the difference from iOS bridge = PlatformClass.createClass(\"demo.JSBridge\");//Create a script proxy } if (os == \"Conch-ios\") { //For iOS, pay attention to the function signature and the difference from Android. alert(bridge.call(\"testString:\",\"hello\")); alert(bridge.call(\"testNumber:\",256.0)); alert(bridge.call(\"testBool:\",false)); obj.value = \"Hello OC!\"; bridge.callWithBack(function(value) { var obj = JSON.parse(value) alert(obj.value); },\"testAsyncCallback:\", JSON.stringify(obj)); } else if (os == \"Conch-android\") { alert(bridge.call(\"testString\",\"hello\")); alert(bridge.call(\"testNumber\",256.0)); alert(bridge.call(\"testBool\",false)); obj.value = \"Hello Java!\"; bridge.callWithBack(function(value) { var obj = JSON.parse(value) alert(obj.value); },\"testAsyncCallback\",JSON.stringify(obj)); } 1.2 Android/Java layer Add the following functions to class JSBridge: public static String testString(String value) { Log.d(\"JSBridge\", \"java: \" + value); return \"LayaBox\"; } public static double testNumber(double value) { Log.d(\"JSBridge\", \"java: \" + value); return 512; } public static boolean testBool(boolean value) { Log.d(\"JSBridge\", \"java: \" + value); return value ? false : true; } public static void testAsyncCallback(String json) { //js thread try { JSONObject root = new JSONObject(json); Log.d(\"JSBridge\", \"java: \" + root.getString( \"value\" )); } catch (JSONException e) { e.printStackTrace(); } m_Handler.post( new Runnable() { public void run() { //ui thread update ui JSONObject obj = new JSONObject(); try { obj.put(\"value\", \"Hello JS!\"); } catch (JSONException e) { e.printStackTrace(); } ExportJavaFunction.CallBackToJS(JSBridge.class,\"testAsyncCallback\", obj.toString()); } }); } 2.1.4 iOS/OC layer Add the following functions to class JSBridge: +(NSString*)testString:(NSString*)value { NSLog(@\"OC: %@\",value); return @\"LayaBox\"; } +(NSNumber*)testNumber:(NSNumber*)value { NSLog(@\"OC: %@\",value); return @512; } +(NSNumber*)testBool:(NSNumber*)value { NSLog(@\"OC: %d\",value.boolValue); return [NSNumber numberWithBool:value.boolValue ? NO : YES]; } +(void)testAsyncCallback:(NSString*)json { //js thread NSError* error = nil; NSData* jsonData = [json dataUsingEncoding:NSUTF8StringEncoding]; NSDictionary* dict = [NSJSONSerialization JSONObjectWithData:jsonData options:NSJSONReadingMutableContainers error:&error]; NSLog(@\"OC: %@\", [dict objectForKey:@\"value\"]); dispatch_async(dispatch_get_main_queue(), ^{ //ui thread NSError* error = nil; NSDictionary* dic = [NSDictionary dictionaryWithObject:@\"Hello JS!\" forKey:@\"value\"]; NSData* jsonData = [NSJSONSerialization dataWithJSONObject:dic options:NSJSONWritingPrettyPrinted error:&error]; NSString* jsonStr = [[NSString alloc] initWithData:jsonData encoding:NSUTF8StringEncoding]; [[conchRuntime GetIOSConchRuntime] callbackToJSWithClass:self.class methodName:@\"testAsyncCallback:\" ret:jsonStr]; }); } Notice: Function parameters only support basic types such as Boolean, floating point, and string, and return values ​​are supported. Native functions run in the script thread. To update the UI, you need to go to the UI thread and support asynchronous callback functions. The suffix of the OC source file must be changed to .mm, and the OC method is a static class method and must use +. Through the above method, secondary development related to native code can be easily carried out. 3. Platform code (android/ios) actively executes js scripts 3.1 IOS/OC executes JS script [[conchRuntime GetIOSConchRuntime] runJS:@\"alert('hello')\"]; 3.2 Android/Java executes JS script ConchJNI.RunJS(\"alert('hello world')\"); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:45:08 "},"released/native/webview/readme.html":{"url":"released/native/webview/readme.html","title":"webview","keywords":"","body":"webview1. Introduction1. Interface definition2. Restrictions2. How to dynamically close the webview page in codewebview 1. Introduction Since LayaNative does not support standard html, sometimes the project needs to display a complete html page. This can be achieved through an interface provided by LayaNative that displays the webview interface. 1. Interface definition /** * Display a webview * @param url {string} The url address to be displayed. * @param posx {number} The upper left corner position of weview * @param posy {number} The upper left corner position of welivew * @param width {number} The width of the webview * @param height {number} The height of the webview * @param canclose {boolean} Whether the webview can be closed. */ setExternalLinkEx(url:string,posx:number,posy:number,width:number,height:number,canclose:boolean):void; This function will display a new view on the top layer of the canvas, where the content of the URL will be displayed. The canclose parameter is used to control whether this webview can be closed: When set to false: code show as below: document.addEventListener('touchstart',()=>{ if(conch){ var l = 50; where t = 50; var w = window.innerWidth - l * 2; var h = window.innerHeight - t * 2; conch.setExternalLinkEx('http://www.layabox.com',l,t,w,h,false); // canclose is set to false //conch.setExternalLink('http://www.baidu.com'); } }); After the webview is displayed, it cannot be closed. The effect is as follows: figure 1 When set to true: code show as below: document.addEventListener('touchstart',()=>{ if(conch){ var l = 50; where t = 50; var w = window.innerWidth - l * 2; var h = window.innerHeight - t * 2; conch.setExternalLinkEx('http://www.layabox.com',l,t,w,h,true); // canclose is set to true //conch.setExternalLink('http://www.baidu.com'); } }); Under iOS, there will be a small close button. Click this button to close the webview. The effect is as follows: figure 2 Because the close button will cover part of the page content, and the back key is provided on Android devices, there is no close button after the webview is displayed on the Android device. You can close the webview through the back key. As shown below: image 3 At this point you can click the back button to close the webview 2. Restrictions Currently webview cannot interact with app. The implementation of webview depends on the system, and lower versions of Android may not be able to display it. Tips1. Conch can only be called in the LayaNative environment. There is no definition of conch in the web version, so you need to check whether it exists. 2. How to dynamically close the webview page in code Call the following code to dynamically close the webview page: conch.closeExternalLink(); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:47:38 "},"released/native/built_in_font/readme.html":{"url":"released/native/built_in_font/readme.html","title":"Fonts","keywords":"","body":"Embed fonts1. Font introduction2. How to embed fonts3. iOS embedded fontsFont modification after version 3.11. Read the font file in the local assets directory, then register the code through registerFont, and then use the associated font through the font name layabox passed in during registration.2. Download remote font files through ttfloader. The font name passed in during registration is the ttf file name.Embed fonts 1. Font introduction Due to the wide variety of Android devices, the non-uniform font files of Android, and the differences in the default Chinese font paths of each system (coupled with the customization of many domestic manufacturers), reading font.ttf is a difficult problem. LayaNative's strategy is to enumerate the path to the font file based on the Android system version number. If the loading is successful, the system default font will be used. If the loading is unsuccessful, a font will be downloaded from the LayaBox website and stored locally. When entering for the second time , read local fonts directly. When developers package apps, they must package fonts into the app by default. If a 4MB TTF font is downloaded on the Internet, it will affect the user experience. 2. How to embed fonts Build the android project, find the assets directory, create a font directory, rename the font file to be implanted to \"layabox.ttf\" and place it in this directory. As shown in Figure 1: Tips: The template project embeds ttf fonts by default, which will increase the size of the apk. If you care about the apk size, you can delete the assets/font/layabox.ttf font file. 3. iOS embedded fonts LayaNative supports iOS embedding default fonts. The specific method is the same as Android. Create a font directory under resource and rename the font to be embedded to layabox.ttf, as shown in Figure 2 below: Font modification after version 3.1 After version 3.1, the font system has been optimized, and system fonts are used first by default. If you need to embed custom fonts, you need to register them with the system before they can be used. The following examples show two embedding methods. 1. Read the font file in the local assets directory, then register the code through registerFont, and then use the associated font through the font name layabox passed in during registration. function registerFont() { var assetFontData = conch.readFileFromAsset('font/layabox.ttf', 'raw'); if (assetFontData) { if (conch.registerFont(\"layabox\", assetFontData)) { log('Font registration successful'); } else { log('Font registration failed'); } } } 2. Download remote font files through ttfloader. The font name passed in during registration is the ttf file name. Laya.loader.load(\"res/maobi.ttf\", Loader.TTF).then(() => { var label: Label = new Label(); label.font = \"maobi\"; label.text = \"Custom embedded font\"; label.fontSize = 30; label.color = '#FFFFFF'; this.Main.box2D.addChild(label); label.pos(30, 50) }); Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:17:34 "},"released/native/zipUpdate/readme.html":{"url":"released/native/zipUpdate/readme.html","title":"zip Update","keywords":"","body":"LayaNative’s resource update method1. User-invisible updates (recommended).2. Visible to users, centralized updates before entering the game.LayaNative’s resource update method After the game is released, you will inevitably encounter update problems. The update here refers to the fact that after the game packaged with LayaNative is released, you want to modify some of the client's code, pictures and other data because of bug fixes or added functions. Currently LayaNative supports two resource update methods: 1. User-invisible updates (recommended). This is an ongoing, ongoing update. This method is in line with the idea of ​​updating web pages: only when a certain resource needs to be used, the resource update process will be triggered. This broken update mechanism allows users to enter the game immediately and complete the update without even realizing it. This update is based on LayaNative's DCC mechanism. For an introduction and usage of LayaDCC, see here. 2. Visible to users, centralized updates before entering the game. Most traditional app update methods are to check whether an update is needed as soon as it comes up. If an update is required, download a large zip file and update it as a whole. The maintenance cost of this kind of update is high, users need to wait for a long time to enter the game, and it also clearly violates Apple's policy prohibiting hot updates. Its advantage is that users can update where there is wifi and play in places where there is no wifi, avoiding wasting data traffic when there is no wifi. Although LayaNative does not directly support this kind of update, it can also achieve this function through the following interfaces (note that these interfaces are internal interfaces and may change in the future): Supports downloadBigFile, a large file download function that can be resumed at breakpoints. (Be careful not to use XMLHttpRequest to download large files, because in this way LayaNative will save the results in memory first, so large files may cause the memory to explode, and this function can be saved at any time.) /** * @param url remote address * @param local save to local file * @param onprog Download progress callback * @param oncomp download completion callback * @param trynum number of retries (0 unlimited retries) * @param opttimeout timeout (recommended to be large enough) */ declare var downloadBigFile:(url:string, local:string, onprog:(total:number,now:number,speed:number)=>boolean,oncomp:(curlret:number, httpret:number)=>void, trynum:number, opttimeout:number)=>void; ZipFile class for processing zip files interface ZipFile{ setSrc(src:string):boolean; /** * Traverse the files in the zip. * id: * name: file name, including path * dir: whether it is a directory * sz: file size */ forEach(func:(id:number,name:string,dir:boolean,sz:number)=>void):void; /** * Read the contents of the file in the zip and return an ArrayBuffer */ readFile(id:number):ArrayBuffer; close():void; new ():ZipFile; } declare var ZipFile:ZipFile; The function of manually updating dcc cache. interface AppCache{ ... /** * Update a file in the dcc cache * @param nameid The id of the updated file. * Path rule: /, indicating the app root directory. For example: hashstr('/index.html'), do not take parameters. If you take parameters - hashstr('/aa/bb.html?ff=2'), no one will be able to find this file. * @param chksum Check code, if 0, this function calculates it by itself. If it is external version control, this is the version number after hashstr. * @param buf ArrayBuffer file content. * @param extversion whether to use external version number * @return boolean If true is returned, it means the update is successful, otherwise, it means the check code is inconsistent, that is * You need to update dcc before it can work. */ updateFile(nameid:number,chksum:number,buf:ArrayBuffer,extversion:boolean):boolean; ... } Through these functions, a centralized update function can be implemented on layaDCC. For example, LayaNative provides an encapsulated update function updateByZip: ​ /** * Update with zip. * @param {string} url zip download address * @param {(event:string,downloadPercent:number,curfile:string)=>void} onEvent event callback. * The event is the event name. Possible events are as follows: * 'downloading' is downloading, and downloadPercent has a value at this time. * 'downloadError' download error * 'downloadOK' Download successful. * 'updating' is being updated. At this time, curfile has a value, indicating the file being updated. * 'updateError' curfile update error. Because curfile is not in the dcc list, or the file content is inconsistent with the dcc content. A small number of update errors can be ignored because they will still be downloaded during actual use. * 'unknownError' * @param {function(localfile:string):void} onEnd update completion callback */ function updateByZip(url, onEvent, onEnd) The implementation code of this function is in the engine’s index.js. So if you have special needs, you can also refer to this function to implement your own update function. ​It should be noted that this function actually only downloads the zip and then updates each file in the zip to the cache. When actually using it, you have to implement version management, interface, download progress prompts and other functions yourself. In order to implement these functions, you may need a local interface for reading and writing files. You can use the following global function (also an internal interface, which may change): ​ declare var fs_readFileSync:(file:string)=>ArrayBuffer; declare var fs_writeFileSync:(file:string,data:string|ArrayBuffer)=>boolean; declare var readFileSync:(file:string,encode:string)=>string;//This directly returns a string. If you need to obtain the cache path, you need the appcache object inside LayaNative: ​ var cachepath = window.appcache.getCachePath() Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:48:25 "},"released/native/apk_expansion/readme.html":{"url":"released/native/apk_expansion/readme.html","title":"APK Expansion","keywords":"","body":"Android file extension mechanism1. Detailed explanation of the mechanism1. Generate DCC2. Compress files3. Copy the zip file to the device directory4. Modify the expansion path in the code5. Enable external storage permissions5. Run the test2. Google Play APK expansion file mechanismAndroid file extension mechanism LayaNative not only supports packaging resources in the assets directory, but also supports packaging resources into zip files and placing them in any file path. The LayaNative file system will first check whether the file exists in the assets directory. If it is not found, it will then search in the specified zip path. This zip mechanism can solve the problem of Google Play stipulating that the APK size exceeds 100MB and requiring the addition of expansion packs. 1. Detailed explanation of the mechanism 1. Generate DCC Test project uses DCC tool to package resources 2. Compress files Put the resource package into the extension file and compress the cache file. The file must be in zip format. The file structure must remain the same as that generated by the DCC tool, as shown below: 3. Copy the zip file to the device directory Create the directory /storage/emulated/0/Android/test/com.layabox.conch6 on the Android phone and upload test.zip to this directory 4. Modify the expansion path in the code Modify the getExpansionMainPath function in RuntimeProxy.java and set the correct zip path. public String getExpansionMainPath() { return \"/storage/emulated/0/Android/test/com.layabox.conch6/test.zip\"; } public String getExpansionPatchPath() { return \"\"; } 5. Enable external storage permissions Machines with Android 6.0 or above may not be able to read external storage and need to actively request permission. Please add the following code or Google related solutions. public static boolean isGrantExternalRW(Activity activity) { if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M && activity.checkSelfPermission( Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) { activity.requestPermissions(new String[]{ Manifest.permission.READ_EXTERNAL_STORAGE, Manifest.permission.WRITE_EXTERNAL_STORAGE }, 1); return false; } return true; } TIPS: LayaNative supports up to two zip files, and the second zip modification·getExpansionPatchPath·this function 5. Run the test Run the APP and see the following log indicating that the resource file was successfully read from the main expansion package. 2. Google Play APK expansion file mechanism (https://developer.android.com/google/play/expansion-files.html) Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:14:59 "},"released/native/build_Cmd/readme.html":{"url":"released/native/build_Cmd/readme.html","title":"Command","keywords":"","body":"LayaNative command line tool1. Detailed explanation of commands1. Install layanative1. Check SDK version information2. Create native project3. Refresh the native project resource package4. Delete the native project resource package3. Application examplesLayaNative command line tool The layanative command line tool is used to generate Android and iOS native projects, as well as the project's resource refresh function to facilitate resource updates during the project iteration process. 1. Detailed explanation of commands 1. Install layanative windows $ npm install -g layanative3 mac $ sudo npm install -g layanative3 1. Check SDK version information SDK is the template for native projects. The listversion command will list all currently available SDK version information. When creating a native project below, you can specify the required version through parameters. $ layanative3 listversions 2. Create native project The createapp command is used to create native projects You can first use the following command to view the help information of the command createapp $ serviceative3 createapp --help Usage: layanative3 createapp [-f res_path] [--path output_path] [-s sdk_path | -v version] [-p all|ios|android_studio] [-t 0|1|2] [-u url] [-n project_name] [-a app_name] [--package_name package_name] Parameter Description: Keywords Description --folder,-f Resource path: Package the game resources into the client to reduce network downloads. Select the local game directory. For example, start index under d:/game/index.js, then the resource path is d:/game. It is not necessary to fill in when t is 0. --path native project output directory [default: \".\"] --version，-v SDK version: Automatically use a specific version of the SDK. The system will download the SDK from the server and store it in a specific location. --version and --sdk conflict with each other and cannot be specified at the same time. If neither is specified, the latest version of the SDK will be used by default. --platform, -p Project platform [optional values: all, ios, android_studio][default value: all] --type, -t Creation type [0: without resource pack 1: with resource pack 2: stand-alone version] [Default: 0] --url, -u Game address [When t is 0 or 1, it must be filled in, when t is 2, it does not need to be filled in] --name, -n Project name: the name of the native project [Default: LayaBox] --app_name, -a Application name: The name displayed after the app is installed on the phone [Default: LayaBox] --package_name Package name [Default: com.layabox.game] --sdk,-s SDK local directory: customized SDK directory, optional parameters. When used when the network is disconnected, it is generally recommended to use the parameter --version. When type is 1 or 2, the resource package will be added to the native project, and when type is 0, it will not be added. The bottom layer of packaged resources is actually the method of calling dcc. For packaged resource dcc, refer to LayaDcc Tool. You can use the --path parameter to specify the output path of the project, and the default output is to the current path. Use v2.0 version of the SDK according to -v $ layanative3 createapp -f SnowBallH5 -t 1 -n SnowBallNative -u http://10.10.20.102:8899/index.js -v v2.0 Neither -v nor -s is specified, use the latest version of the SDK $ layanative3 createapp -f SnowBallH5 -t 1 -n SnowBallNative -u http://10.10.20.102:8899/index.js Specifying the version with --version or -v requires an online environment. If the network is disconnected, you can use --sdk or -s to specify the SDK directory. SDK download address $ layanative3 createapp -f SnowBallH5 -t 1 -n SnowBallNative -u http://10.10.20.102:8899/index.js -s D:/v2.0 3. Refresh the native project resource package The refreshres command is used to refresh the resource package of the native project During the project iteration process, the h5 project has been modified. You can use the refreshres command to repackage the refresh resources and code into the native project. Usage: layanative3 refreshres [-p all|ios|android_studio] [--path path] [-u url] Parameter Description: Keywords Description --platform, -p Project platform [optional values: all, ios, android_studio][default value: all] --path native project path [default: \".\"] --url, -u Game address If the created project is a stand-alone version, you do not need to enter the URL when refreshingres. If you enter the online version URL and get the online version resource package, you need to change the project code to become an online version project. If the created project is an online version, the URL must be entered when refreshres. If you enter a new address, you must also change the code that sets the URL in the project to complete the URL replacement. If you enter the address of the stand-alone version and enter the resource package of the stand-alone version, you still need to change the project code to become a stand-alone version of the project. For manual switching between the stand-alone version and the network version, please refer to LayaBox Build Tool. When creatingapp, the resource path is written in the native.json file in the generated native project directory. If the resource is later moved to another location, an error will be reported that the resource directory cannot be found. When createapp, if the -t parameter is specified as 0, no resources are entered, and the resource path parameter does not need to be specified. The resource path written in native.json is empty. When refreshingres of this kind of project, an error that the resource path is empty will be reported. In the above two cases, you can manually modify the native.json file and specify the correct resource path. 4. Delete the native project resource package The removeres command is used to delete the resource package of the native project Usage: layanative3 removeres [--path path] Parameter Description: Keywords Description --path native project path [default: \".\"] 3. Application examples First create the directory structure shown in the figure below. jellyfish is the html5 project directory Check SDK version information 3.Create native project Generate the directory structure shown in the figure below. Refresh the resource package at any time In the dev directory, specify the directory of the native project through --path Enter the native project directory, there is no need to specify the --path parameter. If the resource package is not needed, delete it In the dev directory, specify the directory of the native project through --path Enter the native project directory, there is no need to specify the --path parameter. Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:15:28 "},"released/native/Other_settings/readme.html":{"url":"released/native/Other_settings/readme.html","title":"Other","keywords":"","body":"Other instructions1. About third-party maps2. About file format3. Debug mode and release mode4. About iOS docking with WeChat5. About iOS Simulator6. Obtain various information7. Block error pop-up boxes in projects8. Exception handling during engine initialization or startup script loading9. Get device modelOther instructions 1. About third-party maps The underlying rendering of LayaNative uses openGLES rendering, using the GLSurfaceView control of Android and the GLKView control of iOS, so it cannot support third-party maps, such as Baidu Maps. 2. About file format Text format files in the project (for example: ini, xml, html, json, js, etc.) must be in utf8 encoding format, because iOS devices do not support files encoded in non-utf8 format. 3. Debug mode and release mode LayaNative's underlying LOG is divided into three types: LOGI common process log LOGW warning log LOGE error log In js scripts, developers can set Debug mode through the following function: if( window.conch ) { //A value of 0 means turning off all log output //The value is 1: indicates that all LOGEs will pop up alerts. //The value is 2: indicates that all LOGE and LOGW will pop up alerts. window.conch.config.setDebugLevel(1); } Tips 1. Conch can only be called in the LayaNative environment. There is no definition of conch in the web version, so you need to check whether it exists. 4. About iOS docking with WeChat When connecting to the WeChat SDK on the iOS platform, the -Objc parameter needs to be added after WeChat version 1.77. WeChat's official documentation allows you to add -Objc -all_load by default, but this will cause compilation errors. If you encounter this situation, you can change the parameter to -Objc -force_load libWeChatSDK.a. After configuration, as shown in Figure 1: 5. About iOS Simulator LayaNative supports the iOS simulator, but due to the low efficiency of the simulator, it is recommended that developers use iOS real machine debugging. 6. Obtain various information function name Function description Return value description Remarks getTotalMem() Get the total memory of the running device Unit is KB getUsedMem() Get the memory occupied by the current application Unit is KB The return value is not very accurate, but it can be used as a reference getAvalidMem() Get available memory Unit is KB The return value is not very accurate, but it can be used as a reference getNetworkType() Get network status Return int value, NET_NO = 0;NET_WIFI = 1;NET_2G = 2;NET_3G = 3;NET_4G = 4;NET_UNKNOWN=5 getRuntimeVersion() Get the Runtime version The return value is a string, similar to ios-conch5-0.9.2, android-conch5-0.9 getOS() Get the current system Return value is similar to \"Conch-ios\" \"Conch-android\" string getAppVersion() Get the version number of iOS-App Return string 1.1 iOS-app version number, through this version number, you can make APP update prompts. getAppLocalVersion() Get the Local version number of iOS-App Return string 1.2 iOS-app version number, through this version number, you can make APP update prompts. These functions all belong to the conch.config class. Calling examples: if( window.conch ) { window.conch.config.getRuntimeVersion(); } Tips 1. Conch can only be called in the LayaNative environment. There is no definition of conch in the web version, so you need to check whether it exists. 7. Block error pop-up boxes in projects Sometimes some error prompts will pop up during the running of the project. These prompts are caused by incorrectly written code in the project. Our suggestion is to resolve the errors in these error pop-ups, and then block them if they cannot be resolved. The error popup code is as follows: window.showAlertOnJsException(false); 8. Exception handling during engine initialization or startup script loading In the LayaNative version, when the engine is initializing and loading the startup script, if an exception occurs (such as network instability), the engine will automatically call the window.onLayaInitError(error) function. This function is defined in config.js by default. The code is as follows : window.onLayaInitError=function(e) { console.log(\"onLayaInitError error=\" + e); alert(\"Loading the game failed, maybe because your network is unstable, please exit and re-enter\"); } Developers can modify error reporting information and error reporting methods according to their own needs. 9. Get device model In LayaNative, iOS can obtain the device model by calling conch.config.getDeviceInfo(). It can be used for head curtain adaptation of iPhone X. The code is as follows: if( window.conch ) { var devInfo = JSON.parse(window.conch.config.getDeviceInfo()); if (devInfo.devicename === 'iPhone10,3' || devInfo.devicename === 'iPhone10,6') { // iPhone X Adaptation } } Copyright ©Layabox 2022 all right reserved，powered by LayaAir EngineUpdate： 2024-02-26 11:41:16 "}}